{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshumanAryan24/AlphaPro-SemEval2025-Task8/blob/main/notebooks/AlphaProQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17e684ec",
      "metadata": {
        "id": "17e684ec"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a429a0",
      "metadata": {
        "id": "37a429a0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import pickle\n",
        "import datasets\n",
        "import json\n",
        "from together import Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b427008",
      "metadata": {
        "id": "1b427008"
      },
      "outputs": [],
      "source": [
        "api_key = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee96ce94",
      "metadata": {
        "id": "ee96ce94"
      },
      "outputs": [],
      "source": [
        "client = Together(\n",
        "  api_key=api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca0920a",
      "metadata": {
        "id": "9ca0920a"
      },
      "source": [
        "# Load Databases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c5ab9c",
      "metadata": {
        "id": "72c5ab9c"
      },
      "outputs": [],
      "source": [
        "with open('datasetDict.pkl', 'rb') as file:\n",
        "    datasetDict = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbd4047",
      "metadata": {
        "id": "3fbd4047"
      },
      "outputs": [],
      "source": [
        "qaDataset = datasets.load_from_disk('./qaDataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299d1239",
      "metadata": {
        "id": "299d1239"
      },
      "outputs": [],
      "source": [
        "ques = qaDataset['question']\n",
        "datasets = qaDataset['dataset']\n",
        "expAns = qaDataset['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a6c31b",
      "metadata": {
        "id": "c5a6c31b"
      },
      "source": [
        "# Prompt Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779df9de",
      "metadata": {
        "id": "779df9de"
      },
      "outputs": [],
      "source": [
        "rewrite_prompt = \"\"\"You will be provided with two pieces of information. The first being a question and the second being the column names along with data types of a dataset. Your objective is twofold, the first to predict the datatype of the answer and second to paraphrase the question aptly such that the next person could generate the python code to required to answer the question while keeping the answer type the same as the given question. You are provided a two examples below.\n",
        "Remember to not change what the original question is actually asking.\n",
        "\n",
        "Important Notes:\n",
        "Do not use markdown. Ever.\n",
        "Do not leave additional line spacing\n",
        "Just follow the template. Do not give anything else.\n",
        "\n",
        "Few Shot Examples:\n",
        "Question: Is the person with the highest net worth self-made?\n",
        "Dataset Name: 001_Forbes\n",
        "Dataset Table Schema: selfMade (bool), finalWorth (int64), city (string), title (string), gender (string), age (float64), rank (int64), philanthropyScore (float64), category (string), source (string), country (string)\n",
        "Answer Type: bool\n",
        "Paraphrased Question: Does the billionaire with the maximum final worth have self made attribute set to True?\n",
        "\n",
        "Question: Did any children below the age of 18 survive?\n",
        "Dataset Name: 002_Titanic\n",
        "Dataset Table Schema: Age (float64), Siblings_Spouses Aboard (int64), Sex (string), Name (string), Pclass (int64), Fare (float64), Survived (bool)\n",
        "Answer Type: bool\n",
        "Paraphrased Question: Were there any survivors aged under 18?\n",
        "\n",
        "The answers types are only of type: [bool, float64, int64, string, list of (type)]\n",
        "\n",
        "Instruction for you to perform:\n",
        "\"\"\"\n",
        "\n",
        "codegen_prompt = '''You will be provided four pieces of information all of which are provided in the means of strings.\n",
        "1. Dataset name:\n",
        "2. Dataset Table Schema:\n",
        "3. Question:\n",
        "4. Expected Answer Type:\n",
        "\n",
        "Your objective is to create a python code to answer the question given the dataset schema. Here is the function you will be needing to complete:\n",
        "def answer_question(db, datasetTableSchema, question, expectedAnswerType):\n",
        "\tanswer = (Here you generate the code which is needed to find the answer)\n",
        "\treturn answer\n",
        "\n",
        "Assume that the pandas library has been imported as pd.\n",
        "Your answer should only contain the function definition. Assume that the dataset schema (containing column names and their datatypes in paranthesis) given is correct. The generated code should be correct. Do not attempt to change the dataset.\n",
        "Your final answer data type should be one of the following categories:\n",
        "1. Boolean: One of True or False.\n",
        "2. Category: A string. For example - CEO, hello, drugstores.\n",
        "3. Number: A numerical value. For example - 20, 23.3223, 414901.0.\n",
        "4. list[category]: A list of strings. For example - ['India', 'Japan', 'China'], ['Ram', 'Shyam', 'Mohan']. Here, each entry should be enclosed within single quotes.\n",
        "5. list[number]: A list of numbers. For example - [20.0, 30.4, 42.1], [171000, 129000, 111000, 107000, 106000, 91400].\n",
        "When the question requests more than value, the expected answer type might be a list of strings or numbers. Ensure that lists are enclosed within square brackets.\n",
        "\n",
        "Note:\n",
        "Do not use markdown\n",
        "Only complete the answer_question function. Assume all other codes outside of it is taken care of.\n",
        "Generate the below code only for python\n",
        "\n",
        "Few Shot Examples:\n",
        "Example 1:\n",
        "1. Dataset name: 001_Forbes\n",
        "2. Dataset Table Schema: selfMade (bool), finalWorth (int64), city (string), title (string), gender (string), age (float64), rank (int64), philanthropyScore (float64), category (string), source (string), country (string)\n",
        "3. Question: Does the individual with the highest final worth value have the selfMade attribute set to True?\n",
        "4. Expected Answer Type: bool\n",
        "\n",
        "Answer:\n",
        "def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):\n",
        "\tmax_worth_individual = dataset.loc[dataset[\"finalWorth\"] == dataset[\"finalWorth\"].max()]\n",
        "\tis_self_made = max_worth_individual[\"selfMade\"].bool()\n",
        "\n",
        "\treturn is_self_made\n",
        "\n",
        "Now, complete the following:'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6df5bf1",
      "metadata": {
        "id": "b6df5bf1"
      },
      "source": [
        "# Auxiliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e887a5b8",
      "metadata": {
        "id": "e887a5b8"
      },
      "outputs": [],
      "source": [
        "def extractFunctionFromString(function_str:str):\n",
        "    '''\n",
        "    Take a string containing a function named 'answer_question' and return the function in scope.\n",
        "    The function will have access to local and global variables.\n",
        "    '''\n",
        "    namespace = {**globals(), **locals()}\n",
        "    exec(function_str, namespace)\n",
        "    return namespace['answer_question']  # 'answer_question' is the default name in the code string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d24c11a0",
      "metadata": {
        "id": "d24c11a0"
      },
      "outputs": [],
      "source": [
        "def getDatasetSchema(df:pd.DataFrame) -> list[str]:\n",
        "  '''\n",
        "  Get the dataset schema from the pandas.DataFrame object.\n",
        "  List entry is - column name (column data type)\n",
        "  '''\n",
        "  schema = df.dtypes\n",
        "  schema_string = \"\"\n",
        "  for col, dtype in schema.items():\n",
        "      if dtype == \"bool\":\n",
        "          dtype_name = \"bool\"\n",
        "      elif dtype == \"int64\":\n",
        "          dtype_name = \"int64\"\n",
        "      elif dtype == \"double\":\n",
        "          dtype_name = \"float64\"\n",
        "      elif dtype == \"object\":\n",
        "          dtype_name = \"string\"\n",
        "      else:\n",
        "          dtype_name = dtype.name\n",
        "\n",
        "      schema_string += f\"{col} ({dtype_name}), \"\n",
        "  # Remove the trailing comma and space\n",
        "  schema_string = schema_string.rstrip(\", \")\n",
        "  return schema_string.split(\", \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Transformation Function"
      ],
      "metadata": {
        "id": "xnxnorKXecXs"
      },
      "id": "xnxnorKXecXs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b071c70",
      "metadata": {
        "id": "4b071c70"
      },
      "outputs": [],
      "source": [
        "def processQuestion(model_name, temperature, question: str, dataset_name: str, schema: str, api_key: str) -> tuple:\n",
        "    '''\n",
        "    Process the question and return predicted answer type and paraphrased question, in that order.\n",
        "    Parameter 'schema' is a comma-separated list of strings - column name (column data type).\n",
        "    '''\n",
        "    # Prepare prompt\n",
        "    prompt = rewrite_prompt + f'''\n",
        "    Question: {question}\n",
        "    Dataset: {dataset_name}\n",
        "    Dataset Table Schema: {schema}\n",
        "    '''\n",
        "\n",
        "    for attempt in range(3):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        content = response.choices[0].message.content\n",
        "        output = content.split('\\n')\n",
        "        if output[0].startswith('A'):\n",
        "            answer_type = output[0][13:].strip()\n",
        "            paraphrased_question = output[1][22:].strip()\n",
        "        else:\n",
        "            answer_type = output[1].strip()\n",
        "            paraphrased_question = ''\n",
        "        return answer_type, paraphrased_question\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e115d6a7",
      "metadata": {
        "id": "e115d6a7"
      },
      "source": [
        "# Generate Code Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa3292f",
      "metadata": {
        "id": "3aa3292f"
      },
      "outputs": [],
      "source": [
        "def generateCode(model_name, temperature, question: str, metaData: dict, api_key: str) -> str:\n",
        "    '''\n",
        "    Generate code string for answering the paraphrased question.\n",
        "    Parameter 'metaData' dictionary:\n",
        "      'dataset_name': str,\n",
        "      'columns': list[str],\n",
        "      'answer_type': str\n",
        "    '''\n",
        "    prompt = codegen_prompt + f'''\n",
        "    1. Dataset name: {metaData['dataset_name']}\n",
        "    2. Dataset Table Schema: {', '.join(metaData['columns'])}\n",
        "    3. Question: {question}\n",
        "    4. Expected Answer Type: {metaData['answer_type']}\n",
        "    '''\n",
        "\n",
        "\n",
        "    for attempt in range(3):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        text = response.choices[0].message.content.strip(\"```\").lstrip(\"python\\n\")\n",
        "        return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f926af",
      "metadata": {
        "id": "a4f926af"
      },
      "source": [
        "# Generate Answer Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04455f0a",
      "metadata": {
        "id": "04455f0a"
      },
      "outputs": [],
      "source": [
        "def getAnswer(model_name, temperature, question:str, datasetMetaData:dict) -> str:\n",
        "  '''\n",
        "  Get final answer along with state information given a question in natural language and a dataset.\n",
        "  Parameter 'datasetMetaData' dictionary:\n",
        "    'dataset': pandas.DataFrame,\n",
        "    'dataset_name': str\n",
        "\n",
        "  Output dictionary:\n",
        "    'original_question' : str,\n",
        "    'rewritten_question' : str,\n",
        "    'code' : str,  (code string)\n",
        "    'answer_type' : str,  (predicted answer type in a string)\n",
        "    'output' : Any  (actual answer - data type of this object depends on the code generated and the question, but the data type of the entity this represents is indicated in 'answer_type' entry)\n",
        "  '''\n",
        "  newQuestion = ''\n",
        "  codeString = ''\n",
        "  answerType = None\n",
        "  output = '-'\n",
        "\n",
        "  # try:\n",
        "  columns = getDatasetSchema(datasetMetaData['dataset'])\n",
        "  datasetMetaData['columns'] = columns\n",
        "\n",
        "  answerType, newQuestion = processQuestion(model_name, temperature, question, datasetMetaData['dataset_name'], str(columns)[1:-1], api_key=api_key)\n",
        "  datasetMetaData['answer_type'] = answerType\n",
        "\n",
        "  codeString = generateCode(model_name, temperature, newQuestion, datasetMetaData, api_key=api_key)\n",
        "  function = extractFunctionFromString(codeString)\n",
        "\n",
        "  output = function(datasetMetaData['dataset'], columns, newQuestion, datasetMetaData['answer_type'])\n",
        "  del function\n",
        "\n",
        "  # except Exception as e:\n",
        "  #   print('Exception ')\n",
        "  #   print(f\"Error: {e}\\nQuestion: {question}\")\n",
        "  #   output = '-'\n",
        "\n",
        "  return {\n",
        "      'original_question' : question,\n",
        "      'rewritten_question' : newQuestion,\n",
        "      'code' : codeString,\n",
        "      'answer_type' : answerType,\n",
        "      'output' : output\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabb1265",
      "metadata": {
        "id": "cabb1265"
      },
      "source": [
        "# Generate Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fe51c87",
      "metadata": {
        "id": "1fe51c87"
      },
      "outputs": [],
      "source": [
        "# Initialize results dictionary with correct keys\n",
        "results = {\n",
        "    'Question': [],\n",
        "    'Rewritten Question': [],\n",
        "    'Code': [],\n",
        "    'Answer Type': [],  # Matched to response key\n",
        "    'Generated Answer': [],\n",
        "    'Expected Answer': []\n",
        "}\n",
        "\n",
        "MODEL_NAME = \"deepseek-ai/DeepSeek-V3\"\n",
        "TEMPERATURE = 0.5\n",
        "\n",
        "start = 305\n",
        "end = 600\n",
        "\n",
        "for i in range(start, end):\n",
        "    try:\n",
        "        res = getAnswer(\n",
        "            question=ques[i],\n",
        "            datasetMetaData={\n",
        "                'dataset': datasetDict[datasets[i]],\n",
        "                'dataset_name': datasets[i]\n",
        "            },\n",
        "            model_name=MODEL_NAME,\n",
        "            temperature=TEMPERATURE\n",
        "        )\n",
        "\n",
        "        # Append results with correct keys\n",
        "        results['Question'].append(ques[i])\n",
        "        results['Rewritten Question'].append(res.get('rewritten_question', ''))\n",
        "        results['Code'].append(res.get('code', ''))\n",
        "        results['Answer Type'].append(res.get('answer_type', ''))\n",
        "        results['Generated Answer'].append(res.get('output', '-'))\n",
        "        results['Expected Answer'].append(expAns[i])\n",
        "\n",
        "        print(f'Finished row {i}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing question {i}: {str(e)}\")\n",
        "        # Append empty values on error\n",
        "        results['Question'].append(ques[i])\n",
        "        results['Rewritten Question'].append('')\n",
        "        results['Code'].append('')\n",
        "        results['Answer Type'].append('')\n",
        "        results['Generated Answer'].append('ERROR')\n",
        "        results['Expected Answer'].append(expAns[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62dacb43",
      "metadata": {
        "id": "62dacb43"
      },
      "source": [
        "# Results Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1204d29c",
      "metadata": {
        "id": "1204d29c"
      },
      "outputs": [],
      "source": [
        "resultTable = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57db70ad",
      "metadata": {
        "id": "57db70ad"
      },
      "outputs": [],
      "source": [
        "resultTable.to_csv(f'DeepSeek-V3-{start}-{end - 1}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf43f02",
      "metadata": {
        "id": "4cf43f02"
      },
      "outputs": [],
      "source": [
        "sample_index = 99\n",
        "print(qaDataset[sample_index])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}