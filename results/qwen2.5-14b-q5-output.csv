Question,Rewritten Question,Code,Answer Type,Generated Answer,Expected Answer,,,,
Is the person with the highest net worth self-made?,Does the individual with the highest final worth have the selfMade attribute set to True?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_worth_individual = dataset.loc[dataset[""finalWorth""] == dataset[""finalWorth""].max()]
is_self_made = max_worth_individual[""selfMade""].bool()

return is_self_made
",bool,True,True,,,,
Does the youngest billionaire identify as male?,Is the gender of the youngest billionaire male?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    youngest_billionaire = dataset.loc[dataset['age'] == dataset['age'].min()]
    is_male = youngest_billionaire['gender'].iloc[0] == 'male'

    return is_male
",bool,False,True,,,,
Is the city with the most billionaires in the United States?,Which city in the United States has the highest number of billionaires?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    us_billionaires = dataset[dataset['country'] == 'United States']
    city_counts = us_billionaires['city'].value_counts()
    highest_count_city = city_counts.idxmax()

    return highest_count_city
",string,New York,True,,,,
Is there a non-self-made billionaire in the top 5 ranks?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the individual with the highest final worth value
    max_worth_individual = dataset.loc[dataset[""finalWorth""] == dataset[""finalWorth""].max()]
    
    # Check if the selfMade attribute is set to True for this individual
    is_self_made = max_worth_individual[""selfMade""].bool()
    
    return is_self_made",bool,True,True,,,,
Does the oldest billionaire have a philanthropy score of 5?,Does the billionaire with the highest age have a philanthropy score of 5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_age_individual = dataset.loc[dataset[""age""] == dataset[""age""].max()]
    has_philanthropy_score_5 = max_age_individual[""philanthropyScore""] == 5

    return has_philanthropy_score_5.bool()
",bool,False,False,,,,
What is the age of the youngest billionaire?,What is the age of the billionaire with the lowest rank?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    lowest_rank_individual = dataset.loc[dataset[""rank""] == dataset[""rank""].min()]
    age_of_lowest_rank_billionaire = lowest_rank_individual[""age""].values[0]

    return age_of_lowest_rank_billionaire
",float64  ,50.0,19.0,,,,
How many billionaires are there from the 'Technology' category?,What is the count of billionaires belonging to the 'Technology' category?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count = dataset[dataset['category'] == 'Technology'].shape[0]
return count",int64,343,343,,,,
What's the total worth of billionaires in the 'Automotive' category?,What is the combined final worth of all billionaires in the Automotive category?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
combined_worth = dataset.loc[dataset['category'] == 'Automotive', 'finalWorth'].sum()

return combined_worth",int64,583600,583600,,,,
How many billionaires have a philanthropy score above 3?,What is the count of billionaires with a philanthropy score greater than 3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count = dataset[dataset[""philanthropyScore""] > 3].shape[0]
    return count
",int64  ,25,25,,,,
What's the rank of the wealthiest non-self-made billionaire?,What is the rank of the wealthiest billionaire who is not self-made?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
wealthiest_non_self_made = dataset.loc[~dataset[""selfMade""]].sort_values(by=""finalWorth"", ascending=False).head(1)
rank = wealthiest_non_self_made[""rank""].iloc[0]

return rank",uint16  ,3,3,,,,
Which category does the richest billionaire belong to?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific attribute value of an individual or some categorical data
    # For example, if the question is ""What is the category of the person with the highest final worth?""
    max_worth_individual = dataset.loc[dataset[""finalWorth""] == dataset[""finalWorth""].max()]
    category_of_max_worth_person = max_worth_individual[""category""].iloc[0]

    return category_of_max_worth_person",category,Automotive,Automotive,,,,
What's the country of origin of the oldest billionaire?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_worth_individual = dataset.loc[dataset[""finalWorth""] == dataset[""finalWorth""].max()]
top_category = max_worth_individual[""category""].iloc[0]

return top_category",category,Automotive,United States,,,,
What's the gender of the billionaire with the highest philanthropy score?,What is the gender of the billionaire with the highest philanthropy score?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    billionaire_with_highest_philanthropy = dataset.loc[dataset[""philanthropyScore""] == dataset[""philanthropyScore""].max()]
    gender = billionaire_with_highest_philanthropy[""gender""].iloc[0]

    return gender
",category,M,M,,,,
What's the source of wealth for the youngest billionaire?,What is the source of wealth for the billionaire with the lowest age?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    youngest_billionaire = dataset.loc[dataset[""age""] == dataset[""age""].min()]
    source_of_wealth = youngest_billionaire[""source""].iloc[0]

    return source_of_wealth
",string,drugstores,drugstores,,,,
What is the title of the billionaire with the lowest rank?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value from a column
    # For example, if the question is ""What is the name of the individual with the highest final worth?"",
    # we can find the answer as follows:

    max_worth_individual = dataset.loc[dataset[""finalWorth""] == dataset[""finalWorth""].max()]
    person_name = max_worth_individual[""personName""].iloc[0]

    return person_name",category,Elon Musk,,,,,
List the top 3 countries with the most billionaires.,Which are the top 3 countries with the highest number of billionaires?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    country_counts = dataset['country'].value_counts().head(3).index.tolist()
    return country_counts
",list of (str),"['United States', 'China', 'India']","['United States', 'China', 'India']",,,,
List the top 2 most common sources of wealth for billionaires.,What are the top 2 most frequent sources of wealth for billionaires?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_sources = dataset['source'].value_counts().head(2).index.tolist()
    return top_sources",list of (string),"['real estate', 'investments']","['real estate', 'investments']",,,,
List the 4 cities where the four youngest billionaires live.,Retrieve the names of the four cities where the four youngest billionaires reside.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by age in ascending order to get the youngest individuals first
    sorted_dataset = dataset.sort_values(by=""age"", ascending=True)
    
    # Select the names of the four cities where the four youngest billionaires reside
    youngest_four_cities = sorted_dataset.head(4)[""city""].tolist()
    
    return youngest_four_cities
",list of (string),"[nan, 'Oslo', 'Jiaozuo', 'Los Angeles']","['', 'Los Angeles', 'Jiaozuo', 'Oslo']",,,,
List the 4 categories with the fewest billionaires.,Provide the four categories with the smallest number of billionaires.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    category_counts = dataset['category'].value_counts()
    smallest_categories = category_counts.nsmallest(4).index.tolist()
    
    return smallest_categories",list of (category),"['Gambling & Casinos', 'Sports', 'Logistics', 'Telecom']","['Telecom', 'Logistics', 'Sports', 'Gambling & Casinos']",,,,
List the 2 countries with the least number of billionaires. If there are more than two with the same number take the first two alphabetically.,"Which are the two countries with the fewest billionaires? In case of a tie, select the first two alphabetically.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    country_counts = dataset['country'].value_counts(ascending=True)
    fewest_billionaires_countries = country_counts.index[:2].tolist()
    
    return fewest_billionaires_countries
",list of (string),"['Andorra', 'Cambodia']","['Algeria', 'Andorra']",,,,
List the top 5 ranks of billionaires who are not self-made.,Retrieve the top 5 ranks of billionaires who have not made their wealth themselves.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter billionaires who are not self-made
    non_self_made_billionaires = dataset[~dataset[""selfMade""]]
    
    # Sort them by final worth in descending order and get the top 5 ranks
    top_5_ranks = non_self_made_billionaires.nlargest(5, ""finalWorth"")[""rank""].tolist()
    
    return top_5_ranks
",list of (int64),"[3, 10, 14, 16, 18]","[3, 10, 14, 16, 18]",,,,
List the youngest 3 ages of billionaires who have a philanthropy score of 5.,Retrieve the ages of the three youngest billionaires who have a philanthropy score of 5.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals with a philanthropy score of 5
    filtered_dataset = dataset[dataset['philanthropyScore'] == 5]
    
    # Sort the filtered dataset by age in ascending order
    sorted_dataset = filtered_dataset.sort_values(by='age')
    
    # Retrieve the ages of the three youngest billionaires
    youngest_ages = sorted_dataset.head(3)['age'].tolist()
    
    return youngest_ages
",list of (float64),"[48.0, 83.0, 83.0]","[48.0, 83.0, 83.0]",,,,
List the highest 6 final worth values of billionaires in the 'Technology' category.,Retrieve the top 6 highest final worth values for billionaires in the Technology category.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_6_technology_worths = dataset[dataset['category'] == 'Technology'].sort_values(by='finalWorth', ascending=False)['finalWorth'].head(6).tolist()
return top_6_technology_worths",list of (int64),"[171000, 129000, 111000, 107000, 106000, 91400]","[171000, 129000, 111000, 107000, 106000, 91400]",,,,
List the top 4 ranks of female billionaires.,What are the ranks of the top 4 female billionaires?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_female_billionaires = dataset.loc[dataset[""gender""] == ""female""].sort_values(by=""finalWorth"", ascending=False).head(4)
ranks = top_female_billionaires[""rank""].tolist()

return ranks
",list of (uint16),[],"[14, 18, 21, 30]",,,,
List the top 2 final worth values of billionaires in the 'Automotive' category.,Retrieve the top 2 highest final worth values from billionaires in the Automotive category.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_dataset = dataset[dataset['category'] == 'Automotive']
    top_2_worths = filtered_dataset.sort_values(by='finalWorth', ascending=False)['finalWorth'].head(2).tolist()
    
    return top_2_worths
",list of (int64),"[219000, 44800]","[219000, 44800]",,,,
Did any children below the age of 18 survive?,Were there any children under the age of 18 who survived?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
children_survived = dataset.loc[(dataset[""Age""] < 18) & (dataset[""Survived""] == True)]
has_children_survived = not children_survived.empty

return has_children_survived",bool,True,True,,,,
Were there any passengers who paid a fare of more than $500?,Were there any passengers on the Titanic who paid a fare greater than $500?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_high_fare = (dataset[""Fare""] > 500).any()
return has_high_fare",bool,True,True,,,,
Is every passenger's name unique?,Are all passenger names in the Titanic dataset unique?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
unique_names = dataset['Name'].nunique() == len(dataset)
return unique_names",bool,True,True,,,,
Were there any female passengers in the 3rd class who survived?,Were there any female passengers in the third class who survived?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
female_third_class_survivors = dataset[(dataset[""Sex""] == ""female"") & (dataset[""Pclass""] == 3) & (dataset[""Survived""] == True)]
has_female_third_class_survivor = not female_third_class_survivors.empty

return has_female_third_class_survivor",bool,True,True,,,,
How many unique passenger classes are present in the dataset?,What is the count of distinct passenger classes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_classes_count = dataset['Pclass'].nunique()
    
    return distinct_classes_count",int64,3,3,,,,
What's the maximum age of the passengers?,What is the highest age recorded among the passengers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_age = dataset[""Age""].max()
return max_age
",float64  ,80.0,80.0,,,,
How many passengers boarded without any siblings or spouses?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for the count of survivors in the Titanic dataset
    survived_count = dataset['Survived'].sum()
    
    return survived_count
",int64,342,604,,,,
"On average, how much fare did the passengers pay?",What is the average fare paid by the passengers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_fare = dataset[""Fare""].mean()
return average_fare",float64,32.30542000000000,32.31,,,,
Which passenger class has the highest number of survivors?,In which passenger class do the most survivors belong?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only survivors
    survivors = dataset[dataset['Survived'] == True]
    
    # Group by passenger class and count the number of survivors in each class
    survivor_counts = survivors.groupby('Pclass').size().reset_index(name='count')
    
    # Find the passenger class with the maximum number of survivors
    max_survivors_class = survivor_counts.loc[survivor_counts['count'].idxmax(), 'Pclass']
    
    return max_survivors_class",uint8,1,1,,,,
What's the most common gender among the survivors?,What is the most frequent gender among those who survived?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
survived_passengers = dataset[dataset['Survived'] == True]
most_frequent_gender = survived_passengers['Sex'].mode()[0]

return most_frequent_gender",string,female,female,,,,
"Among those who survived, which fare range was the most common: (0-50, 50-100, 100-150, 150+)?","For the passengers who survived, which fare range was most frequent: (0-50, 50-100, 100-150, 150+)?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for passengers who survived
    survivors = dataset[dataset['Survived'] == True]
    
    # Define fare ranges
    def get_fare_range(fare):
        if 0 <= fare < 50:
            return '0-50'
        elif 50 <= fare < 100:
            return '50-100'
        elif 100 <= fare < 150:
            return '100-150'
        else:
            return '150+'
    
    # Apply the function to each fare and create a new column
    survivors['FareRange'] = survivors['Fare'].apply(get_fare_range)
    
    # Count the frequency of each fare range
    fare_range_counts = survivors['FareRange'].value_counts()
    
    # Get the most frequent fare range
    most_frequent_fare_range = fare_range_counts.idxmax()
    
    return most_frequent_fare_range
",string,0.0-50,0.0-50,,,,
"What's the most common age range among passengers: (0-18, 18-30, 30-50, 50+)?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fare_passenger = dataset.loc[dataset[""Fare""] == dataset[""Fare""].max()]
    name_of_passenger = max_fare_passenger[""Name""].iloc[0]

    return name_of_passenger",string,Miss. Anna Ward,18.0-30,,,,
Name the top 3 passenger classes by survival rate.,Identify the top 3 passenger classes with the highest survival rates.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Calculate survival rate for each passenger class
    survival_rates = dataset.groupby('Pclass')['Survived'].mean().sort_values(ascending=False)
    
    # Get the top 3 passenger classes with the highest survival rates
    top_3_classes = survival_rates.head(3).index.tolist()
    
    return top_3_classes
",list of (int64),"[1, 2, 3]","[1, 2, 3]",,,,
"Could you list the 3 fare ranges present in the dataset with the least survivors: (0-50, 50-100, 100-150, 150+)?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    male_passengers = dataset[dataset['Sex'] == 'male']
    names_of_male_passengers = male_passengers['Name'].tolist()

    return names_of_male_passengers",list of (string),"['Mr. Owen Harris Braund', 'Mr. William Henry Allen', 'Mr. James Moran', 'Mr. Timothy J McCarthy', 'Master. Gosta Leonard Palsson', 'Mr. William Henry Saundercock', 'Mr. Anders Johan Andersson', 'Master. Eugene Rice', 'Mr. Charles Eugene Williams', 'Mr. Joseph J Fynney', 'Mr. Lawrence Beesley', 'Mr. William Thompson Sloper', 'Mr. Farred Chehab Emir', 'Mr. Charles Alexander Fortune', 'Mr. Lalio Todoroff', 'Don. Manuel E Uruchurtu', 'Mr. Edward H Wheadon', 'Mr. Edgar Joseph Meyer', 'Mr. Alexander Oskar Holverson', 'Mr. Hanna Mamee', 'Mr. Ernest Charles Cann', 'Mr. William John Rogers', 'Mr. Denis Lennon', 'Mr. Youssef Samaan', 'Master. Juha Niilo Panula', 'Mr. Richard Cater Nosworthy', 'Mr. Engelhart Cornelius Ostby', 'Mr. Hugh Woolner', 'Mr. Mansouer Novel', 'Master. William Frederick Goodwin', 'Mr. Orsen Sirayanian', 'Mr. Henry Birkhardt Harris', 'Master. Harald Skoog', 'Mr. Albert A Stewart', 'Master. Gerios Moubarek', 'Mr. Ernest James Crease', 'Mr. Vincenz Kink', 'Mr. Stephen Curnow Jenkin', 'Mr. Ambrose Jr Hood', 'Mr. Apostolos Chronopoulos', 'Mr. Lee Bing', 'Mr. Sigurd Hansen Moen', 'Mr. Ivan Staneff', 'Mr. Rahamin Haim Moutal', 'Master. Alden Gates Caldwell', 'Mr. Achille Waelens', 'Mr. Jan Baptist Sheerlinck', 'Mr. Francisco M Carrau', 'Mr. William Neal Ford', 'Mr. Selman Francis Slocovski', 'Mr. Francesco Celotti', 'Mr. Emil Christmann', 'Mr. Paul Edvin Andreasson', 'Mr. Herbert Fuller Chaffee', 'Mr. Bertram Frank Dean', 'Mr. Daniel Coxon', 'Mr. Charles Joseph Shorney', 'Mr. George B Goldschmidt', 'Mr. William Bertram Greenfield', 'Mr. Sinai Kantor', 'Mr. Pastcho Petroff', 'Mr. Richard Frasar White', 'Mr. Gustaf Joel Johansson', 'Mr. Anders Vilhelm Gustafsson', 'Mr. Stoytcho Mionoff', 'Mr. Albert Johan Moss', 'Mr. Tido Rekic', 'Mr. Walter Chamberlain Porter', 'Mr. David John Barton', 'Mr. Edvard Pekoniemi', 'Mr. Patrick Connors', 'Mr. William John Robert Turpin', 'Mr. Quigg Edmond Baxter', 'Mr. Stanley George Hickman', 'Mr. Leonard Charles Moore', 'Mr. Nicholas Nasser', 'Mr. Percival Wayland White', 'Master. Elias Nicola-Yarred', 'Mr. Martin McMahon', 'Mr. Fridtjof Arne Madsen', 'Mr. Johan Ekstrom', 'Mr. Jozef Drazenoic', 'Mr. Domingos Fernandeo Coelho', 'Mr. Samuel James Hayden Sobey', 'Mr. Emile Richard', 'Mr. Jacques Heath Futrelle', 'Mr. Olaf Elon Osen', 'Mr. Victor Giglio', 'Mr. Jeremiah Burke', 'Mr. Edgardo Samuel Andrew', 'Mr. Joseph Charles Nicholls', 'Mr. August Edvard Andersson', 'Mr. Michel Navratil', 'Rev. Thomas Roussel Davids Byles', 'Rev. Robert James Bateman', 'Mr. Alfonzo Meo', 'Mr. Austin Blyler van Billiard', 'Mr. Ole Martin Olsen', 'Mr. Charles Duane Williams', 'Mr. Harry Corn', 'Mr. Mile Smiljanic', 'Master. Thomas Henry Sage', 'Mr. John Hatfield Cribb', 'Mr. John Viktor Bengtsson', 'Mr. Jovo Calic', 'Master. Eino Viljami Panula', 'Master. Frank John William Goldsmith', 'Mr. John D Baumann', 'Mr. Lee Ling', 'Mr. Wyckoff Van der hoef', 'Master. Arthur Rice', 'Mr. Antti Wilhelm Sivola', 'Mr. James Clinch Smith', 'Mr. Klas Albin Klasen', 'Master. Henry Forbes Lefebre', 'Mr. Reginald Hale', 'Mr. Lionel Leonard', 'Mr. Rene Pernot', 'Master. Clarence Gustaf Hugo Asplund', 'Master. Richard F Becker', 'Mr. Hugh Roscoe Rood', 'Mr. Charles Hallace Romaine', 'Mr. John Bourke', 'Mr. Stjepan Turcin', 'Mr. William Carbines', 'Master. Michel M Navratil', 'Mr. Robert Mernagh', 'Mr. Karl Siegwart Andreas Olsen', 'Mr. Nestor Cyriel Vande Walle', 'Mr. Frederick Sage', 'Mr. Jakob Alfred Johanson', 'Mr. Gerious Youseff', 'Mr. Gurshon Cohen', 'Mr. Karl Alfred Backstrom', 'Mr. Nassef Cassem Albimona', 'Mr. Henry Blank', 'Mr. Ahmed Ali', 'Mr. John Henry Perkin', 'Mr. Hans Kristensen Givard', 'Mr. Philip Kiernan', 'Mr. Sidney Samuel Jacobsohn', 'Mr. Walter Harris', 'Mr. Victor Francis Sunderland', 'Mr. James H Bracken', 'Mr. George Henry Green', 'Mr. Christo Nenkoff', 'Mr. Frederick Maxfield Hoyt', 'Mr. Karl Ivar Sven Berglund', 'Mr. William John Mellors', 'Mr. John Hall Lovell', 'Mr. Arne Jonas Fahlstrom', 'Mr. Bengt Edvin Larsson', 'Mr. Ernst Adolf Sjostedt', 'Mr. Robert William Norman Leyson', 'Mr. Stephen Hold', 'Mr. Frederick William Pengelly', 'Mr. George Henry Hunt', 'Mr. Reginald Charles Coleridge', 'Mr. Matti Alexanteri Maenpaa', 'Mr. Sleiman Attalah', 'Dr. William Edward Minahan', 'Mr. Richard Leonard Beckwith', 'Rev. Ernest Courtenay Carter', 'Mr. James George Reed', 'Mr. William Thomas Stead', 'Mr. William Arthur Lobb', 'Master. Edvin Rojj Felix Asplund', 'Mr. Emil Taussig', 'Mr. William Harrison', 'Mr. David Reeves', 'Mr. Ernesti Arvid Panula', 'Mr. Ernst Ulrik Persson', 'Mr. Alexander Cairns', 'Mr. William Henry Tornquist', 'Mr. Charles H Natsch', 'Mr. Francis Parkes', 'Master. Eric Rice', 'Mr. Frank Duane', 'Mr. Nils Johan Goransson Olsson', 'Mr. Alfons de Pelsmaeker', 'Mr. Edward Arthur Dorking', 'Mr. Richard William Smith', 'Mr. Ivan Stankovic', 'Mr. Theodore de Mulder', 'Mr. Penko Naidenoff', 'Mr. Masabumi Hosono', 'Mr. Rene Jacques Levy', 'Mr. Ivan Mineff', 'Mr. Ervin G Lewy', 'Mr. Mansour Hanna', 'Mr. Adolphe Saalfeld', 'Mr. Bernard McCoy', 'Mr. William Cahoone Jr Johnson', 'Mr. Howard Hugh Williams', 'Master. Hudson Trevor Allison', 'Mr. Samuel Abelson', 'Mr. Ignjac Hendekovic', 'Mr. Benjamin Hart', 'Dr. Ernest Moraweck', 'Mr. Samuel Dennis', 'Mr. Yoto Danoff', 'Mr. George John Jr Sage', 'Mr. Johan Hansen Nysveen', 'Mr. Austen Partner', 'Mr. George Edward Graham', 'Mr. Leo Edmondus Vander Planke', 'Mr. Mitto Denkoff', 'Mr. Thomas Clinton Pears', 'Mr. Karl Edwart Dahl', 'Mr. Stephen Weart Blackwell', 'Master. Edmond Roger Navratil', 'Mr. Erik Gustaf Collander', 'Mr. Charles Frederick Waddington Sedgwick', 'Mr. Stanley Hubert Fox', 'Master. William Loch Coutts', 'Mr. Jovan Dimic', 'Mr. Nils Martin Odahl', 'Mr. Fletcher Fellows Williams-Lambert', 'Mr. Tannous Elias', 'Mr. Josef Arnold-Franchi', 'Mr. Wazli Yousif', 'Mr. Leo Peter Vanden Steen', 'Mr. Wilhelm Skoog', 'Mr. Sebastiano del Carlo', 'Mr. Adola Asim', ""Mr. Thomas O'Brien"", 'Mr. Mauritz Nils Martin Adahl', 'Mr. George Achilles Harder', 'Mr. Jakob Alfred Wiklund', 'Mr. William Thomas Beavan', 'Mr. Sante Ringhini', 'Mr. Harry Elkins Widener', 'Mr. Tannous Betros', 'Mr. Karl Gideon Gustafsson', 'Mr. Juho Tikkanen', 'Mr. Vasil Plotcharsky', 'Mr. Charles Henry Davies', 'Master. Sidney Leonard Goodwin', 'Mr. Matthew Sadlier', 'Mr. William Ernest Carter', 'Mr. Carl Olof Jansson', 'Mr. Johan Birger Gustafsson', 'Mr. Erik Johansson', 'Mr. Peter David McKane', 'Dr. Alfred Pain', 'Mr. Juha Niskanen', 'Mr. John Adams', 'Mr. Pekka Pietari Hakkarainen', 'Mr. Shadrach Gale', 'Mr. Carl/Charles Peter Widegren', 'Master. William Rowe Richards', 'Mr. Hans Martin Monsen Birkeland', 'Mr. Todor Sdycoff', 'Mr. Henry Hart', 'Mr. Alfred Fleming Cunningham', 'Mr. Johan Julian Sundman', 'Mr. William John Matthews', 'Mr. David Charters', 'Mr. Leo Zimmerman', 'Mr. Viktor Richard Rosblom', 'Mr. Phillippe Wiseman', 'Mr. James Flynn', 'Mr. Berk (Berk Trembisky) Pickard', 'Mr. Mauritz Hakan Bjornstrom-Steffansson', 'Mr. Nikolai Erland Kallio', 'Mr. William Baird Silvey', 'Mr. Mark Fortune', 'Mr. Johan Henrik Johannesson Kvillner', 'Mr. Leon Hampe', 'Mr. Johan Emil Petterson', 'Mr. Bernt Johannesen-Bratthammer', 'Master. Washington Dodge', 'Mr. Frederic Kimber Seward', 'Major. Arthur Godfrey Peuchen', 'Mr. Edwy Arthur West', 'Mr. Ingvald Olai Olsen Hagland', 'Mr. Benjamin Laventall Foreman', 'Mr. Samuel L Goldenberg', 'Mr. Joseph Peduzzi', 'Mr. Ivan Jalsevac', 'Mr. Francis Davis Millet', ""Mr. Maurice O'Connor"", 'Mr. Harry Anderson', 'Mr. William Morley', 'Mr. Arthur H Gee', 'Mr. Jacob Christian Milling', 'Mr. Simon Maisner', 'Mr. Manuel Estanslas Goncalves', 'Mr. William Campbell', 'Mr. John Montgomery Smart', 'Mr. James Scanlan', 'Mr. Arthur Keefe', 'Mr. Luka Cacic', 'Mr. George Quincy Clifford', 'Mr. Peter Henry Renouf', 'Mr. Lewis Richard Braund', 'Mr. Nils August Karlsson', 'Master. Harold Victor Goodwin', 'Mr. Anthony Wood Frost', 'Mr. Richard Henry Rouse', 'Mr. Dickinson H Bishop', 'Mr. Edward Austin Kent', 'Mr. Francis William Somerton', 'Master. Eden Leslie Coutts', 'Mr. Konrad Mathias Reiersen Hagland', 'Mr. Einar Windelov', 'Mr. Harry Markland Molson', 'Mr. Ramon Artagaveytia', 'Mr. Edward Roland Stanley', 'Mr. Gerious Yousseff', 'Mr. Frederick William Shellard', 'Mr. Olof Svensson', 'Mr. Petar Calic', 'Mr. Victor de Satode Penasco y Castellana', 'Mr. George Bradley', 'Mr. Henry Margido Olsen', 'Mr. Fang Lang', 'Mr. Eugene Patrick Daly', 'Mr. James Webber', 'Mr. James Robert McGough', 'Mr. Satio Coleff', 'Mr. William Anderson Walker', 'Mr. Patrick Ryan', 'Mr. Stefo Pavlovic', 'Mr. Janko Vovk', 'Mr. Sarkis Lahoud', 'Mr. Fared Kassem', 'Mr. James Farrell', 'Mr. John Farthing', 'Mr. Johan Werner Salonen', 'Mr. Richard George Hocking', 'Mr. Nakli Toufik', 'Mr. Joseph Jr Elias', 'Major. Archibald Willingham Butt', 'Mr. Samuel Beard Risien', 'Mr. Edward Beane', 'Mr. Walter Donald Douglas', 'Mr. Arthur Ernest Nicholson', 'Mr. Julian Padro y Manent', 'Mr. Frank John Goldsmith', 'Master. John Morgan Jr Davies', 'Mr. John Borland Jr Thayer', 'Mr. Percival James R Sharp', ""Mr. Timothy O'Brien"", 'Mr. Fahim Leeni', 'Mr. George Wright', 'Mr. Victor Robbins', 'Mr. Thomas Rowan Morrow', 'Mr. Husein Sivic', 'Mr. Robert Douglas Norman', 'Mr. John Simmons', 'Mr. Alfred J Davies', 'Mr. Ilia Stoytcheff', 'Mr. Tannous Doharr', 'Mr. Carl Jonsson', 'Mr. George Harris', 'Mr. John Irwin Flynn', 'Mr. Alfred George John Rush', 'Mr. George Patchett', 'Mr. Eiriik Jussila', 'Mr. William James Downton', 'Mr. John Hugo Ross', 'Mr. Uscher Paulner', 'Mr. John Denzil Jarvis', 'Mr. Maxmillian Frolicher-Stehli', 'Mr. Eliezer Gilinski', 'Mr. Joseph Murdlin', 'Mr. Matti Rintamaki', 'Mr. William James Elsbury', 'Mr. John Henry Chapman', 'Mr. Jean Baptiste Van Impe', 'Mr. Alfred Johnson', 'Mr. Hanna Boulos', 'Sir. Cosmo Edmund Duff Gordon', 'Mr. Petco Slabenoff', 'Mr. Charles H Harrington', 'Mr. Ernst William Torber', 'Mr. Harry Homer', 'Mr. Edvard Bengtsson Lindell', 'Mr. Milan Karaic', 'Mr. Robert Williams Daniel', 'Mr. Jose Neto Jardin', 'Mr. John Horgan', 'Mr. William Alfred Brocklebank', 'Mr. Ernst Gilbert Danbom', 'Mr. Lawrence Gavey', 'Mr. Antoni Yasbeck', 'Mr. Edwin Nelson Jr Kimball', 'Mr. Sahid Nakid', 'Mr. Henry Damsgaard Hansen', 'Mr. David John Bowen', 'Mr. Frederick Sutton', 'Rev. Charles Leonard Kirkland', 'Mr. Guentcho Bostandyeff', ""Mr. Patrick D O'Connell"", 'Mr. Algernon Henry Wilson Barkworth', 'Mr. Johan Svensson Lundahl', 'Dr. Max Stahelin-Maeglin', 'Mr. William Henry Marsh Parr', 'Mr. Antti Gustaf Leinonen', 'Mr. Harvey Collyer', 'Mr. Percival Thorneycroft', 'Mr. Hans Peder Jensen', 'Mr. Choong Foo', 'Mr. Henry Sleeper Harper', 'Mr. Liudevit Cor', 'Col. Oberst Alfons Simonius-Blumer', 'Mr. Edward Willey', 'Mr. Mito Mitkoff', 'Mr. Johannes Halvorsen Kalvik', 'Mr. Leonard Mark Hickman', 'Mr. Alexander Radeff', 'Mr. George Floyd Eitemiller', 'Mr. Arthur Webster Newell', 'Dr. Henry William Frauenthal', 'Mr. Mohamed Badt', 'Mr. Edward Pomeroy Colley', 'Mr. Peju Coleff', 'Mr. Eino William Lindqvist', 'Mr. Lewis Hickman', 'Mr. Reginald Fenton Butler', 'Mr. Knud Paust Rommetvedt', 'Mr. Jacob Cook', 'Mr. Thornton Davidson', 'Mr. Henry Michael Mitchell', 'Mr. Charles Wilhelms', 'Mr. Ennis Hastings Watson', 'Mr. Gustaf Hjalmar Edvardsson', 'Mr. Frederick Charles Sawyer', 'Mr. Thomas Drake Martinez Cardeza', 'Mr. Hammad Hassab', 'Mr. Thor Anderson Olsvigen', 'Mr. Charles Edward Goodwin', 'Mr. Thomas William Solomon Brown', 'Mr. Joseph Philippe Lemercier Laroche', 'Mr. Jaako Arnold Panula', 'Mr. Branko Dakic', 'Mr. Eberhard Thelander Fischer', 'Mr. Albert Adrian Dick', 'Mr. Ali Lam', 'Mr. Khalil Saad', 'Col. John Weir', 'Mr. Charles Henry Chapman', 'Mr. James Kelly', 'Mr. John Borland Thayer', 'Mr. Adolf Mathias Nicolai Olsen Humblen', 'Mr. Spencer Victor Silverthorne', 'Mr. Martin Gallagher', 'Mr. Henrik Juul Hansen', 'Mr. Henry Samuel Morley', 'Mr. Edward Pennington Calderhead', 'Master. Halim Gonios Moubarek', 'Mr. Herman Klaber', 'Mr. Elmer Zebley Taylor', 'Mr. August Viktor Larsson', 'Mr. Samuel Greenberg', 'Mr. Peter Andreas Lauritz Andersen Soholt', 'Mr. Malkolm Joackim Johnson', 'Mr. Svend Lauritz Jensen', 'Mr. William Henry Gillespie', 'Mr. Henry Price Hodges', 'Mr. Norman Campbell Chambers', 'Mr. Luka Oreskovic', 'Mr. Kurt Arnold Gottfrid Bryhl', 'Mr. Houssein G N Hassan', 'Mr. Robert J Knight', 'Mr. William John Berriman', 'Mr. Moses Aaron Troupiansky', 'Mr. Leslie Williams', 'Mr. Gustave J Lesurer', 'Mr. Kanio Ivanoff', 'Mr. Minko Nankoff', 'Mr. Walter James Hawksford', 'Mr. Tyrell William Cavendish', 'Mr. Neal McNamee', 'Mr. Juho Stranden', 'Capt. Edward Gifford Crosby', 'Mr. Rossmore Edward Abbott', 'Mr. Daniel Warner Marvin', 'Mr. Michael Connaghton', 'Master. Meier Moor', 'Mr. Johannes Joseph Vande Velde', 'Mr. Lalio Jonkoff', 'Master. Viljo Hamalainen', 'Mr. August Sigfrid Carlsson', 'Mr. Percy Andrew Bailey', 'Mr. Thomas Leonard Theobald', 'Mr. John Garfirth', 'Mr. Iisakki Antino Aijo Nirva', 'Mr. Hanna Assi Barah', 'Mr. Hans Linus Eklund', 'Dr. Arthur Jackson Brewe', 'Mr. Daniel J Moran', 'Mr. Daniel Danielsen Gronnestad', 'Mr. Rene Aime Lievens', 'Mr. Niels Peder Jensen', 'Mr. Dibo Elias', 'Mr. Pehr Fabian Oliver Malkolm Myhrman', 'Mr. Roger Tobin', 'Mr. Thomas J Kilgannon', 'Mr. Milton Clyde Long', 'Mr. Andrew G Johnston', 'Mr. William Ali', 'Mr. Abraham (David Lishin) Harmer', 'Master. George Hugh Rice', 'Master. Bertram Vere Dean', 'Mr. Benjamin Guggenheim', 'Mr. Andrew Keane', 'Mr. Alfred Gaskell', 'Mr. William Fisher Hoyt', 'Mr. Ristiu Dantcheff', 'Mr. Richard Otter', 'Mr. Yousseff Ibrahim Shawah', 'Mr. Martin Ponesell', 'Master. William Thornton II Carter', 'Master. Assad Alexander Thomas', 'Mr. Oskar Arvid Hedman', 'Mr. Karl Johan Johansson', 'Mr. Thomas Jr Andrews', 'Mr. August Meyer', 'Mr. William Alexander', 'Mr. James Lester', 'Mr. Richard James Slemen', 'Mr. Ernest Portage Tomlin', 'Mr. Richard Fry', 'Mr. Albert Mallet', 'Mr. John Fredrik Alexander Holm', 'Master. Karl Thorsten Skoog', 'Mr. Nikola Lulic', 'Jonkheer. John George Reuchlin', 'Master. Urho Abraham Panula', 'Mr. John Flynn', 'Mr. Len Lam', 'Master. Andre Mallet', 'Mr. Thomas Joseph McCormack', 'Master. George Sibley Richards', 'Mr. Amin Saad', 'Mr. Albert Augustsson', 'Mr. Owen George Allum', 'Mr. Jakob Pasic', 'Mr. Maurice Sirota', 'Mr. Chang Chip', 'Mr. Pierre Marechal', 'Mr. Ilmari Rudolf Alhomaki', 'Mr. Thomas Charles Mudd', 'Mr. Peter L Lemberopolous', 'Mr. Jeso Culumovic', 'Mr. Anthony Abbing', 'Mr. Douglas Bullen Sage', 'Mr. Marin Markoff', 'Rev. John Harper', 'Master. Sigvard Harald Elias Andersson', 'Mr. Johan Svensson', 'Mr. Peter Denis Daly', 'Mr. Raihed Razi', 'Mr. Claus Peter Hansen', 'Mr. Frederick Edward Giles', 'Mr. John William Gill', 'Mr. Washington Augustus II Roebling', 'Mr. Philemon van Melkebeke', 'Master. Harold Theodor Johnson', 'Mr. Cerin Balkic', 'Mr. Frans Olof Carlsson', 'Mr. Victor Vander Cruyssen', 'Mr. Alfred Ossian Gustafsson', 'Mr. Nedelio Petroff', 'Mr. Kristo Laleff', 'Mr. Johann Markun', 'Mr. Frederick James Banfield', 'Mr. Henry Jr Sutehall', 'Rev. Juozas Montvila', 'Mr. Karl Howell Behr', 'Mr. Patrick Dooley']","['50-100', '150+', '100-150']",,,,
"What are the top 4 age ranges ('30-50', '18-30', '0-18', '50+') with the highest number of survivors?","Which are the top 4 age ranges ('30-50', '18-30', '0-18', '50+') with the highest number of survivors?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Define age ranges
    bins = [0, 18, 30, 50, float('inf')]
    labels = ['0-18', '18-30', '30-50', '50+']
    
    # Create a new column for age range
    dataset['Age_Range'] = pd.cut(dataset['Age'], bins=bins, labels=labels)
    
    # Filter only survivors
    survivors = dataset[dataset['Survived'] == True]
    
    # Count the number of survivors in each age range
    age_range_counts = survivors['Age_Range'].value_counts().nlargest(4)
    
    # Get the top 4 age ranges with the highest number of survivors
    top_age_ranges = list(age_range_counts.index)
    
    return top_age_ranges
",list of (string),"['30-50', '18-30', '0-18', '50+']","['30-50', '18-30', '0-18', '50+']",,,,
What are the top 2 genders by average fare paid?,What are the top 2 genders with the highest average fare paid?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by gender and calculate the average fare for each gender
    avg_fare_by_gender = dataset.groupby('Sex')['Fare'].mean().reset_index()
    
    # Sort the genders by average fare in descending order
    top_genders = avg_fare_by_gender.sort_values(by='Fare', ascending=False)['Sex'][:2].tolist()
    
    return top_genders
",list of (string),"['female', 'male']","['female', 'male']",,,,
What are the oldest 3 ages among the survivors?,What are the top 3 oldest ages among those who survived?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
survived_passengers = dataset[dataset[""Survived""] == True]
top_3_oldest_ages = survived_passengers.nlargest(3, ""Age"")[""Age""].tolist()

return top_3_oldest_ages",list of (float64),"[80.0, 63.0, 63.0]","[80, 63, 63]",,,,
Which are the top 4 fares paid by survivors?,What are the top 4 fares paid by passengers who survived?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only passengers who survived
    survived_passengers = dataset[dataset['Survived'] == True]
    
    # Sort the filtered dataset by Fare in descending order and get the top 4 fares
    top_fares = survived_passengers['Fare'].nlargest(4).tolist()
    
    return top_fares
",list of float64,"[512.3292, 512.3292, 512.3292, 263.0]","[512.329, 512.329, 512.329, 263]",,,,
Could you list the youngest 3 ages among the survivors?,What are the ages of the three youngest survivors?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only survivors
    survivors = dataset[dataset['Survived'] == True]
    
    # Sort the survivors by age in ascending order
    sorted_survivors = survivors.sort_values(by='Age')
    
    # Get the ages of the three youngest survivors
    youngest_ages = sorted_survivors.head(3)['Age'].tolist()
    
    return youngest_ages
",list of (float64),"[1.0, 1.0, 1.0]","[1, 1, 1]",,,,
Which are the lowest 4 fares among those who didn't survive?,What are the four lowest fares for passengers who did not survive?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only passengers who did not survive
    non_survivors = dataset[dataset['Survived'] == False]
    
    # Sort the filtered dataset by Fare in ascending order
    sorted_non_survivors = non_survivors.sort_values(by='Fare')
    
    # Get the four lowest fares
    lowest_fares = sorted_non_survivors['Fare'].head(4).tolist()
    
    return lowest_fares
",list of (float64),"[0.0, 0.0, 0.0, 0.0]","[0, 0, 0, 0]",,,,
Is the average age of the respondents above 30?,,,,ERROR,True,,,,
Are there more single individuals than married ones in the dataset?,,,,ERROR,True,,,,
Do the majority of respondents have a height greater than 170 cm?,,,,ERROR,True,,,,
Is the most frequent hair color black?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is about whether there are any records where the individual has met their sexual partners in a Bar or Restaurant and Through Friends both being True
    result = dataset[(dataset['Where have you met your sexual partners? (In a Bar or Restaurant)'] == True) & 
                     (dataset['Where have you met your sexual partners? (Through Friends)'] == True)].empty
    
    return not result",bool,True,False,,,,
How many unique nationalities are present in the dataset?,,,,ERROR,13,,,,
What is the average gross annual salary?,,,,ERROR,56332.81720400000,,,,
How many respondents wear glasses all the time?,How many respondents wear glasses all the time?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to find individuals who wear glasses all the time
    glasses_all_time = dataset[dataset[""How often do you wear glasses? 👓""] == ""All the time""]
    
    # Count the number of respondents
    count = len(glasses_all_time)
    
    return count
",int64,0,98,,,,
What's the median age of the respondents?,What is the median age of the respondents based on the 'What is your age? 👶🏻👵🏻' column?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    median_age = dataset[""What is your age? 👶🏻👵🏻""].median()
    
    return median_age",float64  ,33.0,33.0,,,,
What is the most common level of studies achieved?,,,,ERROR,Master,,,,
Which body complexity has the least number of respondents?,Which body complexity category has the fewest respondents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    body_complexity_counts = dataset['What is your body complexity? 🏋️'].value_counts()
    min_count_category = body_complexity_counts.idxmin()

    return min_count_category
",string,Very thin,Very thin,,,,
What's the most frequent eye color?,What is the most common eye color among the participants?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_common_eye_color = dataset[""What is your eye color? 👁️""].mode()[0]
    
    return most_common_eye_color
",string,Brown,Brown,,,,
Which sexual orientation has the highest representation?,,,,ERROR,Heterosexual,,,,
List the top 3 most common areas of knowledge.,,,,ERROR,"['Computer Science', 'Business', 'Enginering & Architecture']",,,,
List the bottom 3 hair lengths in terms of frequency.,,,,ERROR,"['Medium', 'Long', 'Bald']",,,,
Name the top 5 civil statuses represented in the dataset.,What are the top 5 civil statuses present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_civil_statuses = dataset['What is your civil status? 💍'].value_counts().head(5).index.tolist()
    
    return top_civil_statuses
",list of (string),"['Single', 'Married', 'In a Relationship', 'In a Relationship Cohabiting', 'Divorced']","['Single', 'Married', 'In a Relationship', 'In a Relationship Cohabiting', 'Divorced']",,,,
What are the 4 least common hair colors?,What are the four least frequently occurring hair colors in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each hair color
    hair_color_counts = dataset['What is your hair color? 👩🦰👱🏽'].value_counts()
    
    # Get the four least frequently occurring hair colors
    least_frequent_hair_colors = hair_color_counts.nsmallest(4).index.tolist()
    
    return least_frequent_hair_colors
",list of (string),"['Blue', 'White', 'Other', 'Red']","['Red', 'Other', 'White', 'Blue']",,,,
What are the top 4 maximum gross annual salaries?,What are the top 4 highest gross annual salaries from the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_salaries = dataset[""Gross annual salary (in euros) 💸""].nlargest(4).tolist()
    
    return top_salaries
",list of (float64),"[500000.0, 360000.0, 300000.0, 300000.0]","[500000.0, 360000.0, 300000.0, 300000.0]",,,,
Name the 3 happiness values for the 3 unhappiest people in the happiness scale.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column's values as a list of numbers
    # For example, if the question asks for all ages, we can extract the 'What is your age? 👶🏻👵🏻' column
    column_name = ""What is your age? 👶🏻👵🏻""
    answer = dataset[column_name].tolist()
    
    return answer",list of (int64),"[51, 28, 45, 29, 27, 46, 39, 44, 29, 45, 28, 42, 40, 41, 34, 42, 27, 22, 60, 36, 49, 51, 27, 22, 44, 31, 46, 30, 39, 30, 41, 47, 39, 29, 35, 34, 30, 24, 34, 65, 37, 55, 42, 47, 27, 32, 27, 36, 30, 26, 33, 26, 32, 30, 26, 34, 19, 41, 26, 43, 25, 23, 30, 41, 48, 26, 41, 35, 30, 31, 26, 47, 28, 26, 27, 29, 32, 40, 41, 27, 46, 33, 27, 59, 29, 41, 23, 39, 41, 31, 36, 31, 30, 45, 37, 19, 25, 29, 32, 21, 47, 28, 35, 24, 35, 20, 22, 40, 59, 42, 31, 36, 24, 28, 32, 31, 32, 54, 27, 25, 35, 41, 37, 22, 32, 24, 23, 51, 50, 53, 55, 28, 24, 21, 20, 31, 33, 28, 52, 24, 33, 32, 41, 46, 32, 39, 38, 45, 34, 23, 28, 29, 36, 29, 45, 60, 45, 33, 29, 39, 41, 41, 25, 44, 48, 23, 42, 35, 32, 40, 30, 55, 38, 28, 47, 37, 41, 35, 35, 32, 48, 37, 40, 23, 27, 32, 32, 34, 47, 37, 26, 50, 35, 33, 52, 38, 35, 28, 43, 52, 45, 31, 30, 26, 31, 36, 31, 41, 24, 43, 55, 23, 44, 28, 48, 28, 52, 56, 35, 40, 33, 25, 29, 35, 41, 43, 30, 35, 24, 36, 58, 30, 24, 50, 24, 51, 38, 37, 24, 33, 26, 25, 31, 30, 27, 34, 62, 31, 33, 46, 39, 47, 26, 23, 35, 46, 50, 22, 21, 32, 32, 26, 30, 30, 52, 44, 31, 29, 35, 36, 45, 49, 22, 40, 29, 26, 41, 24, 50, 28, 44, 21, 37, 37, 37, 21, 28, 42, 29, 29, 36, 53, 27, 29, 24, 37, 29, 31, 24, 25, 32, 23, 45, 44, 45, 25, 36, 32, 30, 30, 34, 33, 23, 47, 31, 33, 28, 27, 30, 28, 37, 39, 44, 46, 39, 39, 31, 39, 38, 27, 35, 37, 45, 46, 55, 30, 46, 31, 25, 26, 32, 36, 52, 25, 25, 32, 34, 26, 27, 48, 32, 28, 26, 39, 38, 43, 43, 49, 26, 28, 30, 28, 29, 24, 32, 26, 22, 50, 21, 33, 34, 23, 36]","[2, 2, 2]",,,,
What are the 5 highest ages present in the dataset?,What are the top 5 highest ages in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by age in descending order and get the top 5 ages
    top_ages = dataset[""What is your age? 👶🏻👵🏻""].nlargest(5).tolist()
    
    return top_ages
",list of int64,"[65, 62, 60, 60, 59]","[65, 62, 60, 60, 59]",,,,
List the bottom 6 skin tone values based on frequency.,,,,ERROR,"[2, 1, 6, 0, 7, 8]",,,,
Are there any trips with a total distance greater than 30 miles?,Is there any taxi trip with a distance greater than 30 miles?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_long_trip = dataset['trip_distance'].max() > 30

    return has_long_trip
",bool,False,False,,,,
Were there any trips that cost more than $100 in total?,Is there any record of a trip where the total amount paid was more than $100?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_expensive_trip = (dataset[""total_amount""] > 100).any()

return has_expensive_trip
",bool,False,False,,,,
Is there any trip with more than 6 passengers?,Are there any trips with a passenger count greater than 6?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_trips_with_passenger_count_greater_than_6 = (dataset[""passenger_count""] > 6).any()
return has_trips_with_passenger_count_greater_than_6",bool,False,False,,,,
Did all the trips use a payment type of either 1 or 2?,Did all the trips use a payment type of either 1 or 2?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    unique_payment_types = dataset['payment_type'].unique()
    return set(unique_payment_types).issubset({1, 2})
",bool  ,False,False,,,,
What is the maximum fare amount charged for a trip?,What is the highest fare amount recorded in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fare_amount = dataset[""fare_amount""].max()
    return max_fare_amount
",float64  ,75.25,75.25,,,,
How many unique pickup locations are in the dataset?,What is the count of distinct pickup locations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_pickup_locations_count = dataset['PULocationID'].nunique()
    
    return distinct_pickup_locations_count
",int64,96,96,,,,
What is the average tip amount given by passengers?,What is the average value of the tip amount received by passengers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_tip_amount = dataset[""tip_amount""].mean()

return average_tip_amount
",float64,2.7366810000000000,2.74,,,,
How many trips took place in the airport area?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a specific value that can be directly extracted from the schema or derived from the data.
# Since no specific question is provided, I'll assume a generic question like ""What is the maximum fare amount?""
max_fare_amount = dataset['fare_amount'].max()
return max_fare_amount",int64,75.25,99807,,,,
Which payment type is the most common in the dataset?,What is the most frequently occurring payment type in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_payment_type = dataset['payment_type'].mode()[0]
    
    return most_frequent_payment_type
",string,1,1,,,,
Which vendor has the most trips recorded?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fare_trip = dataset.loc[dataset[""fare_amount""] == dataset[""fare_amount""].max()]
    vendor_id = max_fare_trip[""VendorID""].iloc[0]

    return vendor_id
",uint8,2,2,,,,
What is the most common drop-off location?,Which drop-off location ID appears most frequently in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_dropoff_id = dataset['DOLocationID'].mode()[0]
    return most_frequent_dropoff_id
",uint16,236,236,,,,
On which date did the first recorded trip occur?,What is the date and time of the earliest recorded trip in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
earliest_trip = dataset.loc[dataset[""tpep_pickup_datetime""] == dataset[""tpep_pickup_datetime""].min()]
return earliest_trip[""tpep_pickup_datetime""].iloc[0]
","datetime64[us, UTC]",31-01-2023 23:52,31-01-2023,,,,
Which are the top 2 most frequent pickup locations?,What are the top 2 most frequently occurring pickup locations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each pickup location
    pickup_location_counts = dataset['PULocationID'].value_counts().head(2)
    
    # Get the top 2 most frequently occurring pickup locations as a list of strings
    top_pickup_locations = pickup_location_counts.index.astype(str).tolist()
    
    return top_pickup_locations
",list of (string),"['161', '237']","[161, 237]",,,,
Name the 4 most common rate codes used.,What are the top 4 most frequently used rate codes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each RatecodeID
    rate_code_counts = dataset['RatecodeID'].value_counts().head(4).index.tolist()
    
    # Convert the rate codes to strings if necessary
    rate_code_counts = [str(code) for code in rate_code_counts]
    
    return rate_code_counts
",list of (string),"['1', '2', '5', '4']","[1, 2, 5, 4]",,,,
list the 2 most frequent store and forward flags.,What are the two most common store and forward flags in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by store_and_fwd_flag and count occurrences
    flag_counts = dataset['store_and_fwd_flag'].value_counts().head(2).index.tolist()
    
    return flag_counts",list of (string),"['N', 'Y']","['N', 'Y']",,,,
Identify the top 4 payment types used by frequency,What are the top 4 most frequently used payment types in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each payment type
    payment_type_counts = dataset['payment_type'].value_counts()
    
    # Get the top 4 most frequently used payment types
    top_payment_types = payment_type_counts.head(4).index.tolist()
    
    return top_payment_types",list of (string),"[1, 2, 4, 3]","[1, 2, 4, 3]",,,,
Report the 4 highest toll amounts paid.,What are the top 4 toll amounts paid?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_toll_amounts = dataset['tolls_amount'].nlargest(4).tolist()
    return top_toll_amounts
",list of (float64),"[0, 0, 0, 0]","[0, 0, 0, 0]",,,,
list the top 3 longest trip distances,What are the top 3 longest trip distances in the taxi dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_longest_trips = dataset.nlargest(3, 'trip_distance')['trip_distance'].tolist()

return top_3_longest_trips",list of (float64),"[19.83, 19.74, 19.68]","[19.83, 19.74, 19.68]",,,,
Identify the 5 largest total amounts paid for trips.,What are the top 5 highest total amounts paid for taxi trips?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_total_amounts = dataset['total_amount'].nlargest(5).tolist()
return top_5_total_amounts",list of (float64),"[80.0, 80.0, 80.0, 80.0, 79.55]","[80.0, 80.0, 80.0, 80.0, 80.0]",,,,
Report the 6 highest fare amounts charged.,What are the six highest fare amounts charged?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_fare_amounts = dataset.nlargest(6, 'fare_amount')['fare_amount'].tolist()
    
    return top_fare_amounts
",list of (float64),"[75.25, 74.4, 73.0, 73.0, 73.0, 73.0]","[75.25, 74.4, 73.0, 73.0, 73.0, 73.0]",,,,
Are there any complaints made in Brooklyn?,Is there any record of a complaint made in Brooklyn?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_brooklyn_complaint = dataset['borough'].str.contains('Brooklyn', na=False).any()
    
    return has_brooklyn_complaint
",bool,False,True,,,,
Do any complaints have 'Dog' as a descriptor?,Are there any complaints where the descriptor includes 'Dog'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_dog_complaint = 'Dog' in dataset['descriptor'].values

    return has_dog_complaint
",bool,True,True,,,,
Were there any complaints raised in April?,Was there at least one complaint raised in April?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    complaints_in_april = dataset[dataset['month_name'] == 'April']
    has_complaints = not complaints_in_april.empty

    return has_complaints
",bool,True,True,,,,
Is the Mayor's office of special enforcement one of the agencies handling complaints?,Does the Mayor's office of special enforcement handle any complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    mayor_office_complaints = dataset[dataset['agency_name'] == 'Mayor\'s Office of Special Enforcement']
    
    return not mayor_office_complaints.empty
",bool,False,True,,,,
How many complaints have been made in Queens?,How many complaints have been registered in the borough of Queens?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    complaints_in_queens = dataset[dataset['borough'] == 'Queens']
    count_of_complaints = len(complaints_in_queens)

    return count_of_complaints
",int64  ,0,23110,,,,
What's the total number of unique agencies handling complaints?,How many distinct agencies are involved in handling complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_agencies_count = dataset['agency'].nunique()
    
    return distinct_agencies_count
",int64,22,22,,,,
How many complaints were raised at midnight?,How many complaints were filed during the midnight hour?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    midnight_complaints_count = dataset[dataset[""hour""] == 0].shape[0]
    
    return midnight_complaints_count
",int64  ,14811,14811,,,,
How many unique descriptors are present in the dataset?,How many distinct descriptors are there in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_descriptors_count = dataset['descriptor'].nunique()
    
    return distinct_descriptors_count
",int64  ,1131,1131,,,,
Which borough has the most complaints?,Which borough has the highest number of complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    borough_counts = dataset['borough'].value_counts()
    borough_with_highest_complaints = borough_counts.idxmax()

    return borough_with_highest_complaints
",string,BROOKLYN,BROOKLYN,,,,
Which month sees the highest number of complaints?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Your code here to answer the question based on the provided schema and expected answer type
return ""Your answer here""",string,Your answer here,July,,,,
Which weekday has the least complaints?,On which weekday were the least number of complaints registered?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by weekday_name and count the number of complaints for each day
    complaint_counts = dataset.groupby('weekday_name').size().reset_index(name='count')
    
    # Find the weekday with the minimum number of complaints
    min_complaints_weekday = complaint_counts.loc[complaint_counts['count'] == complaint_counts['count'].min(), 'weekday_name'].iloc[0]
    
    return min_complaints_weekday
",string,Sunday,Sunday,,,,
Which agency is least frequently handling complaints?,Which agency has the lowest frequency of complaint handling?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    agency_counts = dataset['agency'].value_counts()
    least_frequent_agency = agency_counts.idxmin()

    return least_frequent_agency",string,ACS,ACS,,,,
List the top 5 most frequent complaint types.,What are the top 5 most frequent complaint types in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    complaint_type_counts = dataset['complaint_type'].value_counts().head(5).index.tolist()
    
    return complaint_type_counts
",list of (string),"['Noise - Residential', 'HEAT/HOT WATER', 'Illegal Parking', 'Blocked Driveway', 'Street Condition']","['Noise - Residential', 'HEAT/HOT WATER', 'Illegal Parking', 'Blocked Driveway', 'Street Condition']",,,,
Which 4 agencies handle the most complaints?,What are the names of the top 4 agencies that receive the most complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
agency_counts = dataset['agency'].value_counts().head(4).index.tolist()
return agency_counts",list of (string),"['NYPD', 'HPD', 'DOT', 'DSNY']","['NYPD', 'HPD', 'DOT', 'DSNY']",,,,
Name the 2 least frequent descriptors for complaints by inverse alphabetical order.,"Retrieve the two least frequent descriptors for complaints, sorted by inverse alphabetical order.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    descriptor_counts = dataset['descriptor'].value_counts(ascending=True).tail(2)
    least_frequent_descriptors = descriptor_counts.index.tolist()
    least_frequent_descriptors.sort(reverse=True)

    return list(least_frequent_descriptors)
",list of (string),"['Loud Music/Party', 'ENTIRE BUILDING']","['Booting Company', 'Ready NY - Businesses', 'Animal']",,,,
Mention the 2 most common weekdays for complaints.,What are the two most frequent days of the week for complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by weekday_name and count occurrences
    weekday_counts = dataset['weekday_name'].value_counts().nlargest(2)
    
    # Get the two most frequent days of the week
    most_frequent_days = list(weekday_counts.index)
    
    return most_frequent_days
",list of (string),"['Tuesday', 'Monday']","['Tuesday', 'Monday']",,,,
What are the top 4 hours with the most complaints?,Which are the top 4 hours with the highest number of complaints?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by hour and count the number of complaints for each hour
    hourly_complaints = dataset['hour'].value_counts().head(4).index.tolist()
    
    return hourly_complaints
",list of (int64),"[0, 12, 10, 11]","[0, 12, 10, 11]",,,,
State the 3 lowest unique complaint keys.,What are the three smallest unique complaint keys in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by unique_key and select the first three rows
    smallest_keys = dataset.sort_values(by='unique_key').head(3)['unique_key'].tolist()
    
    return smallest_keys",list of (int64),"[15628852, 15634748, 15634996]","[15628852, 15634748, 15634996]",,,,
Which 2 hours see the least complaints?,During which two hours are complaints the least?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by hour and count the number of complaints in each hour
    hourly_complaints = dataset.groupby('hour').size().reset_index(name='count')
    
    # Find the two hours with the least number of complaints
    two_least_busy_hours = hourly_complaints.nsmallest(2, 'count')['hour'].tolist()
    
    return two_least_busy_hours
",list of (int64),"[4, 5]","[6, 2]",,,,
List the 6 highest complaint numbers from the dataset.,Retrieve the top 6 highest complaint numbers from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by complaint_type and count occurrences to get complaint numbers
    complaint_counts = dataset['complaint_type'].value_counts().nlargest(6).index.tolist()
    
    return complaint_counts",list of (int64),"['Noise - Residential', 'HEAT/HOT WATER', 'Illegal Parking', 'Blocked Driveway', 'Street Condition', 'Street Light Condition']","[54954250, 54954040, 54952675, 54950924, 54950765, 54950581]",,,,
Are all properties in the dataset located in the same neighbourhood?,Do all properties in the dataset belong to the same neighborhood?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
unique_neighbourhoods = dataset['neighbourhood'].nunique()
all_same_neighborhood = unique_neighbourhoods == 1

return all_same_neighborhood",bool,False,False,,,,
Do all hosts verify their identity?,,,,ERROR,False,,,,
Are all reviews_per_month values greater than 5?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is about checking if a certain condition is met for the highest review score
    max_review_score_individual = dataset.loc[dataset[""review_scores_rating""] == dataset[""review_scores_rating""].max()]
    is_instant_bookable = max_review_score_individual[""instant_bookable""].iloc[0] == 't'

    return is_instant_bookable
",bool,False,False,,,,
Are there any listings without a specified room type?,Is there any listing in the dataset where the room type is not specified?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    missing_room_type = dataset['room_type'].isnull().any()
    
    return missing_room_type
",bool,False,False,,,,
How many unique neighbourhoods are there in the dataset?,How many distinct neighbourhoods are present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_neighbourhoods = dataset['neighbourhood_cleansed'].nunique()
    return distinct_neighbourhoods",int64  ,33,563,,,,
How many listings don't have a valid price?,How many listings have an invalid price?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the price column contains invalid values as NaN or non-numeric strings
    invalid_price_count = dataset['price'].isna().sum() + dataset['price'].str.contains(r'\D').sum()
    
    return invalid_price_count
",int64,75241,0,,,,
How many properties have received the worst possible (0-5) review score for communication?,How many properties have a review score of 0 for communication?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count_zero_reviews = dataset[dataset['review_scores_communication'] == 0].shape[0]
    return count_zero_reviews
",int64,6,6,,,,
What is the maximum number of bedrooms a property has in this dataset?,What is the highest number of bedrooms found in a property within this dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_bedrooms = dataset['bedrooms'].max()
    
    return max_bedrooms
",float64  ,22.0,22.0,,,,
Which neighbourhood has the most listings?,Which neighborhood has the highest number of listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
neighborhood_counts = dataset['neighbourhood'].value_counts()
top_neighborhood = neighborhood_counts.idxmax()

return top_neighborhood
",string,"Greater London, England, United Kingdom",Westminster,,,,
What is the most common room type in the listings?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value or a derived value from the dataset.
    # For demonstration, let's assume the question is ""What is the most common neighbourhood cleansed in London?""
    
    # Find the mode of the 'neighbourhood_cleansed' column
    most_common_neighbourhood = dataset['neighbourhood_cleansed'].mode()[0]
    
    return most_common_neighbourhood
",string,Westminster,Entire home/apt,,,,
What property type has the most listings?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific category value based on some condition
    # For example, let's assume the question is ""What is the most common neighbourhood cleansed?""
    
    # Find the most common neighbourhood cleansed
    most_common_neighbourhood = dataset['neighbourhood_cleansed'].mode()[0]
    
    return most_common_neighbourhood
",category,Westminster,Entire rental unit,,,,
Which host verification method is the least used?,,,,ERROR,photographer,,,,
List the top 3 neighbourhoods with the most listings.,What are the top 3 neighbourhoods with the highest number of listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by neighbourhood and count the number of listings in each
    neighbourhood_counts = dataset['neighbourhood'].value_counts()
    
    # Get the top 3 neighbourhoods with the highest number of listings
    top_3_neighbourhoods = neighbourhood_counts.head(3).index.tolist()
    
    return top_3_neighbourhoods
",list of (string),"['Greater London, England, United Kingdom', 'London, United Kingdom', 'London, England, United Kingdom']","['Westminster', 'Tower Hamlets', 'Hackney']",,,,
Which are the top 4 most common property types?,What are the top 4 most frequent property types in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each property type
    property_type_counts = dataset['property_type'].value_counts()
    
    # Get the top 4 most frequent property types
    top_4_property_types = property_type_counts.head(4).index.tolist()
    
    return top_4_property_types
",list of (string),"['Entire rental unit', 'Private room in rental unit', 'Private room in home', 'Entire condo']","['Entire rental unit', 'Private room in rental unit', 'Private room in home', 'Entire condo']",,,,
List the 2 most common host verification methods.,What are the top 2 most frequently used host verification methods?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Split the 'host_verifications' column by commas and explode it into separate rows
    verifications = dataset['host_verifications'].str.split(',').explode()
    
    # Count the occurrences of each verification method
    verification_counts = verifications.value_counts().head(2)
    
    # Get the index (verification methods) as a list
    top_verification_methods = verification_counts.index.tolist()
    
    return top_verification_methods
",list of (string),[],"['phone', 'email']",,,,
Which are the 2 most preferred room types?,What are the two most common room types?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Get the value counts of 'room_type' and get the top 2
    top_room_types = dataset['room_type'].value_counts().index[:2].tolist()
    
    return top_room_types
",list of (string),"['Entire home/apt', 'Private room']","['Entire home/apt', 'Private room']",,,,
What are the top 3 highest review scores for location?,What are the top 3 highest review scores for location?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_review_scores = dataset['review_scores_location'].nlargest(3).tolist()
    return top_review_scores
",list of (float64),"[5.0, 5.0, 5.0]","[5.0, 5.0, 5.0]",,,,
What are the 4 most common number of bedrooms in properties?,What are the top 4 most frequent number of bedrooms in properties?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'bedrooms' and count the occurrences
    bedroom_counts = dataset['bedrooms'].value_counts().nlargest(4).index.tolist()
    
    return bedroom_counts
",list of (int64),"[1.0, 2.0, 3.0, 4.0]","[1.0, 2.0, 3.0, 4.0]",,,,
What are the 5 highest counts of listings by a single host for entire homes?,What are the top 5 host IDs with the highest number of entire home listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_hosts = dataset.sort_values(by='calculated_host_listings_count_entire_homes', ascending=False).head(5)
    host_ids = top_hosts['host_id'].tolist()

    return host_ids
",list of (int64),"[33889201, 33889201, 33889201, 33889201, 33889201]","[288, 288, 288, 288, 288]",,,,
List the 6 lowest review scores for communication.,What are the 6 lowest review scores for communication?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sorted_reviews = dataset.sort_values(by='review_scores_communication', ascending=True)
    lowest_reviews = sorted_reviews['review_scores_communication'].head(6).tolist()

    return lowest_reviews
",list of (float64),"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]","[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]",,,,
Are there players who have a greater overall score than their potential score?,,,,ERROR,False,,,,
Are there any players who joined their current club before they were 18 years old?,,,,ERROR,True,,,,
Are there any players whose preferred foot is left and are from a nationality that starts with 'B'?,,,,ERROR,True,,,,
Are there any players who are taller than 6 feet and have an agility score above 90?,,,,ERROR,False,,,,
What is the average overall score of players from France?,,,,ERROR,67.861432,,,,
How many unique clubs are there in the dataset?,,,,ERROR,683,,,,
What is the highest value (in €) of a player in the dataset?,,,,ERROR,105500000,,,,
How many players have the position 'ST'?,,,,ERROR,414,,,,
What is the most common nationality in the dataset?,,,,ERROR,England,,,,
What is the most common preferred foot amongst players?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here to answer the question based on the provided schema and question
    pass
",category,,Right,,,,
Which club has the most players in the dataset?,,,,ERROR,Crystal Palace,,,,
What is the most common position of players in the dataset?,,,,ERROR,SUB,,,,
Which are the top 5 nationalities in terms of the average overall score of their players?,,,,ERROR,"['Tanzania', 'Syria', 'Mozambique', 'Chad', 'Central African Rep.']",,,,
Which are the top 3 clubs in terms of the total value (in €) of their players?,,,,ERROR,"['Liverpool', 'Manchester City', 'Real Madrid']",,,,
Which are the bottom 4 nationalities in terms of the average agility of their players?,,,,ERROR,"['Macau', 'Andorra', 'Moldova', 'Liechtenstein']",,,,
Which are the top 6 clubs in terms of the average potential score of their players?,,,,ERROR,"['FC Bayern München', 'Real Madrid', 'FC Barcelona', 'Paris Saint-Germain', 'Juventus', 'Manchester City']",,,,
What are the top 3 overall scores in the dataset?,,,,ERROR,"[93, 92, 91]",,,,
What are the bottom 5 potential scores in the dataset?,,,,ERROR,"[48, 48, 49, 50, 50]",,,,
What are the top 4 values (in €) of players in the dataset?,,,,ERROR,"[105500000, 90000000, 87000000, 80000000]",,,,
What are the top 2 wages (in €) of players in the dataset?,,,,ERROR,"[560000, 370000]",,,,
There are no tornadoes that resulted in more than 500 injuries.,Is it true that no tornadoes caused more than 500 injuries?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    return not (dataset['inj'] > 500).any()",bool,False,True,,,,
All tornadoes in the dataset occurred in the 21st century.,Did all tornadoes in the dataset occur in the 21st century?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    all_21st_century = (dataset['yr'] >= 2000).all()
    return all_21st_century
",bool,False,False,,,,
No tornado has a length greater than 100 miles.,Is it true that all tornadoes have a length of 100 miles or less?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    all_tornadoes_length_100_or_less = (dataset['len'] <= 100).all()
    return all_tornadoes_length_100_or_less",bool,False,True,,,,
There are no tornadoes that resulted in more than 100 fatalities.,Are there no tornadoes that have caused more than 100 fatalities?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_more_than_100_fatalities = any(dataset[""fat""] > 100)
    return not has_more_than_100_fatalities
",bool,False,True,,,,
How many unique states are represented in the dataset?,What is the count of distinct states in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_state_count = dataset['st'].nunique()
    
    return distinct_state_count
",int64,53,53,,,,
What is the highest magnitude of tornado recorded in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the maximum magnitude of tornadoes
    max_magnitude = dataset['mag'].max()
    
    return max_magnitude",int8,5,5,,,,
What is the longest length of a tornado path in the dataset?,What is the maximum length of a tornado path in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_length = dataset['len'].max()
    
    return max_length
",float64  ,234.7,234.7,,,,
What is the maximum number of injuries caused by a single tornado?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_injuries = dataset['inj'].max()
    return max_injuries",int64,1740,1740,,,,
Which state has experienced the most tornadoes?,Which state has had the highest number of tornadoes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    state_counts = dataset['st'].value_counts()
    state_with_most_tornados = state_counts.idxmax()

    return state_with_most_tornados
",string,TX,TX,,,,
In which month do most tornadoes occur?,During which month are the most tornadoes recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by month and count the number of tornadoes
    monthly_tornado_counts = dataset.groupby('mo').size()
    
    # Find the month with the maximum number of tornadoes
    month_with_most_tornados = monthly_tornado_counts.idxmax()
    
    return month_with_most_tornados
",int8,5,5,,,,
On what date did the most destructive tornado (by injuries) occur?,What is the date of the tornado that caused the most injuries?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_injuries_tornado = dataset.loc[dataset[""inj""] == dataset[""inj""].max()]
    date_of_max_injuries = max_injuries_tornado[""date""].iloc[0]

    return date_of_max_injuries
","datetime64[ns, UTC]",10-04-1979,10-04-1979,,,,
On what date did the longest tornado (by path length) occur?,What is the date of occurrence for the tornado with the greatest path length?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_length_tornado = dataset.loc[dataset[""len""] == dataset[""len""].max()]
    date_of_occurrence = max_length_tornado[""date""].iloc[0]

    return date_of_occurrence
","datetime64[us, UTC]",22-03-1953,22-03-1953,,,,
Which are the top 5 states with the highest average tornado magnitude?,What are the top 5 states with the highest average tornado magnitude?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by state and calculate the average magnitude for each state
    avg_magnitude_by_state = dataset.groupby('st')['mag'].mean()
    
    # Get the top 5 states with the highest average magnitude
    top_5_states = avg_magnitude_by_state.nlargest(5).index.tolist()
    
    return top_5_states
",list of (string),"['AR', 'KY', 'VT', 'TN', 'MS']","[AR, KY, VT, TN, MS]",,,,
Which are the top 2 states with the most tornado-related injuries? If in a tie then select alphabetically. ,"What are the top 2 states with the highest number of tornado-related injuries, and in case of a tie, choose alphabetically?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by state and sum the injuries
    injury_counts = dataset.groupby('st')['inj'].sum().reset_index()
    
    # Sort by injury count in descending order, then alphabetically by state
    injury_counts_sorted = injury_counts.sort_values(by=['inj', 'st'], ascending=[False, True])
    
    # Get the top 2 states
    top_2_states = injury_counts_sorted.head(2)['st'].tolist()
    
    return top_2_states
",list of (string),"['TX', 'AL']","[TX, AL]",,,,
Which are the top 4 states with the most tornado-related fatalities? If you find a tie select alphabetically.,"What are the top 4 states with the highest number of tornado-related fatalities? In case of a tie, select them alphabetically.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by state and sum the fatalities for each state
    fatality_by_state = dataset.groupby('st')['fat'].sum().reset_index()
    
    # Sort by fatalities in descending order, then alphabetically by state name in case of a tie
    sorted_fatality_by_state = fatality_by_state.sort_values(by=['fat', 'st'], ascending=[False, True])
    
    # Get the top 4 states with the highest number of fatalities
    top_4_states = sorted_fatality_by_state.head(4)['st'].tolist()
    
    return top_4_states
",list of (string),"['AL', 'TX', 'MS', 'OK']","[AL, TX, MS, OK]",,,,
Which are the bottom 2 states in terms of the average tornado path length?,What are the two states with the shortest average tornado path length?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by state and calculate the average path length for each state
    avg_path_length_by_state = dataset.groupby('st')['len'].mean().reset_index()
    
    # Sort the states by their average path length in ascending order
    sorted_states = avg_path_length_by_state.sort_values(by='len')
    
    # Get the two states with the shortest average path length
    top_two_states = sorted_states.head(2)['st'].tolist()
    
    return top_two_states
",list of (string),"['AK', 'VI']","[AK, VI]",,,,
What are the top 3 number of injuries caused by tornadoes in the dataset?,What are the top 3 highest numbers of injuries caused by tornadoes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by the 'inj' column in descending order and get the top 3 values
    top_injuries = dataset.sort_values(by='inj', ascending=False)['inj'].head(3).tolist()
    
    return top_injuries
",list of (int64),"[1740, 1500, 1228]","[1740, 1500, 1228]",,,,
What are the top 5 magnitudes of tornadoes in the dataset?,What are the top 5 largest magnitudes of tornadoes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_5_magnitudes = dataset['mag'].nlargest(5).tolist()
    return top_5_magnitudes
",list of (int8),"[5, 5, 5, 5, 5]","[5, 5, 5, 5, 5]",,,,
What are the top 4 path lengths of tornadoes in the dataset?,What are the four longest path lengths of tornadoes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
longest_paths = dataset.nlargest(4, 'len')['len'].tolist()
return longest_paths
",list of (float64),"[234.7, 217.8, 202.5, 202.1]","[234.7, 217.8, 202.5, 202.1]",,,,
What are the top 6 number of fatalities caused by tornadoes in the dataset?,What are the top 6 highest fatality counts from tornadoes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_fatality_counts = dataset['fat'].nlargest(6).tolist()
return top_fatality_counts",list of (int64),"[158, 116, 114, 94, 80, 72]","[158, 116, 114, 94, 80, 72]",,,,
There were no days when the precipitation was greater than 5 inches.,Was there never a day when the precipitation exceeded 5 inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_precipitation_exceeded_5_inches = (dataset['PRCP'] > 5).any()
    return not has_precipitation_exceeded_5_inches",bool,False,False,,,,
All recorded temperatures are above freezing point.,Are all recorded minimum temperatures above the freezing point?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    all_above_freezing = (dataset['TMIN'] > 0).all()
    
    return all_above_freezing",bool,False,False,,,,
There were no days when the snow depth was more than 10 inches.,Was there never a day when the snow depth exceeded 10 inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    never_exceeded = dataset['SNWD'].max() <= 10

    return never_exceeded",bool,False,False,,,,
There were no days when the maximum temperature was below freezing point.,Was the highest temperature never below freezing point?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_temperature = dataset['TMAX'].max()
    was_below_freezing = (dataset['TMIN'] < 0).any()

    return not was_below_freezing
",bool,False,False,,,,
What is the highest recorded precipitation in inches?,What is the maximum precipitation recorded in inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_precipitation = dataset['PRCP'].max()
    return max_precipitation
",float64  ,8.28,8.28,,,,
What is the lowest minimum temperature recorded?,What is the minimum value of TMIN recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_tmin_value = dataset['TMIN'].min()
    
    return min_tmin_value
",float64,-015.0,-015.0,,,,
What is the highest maximum temperature recorded?,What is the maximum value of TMAX recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_tmax_value = dataset[""TMAX""].max()
    return max_tmax_value
",float64  ,106.0,106.0,,,,
What is the deepest recorded snow depth in inches?,What is the maximum recorded snow depth in inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_snow_depth = dataset['SNWD'].max()
    return max_snow_depth
",float64  ,26.0,26.0,,,,
On which date was the highest precipitation recorded?,What is the date with the highest precipitation recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_precipitation_date = dataset.loc[dataset[""PRCP""] == dataset[""PRCP""].max(), ""DATE""].iloc[0]

    return max_precipitation_date
",datetime64[ns],23-09-3782,23-09-3782,,,,
On which date was the lowest minimum temperature recorded?,What is the date when the minimum temperature was recorded as the lowest?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_temp_date = dataset.loc[dataset[""TMIN""] == dataset[""TMIN""].min(), ""DATE""]
    return min_temp_date.iloc[0]
","datetime64[ns, UTC]",09-02-1934,09-02-1934,,,,
On which date was the highest maximum temperature recorded?,What is the date with the highest maximum temperature recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
date_with_highest_tmax = dataset.loc[dataset[""TMAX""] == dataset[""TMAX""].max(), ""DATE""]
return date_with_highest_tmax.iloc[0]
",datetime64[ns],09-07-1936,09-07-1936,,,,
On which date was the deepest snow depth recorded?,When was the maximum snow depth recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_snow_depth_date = dataset.loc[dataset[""SNWD""] == dataset[""SNWD""].max(), ""DATE""].iloc[0]

return max_snow_depth_date
",datetime64[ns],27-12-1947,27-12-1947,,,,
What are the dates of the top 5 highest recorded precipitation events?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for all dates where PRCP (precipitation) is greater than 0
    rainy_dates = dataset.loc[dataset[""PRCP""] > 0][""DATE""].tolist()
    
    return rainy_dates",list of (datetime64[ns]),"[Timestamp('1869-01-01 00:00:00+0000', tz='UTC'), Timestamp('1869-01-02 00:00:00+0000', tz='UTC'), Timestamp('1869-01-04 00:00:00+0000', tz='UTC'), Timestamp('1869-01-05 00:00:00+0000', tz='UTC'), Timestamp('1869-01-10 00:00:00+0000', tz='UTC'), Timestamp('1869-01-12 00:00:00+0000', tz='UTC'), Timestamp('1869-01-15 00:00:00+0000', tz='UTC'), Timestamp('1869-01-19 00:00:00+0000', tz='UTC'), Timestamp('1869-01-30 00:00:00+0000', tz='UTC'), Timestamp('1869-02-04 00:00:00+0000', tz='UTC'), Timestamp('1869-02-10 00:00:00+0000', tz='UTC'), Timestamp('1869-02-11 00:00:00+0000', tz='UTC'), Timestamp('1869-02-15 00:00:00+0000', tz='UTC'), Timestamp('1869-02-18 00:00:00+0000', tz='UTC'), Timestamp('1869-02-19 00:00:00+0000', tz='UTC'), Timestamp('1869-02-23 00:00:00+0000', tz='UTC'), Timestamp('1869-02-26 00:00:00+0000', tz='UTC'), Timestamp('1869-03-02 00:00:00+0000', tz='UTC'), Timestamp('1869-03-04 00:00:00+0000', tz='UTC'), Timestamp('1869-03-06 00:00:00+0000', tz='UTC'), Timestamp('1869-03-10 00:00:00+0000', tz='UTC'), Timestamp('1869-03-14 00:00:00+0000', tz='UTC'), Timestamp('1869-03-15 00:00:00+0000', tz='UTC'), Timestamp('1869-03-20 00:00:00+0000', tz='UTC'), Timestamp('1869-03-23 00:00:00+0000', tz='UTC'), Timestamp('1869-03-27 00:00:00+0000', tz='UTC'), Timestamp('1869-03-30 00:00:00+0000', tz='UTC'), Timestamp('1869-03-31 00:00:00+0000', tz='UTC'), Timestamp('1869-04-01 00:00:00+0000', tz='UTC'), Timestamp('1869-04-02 00:00:00+0000', tz='UTC'), Timestamp('1869-04-07 00:00:00+0000', tz='UTC'), Timestamp('1869-04-17 00:00:00+0000', tz='UTC'), Timestamp('1869-04-20 00:00:00+0000', tz='UTC'), Timestamp('1869-04-21 00:00:00+0000', tz='UTC'), Timestamp('1869-04-28 00:00:00+0000', tz='UTC'), Timestamp('1869-04-29 00:00:00+0000', tz='UTC'), Timestamp('1869-05-01 00:00:00+0000', tz='UTC'), Timestamp('1869-05-02 00:00:00+0000', tz='UTC'), Timestamp('1869-05-03 00:00:00+0000', tz='UTC'), Timestamp('1869-05-13 00:00:00+0000', tz='UTC'), Timestamp('1869-05-15 00:00:00+0000', tz='UTC'), Timestamp('1869-05-16 00:00:00+0000', tz='UTC'), Timestamp('1869-05-19 00:00:00+0000', tz='UTC'), Timestamp('1869-05-21 00:00:00+0000', tz='UTC'), Timestamp('1869-05-22 00:00:00+0000', tz='UTC'), Timestamp('1869-05-26 00:00:00+0000', tz='UTC'), Timestamp('1869-05-28 00:00:00+0000', tz='UTC'), Timestamp('1869-05-30 00:00:00+0000', tz='UTC'), Timestamp('1869-05-31 00:00:00+0000', tz='UTC'), Timestamp('1869-06-02 00:00:00+0000', tz='UTC'), Timestamp('1869-06-05 00:00:00+0000', tz='UTC'), Timestamp('1869-06-08 00:00:00+0000', tz='UTC'), Timestamp('1869-06-10 00:00:00+0000', tz='UTC'), Timestamp('1869-06-11 00:00:00+0000', tz='UTC'), Timestamp('1869-06-12 00:00:00+0000', tz='UTC'), Timestamp('1869-06-14 00:00:00+0000', tz='UTC'), Timestamp('1869-06-15 00:00:00+0000', tz='UTC'), Timestamp('1869-06-21 00:00:00+0000', tz='UTC'), Timestamp('1869-06-22 00:00:00+0000', tz='UTC'), Timestamp('1869-06-24 00:00:00+0000', tz='UTC'), Timestamp('1869-06-26 00:00:00+0000', tz='UTC'), Timestamp('1869-06-27 00:00:00+0000', tz='UTC'), Timestamp('1869-06-28 00:00:00+0000', tz='UTC'), Timestamp('1869-06-30 00:00:00+0000', tz='UTC'), Timestamp('1869-07-03 00:00:00+0000', tz='UTC'), Timestamp('1869-07-09 00:00:00+0000', tz='UTC'), Timestamp('1869-07-13 00:00:00+0000', tz='UTC'), Timestamp('1869-07-14 00:00:00+0000', tz='UTC'), Timestamp('1869-07-15 00:00:00+0000', tz='UTC'), Timestamp('1869-07-16 00:00:00+0000', tz='UTC'), Timestamp('1869-07-20 00:00:00+0000', tz='UTC'), Timestamp('1869-07-21 00:00:00+0000', tz='UTC'), Timestamp('1869-07-26 00:00:00+0000', tz='UTC'), Timestamp('1869-07-27 00:00:00+0000', tz='UTC'), Timestamp('1869-07-29 00:00:00+0000', tz='UTC'), Timestamp('1869-08-05 00:00:00+0000', tz='UTC'), Timestamp('1869-08-13 00:00:00+0000', tz='UTC'), Timestamp('1869-08-15 00:00:00+0000', tz='UTC'), Timestamp('1869-08-17 00:00:00+0000', tz='UTC'), Timestamp('1869-08-21 00:00:00+0000', tz='UTC'), Timestamp('1869-08-28 00:00:00+0000', tz='UTC'), Timestamp('1869-09-06 00:00:00+0000', tz='UTC'), Timestamp('1869-09-07 00:00:00+0000', tz='UTC'), Timestamp('1869-09-08 00:00:00+0000', tz='UTC'), Timestamp('1869-09-17 00:00:00+0000', tz='UTC'), Timestamp('1869-09-21 00:00:00+0000', tz='UTC'), Timestamp('1869-09-22 00:00:00+0000', tz='UTC'), Timestamp('1869-09-26 00:00:00+0000', tz='UTC'), Timestamp('1869-09-27 00:00:00+0000', tz='UTC'), Timestamp('1869-10-02 00:00:00+0000', tz='UTC'), Timestamp('1869-10-03 00:00:00+0000', tz='UTC'), Timestamp('1869-10-04 00:00:00+0000', tz='UTC'), Timestamp('1869-10-10 00:00:00+0000', tz='UTC'), Timestamp('1869-10-13 00:00:00+0000', tz='UTC'), Timestamp('1869-10-15 00:00:00+0000', tz='UTC'), Timestamp('1869-10-16 00:00:00+0000', tz='UTC'), Timestamp('1869-10-23 00:00:00+0000', tz='UTC'), Timestamp('1869-10-28 00:00:00+0000', tz='UTC'), Timestamp('1869-10-29 00:00:00+0000', tz='UTC'), Timestamp('1869-11-05 00:00:00+0000', tz='UTC'), Timestamp('1869-11-17 00:00:00+0000', tz='UTC'), Timestamp('1869-11-19 00:00:00+0000', tz='UTC'), Timestamp('1869-11-20 00:00:00+0000', tz='UTC'), Timestamp('1869-11-23 00:00:00+0000', tz='UTC'), Timestamp('1869-11-24 00:00:00+0000', tz='UTC'), Timestamp('1869-11-27 00:00:00+0000', tz='UTC'), Timestamp('1869-11-30 00:00:00+0000', tz='UTC'), Timestamp('1869-12-01 00:00:00+0000', tz='UTC'), Timestamp('1869-12-03 00:00:00+0000', tz='UTC'), Timestamp('1869-12-05 00:00:00+0000', tz='UTC'), Timestamp('1869-12-06 00:00:00+0000', tz='UTC'), Timestamp('1869-12-16 00:00:00+0000', tz='UTC'), Timestamp('1869-12-18 00:00:00+0000', tz='UTC'), Timestamp('1869-12-19 00:00:00+0000', tz='UTC'), Timestamp('1869-12-21 00:00:00+0000', tz='UTC'), Timestamp('1869-12-22 00:00:00+0000', tz='UTC'), Timestamp('1869-12-25 00:00:00+0000', tz='UTC'), Timestamp('1869-12-26 00:00:00+0000', tz='UTC'), Timestamp('1869-12-27 00:00:00+0000', tz='UTC'), Timestamp('1869-12-28 00:00:00+0000', tz='UTC'), Timestamp('1870-01-01 00:00:00+0000', tz='UTC'), Timestamp('1870-01-02 00:00:00+0000', tz='UTC'), Timestamp('1870-01-06 00:00:00+0000', tz='UTC'), Timestamp('1870-01-07 00:00:00+0000', tz='UTC'), Timestamp('1870-01-08 00:00:00+0000', tz='UTC'), Timestamp('1870-01-14 00:00:00+0000', tz='UTC'), Timestamp('1870-01-15 00:00:00+0000', tz='UTC'), Timestamp('1870-01-17 00:00:00+0000', tz='UTC'), Timestamp('1870-01-23 00:00:00+0000', tz='UTC'), Timestamp('1870-01-24 00:00:00+0000', tz='UTC'), Timestamp('1870-01-25 00:00:00+0000', tz='UTC'), Timestamp('1870-01-29 00:00:00+0000', tz='UTC'), Timestamp('1870-01-31 00:00:00+0000', tz='UTC'), Timestamp('1870-02-08 00:00:00+0000', tz='UTC'), Timestamp('1870-02-12 00:00:00+0000', tz='UTC'), Timestamp('1870-02-14 00:00:00+0000', tz='UTC'), Timestamp('1870-02-15 00:00:00+0000', tz='UTC'), Timestamp('1870-02-18 00:00:00+0000', tz='UTC'), Timestamp('1870-02-20 00:00:00+0000', tz='UTC'), Timestamp('1870-02-27 00:00:00+0000', tz='UTC'), Timestamp('1870-02-28 00:00:00+0000', tz='UTC'), Timestamp('1870-03-04 00:00:00+0000', tz='UTC'), Timestamp('1870-03-05 00:00:00+0000', tz='UTC'), Timestamp('1870-03-06 00:00:00+0000', tz='UTC'), Timestamp('1870-03-07 00:00:00+0000', tz='UTC'), Timestamp('1870-03-12 00:00:00+0000', tz='UTC'), Timestamp('1870-03-13 00:00:00+0000', tz='UTC'), Timestamp('1870-03-16 00:00:00+0000', tz='UTC'), Timestamp('1870-03-17 00:00:00+0000', tz='UTC'), Timestamp('1870-03-21 00:00:00+0000', tz='UTC'), Timestamp('1870-03-27 00:00:00+0000', tz='UTC'), Timestamp('1870-03-28 00:00:00+0000', tz='UTC'), Timestamp('1870-04-02 00:00:00+0000', tz='UTC'), Timestamp('1870-04-03 00:00:00+0000', tz='UTC'), Timestamp('1870-04-04 00:00:00+0000', tz='UTC'), Timestamp('1870-04-05 00:00:00+0000', tz='UTC'), Timestamp('1870-04-06 00:00:00+0000', tz='UTC'), Timestamp('1870-04-11 00:00:00+0000', tz='UTC'), Timestamp('1870-04-12 00:00:00+0000', tz='UTC'), Timestamp('1870-04-17 00:00:00+0000', tz='UTC'), Timestamp('1870-04-18 00:00:00+0000', tz='UTC'), Timestamp('1870-04-21 00:00:00+0000', tz='UTC'), Timestamp('1870-04-28 00:00:00+0000', tz='UTC'), Timestamp('1870-04-29 00:00:00+0000', tz='UTC'), Timestamp('1870-05-04 00:00:00+0000', tz='UTC'), Timestamp('1870-05-06 00:00:00+0000', tz='UTC'), Timestamp('1870-05-07 00:00:00+0000', tz='UTC'), Timestamp('1870-05-09 00:00:00+0000', tz='UTC'), Timestamp('1870-05-10 00:00:00+0000', tz='UTC'), Timestamp('1870-05-11 00:00:00+0000', tz='UTC'), Timestamp('1870-05-20 00:00:00+0000', tz='UTC'), Timestamp('1870-05-21 00:00:00+0000', tz='UTC'), Timestamp('1870-05-24 00:00:00+0000', tz='UTC'), Timestamp('1870-05-27 00:00:00+0000', tz='UTC'), Timestamp('1870-05-28 00:00:00+0000', tz='UTC'), Timestamp('1870-05-29 00:00:00+0000', tz='UTC'), Timestamp('1870-06-03 00:00:00+0000', tz='UTC'), Timestamp('1870-06-05 00:00:00+0000', tz='UTC'), Timestamp('1870-06-07 00:00:00+0000', tz='UTC'), Timestamp('1870-06-10 00:00:00+0000', tz='UTC'), Timestamp('1870-06-11 00:00:00+0000', tz='UTC'), Timestamp('1870-06-12 00:00:00+0000', tz='UTC'), Timestamp('1870-06-13 00:00:00+0000', tz='UTC'), Timestamp('1870-06-15 00:00:00+0000', tz='UTC'), Timestamp('1870-06-17 00:00:00+0000', tz='UTC'), Timestamp('1870-06-20 00:00:00+0000', tz='UTC'), Timestamp('1870-06-21 00:00:00+0000', tz='UTC'), Timestamp('1870-06-27 00:00:00+0000', tz='UTC'), Timestamp('1870-06-28 00:00:00+0000', tz='UTC'), Timestamp('1870-07-01 00:00:00+0000', tz='UTC'), Timestamp('1870-07-03 00:00:00+0000', tz='UTC'), Timestamp('1870-07-07 00:00:00+0000', tz='UTC'), Timestamp('1870-07-08 00:00:00+0000', tz='UTC'), Timestamp('1870-07-12 00:00:00+0000', tz='UTC'), Timestamp('1870-07-16 00:00:00+0000', tz='UTC'), Timestamp('1870-07-21 00:00:00+0000', tz='UTC'), Timestamp('1870-07-28 00:00:00+0000', tz='UTC'), Timestamp('1870-08-04 00:00:00+0000', tz='UTC'), Timestamp('1870-08-10 00:00:00+0000', tz='UTC'), Timestamp('1870-08-11 00:00:00+0000', tz='UTC'), Timestamp('1870-08-13 00:00:00+0000', tz='UTC'), Timestamp('1870-08-14 00:00:00+0000', tz='UTC'), Timestamp('1870-08-24 00:00:00+0000', tz='UTC'), Timestamp('1870-08-25 00:00:00+0000', tz='UTC'), Timestamp('1870-08-26 00:00:00+0000', tz='UTC'), Timestamp('1870-09-17 00:00:00+0000', tz='UTC'), Timestamp('1870-09-18 00:00:00+0000', tz='UTC'), Timestamp('1870-09-30 00:00:00+0000', tz='UTC'), Timestamp('1870-10-01 00:00:00+0000', tz='UTC'), Timestamp('1870-10-03 00:00:00+0000', tz='UTC'), Timestamp('1870-10-11 00:00:00+0000', tz='UTC'), Timestamp('1870-10-12 00:00:00+0000', tz='UTC'), Timestamp('1870-10-13 00:00:00+0000', tz='UTC'), Timestamp('1870-10-20 00:00:00+0000', tz='UTC'), Timestamp('1870-10-26 00:00:00+0000', tz='UTC'), Timestamp('1870-10-27 00:00:00+0000', tz='UTC'), Timestamp('1870-10-28 00:00:00+0000', tz='UTC'), Timestamp('1870-10-30 00:00:00+0000', tz='UTC'), Timestamp('1870-10-31 00:00:00+0000', tz='UTC'), Timestamp('1870-11-02 00:00:00+0000', tz='UTC'), Timestamp('1870-11-05 00:00:00+0000', tz='UTC'), Timestamp('1870-11-09 00:00:00+0000', tz='UTC'), Timestamp('1870-11-22 00:00:00+0000', tz='UTC'), Timestamp('1870-11-23 00:00:00+0000', tz='UTC'), Timestamp('1870-11-25 00:00:00+0000', tz='UTC'), Timestamp('1870-11-26 00:00:00+0000', tz='UTC'), Timestamp('1870-12-07 00:00:00+0000', tz='UTC'), Timestamp('1870-12-11 00:00:00+0000', tz='UTC'), Timestamp('1870-12-12 00:00:00+0000', tz='UTC'), Timestamp('1870-12-19 00:00:00+0000', tz='UTC'), Timestamp('1870-12-20 00:00:00+0000', tz='UTC'), Timestamp('1870-12-28 00:00:00+0000', tz='UTC'), Timestamp('1870-12-30 00:00:00+0000', tz='UTC'), Timestamp('1871-01-06 00:00:00+0000', tz='UTC'), Timestamp('1871-01-08 00:00:00+0000', tz='UTC'), Timestamp('1871-01-15 00:00:00+0000', tz='UTC'), Timestamp('1871-01-16 00:00:00+0000', tz='UTC'), Timestamp('1871-01-21 00:00:00+0000', tz='UTC'), Timestamp('1871-01-23 00:00:00+0000', tz='UTC'), Timestamp('1871-01-24 00:00:00+0000', tz='UTC'), Timestamp('1871-01-26 00:00:00+0000', tz='UTC'), Timestamp('1871-01-27 00:00:00+0000', tz='UTC'), Timestamp('1871-01-28 00:00:00+0000', tz='UTC'), Timestamp('1871-01-29 00:00:00+0000', tz='UTC'), Timestamp('1871-01-31 00:00:00+0000', tz='UTC'), Timestamp('1871-02-01 00:00:00+0000', tz='UTC'), Timestamp('1871-02-08 00:00:00+0000', tz='UTC'), Timestamp('1871-02-12 00:00:00+0000', tz='UTC'), Timestamp('1871-02-14 00:00:00+0000', tz='UTC'), Timestamp('1871-02-18 00:00:00+0000', tz='UTC'), Timestamp('1871-02-20 00:00:00+0000', tz='UTC'), Timestamp('1871-02-21 00:00:00+0000', tz='UTC'), Timestamp('1871-02-26 00:00:00+0000', tz='UTC'), Timestamp('1871-02-27 00:00:00+0000', tz='UTC'), Timestamp('1871-03-03 00:00:00+0000', tz='UTC'), Timestamp('1871-03-04 00:00:00+0000', tz='UTC'), Timestamp('1871-03-06 00:00:00+0000', tz='UTC'), Timestamp('1871-03-08 00:00:00+0000', tz='UTC'), Timestamp('1871-03-09 00:00:00+0000', tz='UTC'), Timestamp('1871-03-10 00:00:00+0000', tz='UTC'), Timestamp('1871-03-11 00:00:00+0000', tz='UTC'), Timestamp('1871-03-12 00:00:00+0000', tz='UTC'), Timestamp('1871-03-14 00:00:00+0000', tz='UTC'), Timestamp('1871-03-15 00:00:00+0000', tz='UTC'), Timestamp('1871-03-16 00:00:00+0000', tz='UTC'), Timestamp('1871-03-17 00:00:00+0000', tz='UTC'), Timestamp('1871-03-18 00:00:00+0000', tz='UTC'), Timestamp('1871-03-20 00:00:00+0000', tz='UTC'), Timestamp('1871-03-21 00:00:00+0000', tz='UTC'), Timestamp('1871-03-26 00:00:00+0000', tz='UTC'), Timestamp('1871-03-27 00:00:00+0000', tz='UTC'), Timestamp('1871-03-30 00:00:00+0000', tz='UTC'), Timestamp('1871-04-01 00:00:00+0000', tz='UTC'), Timestamp('1871-04-02 00:00:00+0000', tz='UTC'), Timestamp('1871-04-04 00:00:00+0000', tz='UTC'), Timestamp('1871-04-11 00:00:00+0000', tz='UTC'), Timestamp('1871-04-13 00:00:00+0000', tz='UTC'), Timestamp('1871-04-15 00:00:00+0000', tz='UTC'), Timestamp('1871-04-19 00:00:00+0000', tz='UTC'), Timestamp('1871-04-20 00:00:00+0000', tz='UTC'), Timestamp('1871-04-21 00:00:00+0000', tz='UTC'), Timestamp('1871-04-27 00:00:00+0000', tz='UTC'), Timestamp('1871-04-28 00:00:00+0000', tz='UTC'), Timestamp('1871-05-03 00:00:00+0000', tz='UTC'), Timestamp('1871-05-04 00:00:00+0000', tz='UTC'), Timestamp('1871-05-05 00:00:00+0000', tz='UTC'), Timestamp('1871-05-06 00:00:00+0000', tz='UTC'), Timestamp('1871-05-07 00:00:00+0000', tz='UTC'), Timestamp('1871-05-16 00:00:00+0000', tz='UTC'), Timestamp('1871-05-31 00:00:00+0000', tz='UTC'), Timestamp('1871-06-04 00:00:00+0000', tz='UTC'), Timestamp('1871-06-07 00:00:00+0000', tz='UTC'), Timestamp('1871-06-11 00:00:00+0000', tz='UTC'), Timestamp('1871-06-12 00:00:00+0000', tz='UTC'), Timestamp('1871-06-13 00:00:00+0000', tz='UTC'), Timestamp('1871-06-15 00:00:00+0000', tz='UTC'), Timestamp('1871-06-18 00:00:00+0000', tz='UTC'), Timestamp('1871-06-20 00:00:00+0000', tz='UTC'), Timestamp('1871-06-24 00:00:00+0000', tz='UTC'), Timestamp('1871-06-28 00:00:00+0000', tz='UTC'), Timestamp('1871-07-03 00:00:00+0000', tz='UTC'), Timestamp('1871-07-06 00:00:00+0000', tz='UTC'), Timestamp('1871-07-07 00:00:00+0000', tz='UTC'), Timestamp('1871-07-09 00:00:00+0000', tz='UTC'), Timestamp('1871-07-10 00:00:00+0000', tz='UTC'), Timestamp('1871-07-11 00:00:00+0000', tz='UTC'), Timestamp('1871-07-12 00:00:00+0000', tz='UTC'), Timestamp('1871-07-15 00:00:00+0000', tz='UTC'), Timestamp('1871-07-16 00:00:00+0000', tz='UTC'), Timestamp('1871-07-17 00:00:00+0000', tz='UTC'), Timestamp('1871-07-19 00:00:00+0000', tz='UTC'), Timestamp('1871-07-20 00:00:00+0000', tz='UTC'), Timestamp('1871-07-21 00:00:00+0000', tz='UTC'), Timestamp('1871-07-22 00:00:00+0000', tz='UTC'), Timestamp('1871-07-25 00:00:00+0000', tz='UTC'), Timestamp('1871-07-26 00:00:00+0000', tz='UTC'), Timestamp('1871-07-27 00:00:00+0000', tz='UTC'), Timestamp('1871-07-28 00:00:00+0000', tz='UTC'), Timestamp('1871-07-29 00:00:00+0000', tz='UTC'), Timestamp('1871-07-31 00:00:00+0000', tz='UTC'), Timestamp('1871-08-04 00:00:00+0000', tz='UTC'), Timestamp('1871-08-05 00:00:00+0000', tz='UTC'), Timestamp('1871-08-08 00:00:00+0000', tz='UTC'), Timestamp('1871-08-16 00:00:00+0000', tz='UTC'), Timestamp('1871-08-23 00:00:00+0000', tz='UTC'), Timestamp('1871-08-24 00:00:00+0000', tz='UTC'), Timestamp('1871-08-25 00:00:00+0000', tz='UTC'), Timestamp('1871-08-26 00:00:00+0000', tz='UTC'), Timestamp('1871-08-27 00:00:00+0000', tz='UTC'), Timestamp('1871-08-28 00:00:00+0000', tz='UTC'), Timestamp('1871-08-29 00:00:00+0000', tz='UTC'), Timestamp('1871-08-30 00:00:00+0000', tz='UTC'), Timestamp('1871-09-13 00:00:00+0000', tz='UTC'), Timestamp('1871-09-15 00:00:00+0000', tz='UTC'), Timestamp('1871-09-16 00:00:00+0000', tz='UTC'), Timestamp('1871-09-20 00:00:00+0000', tz='UTC'), Timestamp('1871-09-26 00:00:00+0000', tz='UTC'), Timestamp('1871-10-03 00:00:00+0000', tz='UTC'), Timestamp('1871-10-06 00:00:00+0000', tz='UTC'), Timestamp('1871-10-07 00:00:00+0000', tz='UTC'), Timestamp('1871-10-10 00:00:00+0000', tz='UTC'), Timestamp('1871-10-11 00:00:00+0000', tz='UTC'), Timestamp('1871-10-24 00:00:00+0000', tz='UTC'), Timestamp('1871-10-25 00:00:00+0000', tz='UTC'), Timestamp('1871-10-26 00:00:00+0000', tz='UTC'), Timestamp('1871-10-27 00:00:00+0000', tz='UTC'), Timestamp('1871-11-01 00:00:00+0000', tz='UTC'), Timestamp('1871-11-10 00:00:00+0000', tz='UTC'), Timestamp('1871-11-14 00:00:00+0000', tz='UTC'), Timestamp('1871-11-15 00:00:00+0000', tz='UTC'), Timestamp('1871-11-20 00:00:00+0000', tz='UTC'), Timestamp('1871-11-22 00:00:00+0000', tz='UTC'), Timestamp('1871-11-24 00:00:00+0000', tz='UTC'), Timestamp('1871-11-27 00:00:00+0000', tz='UTC'), Timestamp('1871-11-29 00:00:00+0000', tz='UTC'), Timestamp('1871-12-03 00:00:00+0000', tz='UTC'), Timestamp('1871-12-04 00:00:00+0000', tz='UTC'), Timestamp('1871-12-07 00:00:00+0000', tz='UTC'), Timestamp('1871-12-13 00:00:00+0000', tz='UTC'), Timestamp('1871-12-17 00:00:00+0000', tz='UTC'), Timestamp('1871-12-18 00:00:00+0000', tz='UTC'), Timestamp('1871-12-19 00:00:00+0000', tz='UTC'), Timestamp('1871-12-20 00:00:00+0000', tz='UTC'), Timestamp('1871-12-22 00:00:00+0000', tz='UTC'), Timestamp('1871-12-23 00:00:00+0000', tz='UTC'), Timestamp('1871-12-26 00:00:00+0000', tz='UTC'), Timestamp('1871-12-27 00:00:00+0000', tz='UTC'), Timestamp('1871-12-29 00:00:00+0000', tz='UTC'), Timestamp('1871-12-30 00:00:00+0000', tz='UTC'), Timestamp('1871-12-31 00:00:00+0000', tz='UTC'), Timestamp('1872-01-03 00:00:00+0000', tz='UTC'), Timestamp('1872-01-04 00:00:00+0000', tz='UTC'), Timestamp('1872-01-16 00:00:00+0000', tz='UTC'), Timestamp('1872-01-19 00:00:00+0000', tz='UTC'), Timestamp('1872-01-20 00:00:00+0000', tz='UTC'), Timestamp('1872-01-28 00:00:00+0000', tz='UTC'), Timestamp('1872-02-03 00:00:00+0000', tz='UTC'), Timestamp('1872-02-06 00:00:00+0000', tz='UTC'), Timestamp('1872-02-11 00:00:00+0000', tz='UTC'), Timestamp('1872-02-13 00:00:00+0000', tz='UTC'), Timestamp('1872-02-14 00:00:00+0000', tz='UTC'), Timestamp('1872-02-25 00:00:00+0000', tz='UTC'), Timestamp('1872-03-02 00:00:00+0000', tz='UTC'), Timestamp('1872-03-04 00:00:00+0000', tz='UTC'), Timestamp('1872-03-09 00:00:00+0000', tz='UTC'), Timestamp('1872-03-10 00:00:00+0000', tz='UTC'), Timestamp('1872-03-12 00:00:00+0000', tz='UTC'), Timestamp('1872-03-14 00:00:00+0000', tz='UTC'), Timestamp('1872-03-15 00:00:00+0000', tz='UTC'), Timestamp('1872-03-17 00:00:00+0000', tz='UTC'), Timestamp('1872-03-23 00:00:00+0000', tz='UTC'), Timestamp('1872-03-25 00:00:00+0000', tz='UTC'), Timestamp('1872-03-31 00:00:00+0000', tz='UTC'), Timestamp('1872-04-07 00:00:00+0000', tz='UTC'), Timestamp('1872-04-08 00:00:00+0000', tz='UTC'), Timestamp('1872-04-09 00:00:00+0000', tz='UTC'), Timestamp('1872-04-10 00:00:00+0000', tz='UTC'), Timestamp('1872-04-13 00:00:00+0000', tz='UTC'), Timestamp('1872-04-15 00:00:00+0000', tz='UTC'), Timestamp('1872-04-18 00:00:00+0000', tz='UTC'), Timestamp('1872-04-19 00:00:00+0000', tz='UTC'), Timestamp('1872-04-23 00:00:00+0000', tz='UTC'), Timestamp('1872-05-02 00:00:00+0000', tz='UTC'), Timestamp('1872-05-04 00:00:00+0000', tz='UTC'), Timestamp('1872-05-10 00:00:00+0000', tz='UTC'), Timestamp('1872-05-19 00:00:00+0000', tz='UTC'), Timestamp('1872-05-20 00:00:00+0000', tz='UTC'), Timestamp('1872-05-22 00:00:00+0000', tz='UTC'), Timestamp('1872-05-23 00:00:00+0000', tz='UTC'), Timestamp('1872-05-27 00:00:00+0000', tz='UTC'), Timestamp('1872-05-30 00:00:00+0000', tz='UTC'), Timestamp('1872-06-01 00:00:00+0000', tz='UTC'), Timestamp('1872-06-04 00:00:00+0000', tz='UTC'), Timestamp('1872-06-05 00:00:00+0000', tz='UTC'), Timestamp('1872-06-07 00:00:00+0000', tz='UTC'), Timestamp('1872-06-08 00:00:00+0000', tz='UTC'), Timestamp('1872-06-10 00:00:00+0000', tz='UTC'), Timestamp('1872-06-12 00:00:00+0000', tz='UTC'), Timestamp('1872-06-14 00:00:00+0000', tz='UTC'), Timestamp('1872-06-25 00:00:00+0000', tz='UTC'), Timestamp('1872-06-26 00:00:00+0000', tz='UTC'), Timestamp('1872-06-29 00:00:00+0000', tz='UTC'), Timestamp('1872-07-04 00:00:00+0000', tz='UTC'), Timestamp('1872-07-05 00:00:00+0000', tz='UTC'), Timestamp('1872-07-10 00:00:00+0000', tz='UTC'), Timestamp('1872-07-11 00:00:00+0000', tz='UTC'), Timestamp('1872-07-12 00:00:00+0000', tz='UTC'), Timestamp('1872-07-15 00:00:00+0000', tz='UTC'), Timestamp('1872-07-16 00:00:00+0000', tz='UTC'), Timestamp('1872-07-18 00:00:00+0000', tz='UTC'), Timestamp('1872-07-22 00:00:00+0000', tz='UTC'), Timestamp('1872-07-24 00:00:00+0000', tz='UTC'), Timestamp('1872-07-26 00:00:00+0000', tz='UTC'), Timestamp('1872-07-31 00:00:00+0000', tz='UTC'), Timestamp('1872-08-02 00:00:00+0000', tz='UTC'), Timestamp('1872-08-04 00:00:00+0000', tz='UTC'), Timestamp('1872-08-10 00:00:00+0000', tz='UTC'), Timestamp('1872-08-12 00:00:00+0000', tz='UTC'), Timestamp('1872-08-13 00:00:00+0000', tz='UTC'), Timestamp('1872-08-15 00:00:00+0000', tz='UTC'), Timestamp('1872-08-16 00:00:00+0000', tz='UTC'), Timestamp('1872-08-17 00:00:00+0000', tz='UTC'), Timestamp('1872-08-19 00:00:00+0000', tz='UTC'), Timestamp('1872-08-20 00:00:00+0000', tz='UTC'), Timestamp('1872-08-22 00:00:00+0000', tz='UTC'), Timestamp('1872-08-29 00:00:00+0000', tz='UTC'), Timestamp('1872-08-30 00:00:00+0000', tz='UTC'), Timestamp('1872-09-02 00:00:00+0000', tz='UTC'), Timestamp('1872-09-09 00:00:00+0000', tz='UTC'), Timestamp('1872-09-13 00:00:00+0000', tz='UTC'), Timestamp('1872-09-15 00:00:00+0000', tz='UTC'), Timestamp('1872-09-16 00:00:00+0000', tz='UTC'), Timestamp('1872-09-19 00:00:00+0000', tz='UTC'), Timestamp('1872-09-26 00:00:00+0000', tz='UTC'), Timestamp('1872-09-27 00:00:00+0000', tz='UTC'), Timestamp('1872-09-28 00:00:00+0000', tz='UTC'), Timestamp('1872-10-01 00:00:00+0000', tz='UTC'), Timestamp('1872-10-02 00:00:00+0000', tz='UTC'), Timestamp('1872-10-07 00:00:00+0000', tz='UTC'), Timestamp('1872-10-08 00:00:00+0000', tz='UTC'), Timestamp('1872-10-10 00:00:00+0000', tz='UTC'), Timestamp('1872-10-18 00:00:00+0000', tz='UTC'), Timestamp('1872-10-23 00:00:00+0000', tz='UTC'), Timestamp('1872-10-24 00:00:00+0000', tz='UTC'), Timestamp('1872-10-25 00:00:00+0000', tz='UTC'), Timestamp('1872-10-26 00:00:00+0000', tz='UTC'), Timestamp('1872-10-27 00:00:00+0000', tz='UTC'), Timestamp('1872-10-28 00:00:00+0000', tz='UTC'), Timestamp('1872-11-03 00:00:00+0000', tz='UTC'), Timestamp('1872-11-06 00:00:00+0000', tz='UTC'), Timestamp('1872-11-07 00:00:00+0000', tz='UTC'), Timestamp('1872-11-11 00:00:00+0000', tz='UTC'), Timestamp('1872-11-12 00:00:00+0000', tz='UTC'), Timestamp('1872-11-14 00:00:00+0000', tz='UTC'), Timestamp('1872-11-16 00:00:00+0000', tz='UTC'), Timestamp('1872-11-22 00:00:00+0000', tz='UTC'), Timestamp('1872-11-26 00:00:00+0000', tz='UTC'), Timestamp('1872-11-29 00:00:00+0000', tz='UTC'), Timestamp('1872-12-01 00:00:00+0000', tz='UTC'), Timestamp('1872-12-02 00:00:00+0000', tz='UTC'), Timestamp('1872-12-08 00:00:00+0000', tz='UTC'), Timestamp('1872-12-16 00:00:00+0000', tz='UTC'), Timestamp('1872-12-18 00:00:00+0000', tz='UTC'), Timestamp('1872-12-19 00:00:00+0000', tz='UTC'), Timestamp('1872-12-20 00:00:00+0000', tz='UTC'), Timestamp('1872-12-26 00:00:00+0000', tz='UTC'), Timestamp('1872-12-30 00:00:00+0000', tz='UTC'), Timestamp('1872-12-31 00:00:00+0000', tz='UTC'), Timestamp('1873-01-02 00:00:00+0000', tz='UTC'), Timestamp('1873-01-03 00:00:00+0000', tz='UTC'), Timestamp('1873-01-05 00:00:00+0000', tz='UTC'), Timestamp('1873-01-08 00:00:00+0000', tz='UTC'), Timestamp('1873-01-09 00:00:00+0000', tz='UTC'), Timestamp('1873-01-14 00:00:00+0000', tz='UTC'), Timestamp('1873-01-16 00:00:00+0000', tz='UTC'), Timestamp('1873-01-17 00:00:00+0000', tz='UTC'), Timestamp('1873-01-18 00:00:00+0000', tz='UTC'), Timestamp('1873-01-20 00:00:00+0000', tz='UTC'), Timestamp('1873-01-21 00:00:00+0000', tz='UTC'), Timestamp('1873-01-22 00:00:00+0000', tz='UTC'), Timestamp('1873-01-23 00:00:00+0000', tz='UTC'), Timestamp('1873-01-24 00:00:00+0000', tz='UTC'), Timestamp('1873-01-27 00:00:00+0000', tz='UTC'), Timestamp('1873-02-03 00:00:00+0000', tz='UTC'), Timestamp('1873-02-04 00:00:00+0000', tz='UTC'), Timestamp('1873-02-07 00:00:00+0000', tz='UTC'), Timestamp('1873-02-12 00:00:00+0000', tz='UTC'), Timestamp('1873-02-13 00:00:00+0000', tz='UTC'), Timestamp('1873-02-16 00:00:00+0000', tz='UTC'), Timestamp('1873-02-19 00:00:00+0000', tz='UTC'), Timestamp('1873-02-21 00:00:00+0000', tz='UTC'), Timestamp('1873-02-27 00:00:00+0000', tz='UTC'), Timestamp('1873-03-03 00:00:00+0000', tz='UTC'), Timestamp('1873-03-10 00:00:00+0000', tz='UTC'), Timestamp('1873-03-11 00:00:00+0000', tz='UTC'), Timestamp('1873-03-18 00:00:00+0000', tz='UTC'), Timestamp('1873-03-20 00:00:00+0000', tz='UTC'), Timestamp('1873-03-21 00:00:00+0000', tz='UTC'), Timestamp('1873-03-24 00:00:00+0000', tz='UTC'), Timestamp('1873-03-25 00:00:00+0000', tz='UTC'), Timestamp('1873-03-26 00:00:00+0000', tz='UTC'), Timestamp('1873-03-29 00:00:00+0000', tz='UTC'), Timestamp('1873-03-31 00:00:00+0000', tz='UTC'), Timestamp('1873-04-01 00:00:00+0000', tz='UTC'), Timestamp('1873-04-02 00:00:00+0000', tz='UTC'), Timestamp('1873-04-05 00:00:00+0000', tz='UTC'), Timestamp('1873-04-06 00:00:00+0000', tz='UTC'), Timestamp('1873-04-09 00:00:00+0000', tz='UTC'), Timestamp('1873-04-10 00:00:00+0000', tz='UTC'), Timestamp('1873-04-12 00:00:00+0000', tz='UTC'), Timestamp('1873-04-16 00:00:00+0000', tz='UTC'), Timestamp('1873-04-17 00:00:00+0000', tz='UTC'), Timestamp('1873-04-18 00:00:00+0000', tz='UTC'), Timestamp('1873-04-19 00:00:00+0000', tz='UTC'), Timestamp('1873-04-22 00:00:00+0000', tz='UTC'), Timestamp('1873-04-23 00:00:00+0000', tz='UTC'), Timestamp('1873-04-29 00:00:00+0000', tz='UTC'), Timestamp('1873-04-30 00:00:00+0000', tz='UTC'), Timestamp('1873-05-02 00:00:00+0000', tz='UTC'), Timestamp('1873-05-03 00:00:00+0000', tz='UTC'), Timestamp('1873-05-08 00:00:00+0000', tz='UTC'), Timestamp('1873-05-09 00:00:00+0000', tz='UTC'), Timestamp('1873-05-11 00:00:00+0000', tz='UTC'), Timestamp('1873-05-12 00:00:00+0000', tz='UTC'), Timestamp('1873-05-13 00:00:00+0000', tz='UTC'), Timestamp('1873-05-21 00:00:00+0000', tz='UTC'), Timestamp('1873-05-22 00:00:00+0000', tz='UTC'), Timestamp('1873-05-24 00:00:00+0000', tz='UTC'), Timestamp('1873-05-30 00:00:00+0000', tz='UTC'), Timestamp('1873-06-04 00:00:00+0000', tz='UTC'), Timestamp('1873-06-05 00:00:00+0000', tz='UTC'), Timestamp('1873-06-06 00:00:00+0000', tz='UTC'), Timestamp('1873-06-10 00:00:00+0000', tz='UTC'), Timestamp('1873-06-23 00:00:00+0000', tz='UTC'), Timestamp('1873-06-24 00:00:00+0000', tz='UTC'), Timestamp('1873-06-28 00:00:00+0000', tz='UTC'), Timestamp('1873-07-01 00:00:00+0000', tz='UTC'), Timestamp('1873-07-03 00:00:00+0000', tz='UTC'), Timestamp('1873-07-04 00:00:00+0000', tz='UTC'), Timestamp('1873-07-05 00:00:00+0000', tz='UTC'), Timestamp('1873-07-11 00:00:00+0000', tz='UTC'), Timestamp('1873-07-15 00:00:00+0000', tz='UTC'), Timestamp('1873-07-17 00:00:00+0000', tz='UTC'), Timestamp('1873-07-18 00:00:00+0000', tz='UTC'), Timestamp('1873-07-19 00:00:00+0000', tz='UTC'), Timestamp('1873-07-26 00:00:00+0000', tz='UTC'), Timestamp('1873-07-27 00:00:00+0000', tz='UTC'), Timestamp('1873-07-29 00:00:00+0000', tz='UTC'), Timestamp('1873-08-01 00:00:00+0000', tz='UTC'), Timestamp('1873-08-03 00:00:00+0000', tz='UTC'), Timestamp('1873-08-08 00:00:00+0000', tz='UTC'), Timestamp('1873-08-13 00:00:00+0000', tz='UTC'), Timestamp('1873-08-14 00:00:00+0000', tz='UTC'), Timestamp('1873-08-16 00:00:00+0000', tz='UTC'), Timestamp('1873-08-17 00:00:00+0000', tz='UTC'), Timestamp('1873-08-18 00:00:00+0000', tz='UTC'), Timestamp('1873-08-19 00:00:00+0000', tz='UTC'), Timestamp('1873-08-20 00:00:00+0000', tz='UTC'), Timestamp('1873-08-21 00:00:00+0000', tz='UTC'), Timestamp('1873-08-29 00:00:00+0000', tz='UTC'), Timestamp('1873-08-30 00:00:00+0000', tz='UTC'), Timestamp('1873-08-31 00:00:00+0000', tz='UTC'), Timestamp('1873-09-01 00:00:00+0000', tz='UTC'), Timestamp('1873-09-04 00:00:00+0000', tz='UTC'), Timestamp('1873-09-07 00:00:00+0000', tz='UTC'), Timestamp('1873-09-08 00:00:00+0000', tz='UTC'), Timestamp('1873-09-10 00:00:00+0000', tz='UTC'), Timestamp('1873-09-13 00:00:00+0000', tz='UTC'), Timestamp('1873-09-14 00:00:00+0000', tz='UTC'), Timestamp('1873-09-19 00:00:00+0000', tz='UTC'), Timestamp('1873-09-23 00:00:00+0000', tz='UTC'), Timestamp('1873-09-24 00:00:00+0000', tz='UTC'), Timestamp('1873-09-25 00:00:00+0000', tz='UTC'), Timestamp('1873-09-26 00:00:00+0000', tz='UTC'), Timestamp('1873-09-29 00:00:00+0000', tz='UTC'), Timestamp('1873-09-30 00:00:00+0000', tz='UTC'), Timestamp('1873-10-04 00:00:00+0000', tz='UTC'), Timestamp('1873-10-06 00:00:00+0000', tz='UTC'), Timestamp('1873-10-07 00:00:00+0000', tz='UTC'), Timestamp('1873-10-19 00:00:00+0000', tz='UTC'), Timestamp('1873-10-20 00:00:00+0000', tz='UTC'), Timestamp('1873-10-21 00:00:00+0000', tz='UTC'), Timestamp('1873-10-26 00:00:00+0000', tz='UTC'), Timestamp('1873-10-27 00:00:00+0000', tz='UTC'), Timestamp('1873-10-30 00:00:00+0000', tz='UTC'), Timestamp('1873-11-07 00:00:00+0000', tz='UTC'), Timestamp('1873-11-08 00:00:00+0000', tz='UTC'), Timestamp('1873-11-11 00:00:00+0000', tz='UTC'), Timestamp('1873-11-12 00:00:00+0000', tz='UTC'), Timestamp('1873-11-17 00:00:00+0000', tz='UTC'), Timestamp('1873-11-18 00:00:00+0000', tz='UTC'), Timestamp('1873-11-23 00:00:00+0000', tz='UTC'), Timestamp('1873-11-24 00:00:00+0000', tz='UTC'), Timestamp('1873-12-01 00:00:00+0000', tz='UTC'), Timestamp('1873-12-02 00:00:00+0000', tz='UTC'), Timestamp('1873-12-08 00:00:00+0000', tz='UTC'), Timestamp('1873-12-09 00:00:00+0000', tz='UTC'), Timestamp('1873-12-11 00:00:00+0000', tz='UTC'), Timestamp('1873-12-12 00:00:00+0000', tz='UTC'), Timestamp('1873-12-13 00:00:00+0000', tz='UTC'), Timestamp('1873-12-19 00:00:00+0000', tz='UTC'), Timestamp('1873-12-23 00:00:00+0000', tz='UTC'), Timestamp('1873-12-26 00:00:00+0000', tz='UTC'), Timestamp('1873-12-27 00:00:00+0000', tz='UTC'), Timestamp('1873-12-28 00:00:00+0000', tz='UTC'), Timestamp('1874-01-01 00:00:00+0000', tz='UTC'), Timestamp('1874-01-02 00:00:00+0000', tz='UTC'), Timestamp('1874-01-05 00:00:00+0000', tz='UTC'), Timestamp('1874-01-06 00:00:00+0000', tz='UTC'), Timestamp('1874-01-07 00:00:00+0000', tz='UTC'), Timestamp('1874-01-08 00:00:00+0000', tz='UTC'), Timestamp('1874-01-14 00:00:00+0000', tz='UTC'), Timestamp('1874-01-19 00:00:00+0000', tz='UTC'), Timestamp('1874-01-21 00:00:00+0000', tz='UTC'), Timestamp('1874-01-22 00:00:00+0000', tz='UTC'), Timestamp('1874-01-23 00:00:00+0000', tz='UTC'), Timestamp('1874-01-28 00:00:00+0000', tz='UTC'), Timestamp('1874-02-02 00:00:00+0000', tz='UTC'), Timestamp('1874-02-03 00:00:00+0000', tz='UTC'), Timestamp('1874-02-06 00:00:00+0000', tz='UTC'), Timestamp('1874-02-07 00:00:00+0000', tz='UTC'), Timestamp('1874-02-13 00:00:00+0000', tz='UTC'), Timestamp('1874-02-14 00:00:00+0000', tz='UTC'), Timestamp('1874-02-19 00:00:00+0000', tz='UTC'), Timestamp('1874-02-20 00:00:00+0000', tz='UTC'), Timestamp('1874-02-21 00:00:00+0000', tz='UTC'), Timestamp('1874-02-25 00:00:00+0000', tz='UTC'), Timestamp('1874-02-26 00:00:00+0000', tz='UTC'), Timestamp('1874-03-04 00:00:00+0000', tz='UTC'), Timestamp('1874-03-06 00:00:00+0000', tz='UTC'), Timestamp('1874-03-07 00:00:00+0000', tz='UTC'), Timestamp('1874-03-17 00:00:00+0000', tz='UTC'), Timestamp('1874-03-18 00:00:00+0000', tz='UTC'), Timestamp('1874-03-19 00:00:00+0000', tz='UTC'), Timestamp('1874-03-27 00:00:00+0000', tz='UTC'), Timestamp('1874-03-28 00:00:00+0000', tz='UTC'), Timestamp('1874-03-31 00:00:00+0000', tz='UTC'), Timestamp('1874-04-05 00:00:00+0000', tz='UTC'), Timestamp('1874-04-06 00:00:00+0000', tz='UTC'), Timestamp('1874-04-07 00:00:00+0000', tz='UTC'), Timestamp('1874-04-08 00:00:00+0000', tz='UTC'), Timestamp('1874-04-09 00:00:00+0000', tz='UTC'), Timestamp('1874-04-10 00:00:00+0000', tz='UTC'), Timestamp('1874-04-11 00:00:00+0000', tz='UTC'), Timestamp('1874-04-15 00:00:00+0000', tz='UTC'), Timestamp('1874-04-17 00:00:00+0000', tz='UTC'), Timestamp('1874-04-19 00:00:00+0000', tz='UTC'), Timestamp('1874-04-20 00:00:00+0000', tz='UTC'), Timestamp('1874-04-23 00:00:00+000","""[1882-09-23",15-04-2007,08-11-1977,09-10-1903,31-08-2021
What are the dates of the top 3 lowest minimum temperatures recorded?,What are the dates corresponding to the top 3 lowest minimum temperatures?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by TMIN in ascending order
    sorted_dataset = dataset.sort_values(by='TMIN')
    
    # Get the top 3 rows with the lowest minimum temperatures
    top_3_lowest_tmin = sorted_dataset.head(3)
    
    # Extract the dates corresponding to these rows
    dates = top_3_lowest_tmin['DATE'].tolist()
    
    return dates
",list of (datetime64[ns]),"[Timestamp('1934-02-09 00:00:00+0000', tz='UTC'), Timestamp('1917-12-30 00:00:00+0000', tz='UTC'), Timestamp('1943-02-15 00:00:00+0000', tz='UTC')]","[1934-02-09, 1917-12-30, 1943-02-15]",,,,
What are the dates of the top 4 highest maximum temperatures recorded?,What are the dates associated with the top 4 highest maximum temperatures recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by TMAX in descending order and get the top 4 rows
    top_4_max_temps = dataset.nlargest(4, 'TMAX')
    
    # Extract the DATE column from these top 4 rows
    dates = top_4_max_temps['DATE'].tolist()
    
    return dates
",list of (datetime64[ns]),"[Timestamp('1936-07-09 00:00:00+0000', tz='UTC'), Timestamp('1918-08-07 00:00:00+0000', tz='UTC'), Timestamp('1977-07-21 00:00:00+0000', tz='UTC'), Timestamp('2011-07-22 00:00:00+0000', tz='UTC')]","[1936-07-09, 1918-08-07, 1977-07-21, 2011-07-22]",,,,
What are the dates of the top 2 deepest snow depth recorded?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for all dates in the dataset
return dataset['DATE'].tolist()","list of (datetime64[us, UTC])","[Timestamp('1869-01-01 00:00:00+0000', tz='UTC'), Timestamp('1869-01-02 00:00:00+0000', tz='UTC'), Timestamp('1869-01-03 00:00:00+0000', tz='UTC'), Timestamp('1869-01-04 00:00:00+0000', tz='UTC'), Timestamp('1869-01-05 00:00:00+0000', tz='UTC'), Timestamp('1869-01-06 00:00:00+0000', tz='UTC'), Timestamp('1869-01-07 00:00:00+0000', tz='UTC'), Timestamp('1869-01-08 00:00:00+0000', tz='UTC'), Timestamp('1869-01-09 00:00:00+0000', tz='UTC'), Timestamp('1869-01-10 00:00:00+0000', tz='UTC'), Timestamp('1869-01-11 00:00:00+0000', tz='UTC'), Timestamp('1869-01-12 00:00:00+0000', tz='UTC'), Timestamp('1869-01-13 00:00:00+0000', tz='UTC'), Timestamp('1869-01-14 00:00:00+0000', tz='UTC'), Timestamp('1869-01-15 00:00:00+0000', tz='UTC'), Timestamp('1869-01-16 00:00:00+0000', tz='UTC'), Timestamp('1869-01-17 00:00:00+0000', tz='UTC'), Timestamp('1869-01-18 00:00:00+0000', tz='UTC'), Timestamp('1869-01-19 00:00:00+0000', tz='UTC'), Timestamp('1869-01-20 00:00:00+0000', tz='UTC'), Timestamp('1869-01-21 00:00:00+0000', tz='UTC'), Timestamp('1869-01-22 00:00:00+0000', tz='UTC'), Timestamp('1869-01-23 00:00:00+0000', tz='UTC'), Timestamp('1869-01-24 00:00:00+0000', tz='UTC'), Timestamp('1869-01-25 00:00:00+0000', tz='UTC'), Timestamp('1869-01-26 00:00:00+0000', tz='UTC'), Timestamp('1869-01-27 00:00:00+0000', tz='UTC'), Timestamp('1869-01-28 00:00:00+0000', tz='UTC'), Timestamp('1869-01-29 00:00:00+0000', tz='UTC'), Timestamp('1869-01-30 00:00:00+0000', tz='UTC'), Timestamp('1869-01-31 00:00:00+0000', tz='UTC'), Timestamp('1869-02-01 00:00:00+0000', tz='UTC'), Timestamp('1869-02-02 00:00:00+0000', tz='UTC'), Timestamp('1869-02-03 00:00:00+0000', tz='UTC'), Timestamp('1869-02-04 00:00:00+0000', tz='UTC'), Timestamp('1869-02-05 00:00:00+0000', tz='UTC'), Timestamp('1869-02-06 00:00:00+0000', tz='UTC'), Timestamp('1869-02-07 00:00:00+0000', tz='UTC'), Timestamp('1869-02-08 00:00:00+0000', tz='UTC'), Timestamp('1869-02-09 00:00:00+0000', tz='UTC'), Timestamp('1869-02-10 00:00:00+0000', tz='UTC'), Timestamp('1869-02-11 00:00:00+0000', tz='UTC'), Timestamp('1869-02-12 00:00:00+0000', tz='UTC'), Timestamp('1869-02-13 00:00:00+0000', tz='UTC'), Timestamp('1869-02-14 00:00:00+0000', tz='UTC'), Timestamp('1869-02-15 00:00:00+0000', tz='UTC'), Timestamp('1869-02-16 00:00:00+0000', tz='UTC'), Timestamp('1869-02-17 00:00:00+0000', tz='UTC'), Timestamp('1869-02-18 00:00:00+0000', tz='UTC'), Timestamp('1869-02-19 00:00:00+0000', tz='UTC'), Timestamp('1869-02-20 00:00:00+0000', tz='UTC'), Timestamp('1869-02-21 00:00:00+0000', tz='UTC'), Timestamp('1869-02-22 00:00:00+0000', tz='UTC'), Timestamp('1869-02-23 00:00:00+0000', tz='UTC'), Timestamp('1869-02-24 00:00:00+0000', tz='UTC'), Timestamp('1869-02-25 00:00:00+0000', tz='UTC'), Timestamp('1869-02-26 00:00:00+0000', tz='UTC'), Timestamp('1869-02-27 00:00:00+0000', tz='UTC'), Timestamp('1869-02-28 00:00:00+0000', tz='UTC'), Timestamp('1869-03-01 00:00:00+0000', tz='UTC'), Timestamp('1869-03-02 00:00:00+0000', tz='UTC'), Timestamp('1869-03-03 00:00:00+0000', tz='UTC'), Timestamp('1869-03-04 00:00:00+0000', tz='UTC'), Timestamp('1869-03-05 00:00:00+0000', tz='UTC'), Timestamp('1869-03-06 00:00:00+0000', tz='UTC'), Timestamp('1869-03-07 00:00:00+0000', tz='UTC'), Timestamp('1869-03-08 00:00:00+0000', tz='UTC'), Timestamp('1869-03-09 00:00:00+0000', tz='UTC'), Timestamp('1869-03-10 00:00:00+0000', tz='UTC'), Timestamp('1869-03-11 00:00:00+0000', tz='UTC'), Timestamp('1869-03-12 00:00:00+0000', tz='UTC'), Timestamp('1869-03-13 00:00:00+0000', tz='UTC'), Timestamp('1869-03-14 00:00:00+0000', tz='UTC'), Timestamp('1869-03-15 00:00:00+0000', tz='UTC'), Timestamp('1869-03-16 00:00:00+0000', tz='UTC'), Timestamp('1869-03-17 00:00:00+0000', tz='UTC'), Timestamp('1869-03-18 00:00:00+0000', tz='UTC'), Timestamp('1869-03-19 00:00:00+0000', tz='UTC'), Timestamp('1869-03-20 00:00:00+0000', tz='UTC'), Timestamp('1869-03-21 00:00:00+0000', tz='UTC'), Timestamp('1869-03-22 00:00:00+0000', tz='UTC'), Timestamp('1869-03-23 00:00:00+0000', tz='UTC'), Timestamp('1869-03-24 00:00:00+0000', tz='UTC'), Timestamp('1869-03-25 00:00:00+0000', tz='UTC'), Timestamp('1869-03-26 00:00:00+0000', tz='UTC'), Timestamp('1869-03-27 00:00:00+0000', tz='UTC'), Timestamp('1869-03-28 00:00:00+0000', tz='UTC'), Timestamp('1869-03-29 00:00:00+0000', tz='UTC'), Timestamp('1869-03-30 00:00:00+0000', tz='UTC'), Timestamp('1869-03-31 00:00:00+0000', tz='UTC'), Timestamp('1869-04-01 00:00:00+0000', tz='UTC'), Timestamp('1869-04-02 00:00:00+0000', tz='UTC'), Timestamp('1869-04-03 00:00:00+0000', tz='UTC'), Timestamp('1869-04-04 00:00:00+0000', tz='UTC'), Timestamp('1869-04-05 00:00:00+0000', tz='UTC'), Timestamp('1869-04-06 00:00:00+0000', tz='UTC'), Timestamp('1869-04-07 00:00:00+0000', tz='UTC'), Timestamp('1869-04-08 00:00:00+0000', tz='UTC'), Timestamp('1869-04-09 00:00:00+0000', tz='UTC'), Timestamp('1869-04-10 00:00:00+0000', tz='UTC'), Timestamp('1869-04-11 00:00:00+0000', tz='UTC'), Timestamp('1869-04-12 00:00:00+0000', tz='UTC'), Timestamp('1869-04-13 00:00:00+0000', tz='UTC'), Timestamp('1869-04-14 00:00:00+0000', tz='UTC'), Timestamp('1869-04-15 00:00:00+0000', tz='UTC'), Timestamp('1869-04-16 00:00:00+0000', tz='UTC'), Timestamp('1869-04-17 00:00:00+0000', tz='UTC'), Timestamp('1869-04-18 00:00:00+0000', tz='UTC'), Timestamp('1869-04-19 00:00:00+0000', tz='UTC'), Timestamp('1869-04-20 00:00:00+0000', tz='UTC'), Timestamp('1869-04-21 00:00:00+0000', tz='UTC'), Timestamp('1869-04-22 00:00:00+0000', tz='UTC'), Timestamp('1869-04-23 00:00:00+0000', tz='UTC'), Timestamp('1869-04-24 00:00:00+0000', tz='UTC'), Timestamp('1869-04-25 00:00:00+0000', tz='UTC'), Timestamp('1869-04-26 00:00:00+0000', tz='UTC'), Timestamp('1869-04-27 00:00:00+0000', tz='UTC'), Timestamp('1869-04-28 00:00:00+0000', tz='UTC'), Timestamp('1869-04-29 00:00:00+0000', tz='UTC'), Timestamp('1869-04-30 00:00:00+0000', tz='UTC'), Timestamp('1869-05-01 00:00:00+0000', tz='UTC'), Timestamp('1869-05-02 00:00:00+0000', tz='UTC'), Timestamp('1869-05-03 00:00:00+0000', tz='UTC'), Timestamp('1869-05-04 00:00:00+0000', tz='UTC'), Timestamp('1869-05-05 00:00:00+0000', tz='UTC'), Timestamp('1869-05-06 00:00:00+0000', tz='UTC'), Timestamp('1869-05-07 00:00:00+0000', tz='UTC'), Timestamp('1869-05-08 00:00:00+0000', tz='UTC'), Timestamp('1869-05-09 00:00:00+0000', tz='UTC'), Timestamp('1869-05-10 00:00:00+0000', tz='UTC'), Timestamp('1869-05-11 00:00:00+0000', tz='UTC'), Timestamp('1869-05-12 00:00:00+0000', tz='UTC'), Timestamp('1869-05-13 00:00:00+0000', tz='UTC'), Timestamp('1869-05-14 00:00:00+0000', tz='UTC'), Timestamp('1869-05-15 00:00:00+0000', tz='UTC'), Timestamp('1869-05-16 00:00:00+0000', tz='UTC'), Timestamp('1869-05-17 00:00:00+0000', tz='UTC'), Timestamp('1869-05-18 00:00:00+0000', tz='UTC'), Timestamp('1869-05-19 00:00:00+0000', tz='UTC'), Timestamp('1869-05-20 00:00:00+0000', tz='UTC'), Timestamp('1869-05-21 00:00:00+0000', tz='UTC'), Timestamp('1869-05-22 00:00:00+0000', tz='UTC'), Timestamp('1869-05-23 00:00:00+0000', tz='UTC'), Timestamp('1869-05-24 00:00:00+0000', tz='UTC'), Timestamp('1869-05-25 00:00:00+0000', tz='UTC'), Timestamp('1869-05-26 00:00:00+0000', tz='UTC'), Timestamp('1869-05-27 00:00:00+0000', tz='UTC'), Timestamp('1869-05-28 00:00:00+0000', tz='UTC'), Timestamp('1869-05-29 00:00:00+0000', tz='UTC'), Timestamp('1869-05-30 00:00:00+0000', tz='UTC'), Timestamp('1869-05-31 00:00:00+0000', tz='UTC'), Timestamp('1869-06-01 00:00:00+0000', tz='UTC'), Timestamp('1869-06-02 00:00:00+0000', tz='UTC'), Timestamp('1869-06-03 00:00:00+0000', tz='UTC'), Timestamp('1869-06-04 00:00:00+0000', tz='UTC'), Timestamp('1869-06-05 00:00:00+0000', tz='UTC'), Timestamp('1869-06-06 00:00:00+0000', tz='UTC'), Timestamp('1869-06-07 00:00:00+0000', tz='UTC'), Timestamp('1869-06-08 00:00:00+0000', tz='UTC'), Timestamp('1869-06-09 00:00:00+0000', tz='UTC'), Timestamp('1869-06-10 00:00:00+0000', tz='UTC'), Timestamp('1869-06-11 00:00:00+0000', tz='UTC'), Timestamp('1869-06-12 00:00:00+0000', tz='UTC'), Timestamp('1869-06-13 00:00:00+0000', tz='UTC'), Timestamp('1869-06-14 00:00:00+0000', tz='UTC'), Timestamp('1869-06-15 00:00:00+0000', tz='UTC'), Timestamp('1869-06-16 00:00:00+0000', tz='UTC'), Timestamp('1869-06-17 00:00:00+0000', tz='UTC'), Timestamp('1869-06-18 00:00:00+0000', tz='UTC'), Timestamp('1869-06-19 00:00:00+0000', tz='UTC'), Timestamp('1869-06-20 00:00:00+0000', tz='UTC'), Timestamp('1869-06-21 00:00:00+0000', tz='UTC'), Timestamp('1869-06-22 00:00:00+0000', tz='UTC'), Timestamp('1869-06-23 00:00:00+0000', tz='UTC'), Timestamp('1869-06-24 00:00:00+0000', tz='UTC'), Timestamp('1869-06-25 00:00:00+0000', tz='UTC'), Timestamp('1869-06-26 00:00:00+0000', tz='UTC'), Timestamp('1869-06-27 00:00:00+0000', tz='UTC'), Timestamp('1869-06-28 00:00:00+0000', tz='UTC'), Timestamp('1869-06-29 00:00:00+0000', tz='UTC'), Timestamp('1869-06-30 00:00:00+0000', tz='UTC'), Timestamp('1869-07-01 00:00:00+0000', tz='UTC'), Timestamp('1869-07-02 00:00:00+0000', tz='UTC'), Timestamp('1869-07-03 00:00:00+0000', tz='UTC'), Timestamp('1869-07-04 00:00:00+0000', tz='UTC'), Timestamp('1869-07-05 00:00:00+0000', tz='UTC'), Timestamp('1869-07-06 00:00:00+0000', tz='UTC'), Timestamp('1869-07-07 00:00:00+0000', tz='UTC'), Timestamp('1869-07-08 00:00:00+0000', tz='UTC'), Timestamp('1869-07-09 00:00:00+0000', tz='UTC'), Timestamp('1869-07-10 00:00:00+0000', tz='UTC'), Timestamp('1869-07-11 00:00:00+0000', tz='UTC'), Timestamp('1869-07-12 00:00:00+0000', tz='UTC'), Timestamp('1869-07-13 00:00:00+0000', tz='UTC'), Timestamp('1869-07-14 00:00:00+0000', tz='UTC'), Timestamp('1869-07-15 00:00:00+0000', tz='UTC'), Timestamp('1869-07-16 00:00:00+0000', tz='UTC'), Timestamp('1869-07-17 00:00:00+0000', tz='UTC'), Timestamp('1869-07-18 00:00:00+0000', tz='UTC'), Timestamp('1869-07-19 00:00:00+0000', tz='UTC'), Timestamp('1869-07-20 00:00:00+0000', tz='UTC'), Timestamp('1869-07-21 00:00:00+0000', tz='UTC'), Timestamp('1869-07-22 00:00:00+0000', tz='UTC'), Timestamp('1869-07-23 00:00:00+0000', tz='UTC'), Timestamp('1869-07-24 00:00:00+0000', tz='UTC'), Timestamp('1869-07-25 00:00:00+0000', tz='UTC'), Timestamp('1869-07-26 00:00:00+0000', tz='UTC'), Timestamp('1869-07-27 00:00:00+0000', tz='UTC'), Timestamp('1869-07-28 00:00:00+0000', tz='UTC'), Timestamp('1869-07-29 00:00:00+0000', tz='UTC'), Timestamp('1869-07-30 00:00:00+0000', tz='UTC'), Timestamp('1869-07-31 00:00:00+0000', tz='UTC'), Timestamp('1869-08-01 00:00:00+0000', tz='UTC'), Timestamp('1869-08-02 00:00:00+0000', tz='UTC'), Timestamp('1869-08-03 00:00:00+0000', tz='UTC'), Timestamp('1869-08-04 00:00:00+0000', tz='UTC'), Timestamp('1869-08-05 00:00:00+0000', tz='UTC'), Timestamp('1869-08-06 00:00:00+0000', tz='UTC'), Timestamp('1869-08-07 00:00:00+0000', tz='UTC'), Timestamp('1869-08-08 00:00:00+0000', tz='UTC'), Timestamp('1869-08-09 00:00:00+0000', tz='UTC'), Timestamp('1869-08-10 00:00:00+0000', tz='UTC'), Timestamp('1869-08-11 00:00:00+0000', tz='UTC'), Timestamp('1869-08-12 00:00:00+0000', tz='UTC'), Timestamp('1869-08-13 00:00:00+0000', tz='UTC'), Timestamp('1869-08-14 00:00:00+0000', tz='UTC'), Timestamp('1869-08-15 00:00:00+0000', tz='UTC'), Timestamp('1869-08-16 00:00:00+0000', tz='UTC'), Timestamp('1869-08-17 00:00:00+0000', tz='UTC'), Timestamp('1869-08-18 00:00:00+0000', tz='UTC'), Timestamp('1869-08-19 00:00:00+0000', tz='UTC'), Timestamp('1869-08-20 00:00:00+0000', tz='UTC'), Timestamp('1869-08-21 00:00:00+0000', tz='UTC'), Timestamp('1869-08-22 00:00:00+0000', tz='UTC'), Timestamp('1869-08-23 00:00:00+0000', tz='UTC'), Timestamp('1869-08-24 00:00:00+0000', tz='UTC'), Timestamp('1869-08-25 00:00:00+0000', tz='UTC'), Timestamp('1869-08-26 00:00:00+0000', tz='UTC'), Timestamp('1869-08-27 00:00:00+0000', tz='UTC'), Timestamp('1869-08-28 00:00:00+0000', tz='UTC'), Timestamp('1869-08-29 00:00:00+0000', tz='UTC'), Timestamp('1869-08-30 00:00:00+0000', tz='UTC'), Timestamp('1869-08-31 00:00:00+0000', tz='UTC'), Timestamp('1869-09-01 00:00:00+0000', tz='UTC'), Timestamp('1869-09-02 00:00:00+0000', tz='UTC'), Timestamp('1869-09-03 00:00:00+0000', tz='UTC'), Timestamp('1869-09-04 00:00:00+0000', tz='UTC'), Timestamp('1869-09-05 00:00:00+0000', tz='UTC'), Timestamp('1869-09-06 00:00:00+0000', tz='UTC'), Timestamp('1869-09-07 00:00:00+0000', tz='UTC'), Timestamp('1869-09-08 00:00:00+0000', tz='UTC'), Timestamp('1869-09-09 00:00:00+0000', tz='UTC'), Timestamp('1869-09-10 00:00:00+0000', tz='UTC'), Timestamp('1869-09-11 00:00:00+0000', tz='UTC'), Timestamp('1869-09-12 00:00:00+0000', tz='UTC'), Timestamp('1869-09-13 00:00:00+0000', tz='UTC'), Timestamp('1869-09-14 00:00:00+0000', tz='UTC'), Timestamp('1869-09-15 00:00:00+0000', tz='UTC'), Timestamp('1869-09-16 00:00:00+0000', tz='UTC'), Timestamp('1869-09-17 00:00:00+0000', tz='UTC'), Timestamp('1869-09-18 00:00:00+0000', tz='UTC'), Timestamp('1869-09-19 00:00:00+0000', tz='UTC'), Timestamp('1869-09-20 00:00:00+0000', tz='UTC'), Timestamp('1869-09-21 00:00:00+0000', tz='UTC'), Timestamp('1869-09-22 00:00:00+0000', tz='UTC'), Timestamp('1869-09-23 00:00:00+0000', tz='UTC'), Timestamp('1869-09-24 00:00:00+0000', tz='UTC'), Timestamp('1869-09-25 00:00:00+0000', tz='UTC'), Timestamp('1869-09-26 00:00:00+0000', tz='UTC'), Timestamp('1869-09-27 00:00:00+0000', tz='UTC'), Timestamp('1869-09-28 00:00:00+0000', tz='UTC'), Timestamp('1869-09-29 00:00:00+0000', tz='UTC'), Timestamp('1869-09-30 00:00:00+0000', tz='UTC'), Timestamp('1869-10-01 00:00:00+0000', tz='UTC'), Timestamp('1869-10-02 00:00:00+0000', tz='UTC'), Timestamp('1869-10-03 00:00:00+0000', tz='UTC'), Timestamp('1869-10-04 00:00:00+0000', tz='UTC'), Timestamp('1869-10-05 00:00:00+0000', tz='UTC'), Timestamp('1869-10-06 00:00:00+0000', tz='UTC'), Timestamp('1869-10-07 00:00:00+0000', tz='UTC'), Timestamp('1869-10-08 00:00:00+0000', tz='UTC'), Timestamp('1869-10-09 00:00:00+0000', tz='UTC'), Timestamp('1869-10-10 00:00:00+0000', tz='UTC'), Timestamp('1869-10-11 00:00:00+0000', tz='UTC'), Timestamp('1869-10-12 00:00:00+0000', tz='UTC'), Timestamp('1869-10-13 00:00:00+0000', tz='UTC'), Timestamp('1869-10-14 00:00:00+0000', tz='UTC'), Timestamp('1869-10-15 00:00:00+0000', tz='UTC'), Timestamp('1869-10-16 00:00:00+0000', tz='UTC'), Timestamp('1869-10-17 00:00:00+0000', tz='UTC'), Timestamp('1869-10-18 00:00:00+0000', tz='UTC'), Timestamp('1869-10-19 00:00:00+0000', tz='UTC'), Timestamp('1869-10-20 00:00:00+0000', tz='UTC'), Timestamp('1869-10-21 00:00:00+0000', tz='UTC'), Timestamp('1869-10-22 00:00:00+0000', tz='UTC'), Timestamp('1869-10-23 00:00:00+0000', tz='UTC'), Timestamp('1869-10-24 00:00:00+0000', tz='UTC'), Timestamp('1869-10-25 00:00:00+0000', tz='UTC'), Timestamp('1869-10-26 00:00:00+0000', tz='UTC'), Timestamp('1869-10-27 00:00:00+0000', tz='UTC'), Timestamp('1869-10-28 00:00:00+0000', tz='UTC'), Timestamp('1869-10-29 00:00:00+0000', tz='UTC'), Timestamp('1869-10-30 00:00:00+0000', tz='UTC'), Timestamp('1869-10-31 00:00:00+0000', tz='UTC'), Timestamp('1869-11-01 00:00:00+0000', tz='UTC'), Timestamp('1869-11-02 00:00:00+0000', tz='UTC'), Timestamp('1869-11-03 00:00:00+0000', tz='UTC'), Timestamp('1869-11-04 00:00:00+0000', tz='UTC'), Timestamp('1869-11-05 00:00:00+0000', tz='UTC'), Timestamp('1869-11-06 00:00:00+0000', tz='UTC'), Timestamp('1869-11-07 00:00:00+0000', tz='UTC'), Timestamp('1869-11-08 00:00:00+0000', tz='UTC'), Timestamp('1869-11-09 00:00:00+0000', tz='UTC'), Timestamp('1869-11-10 00:00:00+0000', tz='UTC'), Timestamp('1869-11-11 00:00:00+0000', tz='UTC'), Timestamp('1869-11-12 00:00:00+0000', tz='UTC'), Timestamp('1869-11-13 00:00:00+0000', tz='UTC'), Timestamp('1869-11-14 00:00:00+0000', tz='UTC'), Timestamp('1869-11-15 00:00:00+0000', tz='UTC'), Timestamp('1869-11-16 00:00:00+0000', tz='UTC'), Timestamp('1869-11-17 00:00:00+0000', tz='UTC'), Timestamp('1869-11-18 00:00:00+0000', tz='UTC'), Timestamp('1869-11-19 00:00:00+0000', tz='UTC'), Timestamp('1869-11-20 00:00:00+0000', tz='UTC'), Timestamp('1869-11-21 00:00:00+0000', tz='UTC'), Timestamp('1869-11-22 00:00:00+0000', tz='UTC'), Timestamp('1869-11-23 00:00:00+0000', tz='UTC'), Timestamp('1869-11-24 00:00:00+0000', tz='UTC'), Timestamp('1869-11-25 00:00:00+0000', tz='UTC'), Timestamp('1869-11-26 00:00:00+0000', tz='UTC'), Timestamp('1869-11-27 00:00:00+0000', tz='UTC'), Timestamp('1869-11-28 00:00:00+0000', tz='UTC'), Timestamp('1869-11-29 00:00:00+0000', tz='UTC'), Timestamp('1869-11-30 00:00:00+0000', tz='UTC'), Timestamp('1869-12-01 00:00:00+0000', tz='UTC'), Timestamp('1869-12-02 00:00:00+0000', tz='UTC'), Timestamp('1869-12-03 00:00:00+0000', tz='UTC'), Timestamp('1869-12-04 00:00:00+0000', tz='UTC'), Timestamp('1869-12-05 00:00:00+0000', tz='UTC'), Timestamp('1869-12-06 00:00:00+0000', tz='UTC'), Timestamp('1869-12-07 00:00:00+0000', tz='UTC'), Timestamp('1869-12-08 00:00:00+0000', tz='UTC'), Timestamp('1869-12-09 00:00:00+0000', tz='UTC'), Timestamp('1869-12-10 00:00:00+0000', tz='UTC'), Timestamp('1869-12-11 00:00:00+0000', tz='UTC'), Timestamp('1869-12-12 00:00:00+0000', tz='UTC'), Timestamp('1869-12-13 00:00:00+0000', tz='UTC'), Timestamp('1869-12-14 00:00:00+0000', tz='UTC'), Timestamp('1869-12-15 00:00:00+0000', tz='UTC'), Timestamp('1869-12-16 00:00:00+0000', tz='UTC'), Timestamp('1869-12-17 00:00:00+0000', tz='UTC'), Timestamp('1869-12-18 00:00:00+0000', tz='UTC'), Timestamp('1869-12-19 00:00:00+0000', tz='UTC'), Timestamp('1869-12-20 00:00:00+0000', tz='UTC'), Timestamp('1869-12-21 00:00:00+0000', tz='UTC'), Timestamp('1869-12-22 00:00:00+0000', tz='UTC'), Timestamp('1869-12-23 00:00:00+0000', tz='UTC'), Timestamp('1869-12-24 00:00:00+0000', tz='UTC'), Timestamp('1869-12-25 00:00:00+0000', tz='UTC'), Timestamp('1869-12-26 00:00:00+0000', tz='UTC'), Timestamp('1869-12-27 00:00:00+0000', tz='UTC'), Timestamp('1869-12-28 00:00:00+0000', tz='UTC'), Timestamp('1869-12-29 00:00:00+0000', tz='UTC'), Timestamp('1869-12-30 00:00:00+0000', tz='UTC'), Timestamp('1869-12-31 00:00:00+0000', tz='UTC'), Timestamp('1870-01-01 00:00:00+0000', tz='UTC'), Timestamp('1870-01-02 00:00:00+0000', tz='UTC'), Timestamp('1870-01-03 00:00:00+0000', tz='UTC'), Timestamp('1870-01-04 00:00:00+0000', tz='UTC'), Timestamp('1870-01-05 00:00:00+0000', tz='UTC'), Timestamp('1870-01-06 00:00:00+0000', tz='UTC'), Timestamp('1870-01-07 00:00:00+0000', tz='UTC'), Timestamp('1870-01-08 00:00:00+0000', tz='UTC'), Timestamp('1870-01-09 00:00:00+0000', tz='UTC'), Timestamp('1870-01-10 00:00:00+0000', tz='UTC'), Timestamp('1870-01-11 00:00:00+0000', tz='UTC'), Timestamp('1870-01-12 00:00:00+0000', tz='UTC'), Timestamp('1870-01-13 00:00:00+0000', tz='UTC'), Timestamp('1870-01-14 00:00:00+0000', tz='UTC'), Timestamp('1870-01-15 00:00:00+0000', tz='UTC'), Timestamp('1870-01-16 00:00:00+0000', tz='UTC'), Timestamp('1870-01-17 00:00:00+0000', tz='UTC'), Timestamp('1870-01-18 00:00:00+0000', tz='UTC'), Timestamp('1870-01-19 00:00:00+0000', tz='UTC'), Timestamp('1870-01-20 00:00:00+0000', tz='UTC'), Timestamp('1870-01-21 00:00:00+0000', tz='UTC'), Timestamp('1870-01-22 00:00:00+0000', tz='UTC'), Timestamp('1870-01-23 00:00:00+0000', tz='UTC'), Timestamp('1870-01-24 00:00:00+0000', tz='UTC'), Timestamp('1870-01-25 00:00:00+0000', tz='UTC'), Timestamp('1870-01-26 00:00:00+0000', tz='UTC'), Timestamp('1870-01-27 00:00:00+0000', tz='UTC'), Timestamp('1870-01-28 00:00:00+0000', tz='UTC'), Timestamp('1870-01-29 00:00:00+0000', tz='UTC'), Timestamp('1870-01-30 00:00:00+0000', tz='UTC'), Timestamp('1870-01-31 00:00:00+0000', tz='UTC'), Timestamp('1870-02-01 00:00:00+0000', tz='UTC'), Timestamp('1870-02-02 00:00:00+0000', tz='UTC'), Timestamp('1870-02-03 00:00:00+0000', tz='UTC'), Timestamp('1870-02-04 00:00:00+0000', tz='UTC'), Timestamp('1870-02-05 00:00:00+0000', tz='UTC'), Timestamp('1870-02-06 00:00:00+0000', tz='UTC'), Timestamp('1870-02-07 00:00:00+0000', tz='UTC'), Timestamp('1870-02-08 00:00:00+0000', tz='UTC'), Timestamp('1870-02-09 00:00:00+0000', tz='UTC'), Timestamp('1870-02-10 00:00:00+0000', tz='UTC'), Timestamp('1870-02-11 00:00:00+0000', tz='UTC'), Timestamp('1870-02-12 00:00:00+0000', tz='UTC'), Timestamp('1870-02-13 00:00:00+0000', tz='UTC'), Timestamp('1870-02-14 00:00:00+0000', tz='UTC'), Timestamp('1870-02-15 00:00:00+0000', tz='UTC'), Timestamp('1870-02-16 00:00:00+0000', tz='UTC'), Timestamp('1870-02-17 00:00:00+0000', tz='UTC'), Timestamp('1870-02-18 00:00:00+0000', tz='UTC'), Timestamp('1870-02-19 00:00:00+0000', tz='UTC'), Timestamp('1870-02-20 00:00:00+0000', tz='UTC'), Timestamp('1870-02-21 00:00:00+0000', tz='UTC'), Timestamp('1870-02-22 00:00:00+0000', tz='UTC'), Timestamp('1870-02-23 00:00:00+0000', tz='UTC'), Timestamp('1870-02-24 00:00:00+0000', tz='UTC'), Timestamp('1870-02-25 00:00:00+0000', tz='UTC'), Timestamp('1870-02-26 00:00:00+0000', tz='UTC'), Timestamp('1870-02-27 00:00:00+0000', tz='UTC'), Timestamp('1870-02-28 00:00:00+0000', tz='UTC'), Timestamp('1870-03-01 00:00:00+0000', tz='UTC'), Timestamp('1870-03-02 00:00:00+0000', tz='UTC'), Timestamp('1870-03-03 00:00:00+0000', tz='UTC'), Timestamp('1870-03-04 00:00:00+0000', tz='UTC'), Timestamp('1870-03-05 00:00:00+0000', tz='UTC'), Timestamp('1870-03-06 00:00:00+0000', tz='UTC'), Timestamp('1870-03-07 00:00:00+0000', tz='UTC'), Timestamp('1870-03-08 00:00:00+0000', tz='UTC'), Timestamp('1870-03-09 00:00:00+0000', tz='UTC'), Timestamp('1870-03-10 00:00:00+0000', tz='UTC'), Timestamp('1870-03-11 00:00:00+0000', tz='UTC'), Timestamp('1870-03-12 00:00:00+0000', tz='UTC'), Timestamp('1870-03-13 00:00:00+0000', tz='UTC'), Timestamp('1870-03-14 00:00:00+0000', tz='UTC'), Timestamp('1870-03-15 00:00:00+0000', tz='UTC'), Timestamp('1870-03-16 00:00:00+0000', tz='UTC'), Timestamp('1870-03-17 00:00:00+0000', tz='UTC'), Timestamp('1870-03-18 00:00:00+0000', tz='UTC'), Timestamp('1870-03-19 00:00:00+0000', tz='UTC'), Timestamp('1870-03-20 00:00:00+0000', tz='UTC'), Timestamp('1870-03-21 00:00:00+0000', tz='UTC'), Timestamp('1870-03-22 00:00:00+0000', tz='UTC'), Timestamp('1870-03-23 00:00:00+0000', tz='UTC'), Timestamp('1870-03-24 00:00:00+0000', tz='UTC'), Timestamp('1870-03-25 00:00:00+0000', tz='UTC'), Timestamp('1870-03-26 00:00:00+0000', tz='UTC'), Timestamp('1870-03-27 00:00:00+0000', tz='UTC'), Timestamp('1870-03-28 00:00:00+0000', tz='UTC'), Timestamp('1870-03-29 00:00:00+0000', tz='UTC'), Timestamp('1870-03-30 00:00:00+0000', tz='UTC'), Timestamp('1870-03-31 00:00:00+0000', tz='UTC'), Timestamp('1870-04-01 00:00:00+0000', tz='UTC'), Timestamp('1870-04-02 00:00:00+0000', tz='UTC'), Timestamp('1870-04-03 00:00:00+0000', tz='UTC'), Timestamp('1870-04-04 00:00:00+0000', tz='UTC'), Timestamp('1870-04-05 00:00:00+0000', tz='UTC'), Timestamp('1870-04-06 00:00:00+0000', tz='UTC'), Timestamp('1870-04-07 00:00:00+0000', tz='UTC'), Timestamp('1870-04-08 00:00:00+0000', tz='UTC'), Timestamp('1870-04-09 00:00:00+0000', tz='UTC'), Timestamp('1870-04-10 00:00:00+0000', tz='UTC'), Timestamp('1870-04-11 00:00:00+0000', tz='UTC'), Timestamp('1870-04-12 00:00:00+0000', tz='UTC'), Timestamp('1870-04-13 00:00:00+0000', tz='UTC'), Timestamp('1870-04-14 00:00:00+0000', tz='UTC'), Timestamp('1870-04-15 00:00:00+0000', tz='UTC'), Timestamp('1870-04-16 00:00:00+0000', tz='UTC'), Timestamp('1870-04-17 00:00:00+0000', tz='UTC'), Timestamp('1870-04-18 00:00:00+0000', tz='UTC'), Timestamp('1870-04-19 00:00:00+0000', tz='UTC'), Timestamp('1870-04-20 00:00:00+0000', tz='UTC'), Timestamp('1870-04-21 00:00:00+0000', tz='UTC'), Timestamp('1870-04-22 00:00:00+0000', tz='UTC'), Timestamp('1870-04-23 00:00:00+0000', tz='UTC'), Timestamp('1870-04-24 00:00:00+0000', tz='UTC'), Timestamp('1870-04-25 00:00:00+0000', tz='UTC'), Timestamp('1870-04-26 00:00:00+0000', tz='UTC'), Timestamp('1870-04-27 00:00:00+0000', tz='UTC'), Timestamp('1870-04-28 00:00:00+0000', tz='UTC'), Timestamp('1870-04-29 00:00:00+0000', tz='UTC'), Timestamp('1870-04-30 00:00:00+0000', tz='UTC'), Timestamp('1870-05-01 00:00:00+0000', tz='UTC'), Timestamp('1870-05-02 00:00:00+0000', tz='UTC'), Timestamp('1870-05-03 00:00:00+0000', tz='UTC'), Timestamp('1870-05-04 00:00:00+0000', tz='UTC'), Timestamp('1870-05-05 00:00:00+0000', tz='UTC'), Timestamp('1870-05-06 00:00:00+0000', tz='UTC'), Timestamp('1870-05-07 00:00:00+0000', tz='UTC'), Timestamp('1870-05-08 00:00:00+0000', tz='UTC'), Timestamp('1870-05-09 00:00:00+0000', tz='UTC'), Timestamp('1870-05-10 00:00:00+0000', tz='UTC'), Timestamp('1870-05-11 00:00:00+0000', tz='UTC'), Timestamp('1870-05-12 00:00:00+0000', tz='UTC'), Timestamp('1870-05-13 00:00:00+0000', tz='UTC'), Timestamp('1870-05-14 00:00:00+0000', tz='UTC'), Timestamp('1870-05-15 00:00:00+0000', tz='UTC'), Timestamp('1870-05-16 00:00:00+0000', tz='UTC'), Timestamp('1870-05-17 00:00:00+0000', tz='UTC'), Timestamp('1870-05-18 00:00:00+0000', tz='UTC'), Timestamp('1870-05-19 00:00:00+0000', tz='UTC'), Timestamp('1870-05-20 00:00:00+0000', tz='UTC'), Timestamp('1870-05-21 00:00:00+0000', tz='UTC'), Timestamp('1870-05-22 00:00:00+0000', tz='UTC'), Timestamp('1870-05-23 00:00:00+0000', tz='UTC'), Timestamp('1870-05-24 00:00:00+0000', tz='UTC'), Timestamp('1870-05-25 00:00:00+0000', tz='UTC'), Timestamp('1870-05-26 00:00:00+0000', tz='UTC'), Timestamp('1870-05-27 00:00:00+0000', tz='UTC'), Timestamp('1870-05-28 00:00:00+0000', tz='UTC'), Timestamp('1870-05-29 00:00:00+0000', tz='UTC'), Timestamp('1870-05-30 00:00:00+0000', tz='UTC'), Timestamp('1870-05-31 00:00:00+0000', tz='UTC'), Timestamp('1870-06-01 00:00:00+0000', tz='UTC'), Timestamp('1870-06-02 00:00:00+0000', tz='UTC'), Timestamp('1870-06-03 00:00:00+0000', tz='UTC'), Timestamp('1870-06-04 00:00:00+0000', tz='UTC'), Timestamp('1870-06-05 00:00:00+0000', tz='UTC'), Timestamp('1870-06-06 00:00:00+0000', tz='UTC'), Timestamp('1870-06-07 00:00:00+0000', tz='UTC'), Timestamp('1870-06-08 00:00:00+0000', tz='UTC'), Timestamp('1870-06-09 00:00:00+0000', tz='UTC'), Timestamp('1870-06-10 00:00:00+0000', tz='UTC'), Timestamp('1870-06-11 00:00:00+0000', tz='UTC'), Timestamp('1870-06-12 00:00:00+0000', tz='UTC'), Timestamp('1870-06-13 00:00:00+0000', tz='UTC'), Timestamp('1870-06-14 00:00:00+0000', tz='UTC'), Timestamp('1870-06-15 00:00:00+0000', tz='UTC'), Timestamp('1870-06-16 00:00:00+0000', tz='UTC'), Timestamp('1870-06-17 00:00:00+0000', tz='UTC'), Timestamp('1870-06-18 00:00:00+0000', tz='UTC'), Timestamp('1870-06-19 00:00:00+0000', tz='UTC'), Timestamp('1870-06-20 00:00:00+0000', tz='UTC'), Timestamp('1870-06-21 00:00:00+0000', tz='UTC'), Timestamp('1870-06-22 00:00:00+0000', tz='UTC'), Timestamp('1870-06-23 00:00:00+0000', tz='UTC'), Timestamp('1870-06-24 00:00:00+0000', tz='UTC'), Timestamp('1870-06-25 00:00:00+0000', tz='UTC'), Timestamp('1870-06-26 00:00:00+0000', tz='UTC'), Timestamp('1870-06-27 00:00:00+0000', tz='UTC'), Timestamp('1870-06-28 00:00:00+0000', tz='UTC'), Timestamp('1870-06-29 00:00:00+0000', tz='UTC'), Timestamp('1870-06-30 00:00:00+0000', tz='UTC'), Timestamp('1870-07-01 00:00:00+0000', tz='UTC'), Timestamp('1870-07-02 00:00:00+0000', tz='UTC'), Timestamp('1870-07-03 00:00:00+0000', tz='UTC'), Timestamp('1870-07-04 00:00:00+0000', tz='UTC'), Timestamp('1870-07-05 00:00:00+0000', tz='UTC'), Timestamp('1870-07-06 00:00:00+0000', tz='UTC'), Timestamp('1870-07-07 00:00:00+0000', tz='UTC'), Timestamp('1870-07-08 00:00:00+0000', tz='UTC'), Timestamp('1870-07-09 00:00:00+0000', tz='UTC'), Timestamp('1870-07-10 00:00:00+0000', tz='UTC'), Timestamp('1870-07-11 00:00:00+0000', tz='UTC'), Timestamp('1870-07-12 00:00:00+0000', tz='UTC'), Timestamp('1870-07-13 00:00:00+0000', tz='UTC'), Timestamp('1870-07-14 00:00:00+0000', tz='UTC'), Timestamp('1870-07-15 00:00:00+0000', tz='UTC'), Timestamp('1870-07-16 00:00:00+0000', tz='UTC'), Timestamp('1870-07-17 00:00:00+0000', tz='UTC'), Timestamp('1870-07-18 00:00:00+0000', tz='UTC'), Timestamp('1870-07-19 00:00:00+0000', tz='UTC'), Timestamp('1870-07-20 00:00:00+0000', tz='UTC'), Timestamp('1870-07-21 00:00:00+0000', tz='UTC'), Timestamp('1870-07-22 00:00:00+0000', tz='UTC'), Timestamp('1870-07-23 00:00:00+0000', tz='UTC'), Timestamp('1870-07-24 00:00:00+0000', tz='UTC'), Timestamp('1870-07-25 00:00:00+0000', tz='UTC'), Timestamp('1870-07-26 00:00:00+0000', tz='UTC'), Timestamp('1870-07-27 00:00:00+0000', tz='UTC'), Timestamp('1870-07-28 00:00:00+0000', tz='UTC'), Timestamp('1870-07-29 00:00:00+0000', tz='UTC'), Timestamp('1870-07-30 00:00:00+0000', tz='UTC'), Timestamp('1870-07-31 00:00:00+0000', tz='UTC'), Timestamp('1870-08-01 00:00:00+0000', tz='UTC'), Timestamp('1870-08-02 00:00:00+0000', tz='UTC'), Timestamp('1870-08-03 00:00:00+0000', tz='UTC'), Timestamp('1870-08-04 00:00:00+0000', tz='UTC'), Timestamp('1870-08-05 00:00:00+0000', tz='UTC'), Timestamp('1870-08-06 00:00:00+0000', tz='UTC'), Timestamp('1870-08-07 00:00:00+0000', tz='UTC'), Timestamp('1870-08-08 00:00:00+0000', tz='UTC'), Timestamp('1870-08-09 00:00:00+0000', tz='UTC'), Timestamp('1870-08-10 00:00:00+0000', tz='UTC'), Timestamp('1870-08-11 00:00:00+0000', tz='UTC'), Timestamp('1870-08-12 00:00:00+0000', tz='UTC'), Timestamp('1870-08-13 00:00:00+0000', tz='UTC'), Timestamp('1870-08-14 00:00:00+0000', tz='UTC'), Timestamp('1870-08-15 00:00:00+0000', tz='UTC'), Timestamp('1870-08-16 00:00:00+0000', tz='UTC'), Timestamp('1870-08-17 00:00:00+0000', tz='UTC'), Timestamp('1870-08-18 00:00:00+0000', tz='UTC'), Timestamp('1870-08-19 00:00:00+0000', tz='UTC'), Timestamp('1870-08-20 00:00:00+0000', tz='UTC'), Timestamp('1870-08-21 00:00:00+0000', tz='UTC'), Timestamp('1870-08-22 00:00:00+0000', tz='UTC'), Timestamp('1870-08-23 00:00:00+0000', tz='UTC'), Timestamp('1870-08-24 00:00:00+0000', tz='UTC'), Timestamp('1870-08-25 00:00:00+0000', tz='UTC'), Timestamp('1870-08-26 00:00:00+0000', tz='UTC'), Timestamp('1870-08-27 00:00:00+0000', tz='UTC'), Timestamp('1870-08-28 00:00:00+0000', tz='UTC'), Timestamp('1870-08-29 00:00:00+0000', tz='UTC'), Timestamp('1870-08-30 00:00:00+0000', tz='UTC'), Timestamp('1870-08-31 00:00:00+0000', tz='UTC'), Timestamp('1870-09-01 00:00:00+0000', tz='UTC'), Timestamp('1870-09-02 00:00:00+0000', tz='UTC'), Timestamp('1870-09-03 00:00:00+0000', tz='UTC'), Timestamp('1870-09-04 00:00:00+0000', tz='UTC'), Timestamp('1870-09-05 00:00:00+0000', tz='UTC'), Timestamp('1870-09-06 00:00:00+0000', tz='UTC'), Timestamp('1870-09-07 00:00:00+0000', tz='UTC'), Timestamp('1870-09-08 00:00:00+0000', tz='UTC'), Timestamp('1870-09-09 00:00:00+0000', tz='UTC'), Timestamp('1870-09-10 00:00:00+0000', tz='UTC'), Timestamp('1870-09-11 00:00:00+0000', tz='UTC'), Timestamp('1870-09-12 00:00:00+0000', tz='UTC'), Timestamp('1870-09-13 00:00:00+0000', tz='UTC'), Timestamp('1870-09-14 00:00:00+0000', tz='UTC'), Timestamp('1870-09-15 00:00:00+0000', tz='UTC'), Timestamp('1870-09-16 00:00:00+0000', tz='UTC'), Timestamp('1870-09-17 00:00:00+0000', tz='UTC'), Timestamp('1870-09-18 00:00:00+0000', tz='UTC'), Timestamp('1870-09-19 00:00:00+0000', tz='UTC'), Timestamp('1870-09-20 00:00:00+0000', tz='UTC'), Timestamp('1870-09-21 00:00:00+0000', tz='UTC'), Timestamp('1870-09-22 00:00:00+0000', tz='UTC'), Timestamp('1870-09-23 00:00:00+0000', tz='UTC'), Timestamp('1870-09-24 00:00:00+0000', tz='UTC'), Timestamp('1870-09-25 00:00:00+0000', tz='UTC'), Timestamp('1870-09-26 00:00:00+0000', tz='UTC'), Timestamp('1870-09-27 00:00:00+0000', tz='UTC'), Timestamp('1870-09-28 00:00:00+0000', tz='UTC'), Timestamp('1870-09-29 00:00:00+0000', tz='UTC'), Timestamp('1870-09-30 00:00:00+0000', tz='UTC'), Timestamp('1870-10-01 00:00:00+0000', tz='UTC'), Timestamp('1870-10-02 00:00:00+0000', tz='UTC'), Timestamp('1870-10-03 00:00:00+0000', tz='UTC'), Timestamp('1870-10-04 00:00:00+0000', tz='UTC'), Timestamp('1870-10-05 00:00:00+0000', tz='UTC'), Timestamp('1870-10-06 00:00:00+0000', tz='UTC'), Timestamp('1870-10-07 00:00:00+0000', tz='UTC'), Timestamp('1870-10-08 00:00:00+0000', tz='UTC'), Timestamp('1870-10-09 00:00:00+0000', tz='UTC'), Timestamp('1870-10-10 00:00:00+0000', tz='UTC'), Timestamp('1870-10-11 00:00:00+0000', tz='UTC'), Timestamp('1870-10-12 00:00:00+0000', tz='UTC'), Timestamp('1870-10-13 00:00:00+0000', tz='UTC'), Timestamp('1870-10-14 00:00:00+0000', tz='UTC'), Timestamp('1870-10-15 00:00:00+0000', tz='UTC'), Timestamp('1870-10-16 00:00:00+0000', tz='UTC'), Timestamp('1870-10-17 00:00:00+0000', tz='UTC'), Timestamp('1870-10-18 00:00:00+0000', tz='UTC'), Timestamp('1870-10-19 00:00:00+0000', tz='UTC'), Timestamp('1870-10-20 00:00:00+0000', tz='UTC'), Timestamp('1870-10-21 00:00:00+0000', tz='UTC'), Timestamp('1870-10-22 00:00:00+0000', tz='UTC'), Timestamp('1870-10-23 00:00:00+0000', tz='UTC'), Timestamp('1870-10-24 00:00:00+0000', tz='UTC'), Timestamp('1870-10-25 00:00:00+0000', tz='UTC'), Timestamp('1870-10-26 00:00:00+0000', tz='UTC'), Timestamp('1870-10-27 00:00:00+0000', tz='UTC'), Timestamp('1870-10-28 00:00:00+0000', tz='UTC'), Timestamp('1870-10-29 00:00:00+0000', tz='UTC'), Timestamp('1870-10-30 00:00:00+0000', tz='UTC'), Timestamp('1870-10-31 00:00:00+000","""[1947-12-27",30-11-1947,,,
What are the 3 highest recorded precipitation events in inches?,What are the top 3 highest precipitation amounts recorded in inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_precipitations = dataset.nlargest(3, 'PRCP')['PRCP'].tolist()

return top_3_precipitations",list of (float64),"[8.28, 7.57, 7.4]","[8.28, 7.57, 7.4]",,,,
What are the 5 lowest minimum temperatures recorded?,What are the 5 minimum recorded temperatures?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_temperatures = dataset['TMIN'].nsmallest(5).tolist()
    
    return min_temperatures
",list of (float64),"[-15.0, -13.0, -8.0, -7.0, -7.0]","[-15.0, -13.0, -8.0, -7.0, -7.0]",,,,
What are the 4 highest maximum temperatures recorded?,What are the four highest maximum temperatures recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_four_max_temperatures = dataset.nlargest(4, 'TMAX')['TMAX'].tolist()
    
    return top_four_max_temperatures
",list of (float64),"[106.0, 104.0, 104.0, 104.0]","[106.0, 104.0, 104.0, 104.0]",,,,
What are the 2 deepest snow depth recorded in inches?,What are the two highest snow depths recorded in inches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sorted_snow_depths = dataset.sort_values(by='SNWD', ascending=False)['SNWD'].head(2).tolist()
    return sorted_snow_depths
",list of (float64),"[26.0, 25.0]","[26.0, 25.0]",,,,
Are there more than 20 unique clothing items in the dataset?,Does the dataset contain more than 20 unique clothing items?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
unique_clothing_count = dataset['Clothing ID'].nunique()
has_more_than_20_unique_items = unique_clothing_count > 20

return has_more_than_20_unique_items",bool,True,True,,,,
Is the age of the reviewers above 50 years on average?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks if there is any recommended product with a rating of 5
    recommended_products = dataset[dataset['Recommended IND'] == 1]
    top_rated_product = recommended_products[recommended_products['Rating'] == 5]
    
    return not top_rated_product.empty
",bool,True,False,,,,
Do all reviews come from the same department?,Are all the reviews associated with the same department?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    unique_departments = dataset['Department Name'].nunique()
    is_all_same_department = (unique_departments == 1)
    
    return is_all_same_department
",bool,False,False,,,,
Are all products recommended?,Is the Recommended IND attribute set to True for all products?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    is_all_recommended = (dataset['Recommended IND'] == 1).all()
    
    return is_all_recommended",bool,False,False,,,,
What is the average age of the reviewers?,,,,ERROR,43.198544000000000,,,,
What's the highest number of positive feedback received for a review?,What is the maximum number of positive feedbacks received for any review?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_positive_feedback = dataset['Positive Feedback Count'].max()
return max_positive_feedback",uint8,122,122,,,,
What is the most common rating given by reviewers?,What is the most frequent rating provided by users?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_rating = dataset['Rating'].mode().iloc[0]
    return most_frequent_rating",uint8  ,5,5,,,,
How many unique clothing items are there in the dataset?,What is the count of distinct clothing items in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_clothing_count = dataset['Clothing ID'].nunique()

    return distinct_clothing_count",int64,1206,1206,,,,
Which department has the most reviews?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value from the dataset
    # For example, if the question is ""What is the division name of the first entry?""
    # We can access it as follows:
    
    # Extracting the first division name from the dataset
    first_division_name = dataset['Division Name'].iloc[0]
    
    return first_division_name
",string,Initmates,Tops,,,,
Which class of clothing is most commonly reviewed?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is about finding the most common division name
    most_common_division = dataset['Division Name'].mode()[0]
    
    return most_common_division",string,General,Dresses,,,,
Which division is most commonly mentioned in the reviews?,Which division name appears most frequently in the reviews?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_division = dataset['Division Name'].mode()[0]
    
    return most_frequent_division
",string,General,General,,,,
What is the most frequently reviewed clothing item? If you find a tie answer with row order.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific piece of information from the dataset
    # For example, let's say the question is ""What is the most common division name?""
    # The code below will find the division name with the highest count in the dataset

    # Count the occurrences of each division name
    division_counts = dataset['Division Name'].value_counts()

    # Get the division name with the highest count
    most_common_division = division_counts.idxmax()

    return most_common_division",string,General,1078,,,,
Which are the 4 most reviewed categories in Department Name?,What are the top 4 categories by number of reviews in Department Name?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Department Name' and count the number of reviews for each department
    review_counts = dataset['Department Name'].value_counts().head(4).index.tolist()
    
    return review_counts
",list of (string),"['Tops', 'Dresses', 'Bottoms', 'Intimate']","['Tops', 'Dresses', 'Bottoms', 'Intimate']",,,,
Which are the top 2 most reviewed categories in Class Name?,What are the top 2 categories with the most reviews in Class Name?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Class Name' and count the number of reviews for each category
    review_counts = dataset.groupby('Class Name')['Review Text'].count().reset_index(name='review_count')
    
    # Sort the categories by the number of reviews in descending order
    sorted_reviews = review_counts.sort_values(by='review_count', ascending=False)
    
    # Get the top 2 categories with the most reviews
    top_2_categories = sorted_reviews.head(2)['Class Name'].tolist()
    
    return top_2_categories
",list of (string),"['Dresses', 'Knits']","['Dresses', 'Knits']",,,,
Which are the 2 most reviewed categories in Division Name?,What are the top 2 categories by review count in Division Name?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Division Name' and sum the 'Positive Feedback Count' to get total reviews per division
    review_count_by_division = dataset.groupby('Division Name')['Positive Feedback Count'].sum().reset_index()
    
    # Sort the divisions by review count in descending order
    sorted_divisions = review_count_by_division.sort_values(by='Positive Feedback Count', ascending=False)
    
    # Get the top 2 divisions by review count
    top_2_divisions = sorted_divisions.head(2)['Division Name'].tolist()
    
    return top_2_divisions
",list of (string),"['General', 'General Petite']","['General', 'General Petite']",,,,
What are the 4 highest ratings given by reviewers?,What are the top 4 highest ratings provided by reviewers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by Rating in descending order and select the top 4 unique ratings
    top_ratings = dataset['Rating'].sort_values(ascending=False).unique()[:4]
    
    return list(top_ratings)
",list of (uint8),"[np.uint8(5), np.uint8(4), np.uint8(3), np.uint8(2)]","[5, 4, 3, 2]",,,,
What are the 5 oldest Ages of reviewers?,What are the top 5 highest ages among reviewers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_ages = dataset['Age'].nlargest(5).tolist()
return top_ages",list of (int64),"[99, 99, 94, 94, 94]","[99, 99, 94, 94, 94]",,,,
What are the 4 most common Positive Feedback Counts of reviewers?,What are the top 4 most frequent Positive Feedback Counts from reviewers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Positive Feedback Count' and count occurrences
    feedback_counts = dataset['Positive Feedback Count'].value_counts().head(4).index.tolist()
    
    return feedback_counts
",list of (int64),"[0, 1, 2, 3]","[0, 1, 2, 3]",,,,
What are the 2 most common values for recommendation indicator?,What are the top 2 most frequent values for the recommendation indicator?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
recommendation_counts = dataset['Recommended IND'].value_counts().head(2).index.tolist()
return recommendation_counts",list of (uint8),"[1, 0]","[1, 0]",,,,
What are the 2 most common clothing IDs in the reviews? If you find a tie answer in row order.,"Find the top 2 most frequent Clothing IDs in the reviews. In case of a tie, return them in the order they appear in the dataset.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    clothing_id_counts = dataset['Clothing ID'].value_counts()
    top_2_clothing_ids = clothing_id_counts.head(2).index.tolist()

    return top_2_clothing_ids
",list of (uint16),"[1078, 862]","[1078, 862]",,,,
Was the highest reported incident in the year 2023 filed online?,Was the most recent incident in 2023 reported online?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter incidents that occurred in 2023
    incidents_2023 = dataset[dataset['Incident Year'] == 2023]
    
    # Get the most recent incident by sorting by 'Incident Datetime' in descending order
    most_recent_incident = incidents_2023.sort_values(by='Incident Datetime', ascending=False).head(1)
    
    # Check if the most recent incident was reported online
    is_reported_online = most_recent_incident['Filed Online'].iloc[0] == 'Yes'
    
    return is_reported_online
",bool,False,False,,,,
Are all incidents reported on Mondays resolved?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking about a specific condition related to the dataset
    # For example, let's assume the question is ""Is there any incident that occurred on a weekend?""
    
    # Filter incidents that occurred on a weekend (Saturday or Sunday)
    weekend_incidents = dataset[dataset['Incident Day of Week'].isin(['Saturday', 'Sunday'])]
    
    # Check if there are any incidents on the weekend
    has_weekend_incident = not weekend_incidents.empty
    
    return has_weekend_incident",bool,True,False,,,,
Do any incidents reported in Police District 'Central' fall in Supervisor District 5?,Are there any incidents in the Police District 'Central' that are located in Supervisor District 5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_incidents = dataset[(dataset['Police District'] == 'Central') & (dataset['Supervisor District'] == 5)]
    has_incident = not filtered_incidents.empty

    return has_incident
",bool,True,False,,,,
Are there any incidents that occurred at the same latitude and longitude more than once?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any incidents recorded in the dataset
    has_incidents = not dataset.empty
    
    return has_incidents
",bool,True,True,,,,
How many unique types of incident categories are there in the dataset?,What is the count of distinct incident categories in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_categories_count = dataset['Incident Category'].nunique()
    
    return distinct_categories_count
",int64,49,49,,,,
What's the total number of incidents reported online?,How many incidents were reported online?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    online_incidents_count = dataset[dataset['Filed Online'] == 'Yes'].shape[0]
    
    return online_incidents_count",int64  ,0,144099,,,,
How many different police districts are there in the dataset?,How many unique police districts are present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    unique_police_districts = dataset['Police District'].nunique()
    return unique_police_districts
",int64  ,11,11,,,,
What is the average incident count per year?,What is the mean incident count per year?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    mean_incident_count = dataset['Incident Year'].value_counts().mean()
    return mean_incident_count
",float64,118851.16666700000,118851.16666700000,,,,
What is the most common incident category?,What is the most frequent incident category?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_category = dataset['Incident Category'].mode()[0]
    
    return most_frequent_category
",string,Larceny Theft,Larceny Theft,,,,
Which day of the week has the highest number of incidents?,On which day of the week do the most incidents occur?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    incident_day_counts = dataset['Incident Day of Week'].value_counts()
    most_common_day = incident_day_counts.idxmax()

    return most_common_day
",string  ,Friday,Friday,,,,
What is the most common resolution for incidents reported online?,,,,ERROR,Open or Active,,,,
What is the Police District with the most incidents?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value from the dataset
    # For example, if the question is ""What is the most common Incident Category?""
    incident_category = dataset['Incident Category'].mode()[0]

    return incident_category
",category,Larceny Theft,Central,,,,
What are the three most common incident descriptions?,What are the top three most frequent incident descriptions?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the top three most frequent incident descriptions
    top_three_incident_descriptions = dataset['Incident Description'].value_counts().head(3).index.tolist()
    
    return top_three_incident_descriptions
",list of (string),"['Theft, From Locked Vehicle, >$950', 'Malicious Mischief, Vandalism to Property', 'Battery']","['Theft, From Locked Vehicle, >$950', 'Malicious Mischief, Vandalism to Property', 'Battery']",,,,
Name the 4 most frequently occurring police districts.,What are the names of the top 4 most frequently occurring police districts?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_4_police_districts = dataset['Police District'].value_counts().head(4).index.tolist()
    
    return top_4_police_districts
",list of (string),"['Central', 'Northern', 'Mission', 'Southern']","[Central, Northern, Mission, Southern]",,,,
List the three most common incident categories on Fridays.,What are the top three most frequent incident categories that occurred on Fridays?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
fridays_data = dataset[dataset['Incident Day of Week'] == 'Friday']
top_categories = fridays_data['Incident Category'].value_counts().head(3).index.tolist()
return top_categories
",list of (string),"['Larceny Theft', 'Malicious Mischief', 'Other Miscellaneous']","[Larceny Theft, Malicious Mischief, Other Miscellaneous]",,,,
Give the 6 most common resolutions for incidents.,What are the top 6 most frequent resolutions for incidents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    resolution_counts = dataset['Resolution'].value_counts().head(6)
    top_resolutions = resolution_counts.index.tolist()
    
    return top_resolutions
",list of (string),"['Open or Active', 'Cite or Arrest Adult', 'Unfounded', 'Exceptional Adult']","[Open or Active, Cite or Arrest Adult, Unfounded, Exceptional Adult]",,,,
List the years with the top 4 highest incident counts.,What are the top 4 years with the highest number of incidents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Incident Year and count the number of incidents for each year
    incident_counts = dataset['Incident Year'].value_counts().head(4).index.tolist()
    
    return incident_counts
",list of (uint16),"[2018, 2019, 2022, 2021]","[2018, 2019, 2022, 2021]",,,,
Which 3 incident years have the lowest number of online filed reports? If two have the same number choose the latest year,"What are the three incident years with the lowest number of online filed reports? If two years have the same count, choose the more recent year.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter out rows where 'Filed Online' is 'N'
    online_reports = dataset[dataset['Filed Online'] == 'Y']
    
    # Group by 'Incident Year' and count the number of reports for each year
    yearly_counts = online_reports.groupby('Incident Year').size().reset_index(name='count')
    
    # Sort by count in ascending order, then by 'Incident Year' in descending order to prioritize recent years
    sorted_years = yearly_counts.sort_values(by=['count', 'Incident Year'], ascending=[True, False])
    
    # Get the top 3 incident years with the lowest number of online filed reports
    top_3_years = sorted_years['Incident Year'].head(3).tolist()
    
    return top_3_years
",list of (int64),[],"[2023, 2020, 2021]",,,,
What are the 2 years with the highest incident counts.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column's values as a list of numbers
    # For example, if the question is ""What are all the Incident Numbers?""
    column_name = 'Incident Number'  # This should be replaced with the actual column name from the question
    answer = dataset[column_name].tolist()
    
    return answer",list of (int64),"[230167874, 236046151, 220343896, 230174885, 230176728, 236046123, 236046004, 236046850, 236045937, 230182844, 236047096, 230184129, 230185672, 230187101, 236047529, 230178047, 236049456, 236046816, 236050049, 230172566, 236048862, 236049876, 230188660, 236049951, 236048765, 226100018, 236050102, 230130047, 236048420, 230081127, 230195483, 236049490, 236050889, 230199764, 236050726, 186245900, 196009821, 180833020, 236012936, 190574333, 216013700, 186033620, 196096505, 186202483, 186264546, 196044297, 186189728, 206043927, 196266344, 200181434, 206004349, 210006082, 219002362, 220625666, 216166854, 200490150, 216149929, 216012398, 200356530, 186016096, 226083367, 210537297, 186155547, 206006919, 186258301, 216042919, 226227189, 186092682, 196029073, 180641782, 186176587, 190363324, 180899232, 226121406, 186202687, 226007135, 200359302, 196026091, 196163972, 210061575, 226064812, 196093818, 226150295, 210141149, 220859649, 206179174, 210224892, 220435590, 219002500, 210036039, 216095203, 186153234, 190240562, 230068636, 226050087, 196195624, 206038398, 196050802, 186179519, 200448096, 196260421, 226076845, 206016366, 216059152, 216007214, 206095837, 216042806, 186030002, 216077825, 196036658, 216191152, 196184508, 216172287, 186159016, 180114983, 220334679, 196148902, 196227045, 196214224, 180623053, 196119254, 200330095, 180051573, 186100514, 236044202, 196243574, 220083202, 196278189, 186153319, 210829339, 186213377, 186134604, 216110588, 226190837, 196004241, 206078225, 186001451, 186154668, 186056553, 196023257, 186259804, 220428783, 220508846, 226131405, 216113281, 190548297, 200315724, 226216364, 180417624, 226130112, 190551046, 186112854, 216068761, 226169086, 206167903, 196108752, 226006585, 206095699, 190018290, 186264035, 206074518, 196256486, 200244800, 210610207, 216054027, 196186037, 186016472, 190395628, 196213969, 190475985, 196223037, 216200725, 180758967, 200557556, 200001365, 210433554, 226183672, 206102755, 206108236, 196146887, 196124952, 196165310, 196027083, 216015734, 196093614, 196148639, 196049231, 206052843, 226167955, 196255206, 186152929, 186292581, 196043023, 226045367, 210394718, 210460353, 210568565, 216114358, 210527555, 216095651, 216082288, 216069907, 216147412, 186153541, 210661056, 219002538, 216150879, 216056487, 210854643, 210356570, 219002146, 216147020, 219002146, 210060232, 210417332, 216098495, 210531948, 216182656, 216075396, 216067923, 210440565, 210426383, 210317049, 210321367, 216061317, 216123133, 210459958, 216119449, 216160248, 226213423, 210207854, 186155490, 216098564, 210547860, 210347977, 216087965, 210345909, 210742214, 210430287, 190202001, 216071009, 210529777, 186173878, 216069082, 210323193, 226005775, 210412508, 216081707, 210564381, 216144907, 216082620, 210388664, 216116348, 216118269, 210375837, 186184499, 210455934, 210394611, 216084842, 210358980, 216183466, 216183115, 216106747, 216184113, 216087777, 200640537, 216087614, 210416011, 200619899, 200605569, 216084795, 216071491, 216148539, 216078663, 216126698, 210672122, 216077665, 210553522, 226213194, 210424020, 216152239, 186054983, 216191265, 216117910, 216089682, 210668858, 210304513, 210407979, 216179879, 186094967, 210706414, 210523456, 216070584, 216096057, 210671027, 216117001, 216118156, 216084143, 210532918, 216143733, 216115243, 216209090, 210301183, 186056359, 210440703, 210307357, 210630835, 219001790, 210436207, 210348157, 216126450, 216178865, 216126808, 210785098, 186182904, 186039587, 216074871, 210670239, 216023141, 216083264, 216083979, 210476350, 210431401, 210433582, 216181238, 216116718, 216146630, 210345595, 216089529, 216125543, 216150261, 216088559, 210565602, 216101509, 216124943, 216071786, 210783519, 210229773, 220046119, 210362878, 216064208, 216083026, 220659671, 216092328, 210780214, 216099302, 216078657, 210414576, 210629377, 216152041, 216086406, 220109284, 210482761, 216154699, 210619635, 210790439, 210322311, 210564444, 226040696, 186087906, 216018120, 210464850, 216126739, 216098304, 216118811, 210491007, 216129216, 216104638, 216099352, 216090899, 210425551, 186039474, 210416566, 210566854, 226109082, 216088593, 216118485, 216114063, 216159326, 210609288, 219002538, 210389032, 186121786, 220133716, 216116570, 216096455, 186070616, 210663864, 216150540, 216073970, 216209119, 216150681, 216134550, 186111533, 216079893, 210455934, 210445894, 210475829, 210771724, 180459626, 216156087, 216066947, 216104365, 210705347, 216115152, 226007179, 210771310, 216118742, 210396786, 210762864, 216183422, 210381298, 216148090, 216101010, 210455257, 210387218, 216088151, 216080721, 210670007, 220162652, 226109048, 210367709, 219001687, 210408353, 219002572, 216151623, 186027849, 216151946, 216086042, 216169842, 220094613, 226109076, 216154398, 210532786, 216133267, 210690453, 210551435, 216110798, 210637803, 210690566, 216131095, 210535887, 220047929, 220013732, 220032663, 210613427, 210731546, 210602129, 216158312, 180232450, 210495059, 210730623, 210694665, 210130512, 220047361, 210615978, 210563593, 216124614, 216166973, 210416011, 220094629, 210228656, 216123735, 216120719, 186176139, 210735736, 216092522, 216101684, 186183849, 216161042, 186018149, 216172970, 210754902, 216151297, 220045553, 210460018, 186137238, 216097776, 219001803, 210378712, 216104503, 210599617, 210683931, 220174334, 216188256, 220023593, 216185694, 210601187, 216125361, 220279467, 216156855, 210434922, 216091433, 216169331, 210691865, 210754140, 216129238, 216158986, 210677887, 216087307, 216131421, 216161672, 216103016, 216136891, 226006773, 216160345, 210490758, 216116150, 216183234, 216175203, 210697277, 210706806, 226075364, 216169171, 210482040, 186160461, 210567266, 210082418, 210655883, 216184492, 210691354, 220389696, 216099120, 210595132, 210611211, 210753368, 210696956, 210491314, 216131142, 210488480, 216138530, 210791857, 210596334, 216192069, 210857813, 226041177, 216125731, 216102808, 210711623, 216128650, 186103966, 216104008, 216012843, 216130514, 216193001, 210604460, 210591061, 216123967, 210031346, 210466953, 210714752, 226003456, 210387741, 210652237, 180023152, 216153146, 216146505, 216127652, 210564444, 210476651, 216191293, 210591061, 226008785, 210593465, 216170225, 210604749, 216190455, 226056041, 210225931, 210614679, 216104644, 210764945, 216139447, 220017182, 210619312, 210716902, 210783042, 210792316, 216169234, 216199015, 210853930, 216138427, 220048911, 216203876, 210485486, 210705450, 216184828, 210837837, 216200593, 216091449, 216196431, 216161898, 216138477, 216162222, 210711037, 216126068, 186133173, 210854728, 210812265, 220048002, 216162711, 186076567, 210808145, 210726268, 186068699, 210239396, 216120872, 226008183, 210611841, 216162783, 210701179, 210556764, 210741476, 216103561, 220306195, 226075502, 220040854, 210842353, 210695823, 220041078, 210734772, 226077122, 216190615, 226041296, 216159354, 216128252, 216192730, 220179964, 216104531, 216185973, 210829094, 210806826, 216172754, 216158431, 216170645, 220045042, 200648995, 210803656, 210758346, 216128854, 226004664, 226109634, 216151112, 216190847, 216186551, 220069694, 220095081, 186083023, 186118090, 210794839, 216138900, 210697562, 210719263, 216202458, 216201591, 216139124, 216168151, 210846101, 196001125, 210794839, 210843787, 210709496, 216104779, 210701715, 210697960, 216201171, 220043626, 210610304, 226075778, 226110017, 210735617, 216131647, 226109361, 216165878, 226009084, 210837100, 226011302, 210796277, 216192495, 216157148, 210738213, 220299891, 216174954, 216159213, 210502541, 216162426, 220080719, 216195819, 216190483, 210608456, 210635261, 216156366, 210753415, 210754980, 210505959, 216157524, 226008406, 216164068, 210728913, 216171477, 186041946, 210698708, 216154752, 226014704, 216173069, 216196629, 216199849, 216170178, 216206632, 210745939, 186121504, 226078045, 216200076, 210862561, 216195461, 226042971, 210711457, 216193716, 216202038, 210822571, 210810827, 216201808, 210693275, 210759134, 216196306, 210716106, 216165044, 210852857, 216038861, 216139588, 216192172, 210828450, 216201074, 210468341, 220059178, 226076243, 220164125, 220300181, 216174807, 210853065, 170927467, 226010326, 220014031, 216194043, 216168236, 210835370, 216169717, 216202129, 220307682, 210732845, 220002365, 226053263, 216200656, 226049290, 210763680, 216166989, 226000377, 216176609, 226114360, 216195154, 216127533, 226019102, 226077229, 210851859, 220198839, 220381727, 226002351, 220151116, 210846101, 210836704, 220159245, 216172572, 216192445, 220047145, 226060503, 226001115, 220084567, 216164240, 226024913, 220032641, 216168430, 220074477, 210768050, 226063911, 226042084, 220279655, 226117342, 226109690, 216177306, 226015445, 220041078, 210777807, 186041407, 186179224, 216175225, 180421807, 216177754, 220710609, 216173558, 226017065, 216205593, 210731778, 210593857, 216205844, 226016835, 216173683, 210765391, 216172215, 220007371, 210793552, 210591061, 210856194, 210819841, 210839178, 210653865, 210854433, 226014914, 220055035, 210727777, 220016510, 220282959, 220079938, 220426185, 226014287, 220281519, 216201381, 210756500, 216166848, 210818542, 216206604, 226081678, 226024151, 226081032, 226042103, 226015752, 210506515, 220014940, 210854819, 220009098, 226002260, 200673469, 226001325, 180144952, 220094522, 220129458, 220135728, 216175598, 226044165, 220189292, 220011429, 226026668, 226016540, 220194605, 216167692, 216209517, 220298940, 210813649, 226109430, 220065147, 226043327, 180209186, 220076401, 210609153, 210833584, 226076174, 220779699, 210561854, 220365389, 220065476, 226032665, 220075845, 220303715, 220211908, 216203296, 226016885, 226013433, 226042642, 226016205, 186116107, 226042777, 210077607, 216026775, 210814158, 220077960, 226031140, 226030926, 210816198, 226042078, 226019431, 220025947, 216208729, 220439047, 216207022, 210848408, 226045191, 226054192, 220019401, 220062438, 216202204, 226146959, 220464395, 220204771, 210751049, 220107119, 210697562, 170871513, 220149898, 220427848, 220136867, 226024521, 226028357, 220094328, 220089761, 226018900, 220085010, 226029537, 220132718, 186111925, 226051079, 216165038, 220304133, 226026793, 216177118, 226111758, 210716708, 226029208, 186158096, 220069569, 220307773, 226002044, 220072722, 220780721, 226014419, 226124977, 220075055, 226041917, 220078281, 226046230, 216201353, 210699938, 220000820, 220051964, 220055819, 226029935, 226024468, 226016891, 216198318, 226110534, 210438827, 220137144, 216138659, 220007490, 226020585, 220193613, 220185676, 216190217, 220198889, 220012223, 226112308, 226014340, 216173542, 226042573, 226021016, 216204937, 216207339, 220059930, 220147494, 210857233, 210840040, 210817497, 210709123, 220432831, 210694552, 226032386, 220297431, 216176900, 226111231, 216195217, 216201030, 220431689, 220139156, 220128660, 220087840, 220259312, 220018958, 220183824, 220144876, 220144406, 226057732, 226059108, 220119932, 226052566, 226111952, 226250588, 220238344, 226095629, 226055833, 226024480, 220017615, 226250685, 216196033, 186082683, 220366440, 220221587, 220412015, 226113077, 226034451, 220158203, 226026806, 226030471, 226052453, 226083577, 220581773, 226043010, 226046951, 226250817, 210863218, 226030192, 226034207, 220214720, 220431178, 226082858, 210855986, 186137454, 226055059, 220027131, 220161751, 180085182, 220024290, 226112659, 220229581, 210210073, 220333621, 226053376, 220027692, 220198049, 220301474, 226036554, 226163260, 226027860, 186023972, 226082438, 226147640, 186124100, 226004125, 196102958, 226032110, 220065181, 226016750, 226080921, 220009935, 226101492, 180000558, 220219087, 186044213, 220202101, 220193895, 210265125, 216207862, 226015564, 220280389, 220104109, 220380575, 180679783, 220146703, 226019033, 220061991, 226061501, 226083533, 220020561, 220308931, 226044808, 220002111, 220180319, 220090213, 220124038, 226050203, 220433033, 226029731, 220008614, 186069675, 226001206, 190272797, 220122769, 220443123, 226032546, 216050934, 220221866, 226018289, 226047589, 186050997, 220127797, 226062769, 226111805, 226028034, 220035582, 226147781, 220238366, 220015716, 210861767, 220658479, 220054134, 226048606, 226035330, 226083834, 226080802, 210857108, 226081496, 226057566, 226029515, 226082416, 226026674, 220048767, 226084224, 186031129, 226050338, 220097281, 226144226, 210571609, 210724591, 226039473, 220098916, 220652960, 216206262, 226046519, 216202470, 226083210, 226054415, 220557514, 226064533, 220580515, 226083715, 226111980, 220165270, 220103480, 196101916, 186246839, 216212112, 226038102, 226086571, 226060008, 226050413, 220155936, 196073854, 186024334, 210842927, 226063488, 226177487, 210271332, 196007013, 220152716, 220653366, 226061830, 226148187, 220227789, 196100059, 226046252, 226055764, 226025808, 220157089, 220148947, 220150271, 226051386, 220253358, 220323848, 220222563, 226090083, 226052522, 220552100, 220126175, 220096233, 210061901, 226090538, 220164777, 226115396, 226049422, 226054211, 226114718, 186209451, 220246397, 220240593, 220314110, 226051966, 220082997, 220293053, 220123137, 196043562, 226083674, 210865496, 226023971, 220263658, 220210342, 226034887, 220324733, 220228878, 220003868, 226151293, 226025579, 220445680, 226050861, 226046478, 186003281, 220333728, 226114116, 226031300, 226032615, 226026737, 220347252, 226055316, 220478625, 220290833, 220345256, 226115001, 220473415, 196000227, 226148400, 226068165, 226064016, 226072605, 226058304, 220472605, 220250332, 226062628, 220354150, 226083254, 220362329, 220204947, 226022086, 226029640, 226147872, 226148842, 220240430, 220439570, 220356316, 220339704, 226066846, 210493978, 226035249, 220148339, 220428595, 220242925, 196020623, 226057049, 220217445, 186214751, 220128030, 226093021, 226038419, 226149044, 220888228, 196009865, 226068808, 226073631, 226040577, 226056477, 210691837, 220204787, 226090710, 220233623, 226082701, 226177227, 226049961, 226044557, 220150823, 220325264, 236017732, 226036275, 220248111, 220354605, 220375504, 226151801, 220747135, 220170194, 226136637, 220376568, 220384276, 190164865, 220530504, 226067054, 226066733, 220310889, 226066294, 220547963, 226058279, 226066103, 226090174, 220355794, 220571360, 226214669, 220556920, 226149953, 220459164, 226087256, 220384317, 226119746, 220572603, 226096229, 190243936, 220293417, 196068059, 226104593, 220292005, 226101094, 226151635, 226072718, 226098140, 220341226, 226094706, 226091962, 226092750, 226066078, 226095635, 226116504, 220250166, 226114398, 226066539, 220411330, 220342650, 226099994, 226094433, 226115186, 220250263, 220260080, 196011672, 226144561, 226064668, 226057726, 220669266, 220275164, 226115045, 226088038, 226060735, 220267127, 226098736, 220269139, 190015133, 220274724, 226070154, 226092261, 220347650, 226082717, 226039495, 226091047, 226145525, 220458003, 226023987, 226097619, 226116764, 220268363, 190162364, 220353033, 226064624, 220881670, 226107848, 220374619, 226072495, 220246187, 196103019, 226037621, 226092631, 226104195, 180799820, 226072746, 210630073, 196097826, 226063212, 226153114, 220283537, 226070615, 220277916, 220231097, 226093651, 220452287, 220469511, 226114213, 226120624, 226089042, 226091332, 220352643, 196008425, 220454904, 226063955, 220335025, 226039075, 226150273, 226092948, 226064000, 220333950, 220335150, 220580640, 220319320, 220890756, 226152326, 226135708, 226101652, 226100046, 220212348, 226251906, 220185109, 210850635, 220364814, 220155851, 220786650, 220474764, 220473722, 226118033, 220323014, 196074686, 220585628, 226151817, 220367197, 220451756, 220459346, 226179104, 226090124, 220486521, 226127028, 220157095, 220356645, 226095259, 226087701, 226095215, 226134619, 226117847, 226098560, 220143696, 226105353, 226100701, 220347519, 226153926, 220308577, 226179922, 220249993, 236015968, 236001337, 226100723, 226136477, 220624066, 226125721, 226182806, 220347666, 220285000, 226133809, 196215868, 226122761, 226114887, 220516435, 220390483, 226131740, 220578372, 220555778, 220368888, 220490055, 220567240, 220449808, 220424684, 220790388, 226150267, 220480874, 220416299, 220762296, 226247820, 220170241, 226181977, 226251354, 226120561, 220573037, 226107127, 226182345, 220389157, 220676396, 221925500, 236017760, 186190957, 226104913, 226151027, 220371217, 226151469, 220308577, 220667016, 220190421, 226153471, 226036946, 226090293, 226105375, 226100284, 226096144, 226121917, 226070950, 220394952, 186230343, 226066056, 226100892, 180905817, 226215441, 220550182, 220575635, 226107008, 236036287, 220267553, 220531643, 220587505, 226069696, 220678881, 236027543, 220789999, 226068610, 226123690, 220680488, 226106072, 220665731, 220562303, 226117609, 220369698, 226007107, 190125293, 190165073, 226073926, 226103313, 226088975, 220785840, 196015276, 226151726, 220458439, 220260171, 226070035, 186291260, 226135742, 226214324, 226116231, 220269963, 226182878, 226182828, 220674635, 226156061, 220677833, 226167745, 226182787, 226123082, 226096746, 220583713, 220672479, 220396221, 220496906, 226153211, 226167109, 226126371, 226144577, 220684634, 226108404, 226143206, 200101125, 226143165, 226252227, 226140597, 226194497, 226143905, 226216574, 210601858, 220683909, 226164707, 220701012, 226217118, 230155584, 190263116, 226251564, 220491376, 226156704, 196007126, 196133260, 220770017, 220020157, 220759209, 226087381, 226158506, 226121622, 226101088, 226146539, 223170997, 220610598, 220417225, 226161032, 226155063, 206088882, 230033667, 226126280, 220507111, 226220989, 226167701, 190616684, 226165454, 220773306, 220501317, 220889351, 226129397, 220685927, 226169694, 196095193, 220065181, 226122830, 220587890, 226165937, 226140707, 180866617, 226101367, 226151986, 226143808, 226163577, 220512154, 186298573, 190272612, 220465848, 226141965, 223012838, 226117104, 226254132, 196157420, 220494314, 226100529, 226069511, 220587709, 196135125, 226145274, 226229652, 196023122, 226180361, 226121832, 220495522, 220556566, 226251605, 220613398, 226119699, 220105486, 226157138, 226154899, 220584266, 226157376, 226134954, 226131502, 226106066, 226187646, 226103028, 220463234, 220657788, 220672225, 220618774, 226106179, 226100654, 220407367, 226123305, 220467935, 230158447, 226137196, 226141777, 226132130, 180903667, 226138843, 230080210, 226123004, 220479617, 226162109, 220674475, 220497619, 196281273, 196078650, 226143767, 226160517, 196058646, 226102133, 220576235, 226133144, 220378207, 220685927, 220458003, 220547678, 220722171, 220857370, 226096166, 220519291, 220267321, 220694172, 220546658, 226124858, 220892718, 226174289, 200588937, 226165313, 226143422, 226141943, 226143886, 226135134, 226180258, 230119518, 220587975, 220471237, 226140296, 226167701, 220536013, 210602367, 220604450, 226193499, 220592764, 220810801, 226143751, 226168533, 226161656, 226143983, 220614158, 226169917, 220624191, 226171213, 226141410, 226184523, 210483048, 196039248, 220212332, 226192548, 226221705, 196081982, 226159350, 226125680, 226168890, 220455598, 226145111, 220687575, 186241293, 230071918, 226225713, 216212601, 220545440, 226184614, 226167864, 226128327, 226133229, 226162234, 226195542, 230080301, 236042842, 226220622, 236000179, 226185123, 196094101, 220550740, 226163759, 226143096, 226126296, 220473829, 226126650, 226141658, 226165294, 230078055, 220787288, 226167610, 220625070, 220538649, 226198035, 196241556, 196037333, 186292296, 226253996, 226197134, 220894805, 226136728, 226146799, 220639106, 226161991, 226184830, 220078623, 226194704, 226166640, 180713096, 226200135, 226140622, 190097501, 226143795, 226251235, 226198295, 220530491, 220578617, 220608355, 220534380, 236032188, 220709953, 220806935, 226250679, 226238095, 226242171, 226218075, 230201961, 230125963, 236051978, 230204539, 226238722, 230202577, 230204454, 226218774, 236031817, 236031782, 230203456, 230204846, 230203246, 226241866, 230203274, 230202561, 226250588, 226229163, 226240705, 230204153, 220850829, 230203553, 236041032, 230203995, 230205264, 236032821, 230204664, 230201961, 230205060, 230204830, 226240448, 236031748, 236031384, 236052051, 230191099, 226217704, 236031130, 230203644, 230202561, 230197633, 230193437, 226229204, 236031293, 226218815, 236041145, 230201767, 230203230, 236051940, 236052158, 226240357, 220726690, 230205151, 236032934, 230203252, 226238675, 230203337, 230203553, 230203440, 230204595, 230201632, 230202925, 230203644, 236032746, 230204125, 230204727, 230203315, 236041612, 230203224, 230204078, 236050306, 230204056, 230202248, 230203581, 226218194, 230198578, 230183610, 230203199, 236052164, 230205145, 230204200, 230203951, 230203531, 226241098, 230204868, 230203149, 230203070, 236031425, 230203826, 230200941, 230205123, 230205424, 230196914, 230054754, 230204551, 226208979, 230203901, 230204363, 230196180, 230176392, 230204692, 230204222, 230203741, 230203202, 230204432, 230204175, 230204802, 230205123, 220735867, 226241474, 220871831, 226241383, 236031679, 230205468, 236033186, 226238738, 230205032, 226186018, 226209400, 236032796, 236041656, 230204404, 230185644, 230198578, 230204909, 230196867, 236041543, 230204119, 236047961, 230203547, 236032467, 226229389, 230144521, 230203622, 230204965, 230203315, 230204147, 230204028, 226241167, 226239883, 226240545, 226241214, 236052089, 236040824, 230203111, 226229232, 230201632, 236033249, 230204874, 230203672, 230204567, 226208844, 230203315, 230204573, 230202721, 230204288, 230203371, 230205333, 236041101, 226228911, 230192144, 226218649, 230203995, 230203672, 230204056, 230203183, 236051990, 230204896, 230205258, 230202044, 230203569, 230205220, 230204448, 230203666, 226240539, 236040830, 226241264, 230193443, 230203337, 236032893, 230194322, 230203973, 230201892, 230205327, 230203989, 230203224, 236033136, 226238346, 236052017, 230205292, 230202759, 230203600, 226240711, 230200941, 230204385, 230203917, 226242024, 230204272, 236052114, 230204523, 226209541, 230203735, 236041496, 230204084, 230202129, 230202561, 230201278, 230204517, 236051956, 230205004, 230203365, 230203519, 230042577, 230204410, 230204987, 230203763, 226218360, 230203428, 230200076, 226219164, 236033192, 230203315, 226229248, 220494149, 230203616, 230203246, 226218116, 226239532, 230204476, 230204006, 230204175, 226238540, 236031572, 226240943, 230203086, 230204818, 230202301, 226241634, 230198625, 230204147, 226218809, 226240670, 230203644, 230204539, 230204799, 236040818, 230204385, 226240272, 230087670, 226208822, 236052136, 230203202, 230204090, 230203989, 226217760, 220866434, 226241452, 230201767, 236051928, 226239786, 226238114, 230204379, 230204181, 230205060, 230201767, 230204971, 226241145, 230204460, 230204937, 230199548, 230203525, 230204567, 230203713, 220618677, 230204539, 236052045, 230204670, 226238302, 230200941, 230203393, 236052067, 226228983, 230203343, 226209278, 230203490, 230204216, 236041402, 230205264, 226240335, 236031497, 226209193, 226209052, 230204589, 230182935, 230203989, 230204482, 236051912, 230203644, 230202981, 236041305, 230203898, 230203183, 226238772, 226240103, 230203092, 236040921, 226218279, 230205195, 230202721, 220751813, 230204608, 230204335, 236051962, 230204266, 230204266, 230203014, 230204238, 230202044, 230196340, 230204761, 230205101, 230147246, 230204711, 230204090, 230205195, 230204818, 226241565, 230204169, 230204147, 236052023, 236041098, 236032279, 230205286, 230046068, 226242096, 236032285, 230203086, 236052120, 230204545, 236052108, 236052142, 226238788, 236032360, 230205349, 226239714, 226218423, 236031544, 230203490, 230203218, 230204705, 236032489, 230178514, 236032263, 230203315, 230204040, 226219186, 230205026, 230202323, 230204404, 226241894, 230203854, 226209507, 230202511, 220873912, 230205010, 236031851, 230204880, 230205139, 230204062, 230205026, 230202511, 230202953, 226208800, 230063056, 230204589, 226217914, 226240379, 230204197, 230203086, 230203246, 230202129, 236052039, 230205220, 230203779, 226238744, 236051984, 226239673, 230202721, 230201767, 230205208, 230203616, 230205377, 230204103, 230202953, 230204539, 230204567, 230201905, 230203729, 236032677, 226198728, 230204874, 230205236, 230201585, 230205418, 230134481, 230201234, 230203359, 230203672, 230204783, 230203757, 230204335, 230203622, 230203393, 226219211, 230203644, 230204874, 230195455, 230203274, 230203111, 230074746, 230205430, 230201983, 230203791, 230203393, 226239902, 230202511, 230204642, 230204385, 236052095, 230204410, 236032417, 230202301, 236052073, 226238948, 230204482, 230203086, 226209723, 236052001, 230201331, 230204391, 230203406, 230203484, 230204103, 230203672, 220863311, 230204410, 226238299, 226219120, 230202301, 226242187, 230203371, 226240084, 226241292, 230204620, 226238528, 230204103, 236052170, 230203387, 226240658, 226217710, 230204880, 230204482, 230203939, 230205060, 230196914, 236033465, 236052556, 236052352, 236052277, 236052318, 230205543, 230205690, 230204307, 230205446, 230206977, 236052324, 236052302, 230194162, 230207260, 230206676, 230206789, 230206159, 230206494, 230179857, 230205355, 230206717, 230206074, 230206193, 230205383, 230205474, 230206381, 230181937, 230205515, 230003654, 230205082, 230206773, 230205838, 230205888, 230206018, 230205941, 230206319, 230206870, 230206109, 230201961, 230205593, 230205731, 230206143, 230207129, 236052534, 230206591, 230206096, 230206068, 230206905, 230207721, 230205866, 230206438, 236052647, 230206284, 230196914, 230206400, 210481490, 230207442, 230205606, 230206610, 230206905, 230206397, 236052619, 236052415, 230206068, 230206444, 230206278, 230207533, 230207226, 230205559, 230205844, 230206353, 230205963, 236052540, 230169290, 236052506, 226139039, 230206961, 230205383, 230206660, 236052459, 230207276, 230207301, 230206080, 236052261, 230206654, 230206529, 236052443, 230204852, 230168424, 230206422, 236052631, 230205703, 230207044, 236052227, 230205214, 230206369, 230205559, 220828694, 230206002, 230206585, 230205800, 230205850, 230189549, 230207414, 230206121, 230206397, 236052380, 230207016, 230205656, 230206507, 236052368, 230206052, 236052653, 230207486, 236052374, 230205725, 230207492, 230205894, 230205098, 230205446, 230206466, 230206187, 230206723, 236052625, 230207408, 230206234, 230206206, 220811467, 230177635, 230169290, 230207395, 230207420, 236051285, 230206024, 230205719, 230205214, 230204852, 230178815, 226188945, 230205565, 236052528, 230206319, 230204498, 230207179, 230204749, 230205747, 236052471, 230206256, 236052255, 230205634, 230206319, 230205678, 230205054, 230205098, 230205587, 230207022, 230207373, 230188319, 230207743, 230206513, 230205521, 200789226, 230203876, 230195803, 230205662, 230205929, 230206977, 230205656, 230206591, 230206795, 236052186, 230205571, 230200098, 230205957, 230183319, 236052330, 230196340, 230207840, 230206563, 236052578, 230169290, 230205991, 230207458, 236052283, 236052512, 230206381, 230207624, 230207191, 236052299, 230206375, 230203832, 236052421, 230205872, 236052465, 230206983, 230205521, 230204830, 230206115, 230205214, 230205838, 230196340, 230207806, 230207696, 230206284, 230207862, 230205048, 230205399, 230206864, 230205565, 230205907, 230205612, 230205399, 230205446, 230207107, 230206541, 236052493, 230205929, 230205496, 230206080, 230206660, 236052487, 230206911, 230196340, 230206422, 230207038, 230206165, 230206660, 230207577, 230205048, 230206814, 230175338, 230206579, 230205797, 236052584, 230206892, 230204852, 230205628, 230206240, 230207113, 230203967, 236052249, 230205286, 230200010, 230205640, 230206381, 230207555, 236052562, 236052437, 230205565, 230206325, 230204921, 230206262, 236052409, 230205797, 230205628, 230205509, 210481490, 230206331, 230206949, 236052346, 230206836, 236052590, 230204034, 236052205, 230206842, 230206046, 230206159, 230207561, 230205957, 230205775, 230206074, 230205822, 236052603, 230204341, 230206858, 236052233, 230205571, 236052396, 230206165, 230206933, 230206228, 230205797, 236052192, 230206795, 230206068, 230205957, 230206820, 230205929, 230206911, 230206557, 230205985, 230206767, 230197564, 230202840, 236053441, 226137607, 230211528, 230139760, 220599986, 236054455, 186267590, 236054530, 236054580, 220253392, 236053184, 236054693, 226198029, 236053015, 236053554, 226154805, 230209573, 236054217, 230208224, 230209379, 230208406, 226173918, 230209266, 230211471, 236054085, 230208967, 230208882, 236052788, 236053338, 230209197, 230065290, 230208531, 230208644, 230211324, 230210235, 236053651, 236052891, 230210837, 230210257, 230186545, 230211318, 230211697, 236053805, 230211227, 230208230, 230210912, 230209329, 230209454, 230210138, 230206165, 230210912, 230211857, 230208127, 230211114, 230208412, 230208882, 230209539, 236053491, 230207351, 230210229, 236054132, 236053526, 230206193, 230210912, 236053617, 230209498, 236054007, 230208490, 236052926, 230209937, 230209608, 230207856, 230210837, 236053429, 236052772, 230209987, 230211039, 230209216, 236053582, 230211380, 230206234, 230209523, 230211534, 230210360, 230209222, 230211653, 236054596, 230207771, 230207282, 230211211, 230210702, 230210564, 236054126, 230208945, 236054433, 230209943, 230209802, 220787181, 230208105, 230211459, 236053162, 230211863, 230210116, 230209620, 230209915, 236053457, 230209460, 230207812, 236054201, 230207953, 230210627, 236052722, 236052675, 230182214, 230209363, 236054273, 230208280, 230207226, 236053316, 236053021, 230209501, 236053112, 230210627, 230208230, 230209664, 230209062, 230208989, 230195574, 230210592, 230211835, 236053968, 230210592, 230211324, 230209426, 236052948, 236052738, 230210633, 236053297, 230207527, 230210564, 230210332, 230210558, 230210859, 230208183, 230207094, 230207254, 230206165, 236054110, 230210291, 230210978, 236054289, 236054461, 230209391, 230211192, 236053275, 230207470, 230210263, 230211487, 236053269, 230210310, 236053388, 230211578, 230209056, 200143280, 230208412, 236054308, 236054386, 236054687, 230211675, 230209244, 230209830, 230200662, 230210291, 230208672, 230207345, 236053645, 230208688, 230211829, 236053786, 236054637, 236053576, 230211164, 230211863, 230191516, 230208832, 230208854, 230208848, 230208042, 230211766, 230208462, 230208713, 236053877, 230208224, 230208741, 236053764, 236052700, 230209711, 230207050, 236053974, 236053946, 230211299, 230117772, 230122226, 230207947, 236054057, 230208757, 230209307, 236053322, 230207351, 236053714, 230210348, 230211744, 236052835, 236054079, 236053231, 230207812, 236054342, 236053407, 230211493, 230208268, 230207680, 230185280, 230210746, 230208650, 230211001, 230211998, 230210984, 230209971, 230192912, 230211722, 230209084, 236054160, 230211681, 236054358, 230208484, 230208569, 230210956, 230209294, 236053247, 236054659, 230210489, 236053996, 230196566, 230201450, 230206927, 230209896, 230209288, 230209147, 230200189, 230207050, 236054518, 230208503, 230211813, 230210887, 236053899, 230211277, 230211368, 230198528, 230209385, 230211910, 230205894, 230208343, 230209341, 230211631, 230208525, 226163000, 230208036, 230209971, 236052766, 236052669, 230211443, 230209034, 236052744, 236054615, 230211249, 230177641, 230211540, 236054712, 230208616, 230208183, 230210138, 230210774, 230211045, 230210100, 220787181, 230211813, 230209818, 230208967, 220787181, 230208785, 230210285, 230208393, 236054182, 230207088, 236053689, 236054449, 230210417, 236053128, 236054483, 236053924, 230208525, 236053601, 230209830, 230209965, 230210495, 230208876, 230210075, 236054609, 230211089, 230208014, 230210699, 230208058, 230211465, 236053883, 230209852, 230209169, 230210445, 236053952, 230209959, 230209658, 230096251, 230211352, 230210019, 230209868, 236052910, 230211700, 226146943, 230209335, 236053435, 236052998, 236054063, 230208638, 230209200, 230210542, 230207094, 230210768, 236053190, 230208826, 230203553, 230208791, 230207602, 230211277, 230207890, 236054621, 230197928, 230211136, 230210473, 236053736, 236053485, 230209090, 230211807, 230209410, 230209238, 230207947, 230208111, 230210655, 230211697, 230195336, 230211045, 230210354, 230207787, 236052794, 236052976, 230211506, 230209880, 230208973, 230208064, 226176279, 230210382, 230211233, 236053009, 230208553, 230211556, 230209755, 230209006, 230207248, 236054336, 220651019, 230203553, 230209006, 220796035, 230192683, 230210235, 236023074, 230211283, 236054251, 236053833, 230209006, 236053720, 236053651, 230199441, 230211415, 230210724, 230209517, 230191629, 230208252, 230209868, 230211108, 230207436, 230211318, 230208616, 236053902, 230189420, 230211562, 236054314, 236054148, 230209545, 230209846, 230208547, 230207715, 230210796, 230201450, 230207903, 230208810, 230209777, 230176950, 230208199, 236054295, 236053350, 230205979, 230209391, 236052841, 236053106, 236053695, 230208553, 236053849, 230196801, 236054245, 230178489, 236053281, 230195659, 230208315, 23018553","""[2018","2019.0]""",,,
Name the 6 years with the most number of unique incident categories.,Which are the top 6 years with the highest number of distinct incident categories?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Incident Year and count distinct Incident Categories
    year_category_counts = dataset.groupby('Incident Year')['Incident Category'].nunique().reset_index()
    
    # Sort the results in descending order based on the count of distinct categories
    top_years = year_category_counts.sort_values(by='Incident Category', ascending=False)
    
    # Get the top 6 years with the highest number of distinct incident categories
    top_6_years = top_years.head(6)['Incident Year'].tolist()
    
    return top_6_years
",list of (int64),"[2018, 2019, 2020, 2021, 2022, 2023]","[2018, 2019, 2020, 2021, 2022, 2023]",,,,
Do all patients experience exercise-induced angina?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks if there is any individual with HeartDisease set to 1
    has_heart_disease = (dataset['HeartDisease'] == 1).any()
    
    return has_heart_disease",bool,True,False,,,,
Does any patient have a resting blood pressure above 200?,Is there any patient with a resting blood pressure greater than 200?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_high_bp = dataset[""RestingBP""].max() > 200

return has_high_bp
",bool,False,False,,,,
Are there patients without heart disease?,Is there at least one patient without heart disease?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_no_heart_disease = dataset['HeartDisease'].min() == 0

return has_no_heart_disease",bool,True,True,,,,
Does everyone have normal resting electrocardiographic results?,Are all individuals recorded with normal resting electrocardiographic results?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
are_all_normal = dataset[""RestingECG""].isin([""Normal""]).all()
return are_all_normal",bool,False,False,,,,
What is the maximum age of patients in the dataset?,What is the highest age present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_age = dataset['Age'].max()
    return max_age
",uint8,77,77,,,,
What is the minimum resting blood pressure among the patients?,What is the lowest value of RestingBP in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_resting_bp = dataset[""RestingBP""].min()
    
    return min_resting_bp",uint8,0,0,,,,
What is the average cholesterol level in the dataset?,What is the mean value of the Cholesterol column in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    cholesterol_mean = dataset['Cholesterol'].mean()
    
    return cholesterol_mean
",float64  ,198.7995640000000,198.7995640000000,,,,
What is the standard deviation of maximum heart rate among the patients?,What is the standard deviation of the maximum heart rate for all patients?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_hr_std = dataset[""MaxHR""].std()
    return max_hr_std
",float64  ,25.4603340000000,25.4603340000000,,,,
What is the most common chest pain type among patients?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column value or a derived string from the data
    # For demonstration purposes, let's assume the question is ""What is the most common ChestPainType?""
    most_common_chest_pain_type = dataset['ChestPainType'].mode()[0]
    
    return str(most_common_chest_pain_type)",string,ASY,ASY,,,,
What is the least common resting electrocardiographic result?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column value or some derived information from the dataset.
    # For demonstration purposes, let's assume the question is: ""What is the most common ChestPainType?""
    
    # Find the mode of the 'ChestPainType' column
    most_common_chest_pain_type = dataset['ChestPainType'].mode()[0]
    
    return str(most_common_chest_pain_type)",string,ASY,ST,,,,
What is the most common ST slope among patients with heart disease?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a specific categorical value from the dataset
# For example, if the question is ""What is the most common ChestPainType?""
if question == ""What is the most common ChestPainType?"":
most_common_cptype = dataset['ChestPainType'].mode()[0]
return most_common_cptype

# Add more conditions based on different questions
# For example, if the question is ""What is the most common Sex?""
elif question == ""What is the most common Sex?"":
most_common_sex = dataset['Sex'].mode()[0]
return most_common_sex

# Default return (modify as needed)
return None",category,,Flat,,,,
What is the least common chest pain type among male patients?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value or some derived information from the dataset.
    # For demonstration purposes, let's assume the question asks for the most common 'ChestPainType'.
    
    # Find the most common 'ChestPainType'
    most_common_chest_pain_type = dataset['ChestPainType'].mode()[0]
    
    return most_common_chest_pain_type
",string,ASY,TA,,,,
What are the top 3 most common chest pain types?,What are the three most frequent types of chest pain?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each ChestPainType
    chest_pain_counts = dataset['ChestPainType'].value_counts()
    
    # Get the three most frequent types of chest pain
    top_three_chest_pains = chest_pain_counts.head(3).index.tolist()
    
    return top_three_chest_pains",list of (string),"['ASY', 'NAP', 'ATA']","['ASY', 'NAP', 'ATA']",,,,
Which 4 resting electrocardiographic results are least common?,What are the four least common resting electrocardiographic results?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    resting_ecg_counts = dataset['RestingECG'].value_counts(ascending=True).head(4)
    least_common_resting_ecg = resting_ecg_counts.index.tolist()
    
    return least_common_resting_ecg
",list of (string),"['ST', 'LVH', 'Normal']","['ST', 'LVH', 'Normal']",,,,
What are the 2 most common ST slopes among patients with heart disease?,What are the two most frequent ST slopes for patients diagnosed with heart disease?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_dataset = dataset[dataset['HeartDisease'] == 1]
    st_slope_counts = filtered_dataset['ST_Slope'].value_counts().head(2).index.tolist()
    
    return st_slope_counts",list of (string),"['Flat', 'Up']","['Flat', 'Up']",,,,
What are the 4 most common chest pain types among male patients?,What are the four most frequent types of chest pain experienced by male patients?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for male patients
    male_patients = dataset[dataset['Sex'] == 'M']
    
    # Get the frequency of each chest pain type among male patients
    chest_pain_freq = male_patients['ChestPainType'].value_counts()
    
    # Get the four most frequent types of chest pain
    top_four_chest_pains = chest_pain_freq.head(4).index.tolist()
    
    return top_four_chest_pains
",list of (string),"['ASY', 'NAP', 'ATA', 'TA']","['TA', 'ATA', 'NAP', 'ASY']",,,,
What are the ages of the 5 oldest patients in the dataset?,What are the ages of the top 5 oldest patients in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by age in descending order and get the top 5 ages
    top_5_oldest = dataset.sort_values(by='Age', ascending=False)['Age'].head(5).tolist()
    
    return top_5_oldest
",list of (int64),"[77, 77, 76, 76, 75]","[77, 77, 76, 76, 75]",,,,
What are the 4 highest resting blood pressures?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column of values
    # For example, if the question asks for all ages, we can extract that column
    age_values = dataset['Age'].tolist()
    
    return age_values
",list of (int64),"[40, 49, 37, 48, 54, 39, 45, 54, 37, 48, 37, 58, 39, 49, 42, 54, 38, 43, 60, 36, 43, 44, 49, 44, 40, 36, 53, 52, 53, 51, 53, 56, 54, 41, 43, 32, 65, 41, 48, 48, 54, 54, 35, 52, 43, 59, 37, 50, 36, 41, 50, 47, 45, 41, 52, 51, 31, 58, 54, 52, 49, 43, 45, 46, 50, 37, 45, 32, 52, 44, 57, 44, 52, 44, 55, 46, 32, 35, 52, 49, 55, 54, 63, 52, 56, 66, 65, 53, 43, 55, 49, 39, 52, 48, 39, 58, 43, 39, 56, 41, 65, 51, 40, 40, 46, 57, 48, 34, 50, 39, 59, 57, 47, 38, 49, 33, 38, 59, 35, 34, 47, 52, 46, 58, 58, 54, 34, 48, 54, 42, 38, 46, 56, 56, 61, 49, 43, 39, 54, 43, 52, 50, 47, 53, 56, 39, 42, 43, 50, 54, 39, 48, 40, 55, 41, 56, 38, 49, 44, 54, 59, 49, 47, 42, 52, 46, 50, 48, 58, 58, 29, 40, 53, 49, 52, 43, 54, 59, 37, 46, 52, 51, 52, 46, 54, 58, 58, 41, 50, 53, 46, 50, 48, 45, 41, 62, 49, 42, 53, 57, 47, 46, 42, 31, 56, 50, 35, 35, 28, 54, 48, 50, 56, 56, 47, 30, 39, 54, 55, 29, 46, 51, 48, 33, 55, 50, 53, 38, 41, 37, 37, 40, 38, 41, 54, 39, 41, 55, 48, 48, 55, 54, 55, 43, 48, 54, 54, 48, 45, 49, 44, 48, 61, 62, 55, 53, 55, 36, 51, 55, 46, 54, 46, 59, 47, 54, 52, 34, 54, 47, 45, 32, 55, 55, 45, 59, 51, 52, 57, 54, 60, 49, 51, 55, 42, 51, 59, 53, 48, 36, 48, 47, 53, 65, 32, 61, 50, 57, 51, 47, 60, 55, 53, 62, 51, 51, 55, 53, 58, 57, 65, 60, 41, 34, 53, 74, 57, 56, 61, 68, 59, 63, 38, 62, 46, 42, 45, 59, 52, 60, 60, 56, 38, 40, 51, 62, 72, 63, 63, 64, 43, 64, 61, 52, 51, 69, 59, 48, 69, 36, 53, 43, 56, 58, 55, 67, 46, 53, 38, 53, 62, 47, 56, 56, 56, 64, 61, 68, 57, 63, 60, 66, 63, 59, 61, 73, 47, 65, 70, 50, 60, 50, 43, 38, 54, 61, 42, 53, 55, 61, 51, 70, 61, 38, 57, 38, 62, 58, 52, 61, 50, 51, 65, 52, 47, 35, 57, 62, 59, 53, 62, 54, 56, 56, 54, 66, 63, 44, 60, 55, 66, 66, 65, 60, 60, 60, 56, 59, 62, 63, 57, 62, 63, 46, 63, 60, 58, 64, 63, 74, 52, 69, 51, 60, 56, 55, 54, 77, 63, 55, 52, 64, 60, 60, 58, 59, 61, 40, 61, 41, 57, 63, 59, 51, 59, 42, 55, 63, 62, 56, 53, 68, 53, 60, 62, 59, 51, 61, 57, 56, 58, 69, 67, 58, 65, 63, 55, 57, 65, 54, 72, 75, 49, 51, 60, 64, 58, 61, 67, 62, 65, 63, 69, 51, 62, 55, 75, 40, 67, 58, 60, 63, 35, 62, 43, 63, 68, 65, 48, 63, 64, 61, 50, 59, 55, 45, 65, 61, 49, 72, 50, 64, 55, 63, 59, 56, 62, 74, 54, 57, 62, 76, 54, 70, 61, 48, 48, 61, 66, 68, 55, 62, 71, 74, 53, 58, 75, 56, 58, 64, 54, 54, 59, 55, 57, 61, 41, 71, 38, 55, 56, 69, 64, 72, 69, 56, 62, 67, 57, 69, 51, 48, 69, 69, 64, 57, 53, 37, 67, 74, 63, 58, 61, 64, 58, 60, 57, 55, 55, 56, 57, 61, 61, 74, 68, 51, 62, 53, 62, 46, 54, 62, 55, 58, 62, 70, 67, 57, 64, 74, 65, 56, 59, 60, 63, 59, 53, 44, 61, 57, 71, 46, 53, 64, 40, 67, 48, 43, 47, 54, 48, 46, 51, 58, 71, 57, 66, 37, 59, 50, 48, 61, 59, 42, 48, 40, 62, 44, 46, 59, 58, 49, 44, 66, 65, 42, 52, 65, 63, 45, 41, 61, 60, 59, 62, 57, 51, 44, 60, 63, 57, 51, 58, 44, 47, 61, 57, 70, 76, 67, 45, 45, 39, 42, 56, 58, 35, 58, 41, 57, 42, 62, 59, 41, 50, 59, 61, 54, 54, 52, 47, 66, 58, 64, 50, 44, 67, 49, 57, 63, 48, 51, 60, 59, 45, 55, 41, 60, 54, 42, 49, 46, 56, 66, 56, 49, 54, 57, 65, 54, 54, 62, 52, 52, 60, 63, 66, 42, 64, 54, 46, 67, 56, 34, 57, 64, 59, 50, 51, 54, 53, 52, 40, 58, 41, 41, 50, 54, 64, 51, 46, 55, 45, 56, 66, 38, 62, 55, 58, 43, 64, 50, 53, 45, 65, 69, 69, 67, 68, 34, 62, 51, 46, 67, 50, 42, 56, 41, 42, 53, 43, 56, 52, 62, 70, 54, 70, 54, 35, 48, 55, 58, 54, 69, 77, 68, 58, 60, 51, 55, 52, 60, 58, 64, 37, 59, 51, 43, 58, 29, 41, 63, 51, 54, 44, 54, 65, 57, 63, 35, 41, 62, 43, 58, 52, 61, 39, 45, 52, 62, 62, 53, 43, 47, 52, 68, 39, 53, 62, 51, 60, 65, 65, 60, 60, 54, 44, 44, 51, 59, 71, 61, 55, 64, 43, 58, 60, 58, 49, 48, 52, 44, 56, 57, 67, 53, 52, 43, 52, 59, 64, 66, 39, 57, 58, 57, 47, 55, 35, 61, 58, 58, 58, 56, 56, 67, 55, 44, 63, 63, 41, 59, 57, 45, 68, 57, 57, 38]","[200, 200, 200, 200]",,,,
What are the 6 lowest cholesterol levels in the dataset?,Find the six smallest cholesterol levels in the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
sorted_cholesterol = dataset[""Cholesterol""].sort_values().head(6).tolist()
return sorted_cholesterol
",list of (int64),"[0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0]",,,,
What are the 3 highest maximum heart rates among the patients?,Find the top 3 maximum heart rates from the patients' records.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_3_max_hr = dataset['MaxHR'].nlargest(3).tolist()
    return top_3_max_hr
",list of (int64),"[202, 195, 194]","[202, 195, 194]",,,,
Did the oldest roller coaster in the dataset still operate?,Is the roller coaster with the earliest opening date still operational?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the roller coaster with the earliest opening date
    earliest_coaster = dataset.loc[dataset['opening_date_clean'] == dataset['opening_date_clean'].min()]
    
    # Check if the status of this roller coaster is 'Operating'
    is_operational = earliest_coaster['Status'].str.contains('Operating', na=False).bool()
    
    return is_operational
",bool,False,True,,,,
Is there a roller coaster in the dataset that operates at a speed more than 100 mph?,Is there any roller coaster in the dataset with a speed greater than 100 mph?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_speed = not dataset[dataset['speed_mph'] > 100].empty

    return has_high_speed
",bool  ,True,True,,,,
Are all roller coasters in the dataset designed by 'Werner Stengel' removed?,,,,ERROR,False,,,,
Does every roller coaster have a G-force value?,Is the G-force value available for all roller coasters?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_g_force_value = not dataset['Gforce_clean'].isnull().any()
    
    return has_g_force_value
",bool,False,False,,,,
What is the maximum speed (in mph) for roller coasters in the dataset?,What is the highest speed in mph recorded for roller coasters in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_speed = dataset['speed_mph'].max()
    return max_speed
",float64  ,149.1,149.1,,,,
How many roller coasters were introduced in the year 2000?,How many roller coasters were introduced in the year 2000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
coasters_introduced_in_2000 = dataset[dataset['year_introduced'] == 2000]
count = len(coasters_introduced_in_2000)

return count
",int64,47,47,,,,
What is the average G-force across all roller coasters in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a numerical value from the dataset
    # For demonstration purposes, let's assume the question asks for the average speed of all coasters in mph.
    average_speed = dataset['speed_mph'].mean()

    return average_speed",float64,48.617289000000000,3.8240060000000000,,,,
What is the total number of roller coasters designed by 'Edwin Madeupname' in the dataset?,How many roller coasters in the dataset were designed by Edwin Madeupname?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    designer_name = ""Edwin Madeupname""
    count = dataset[dataset[""Designer""] == designer_name].shape[0]
    
    return count
",int64,0,0,,,,
Which manufacturer has built the fastest roller coaster?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Placeholder for the actual implementation
    return None",category,,Intamin,,,,
What is the status of the roller coaster with the highest G-force?,,,,ERROR,Removed,,,,
What type of the roller coaster is the oldest in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value from the dataset
    # For example, if the question is ""What is the name of the roller coaster with the highest height?"",
    # we would find the row with the maximum height and return its 'coaster_name'.
    
    # Extracting the column name from the question (for demonstration purposes)
    # In a real scenario, you would need to parse the question to extract this information
    column_to_extract = 'coaster_name'
    
    # Finding the row with the maximum height
    max_height_row = dataset.loc[dataset['height_value'] == dataset['height_value'].max()]
    
    # Extracting the value from the specified column
    answer = max_height_row[column_to_extract].values[0]
    
    return answer
",category,Smoky Mountain Alpine Coaster,Wood,,,,
What is the location of the roller coaster with the highest number of inversions?,Where is the roller coaster located that has the highest number of inversions?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_inversions_roller_coaster = dataset.loc[dataset[""Inversions_clean""] == dataset[""Inversions_clean""].max()]
    location = max_inversions_roller_coaster[""Location""].iloc[0]

    return location
",string,Alton Towers,Alton Towers,,,,
What are the names of the top 3 fastest roller coasters?,What are the names of the top 3 roller coasters with the highest speeds?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by speed in descending order and select the top 3 roller coasters
    top_3_coasters = dataset.sort_values(by='speed_mph', ascending=False).head(3)
    
    # Extract the names of the top 3 roller coasters
    top_3_names = top_3_coasters['coaster_name'].tolist()
    
    return top_3_names
",list of (string),"['Formula Rossa', 'Kingda Ka', 'Top Thrill Dragster']","[Formula Rossa, Kingda Ka, Top Thrill Dragster]",,,,
Which 2 roller coasters have the highest number of inversions?,What are the names of the two roller coasters with the highest number of inversions?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_2_coasters = dataset.nlargest(2, 'Inversions')
coaster_names = top_2_coasters['Name'].tolist()

return coaster_names",list of (string),"[nan, nan]","[The Smiler, Colossus (Thorpe Park)]",,,,
What are the locations of the top 5 roller coasters with the highest G-force?,What are the locations of the top 5 roller coasters with the highest G-force?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Gforce_clean' in descending order to get the top 5 roller coasters with the highest G-force
    top_5_g_force_coasters = dataset.sort_values(by='Gforce_clean', ascending=False).head(5)
    
    # Extract the 'Location' column for these top 5 roller coasters
    locations = top_5_g_force_coasters['Location'].tolist()
    
    return locations
",list of (string),"['Sea Lion Park', 'Fuji-Q Highland', 'Six Flags Over Texas', 'Nürburgring', 'Other']","[Sea Lion Park, Fuji-Q Highland, Six Flags Over Texas, Nürburgring, Morey's Piers]",,,,
Name the 4 oldest roller coasters in the dataset.,What are the names of the 4 oldest roller coasters in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by opening_date_clean in ascending order to get the oldest roller coasters first
    sorted_dataset = dataset.sort_values(by='opening_date_clean', ascending=True)
    
    # Get the names of the 4 oldest roller coasters
    oldest_coaster_names = sorted_dataset['Name'].head(4).tolist()
    
    return oldest_coaster_names
",list of (string),"[nan, nan, nan, nan]","[Switchback Railway, Flip Flap Railway, Loop the Loop (Coney Island), Loop the Loop (Young's Pier)]",,,,
What are the top 3 speeds (in mph) of roller coasters in the dataset?,What are the top 3 speeds in mph for roller coasters listed in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by speed_mph in descending order and get the top 3 speeds
    top_3_speeds = dataset['speed_mph'].nlargest(3).tolist()
    
    return top_3_speeds
",list of (float64),"[149.1, 128.0, 120.0]","[149.1, 128.0, 120.0]",,,,
List the G-force values of the 2 roller coasters with the highest G-force.,What are the G-force values for the top 2 roller coasters with the highest G-force?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by G-force in descending order and select the top 2 rows
    top_2_gforce_coasters = dataset.sort_values(by='Gforce_clean', ascending=False).head(2)
    
    # Extract the G-force values from these top 2 rows
    gforce_values = top_2_gforce_coasters['Gforce_clean'].tolist()
    
    return gforce_values
",list of (float64),"[12.0, 6.5]","[12.0, 6.5]",,,,
What are the heights (in ft) of the top 4 tallest roller coasters?,What are the heights in feet of the top 4 tallest roller coasters?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by height_value in descending order and get the top 4 rows
    top_4_tallest_coasters = dataset.sort_values(by='height_value', ascending=False).head(4)
    
    # Extract the height_ft column values as a list
    heights_in_feet = top_4_tallest_coasters['height_ft'].tolist()
    
    return heights_in_feet
",list of (float64),"[nan, nan, nan, nan]","[377.3, 367.5, 318.2, 306.1]",,,,
Name the introduction years of the 6 oldest roller coasters in the dataset.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of years introduced
    unique_years = dataset['year_introduced'].unique().tolist()
    
    return unique_years",list of uint16,"[1884, 1895, 1896, 1901, 1902, 1904, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1917, 1919, 1920, 1921, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1932, 1933, 1934, 1935, 1937, 1938, 1940, 1941, 1946, 1950, 1951, 1952, 1955, 1956, 1958, 1959, 1961, 1964, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]","[1884, 1895, 1901, 1901, 1902, 1902]",,,,
Is there a rental property with exactly 5 bedrooms?,Is there any Airbnb listing with exactly 5 bedrooms?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_five_bedrooms = (dataset['bedrooms'] == 5).any()
    
    return has_five_bedrooms
",bool,True,True,,,,
Is there a rental property listed by a superhost that is instantly bookable?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code to answer the question goes here
    return None
",bool,,True,,,,
Are there any rental properties that can accommodate more than 10 guests?,Is there any rental property on Airbnb that can accommodate more than 10 guests?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_accommodates_more_than_10 = dataset[""accommodates""] > 10
    return has_accommodates_more_than_10.any()
",bool,True,True,,,,
Is there a rental property that has received a perfect review score?,Is there any rental property with a review score of 10?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_review_score_10 = dataset['review_scores_rating'].max() == 10

return has_review_score_10",bool,False,False,,,,
How many rental properties are there in the dataset?,What is the total count of rental properties in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    total_count = len(dataset)
    return total_count
",int64,20776,20776,,,,
What is the maximum number of bedrooms in a property?,What is the highest number of bedrooms in any property listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_bedrooms = dataset[""bedrooms""].max()
    
    return max_bedrooms
",float64  ,18.0,18.0,,,,
What is the highest price per night for a rental property?,,,,ERROR,95150.0,,,,
What is the maximum number of reviews a property has received?,What is the highest number of reviews received by any property?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_reviews = dataset['number_of_reviews'].max()
return max_reviews
",int64  ,870,870,,,,
What is the host response time for the property with the highest number of bedrooms?,,,,ERROR,within an hour,,,,
What type of room is the most expensive property?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    return None
",string,,Entire home/apt,,,,
What is the property type of the listing with the most reviews?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the property type of the listing with the highest review score rating
    max_rating_listing = dataset.loc[dataset[""review_scores_rating""] == dataset[""review_scores_rating""].max()]
    property_type = max_rating_listing[""property_type""].iloc[0]

    return property_type
",category,Entire rental unit,Entire rental unit,,,,
What is the acceptance rate of the host of the property that can accommodate the most number of guests?,,,,ERROR,100.0%,,,,
Which are the 2 lowest values of host response rates above 0% ?,,,,ERROR,"['5%', '10%']",,,,
Which are the 2 lowest values of host response rates?,What are the two smallest values for host response rates?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Remove '%' sign and convert to float
    dataset['host_response_rate'] = dataset['host_response_rate'].str.rstrip('%').astype(float)
    
    # Sort by host response rate in ascending order
    sorted_host_response_rates = dataset.sort_values(by='host_response_rate')
    
    # Get the two smallest values for host response rates
    two_smallest_response_rates = sorted_host_response_rates['host_response_rate'].head(2).astype(str) + '%'
    
    return two_smallest_response_rates.tolist()
",list of (string),"['0.0%', '0.0%']","['0%', '0%']",,,,
What are the 4 highest values of host acceptance rates?,,,,ERROR,"['99%', '99%', '99%', '99%']",,,,
What are the 2 least common scraping sources?,What are the two least frequently occurring scraping sources?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    source_counts = dataset['source'].value_counts().sort_values(ascending=True).head(2)
    least_frequent_sources = source_counts.index.tolist()

    return least_frequent_sources
",list of (category),"['previous scrape', 'city scrape']","['previous scrape', 'city scrape']",,,,
What are the 3 prices of the most expensive properties?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column's unique categories
    column_name = ""property_type""  # Example column name, replace with actual column if needed
    unique_categories = dataset[column_name].unique().tolist()
    
    return unique_categories",list of (category),"['Private room in rental unit', 'Entire rental unit', 'Entire loft', 'Private room in hostel', 'Private room in home', 'Entire condo', 'Shared room in rental unit', 'Private room in casa particular', 'Private room in guest suite', 'Private room in chalet', 'Entire serviced apartment', 'Private room in bed and breakfast', 'Entire home', 'Private room in condo', 'Shared room in hut', 'Private room in loft', 'Entire bungalow', 'Shared room in hostel', 'Shared room in bed and breakfast', 'Casa particular', 'Private room in floor', 'Entire vacation home', 'Dome', 'Entire place', 'Private room', 'Shared room in home', 'Room in boutique hotel', 'Private room in serviced apartment', 'Room in serviced apartment', 'Private room in guesthouse', 'Entire bed and breakfast', 'Private room in townhouse', 'Entire guesthouse', 'Room in aparthotel', 'Floor', 'Room in hotel', 'Shared room in loft', 'Entire townhouse', 'Shared room in condo', 'Hut', 'Entire guest suite', 'Camper/RV', 'Entire home/apt', 'Room in hostel', 'Private room in villa', 'Private room in bungalow', 'Shared room in resort', 'Private room in tiny home', 'Room in bed and breakfast', 'Entire villa', 'Private room in barn', 'Room in casa particular', 'Private room in dome', 'Tiny home', 'Entire chalet', 'Private room in earthen home', 'Shared room in dome', 'Private room in ice dome', 'Private room in cottage', 'Yurt', 'Private room in pension', 'Entire cabin', 'Shared room in chalet', 'Shared room in serviced apartment', 'Cave', 'Private room in ryokan', 'Shared room', 'Private room in minsu', 'Shared room in hotel', 'Private room in vacation home', 'Shared room in vacation home', 'Private room in cave', 'Shared room in boutique hotel', 'Shared room in casa particular', 'Bus']","[95150.0, 90130.0, 64430.0]",,,,
What are the 2 prices of the least expensive properties?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column's unique values as a list of categories
    # For example, if the question is ""What are the unique neighbourhoods in the dataset?""
    column_name = 'neighbourhood'  # Replace with the actual column name from the question
    unique_values = dataset[column_name].unique().tolist()
    
    return unique_values
",list of (category),"[nan, 'Madrid, Spain', 'Madrid, Comunidad de Madrid, Spain', 'Madrid, Community of Madrid, Spain', 'Madrid, Comunidad de  Madrid, Spain', 'MADRID, Spain', 'Madrid, Co, Spain', 'Lavapies, Comunidad de Madrid, Spain', 'Madrid, madrid, Spain', 'Madrid , Madrid, Spain', 'madrid, Comunidad de Madrid, Spain', 'Aravaca (Madrid), Community of Madrid, Spain', 'Madrid, MADRID, Spain', 'Madrid , Comunidad de Madrid, Spain', 'Madrid, Comunidad de Madrid, ES, Madrid, Spain', '马德里, 马德里自治区, Spain', 'madrid, Madrid, Spain', 'Pozuelo de Alarcón, Comunidad de Madrid, Spain', 'Madrid, Palos de Moguer , Spain', 'Madrid, Comunidad de Madrid , Atocha, Spain', 'Madrid, La Latina/Palacio , Madrid, Spain', 'Las Rozas, Comunidad de Madrid, Spain', 'Madrid Center, Madrid, Spain', 'Madrid, CM, Spain', 'Chueca, Madrid, Spain', 'Spain', 'Madrid, SPAIN  Madrid Madrid, Spain', 'Madrid, Spain Madrid Madrid, Spain', 'Madrid, centro , Comunidad de Madrid. Zona centro., Spain', 'Comunidad de Madrid, Madrid , Spain', 'Madrid , Comunidad de Madrid, España, Spain', 'Madrid, Comunidad de Madrid, España, Spain']","[0.0, 0.0]",,,,
What are the 2 numbers of reviews received by the 2 most reviewed properties?,What are the number_of_reviews for the two properties with the highest number_of_reviews?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_two_properties = dataset.nlargest(2, 'number_of_reviews')
    reviews_list = top_two_properties['number_of_reviews'].tolist()

    return reviews_list
",list of (int64),"[870, 822]","[870, 822]",,,,
What are the 5 numbers of guests accommodated by the properties that can accommodate the most guests?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the host IDs from the dataset
    host_ids = dataset['host_id'].unique().tolist()
    
    return host_ids",list of int64,"[13660, 83531, 346366726, 132883, 162926, 114340, 130907, 303845, 218515, 353738, 353616, 34217435, 448981, 391014, 259229, 499977, 487095, 364585, 655088, 527760, 3540348, 2150362, 533936, 1408525, 2024487, 3021792, 539643, 2068619, 9934732, 3569462, 3606346, 361930, 3648882, 3654886, 2106353, 2134007, 605612, 3691303, 3698406, 2230279, 650803, 666482, 2240898, 617086, 739627, 2290984, 1954334, 3724500, 780107, 2555202, 796746, 3746437, 2296476, 814490, 2322563, 2332600, 498646, 1566057, 2376402, 2427722, 3797913, 596469, 2456671, 852616, 2467212, 2480913, 3821608, 749212, 3825783, 3591751, 1932547, 2501740, 2517520, 75944, 1008659, 2536524, 1150912, 1625657, 1888816, 1031664, 2563986, 1090760, 1652272, 124972, 1732442, 3951702, 2576044, 2249249, 1134989, 3898452, 1146227, 216570, 1174648, 3438657, 3960415, 2613319, 447969, 2638528, 2659070, 1172225, 1130651, 2661721, 1402142, 3961468, 3983613, 1284868, 1359945, 2673517, 2713304, 4008643, 4012305, 2747005, 1367452, 4012290, 1351865, 2779192, 4032439, 1373873, 4036376, 2795931, 2347489, 1689652, 1406073, 2312712, 2847013, 4053105, 1425071, 2902269, 4068975, 1466005, 2057313, 2267893, 1496188, 901218, 2913511, 153391, 4128029, 1522694, 4132185, 2940355, 4677030, 2678039, 1567773, 23603298, 4181071, 1596220, 4198169, 2960080, 1095831, 2990747, 4235741, 1716726, 4277536, 2993477, 1713427, 2783896, 3010452, 4159117, 4280501, 4281126, 3017315, 6365055, 2174652, 3053021, 4286142, 1721158, 4292037, 4295642, 2773350, 1722284, 3121587, 3141727, 4305310, 1694537, 4365768, 4190662, 4279976, 3290138, 3226403, 3338284, 3352121, 3385307, 1703448, 3317937, 9228673, 3487329, 4396676, 4410687, 1738846, 2489796, 1941314, 4424222, 4424070, 4247556, 3494012, 3357259, 1751133, 4522970, 4777959, 1331093, 4831338, 3631892, 4582755, 1729503, 4504807, 4839888, 1836617, 4603165, 1871034, 4617027, 4860266, 4897332, 1884261, 4903694, 4677458, 4684397, 4905854, 1892467, 4651429, 1574604, 4697070, 4710774, 1981346, 4738576, 4739098, 4975799, 6928584, 4977367, 4735460, 2833018, 9243583, 534128, 2864064, 153695733, 9277975, 4003806, 3661209, 6871745, 5084073, 142989, 5211661, 5234573, 4200231, 7129474, 1713524, 7049661, 1470394, 6363695, 4190343, 5360317, 5386426, 5386601, 4231218, 6915283, 5542111, 5389129, 7117225, 3585435, 2883346, 9525646, 9570589, 3747785, 5561312, 7153063, 5649948, 2519411, 7170175, 1364024, 9696587, 5712665, 5719307, 7201628, 7218465, 5751753, 9699624, 5785483, 5919800, 397053855, 8276432, 5798033, 7033920, 5801580, 9872400, 7249376, 1985408, 5814460, 5824815, 5831420, 5735364, 9940609, 7306349, 5876034, 8602354, 9278712, 5896428, 7394119, 19639638, 7375454, 5149901, 7395294, 1784424, 5950981, 7420783, 2228918, 10189139, 7539510, 10346363, 3612732, 2044655, 7552386, 5969817, 2444553, 7595958, 10516522, 6979632, 993166, 5633658, 6075016, 6104199, 2750053, 762655, 7527702, 10561681, 6112385, 6152491, 2564339, 6191568, 1450378, 3048290, 7448200, 8447678, 641820, 6284655, 10654623, 1706029, 7751680, 2425848, 5500409, 927713, 6427023, 6436336, 7828783, 6466920, 10863262, 10940437, 7652350, 11116174, 6490189, 4790263, 11146984, 6895308, 2662680, 7943769, 11179787, 3331390, 6566447, 11262144, 11262545, 11479457, 6693661, 6598518, 5574921, 6818751, 6832983, 6730063, 11385250, 8125749, 1843216, 8130428, 6774354, 8158807, 2067969, 8584829, 116363697, 8231348, 8515277, 10037966, 8345477, 11942663, 6816328, 11964814, 9805902, 8449261, 2933277, 8508444, 12027564, 1666293, 3317185, 12077356, 6844474, 8532170, 15328893, 12142565, 5790036, 15960490, 1973600, 15992732, 12183135, 5149908, 3514685, 10233660, 8577935, 2711109, 4936824, 11257868, 15819115, 8631882, 12312704, 16196357, 8647044, 15559851, 15267292, 12641432, 12698367, 16317765, 8664077, 12202578, 11824804, 15520459, 8705535, 10569881, 12791313, 1766434, 12691164, 16463761, 12904592, 383302726, 16509221, 13054728, 13097473, 3374080, 15459232, 13253937, 2932927, 3524291, 16457137, 8807899, 13336994, 8814428, 13340216, 16698769, 2136244, 13375273, 8901422, 9757922, 16424237, 8933508, 2242135, 13438040, 13440901, 13569734, 1216993, 16579334, 8282386, 1156753, 13686767, 3945807, 9137401, 16696852, 15292472, 13689103, 13742566, 9145004, 2546805, 9172209, 5637876, 13751801, 9210324, 17066096, 6205683, 6976114, 13808615, 4794809, 16958375, 17237438, 18717127, 14001302, 13612054, 17214333, 15604118, 18750162, 17279710, 7880786, 17282045, 18794911, 17236814, 4416684, 18396400, 132052, 3039427, 14629836, 901541, 5883981, 17371009, 17418454, 4083688, 17515542, 14782097, 14800337, 2582956, 17526190, 19067404, 12955322, 17613548, 14896086, 17499500, 15299751, 3233170, 16287439, 14032635, 13053383, 15081813, 9324929, 17701468, 19222865, 17707970, 15132401, 9261352, 14077633, 17776276, 13452314, 15904655, 17335732, 2685375, 17866170, 19325449, 8894761, 15381133, 19368877, 18034966, 4364415, 12381498, 15425240, 7198967, 15556828, 18081659, 6552198, 18091849, 3604783, 7500680, 18134739, 7267067, 15519226, 8286954, 5012713, 18177812, 4112877, 15731417, 19668718, 15163158, 13498357, 18206447, 18195065, 15796375, 19687824, 18382341, 19731154, 17556638, 18487884, 15819629, 15296672, 20310728, 19734284, 10843382, 24649353, 24687655, 20033541, 9392971, 12957874, 19887379, 13643859, 4615520, 24975550, 16050504, 2991925, 7164070, 14573633, 5704937, 16859206, 25164639, 8405202, 2837886, 22529933, 2067322, 14968320, 22097186, 20181187, 2280785, 22670177, 22722667, 25298984, 25434664, 25488411, 17902428, 25495086, 37425518, 8321213, 22810805, 2620608, 5906378, 25395270, 24548032, 22374109, 20311009, 2116117, 21434856, 3211214, 25620553, 20195703, 17688059, 4023064, 3219367, 5238691, 3960473, 14324611, 16272328, 23911961, 26147086, 23081948, 6722806, 9629764, 23218041, 23262474, 6980058, 5031865, 20678105, 26402947, 26515719, 26659524, 23298612, 23004820, 1693976, 23452445, 23563401, 2521612, 20936304, 163703704, 21014080, 23715618, 17378912, 8986611, 26780049, 23734195, 5239042, 23844357, 23858258, 26856191, 21178453, 3193467, 23858815, 16255963, 20907323, 23865045, 11424503, 21324816, 27037481, 2980994, 20573345, 11156525, 10574763, 27120424, 19521285, 17443242, 24099435, 21318566, 23649429, 27366104, 13827688, 9350319, 12317432, 24567489, 27508261, 9792381, 24200746, 7041630, 23931410, 12199712, 24219783, 15784616, 24204736, 27607042, 10024931, 24314174, 8113793, 21694316, 27652648, 20203062, 2036230, 24350871, 11751342, 4672394, 53526, 20760546, 24373623, 21435450, 3360175, 18991468, 21792828, 24377074, 24393367, 24396830, 24416580, 27844535, 27849067, 7474803, 18096917, 723539, 18008880, 27984641, 24430633, 24472241, 21965811, 24247550, 24540348, 1206817, 28116670, 12186814, 24595812, 27611473, 3162116, 28207769, 28212077, 28573875, 17521594, 25433096, 26346310, 7071874, 24861646, 24654581, 32068100, 32099032, 6386247, 5298015, 7850049, 28443616, 34623998, 34661997, 34719337, 34808128, 34866834, 3147269, 17155315, 32186382, 32242323, 32947142, 29561497, 32046323, 3884805, 34914709, 8125450, 4326117, 30360739, 34972297, 34999628, 28789095, 35051974, 32552981, 22392452, 35084340, 28800342, 28845746, 8244614, 26428861, 2900675, 32685730, 28953035, 1549114, 1450405, 26362423, 35192943, 28956477, 35196559, 23205943, 16500535, 22361249, 32836516, 18032526, 33564448, 35308941, 24085430, 35268271, 32901590, 29182612, 31985091, 28038703, 35446749, 35453137, 32971833, 29236345, 32989497, 23473292, 33180310, 25129863, 35550751, 11200333, 29118911, 35640485, 35762223, 35796928, 13116647, 17523018, 10169235, 3908623, 7914073, 27997968, 30352504, 35844923, 33335043, 29331987, 33435971, 35901873, 29460378, 10143915, 33439191, 27155728, 33446067, 29552300, 35939902, 29552466, 16960262, 34838372, 33494165, 33512061, 16177101, 33577497, 17444591, 2921035, 6288128, 36074091, 29672205, 4057198, 15183471, 29744543, 33626657, 30278385, 36098384, 29149021, 36068881, 15711503, 6677325, 23540342, 3400990, 29138895, 33844767, 7042137, 2959335, 29355718, 36215080, 36245009, 18122634, 33977951, 28054431, 35941439, 29860982, 30008656, 36283990, 33850021, 18407534, 6479768, 15605156, 36258279, 30048748, 36340994, 11133659, 34120401, 2163664, 30168983, 24724079, 30039646, 34209057, 30435890, 16848395, 335685, 19678357, 4030132, 33179537, 22471045, 33577357, 34274924, 26732121, 8760140, 36380316, 8991046, 34331457, 30393932, 2005152, 12252321, 30297314, 36591599, 36694694, 30696902, 16489351, 34372914, 2288706, 36702293, 36718869, 36767873, 34510984, 30377153, 32339668, 15152516, 27300492, 38908634, 26495244, 30494183, 37889820, 36813207, 36849612, 30686730, 36883916, 38935659, 36886407, 30784097, 24310137, 36924831, 38944850, 9414656, 36956773, 34187160, 30829022, 36976163, 85664504, 14668598, 15284847, 37026886, 26213466, 35217913, 30348413, 30969215, 290725310, 6821236, 37072666, 30969714, 31024847, 39173356, 6025388, 15130417, 5161406, 11071264, 37145442, 2873877, 11025286, 39354583, 1300909, 31353361, 1811513, 9865132, 20577458, 37222676, 3068676, 19830019, 39362213, 15600875, 31509536, 37253804, 39553794, 31629152, 21949473, 37291567, 39705260, 18206649, 39758265, 1712644, 18109796, 39894267, 9514089, 37334057, 4427207, 39958878, 21556243, 7156044, 19886194, 31611340, 37371536, 8710915, 16247983, 6733639, 106801, 5592376, 37525983, 31748791, 37536319, 6964389, 40294587, 23849920, 11473376, 31774454, 40383309, 37579426, 4644971, 21144062, 37611348, 17968917, 10800818, 40399486, 42199477, 40458219, 37643913, 37648879, 8831188, 37652506, 37651860, 6159520, 37647001, 40516896, 42316038, 39102439, 40604479, 37687278, 37718197, 18267995, 40620794, 15347349, 37828222, 40635332, 38381963, 19227342, 2055047, 5114074, 37898973, 1706305, 37962660, 36702547, 40669866, 14239786, 3053198, 41633971, 39547828, 42550987, 40847316, 479316899, 38092822, 40870178, 42359977, 40957790, 38109437, 42574276, 38186336, 2932449, 35509766, 42476287, 4760483, 23687124, 28064249, 27723165, 41130999, 21479826, 38319548, 11045636, 38327906, 41092861, 23851382, 38358846, 21457188, 25122859, 25948983, 21093815, 6015469, 37823625, 42917712, 38426919, 677895, 40324020, 26205011, 41372542, 1571660, 200731, 41398111, 33447642, 38326838, 38476638, 38489875, 42484564, 5976605, 2207264, 36434699, 41415670, 11340614, 41831324, 1316009, 38574593, 14034758, 17784363, 30472095, 41992541, 43124108, 8815003, 20111903, 38760121, 22480941, 43211259, 10654631, 14920069, 43255183, 1899974, 45059320, 13568612, 45605026, 43259319, 107929031, 43063704, 8540658, 17198012, 43424967, 47923936, 1232533, 26340878, 19858798, 42621480, 46104888, 18722274, 48007916, 42509108, 43605966, 24864006, 3440242, 43610052, 2925707, 24080903, 168241843, 43617356, 33832455, 48219632, 43653323, 45849398, 15233548, 45882418, 48327231, 4032377, 48385280, 3836436, 48398877, 45917370, 45924302, 32050733, 45954091, 43919337, 36628443, 31127756, 34925981, 43988161, 45932441, 45339508, 48588027, 34808244, 2321467, 48666465, 20754377, 16655057, 44034356, 47410479, 8229155, 46308055, 44107041, 20740084, 4815394, 48769462, 5746574, 48794838, 44033485, 48874758, 2260846, 46442859, 3323346, 6213248, 48951414, 22168282, 48992339, 44720161, 24333252, 44233425, 15208964, 43940819, 46533685, 42748420, 47554470, 14636546, 28404781, 46567593, 7597002, 3939801, 46624167, 46623913, 44902886, 3885180, 49182810, 15720962, 5700613, 49261148, 9360920, 17456435, 43172155, 37415721, 46725622, 37427328, 584351, 49397122, 351833151, 7702501, 43787660, 29442756, 44604616, 22329344, 46845753, 2249606, 44550572, 14269367, 15644991, 17979672, 38429316, 46800094, 4835230, 46178038, 46902285, 44860676, 16731732, 31608532, 46910088, 44939562, 49876674, 46991632, 13471137, 16193294, 49659497, 45069177, 793546, 47082983, 14463303, 45102439, 27091473, 41563621, 32664600, 50350288, 49326150, 3663439, 47196774, 16799632, 50128107, 47332487, 14259451, 50183470, 20437708, 47406181, 50384101, 41274031, 50211168, 50392291, 16284786, 23999609, 36225435, 47548107, 34163379, 50500757, 50293657, 50302503, 26921472, 47607603, 50518604, 47611007, 36711312, 53530177, 46219257, 51581852, 30629489, 2752722, 9846285, 9745294, 1108348, 53603206, 35141863, 28457745, 14496336, 9900516, 53916422, 17160544, 53929658, 33575562, 50758294, 47983688, 40877988, 11128470, 34264356, 26609247, 36542167, 14695154, 19238205, 7657596, 50883425, 5823271, 57729379, 54086531, 50894507, 54095349, 54186796, 21305575, 9874092, 57884536, 50918682, 50366884, 2009482, 20888962, 111968166, 46270528, 48340394, 6649054, 22474892, 41731653, 54347960, 12898424, 55015776, 19046031, 57548030, 51127160, 58180200, 50661039, 52766867, 19327847, 10283018, 58293598, 51176570, 14671913, 54484373, 51205748, 4219180, 2931421, 6928335, 58339419, 56400138, 15255000, 51230196, 54623373, 51165124, 17163339, 1410233, 4943529, 8750775, 58582092, 35575308, 38143510, 34498791, 7906474, 22416437, 2028768, 55149356, 23491551, 50542973, 4599113, 55278897, 39267929, 8124160, 1415413, 55087655, 55569131, 55632261, 29085468, 7693334, 56014328, 38423128, 59199058, 25948109, 55671582, 17201449, 55742820, 59287249, 59342358, 14314106, 51588646, 28768454, 45698435, 15798178, 51592261, 7050715, 51644832, 43622364, 56195761, 35712072, 57413149, 53849192, 59638988, 51683642, 58903512, 29107891, 51247441, 46130675, 56486845, 52771278, 51736845, 392790154, 21209363, 26969716, 51936850, 23774906, 29089953, 51988528, 60088973, 52100521, 7323066, 53400845, 8631060, 56643633, 6673480, 4800628, 40564496, 39589239, 2124038, 3626994, 135579, 50721750, 38347848, 13462483, 22786706, 60267556, 28420470, 4556288, 4503896, 52847482, 2428976, 57231649, 60584653, 52908134, 52305534, 57314745, 15251762, 60642207, 53056350, 17251216, 53138239, 3733961, 39067028, 57286373, 9211956, 35238495, 37175945, 17655057, 19043009, 10435742, 60973924, 52454284, 61050695, 46520875, 57550099, 54391165, 57614931, 41479824, 61804854, 1384218, 5835481, 61529290, 28362136, 2241463, 11158986, 244170453, 3644603, 61661945, 69324698, 65025401, 25580495, 38098725, 65179568, 34598812, 2204184, 69448895, 6741653, 7374494, 3384746, 61770728, 56173202, 69505139, 68785784, 10752242, 69336259, 25469639, 3330931, 14845724, 67418419, 61814956, 69613056, 33049567, 30087751, 61820537, 62648614, 3786952, 66155115, 59872792, 28621534, 6485951, 61917196, 65773421, 7734353, 69819428, 51829772, 69847713, 30338795, 68802394, 20084909, 38320386, 10592426, 59710186, 36449594, 18016640, 66126549, 60983607, 66017814, 66179637, 23190004, 48387429, 2987457, 63711416, 4513375, 54386514, 62091722, 51828290, 50838254, 35447033, 33722058, 70333566, 49624058, 61602987, 66381920, 70358747, 40701442, 31129504, 69164206, 43273943, 12844774, 6072314, 45907677, 47852337, 66603720, 65356385, 70521734, 9194351, 62239322, 4409666, 58609937, 70581423, 70618403, 70618630, 66728317, 5157498, 50273790, 43340350, 24531638, 5731297, 62382259, 70123592, 25291318, 70413516, 66852008, 67071342, 62429541, 66713352, 55863769, 27175062, 70761322, 1271495, 67293185, 62013227, 7241205, 7773266, 71435660, 18621095, 8867408, 24612376, 62638490, 5029203, 63869203, 67749493, 39069497, 62723706, 67598709, 51636039, 67754178, 3266706, 10829751, 56809542, 15422926, 67869308, 15762076, 52141441, 35398617, 18364470, 71934318, 68123842, 72107911, 51564174, 19330033, 55440257, 37763100, 29642251, 62882772, 68370999, 17507043, 39824265, 58001141, 62929255, 57525087, 9335270, 67058529, 63037289, 25184388, 72338355, 68664241, 20131276, 60077331, 62410896, 72464343, 11060534, 66773801, 57303476, 19501954, 68842119, 7276873, 35662774, 29958057, 73034110, 68881258, 63199998, 50665574, 49772159, 11805341, 23289188, 17010185, 2189007, 69026778, 5200972, 71684922, 73279503, 69055146, 63266721, 30606615, 73347533, 32199783, 23442550, 37330209, 74296033, 57798246, 69416543, 23122774, 10031300, 21949890, 73502868, 25706217, 16865089, 14441728, 6408349, 35400449, 63913877, 61107172, 73741764, 41237600, 63913278, 63059592, 34575991, 22581022, 11872121, 1303366, 74984183, 3926474, 75066973, 73908972, 34598028, 23490982, 46137740, 64402485, 74767650, 77532798, 6191153, 33572909, 24239436, 72876550, 15199892, 23264507, 8902654, 45545917, 53263666, 25811165, 75260127, 5461652, 4411586, 75269343, 74245355, 77677204, 36135261, 46959915, 39499350, 75356257, 30855038, 21669327, 77560630, 64636177, 64604961, 53586711, 16097478, 34054380, 64660753, 77858368, 74608678, 77925594, 77944258, 6993782, 6403200, 33042926, 12523869, 19897373, 80473977, 30861100, 78069858, 38013355, 80486475, 75604545, 75603735, 50276797, 27320546, 75608415, 1175985, 1819849, 70463864, 14080048, 70635838, 63720237, 8275478, 78325794, 26435996, 78412962, 7793193, 73339562, 3378492, 75886358, 20922102, 44844031, 78465817, 24360738, 22924722, 75905493, 10409026, 39434420, 23285325, 48754379, 75150135, 66110302, 59577568, 76136564, 61533460, 60992299, 73091098, 69224732, 5756870, 78593983, 47558375, 14626191, 57944144, 78591533, 80972004, 74272402, 29281033, 81039689, 76373989, 78658531, 81061442, 81077534, 81148178, 72129593, 26517191, 8363103, 81285009, 21979338, 3038578, 2217863, 56384322, 27595785, 78776620, 68834672, 71192482, 886570, 51929347, 78820426, 16517500, 2353995, 76574387, 20751539, 8135829, 78896128, 60410965, 78303375, 16257156, 69600676, 76707968, 81562865, 17395577, 79066046, 79065023, 81577110, 79210160, 38217771, 81682959, 38497144, 79217476, 76579393, 81681991, 13992061, 9205789, 15872130, 72163859, 30897075, 54360476, 81140224, 30256733, 18471448, 18047243, 81834320, 77045622, 6704015, 79113388, 55364006, 12455551, 79471710, 81886881, 71159893, 38146720, 79493995, 6341553, 70547446, 79480364, 82042954, 77314309, 82071768, 2805356, 538165, 79658460, 20160777, 83702011, 12572313, 42763400, 70029771, 78262837, 3779898, 29053317, 83252554, 21350181, 11512748, 83784955, 25002262, 82344013, 80228133, 14785920, 80242790, 84195306, 51140959, 15089926, 61289160, 47830215, 54223695, 15192635, 26072216, 33232694, 80439881, 9383666, 44325982, 14350079, 77573144, 4630691, 72658130, 40475538, 82552606, 90311483, 31143239, 84739248, 84853305, 39578306, 16666103, 51647919, 66881515, 29100549, 90638422, 45532164, 82770913, 84957063, 90647789, 2555689, 84941846, 41181513, 553980, 82792538, 36218544, 16730589, 14809898, 90760470, 82806034, 85434797, 20623401, 17586391, 685804, 82817010, 45926015, 18942409, 82888325, 52355783, 86448252, 42069225, 13787659, 39733371, 75151804, 291253690, 86658727, 24360416, 2950145, 20767098, 4490435, 91199417, 11201423, 83152628, 26914836, 11660622, 26067468, 91443917, 10399884, 2167068, 80696645, 30040334, 17855462, 83323141, 39971222, 18181859, 80843965, 91663211, 83505402, 91717192, 9180115, 47267274, 86307067, 91494388, 83572397, 17072529, 6518860, 70516728, 83110708, 134769765, 92507879, 50716384, 125352528, 36123861, 23205522, 31162415, 92757622, 84048574, 3469754, 34598150, 96155047, 92994648, 34371900, 24375266, 4696534, 94988412, 82262913, 96175251, 85423259, 96204145, 19099150, 93628020, 24220770, 87545578, 12859487, 93850432, 91506664, 80852131, 27482347, 87675124, 25418485, 91944003, 67531310, 94189576, 84973000, 39793561, 16310133, 2560898, 35604781, 96502620, 17320590, 7644518, 42149444, 12917441, 88187977, 96582083, 94575991, 87442793, 12090537, 44430986, 46730045, 12665714, 2626919, 12353738, 8139292, 88936948, 94675541, 94757792, 88853220, 54821067, 9536395, 24941970, 73025086, 96804915, 7131867, 62605973, 89214065, 87441528, 4294346, 83155660, 8381047, 95225887, 2169208, 318101, 43924905, 31505020, 58610891, 95273679, 28786243, 78780938, 67914605, 5291754, 19460858, 89814373, 15378510, 89296365, 9886831, 95836067, 11515100, 64042950, 69022392, 96795800, 44107283, 103860984, 20609984, 87501614, 10005634, 12359504, 97534010, 378073, 75395852, 14395069, 26961007, 104082974, 104127552, 96269561, 31402665, 99899485, 2354308, 20331608, 99991901, 104222561, 104227989, 97072466, 97662648, 82169126, 100030664, 18068302, 2916652, 101930506, 22323527, 97803988, 28442060, 52909083, 1202660, 70165534, 67924537, 99018982, 100329321, 27027308, 104512277, 36053006, 2245134, 22546005, 61670134, 15194266, 95238188, 75147810, 5144517, 10818372, 104821476, 100634083, 1847346, 100664770, 94914522, 25143824, 75212526, 3483733, 98642939, 98772913, 7855675, 100942694, 104894903, 104897414, 32420211, 61295887, 49189008, 60358230, 42566468, 2105590, 61695112, 94085556, 72451667, 36108886, 104237072, 88114027, 51571327, 100909442, 8028369, 99229317, 105301845, 105344430, 48311054, 99655956, 77420214, 101364436, 99303058, 66868893, 20426538, 99311430, 37016632, 69094098, 105415029, 105412806, 7280945, 92009319, 12230900, 48778417, 21807514, 98792164, 90673639, 5795235, 505981, 50648232, 13633294, 15456024, 105708985, 11630009, 92410628, 34904217, 101940826, 105797031, 85472776, 62948205, 105833157, 101759198, 105847696, 97664409, 8296925, 31622, 102178224, 801026, 106013121, 28154148, 102195112, 102114225, 81419019, 19814690, 32701014, 71459759, 2508886, 96436426, 19513059, 26949088, 6271519, 29472701, 71271556, 57011514, 34590170, 102614390, 105024501, 14157543, 95974436, 33958244, 45522310, 107112737, 41604848, 7592820, 16010816, 34945448, 93868864, 62422731, 10868009, 106532211, 107146856, 79020953, 86101175, 85083264, 24230477, 60115303, 106688999, 103128901, 48409270, 3305388, 106691772, 107270256, 106722925, 3175924, 107292412, 3664479, 103222038, 65220850, 103266528, 77213873, 44739867, 77865947, 32887826, 92253742, 103332319, 103336792, 86524177, 103360489, 20054897, 107335103, 2271668, 111176074, 104152621, 23219011, 52332915, 22411142, 97914995, 107665197, 3525874, 5543060, 11998458, 54778811, 115490364, 20252804, 101604381, 111316908, 57001974, 73197739, 82304093, 52879640, 59187172, 11384515, 62772067, 106491123, 115485713, 21758733, 27530449, 111797968, 24258953, 26530864, 115821986, 115829298, 115893857, 107141654, 100083495, 4618598, 112053373, 108034257, 112118876, 21731634, 116088603, 33046024, 97771688, 112223963, 108167619, 102717354, 5387587, 112373304, 38317577, 61459850, 85187956, 31733456, 108285137, 68247371, 116361333, 15960349, 108573127, 116358400, 112036768, 107757166, 112661737, 29638657, 106144242, 112858693, 18760415, 101837171, 61396897, 116591604, 88431017, 108592636, 72165839, 12261126, 116641080, 11241107, 116196433, 108860717, 111301181, 53607174, 116645943, 108972672, 113051725, 112913580, 112287456, 84932839, 90563336, 88384826, 61040597, 104887235, 106591951, 18408910, 116935070, 109142681, 117588497, 34265279, 109353801, 113708203, 53282895, 117665543, 93808783, 88175409, 117733884, 111323231, 118146363, 113826816, 109486551, 47535952, 90567419, 109655498, 2417533, 32849832, 118370170, 24109233, 11384281, 109772930, 13203132, 11977337, 109784214, 16921811, 2059942, 114253146, 3053459, 112765104, 118085797, 63264144, 118572350, 118626224, 45621438, 91303637, 29226090, 93081699, 118793746, 69009447, 118855251, 23882318, 4839218, 45415582, 5330387, 111173147, 74083506, 35307050, 70221288, 3838935, 116954432, 95927881, 104826573, 115075966, 88435271, 88670939, 119002469, 24405391, 26868083, 55725852, 102232154, 57842730, 29939898, 26255620, 36433297, 4508810, 119273434, 64956719, 119315330, 119689103, 95998242, 4316644, 99785421, 122804913, 33710002, 11429807, 119754501, 123778623, 119777096, 125191135, 115458397, 37886438, 122977557, 36144768, 111643890, 114454030, 20512685, 116399768, 99981049, 96019257, 359844, 41732982, 877001, 12631821, 50676770, 23785035, 4348783, 43844074, 122981276, 120066393, 63619116, 67024778, 19671287, 16245561, 90571195, 56518442, 96718304, 123502010, 120117109, 126071208, 2098458, 68669881, 22305391, 13147649, 47303750, 16219667, 67227288, 126308580, 121825815, 123726483, 10130188, 70811133, 126420664, 58980411, 123873639, 14314879, 120411706, 14421692, 120460654, 123909786, 91005550, 96541548, 37458135, 98780528, 27027172, 23301367, 4666474, 79224227, 85085945, 123370795, 126730904, 62386612, 20552482, 124105329, 124191305, 77505621, 125393316, 16829566, 8439404, 37726209, 69998776, 45617608, 72547034, 8077001, 124249535, 127081838, 38352975, 99880805, 42611021, 4172001, 213577311, 2425469, 127176867, 55523234, 127199722, 124381557, 120900525, 4977064, 124524030, 14533108, 28544286, 21345930, 64932035, 124542073, 95453068, 105805233, 14713230, 39584479, 124558373, 31083349, 27839309, 2737369, 118174320, 127522591, 104403656, 17204886, 109542538, 122183673, 127569594, 68399986, 16277645, 28382647, 112924535, 124678499, 121195987, 46479213, 49538086, 28608614, 127734531, 117402609, 124713283, 123628530, 119826562, 124730023, 71433755, 127834076, 127871433, 121346580, 124753355, 95404148, 53351829, 124507931, 89137081, 107177213, 28047841, 127953232, 96846155, 124684693, 53077312, 100939487, 128093440, 40730378, 122001666, 121548934, 128136044, 23091391, 97747522, 3404569, 127976288, 88018776, 2405945, 128146422, 110651397, 56600530, 125049921, 125123150, 69326677, 53928475, 88043, 20128787, 121724634, 125126426, 59383880, 107133371, 122465477, 96446898, 38057762, 102622433, 16451838, 51674218, 128279375, 122624585, 127719306, 51908545, 10569937, 122631275, 119119872, 122388260, 128437708, 12996126, 132988737, 7768922, 133009456, 1019300, 128508859, 131308210, 71469882, 6489276, 131352142, 23390574, 133056146, 15295190, 43035746, 124396611, 109587379, 20892661, 132999570, 26802755, 2563960, 19510849, 31839003, 133112800, 86055911, 126666966, 22664780, 37223704, 128893965, 26433915, 131572936, 60469442, 52234994, 43272850, 120664285, 121913781, 126813611, 131615518, 119095036, 19333624, 129010427, 14714896, 2419618, 131662653, 131666468, 116985999, 131888322, 128976579, 86545061, 19896856, 95509779, 68821735, 1373654, 3385435, 112271726, 14959319, 129002665, 37321694, 73620640, 67964500, 132052020, 128982812, 28993412, 58588704, 120627887, 132095385, 63334588, 132177161, 130902460, 132287425, 108816400, 57404543, 105083695, 93802905, 37454801, 129573308, 129584698, 44071767, 115351358, 13892378, 133588020, 19307326, 1957992, 113673609, 16423549, 104235882, 86356773, 86055764, 87730856, 39847153, 133611970, 64720844, 36129591, 70466306, 39172650, 128990132, 128598612, 132637315, 133667412, 22283088, 133688330, 53974578, 130944189, 96986176, 57631899, 50805728, 42666741, 49716536, 133742725, 84336811, 309474285, 37691015, 21608505, 104954660, 133711744, 130135247, 20155072, 15617046, 17812618, 25861473, 102675796, 6346734, 16730163, 132214458, 97075909, 52873124, 42387694, 130442142, 109127284, 9219542, 26264376, 132903896, 107685968, 36989865, 52803269, 45979786, 124457750, 97469156, 91620597, 7179574, 134388380, 3113415, 121024104, 134063747, 15512877, 23444591, 79215007, 3537382, 134667286, 12206959, 130953064, 47916209, 29703574, 134083015, 121539601, 12415691, 135531703, 135537749, 134697385, 134765355, 128818407, 15816070, 135540672, 133790461, 134833425, 77429075, 134115383, 134851409, 2289663, 1689419, 97610526, 134157316, 3892548, 94099585, 84019234, 52694809, 135647274, 17807880, 3540591, 134917762, 134922009, 35626245, 132278256, 135654202, 14070517, 134921669, 55942251, 8113146, 62517062, 135611405, 135007921, 117427849, 56701500, 7092794, 16741274, 70938636, 28311528, 135014838, 134124301, 133391337, 4499460, 82696011, 48338535, 47465679, 113360368, 136343078, 135066475, 135073235, 33284006, 28798081, 79260919, 30343077, 19021732, 135791645, 31653670, 33582127, 127316961, 4857450, 135109785, 134857641, 107579114, 136378184, 135055621, 135179620, 110834791, 84749064, 25186826, 136403836, 38076518, 39148845, 135188458, 136436631, 135189907, 135194065, 135194142, 50392421, 9863470, 27607837, 135488502, 14486303, 135882514, 5990551, 33104035, 136229873, 40895919, 135248962, 49364556, 136443172, 36131432, 55282949, 82919381, 40130130, 36522281, 73164415, 44255158, 73434102, 135248994, 135987483, 135345875, 29029426, 131884023, 10500150, 13034763, 78780457, 128646124, 112299292, 75196508, 83365225, 36280055, 107673993, 16690204, 135480379, 136562962, 3172624, 94597892, 135610731, 10317192, 27844010, 113698599, 5533978, 105909586, 9906173, 136019037, 136035425, 136049113, 136643755, 130426702, 135507348, 45022366, 33315670, 136051619, 136666217, 113968796, 120594962, 37780766, 20174349, 136696867, 136067732, 20162656, 136718347, 137470636, 45759520, 136081446, 75755205, 136719247, 5587355, 52804033, 136720840, 137501555, 137503815, 137502667, 51017752, 136728521, 58299194, 136390185, 136759321, 8381892, 137521324, 136541023, 37355962, 39066880, 136751341, 124284096, 137912568, 137306773, 136160315, 34275236, 136784053, 41046144, 75965606, 19015499, 14203430, 136207924, 119609257, 137641889, 129912725, 117161053, 61935235, 105781329, 136874483, 6804673, 136856710, 140013717, 114230750, 139639041, 136885276, 137842519, 69502268, 29939924, 100944934, 12475744, 134669285, 136920800, 111310737, 58760044, 19531394, 39094209, 84151361, 7603955, 21860204, 2677326, 137020857, 140377797, 140446987, 23716700, 17926399, 138050450, 122532247, 89509567, 8170169, 63046221, 137677410, 70318261, 11758246, 79126282, 5450900, 137795776, 137075869, 35756885, 136545366, 55441969, 138362431, 47236375, 140663252, 140698452, 9922110, 137997860, 39412175, 5086226, 138475528, 9443896, 14387803, 122900519, 138506958, 8151819, 4961228, 135206534, 140815424, 21758923, 135865098, 51196774, 140956171, 51735211, 39645021, 119507675, 137157856, 141132718, 134687379, 137029509, 138673996, 136986473, 140876031, 131796408, 100772947, 76061099, 141315541, 137245275, 2663124, 137252326, 118317222, 2155254, 47787009, 106484041, 71535919, 141404257, 24617398, 137311372, 20618932, 141483194, 138787405, 130379031, 25545485, 137328910, 97542643, 138159354, 21514613, 137372436, 76103306, 139052443, 79217020, 141581320, 35269260, 17482222, 139232888, 143197318, 20815337, 16439253, 3242438, 80622565, 35303680, 143500952, 139601798, 4063691, 131931072, 10734785, 4396399, 8200623, 127133256, 89312279, 135512858, 141685867, 140578346, 63513630, 11050062, 48927615, 80975233, 143643220, 138219052, 100873847, 15328438, 143668307, 33615726, 107851515, 146165870, 4781287, 23441165, 3940766, 91523667, 143748236, 4494827, 142056043, 931326, 14375690, 143860194, 98418011, 67353, 142370857, 108518306, 26066432, 132022481, 146471967, 66304132, 7858753, 66678110, 142432286, 94373056, 142605684, 123995944, 146578918, 20597678, 142837429, 25814517, 4956262, 141317027, 142223688, 139794958, 37918137, 128843761, 98683967, 146871714, 3406101, 21389511, 6509657, 6288367, 96188253, 38709658, 12572179, 149217622, 144230807, 43833108, 149359887, 132433964, 144231457, 15737478, 76121513, 17011441, 92184438, 34263466, 62779009, 145123279, 11086450, 20437430, 87910953, 146759457, 144459849, 89126645, 5283966, 144590767, 22910358, 19458219, 3063420, 9264506, 45678654, 87717736, 99706846, 3387630, 67365849, 8132636, 36655351, 149685605, 118075498, 145213051, 39960826, 66691960, 42756640, 78030988, 31854771, 11766537, 27110709, 31775561, 14528428, 144826971, 147753486, 145003335, 147806949, 150128214, 99373514, 119833293, 30949874, 83597722, 148022884, 23523746, 2507824, 27426508, 150237695, 40472125, 145098480, 148079143, 35186383, 103602854, 107264899, 75744, 145121682, 7145793, 150436108, 148189900, 101935713, 148208639, 145205078, 145991627, 150473901, 4184655, 140215666, 29269425, 19628784, 70147780, 143601328, 147605023, 6040093, 148490123, 145447488, 25758510, 61435194, 150584965, 145516213, 148699176, 54952134, 138397676, 54317950, 150663188, 145598915, 82109005, 145813916, 89909066, 105943452, 71137764, 149067447, 145927008, 114296818, 87677104, 14078700, 83132131, 47836162, 23966879, 62150493, 102627910, 86843365, 149228471, 149233829, 150875589, 53072657, 93909471, 151042704, 149257574, 1162847, 143735161, 30782142, 62427231, 152332571, 155116115, 60179393, 152332928, 155117856, 15423690, 49124821, 152352690, 125712780, 152360357, 151262541, 11650091, 104415609, 13705826, 109948084, 18051792, 151498184, 151501397, 152670340, 139417722, 155231088, 121386425, 91768042, 152145070, 142768682, 10106547, 150970727, 152806944, 51411572, 71696262, 155410174, 35813772, 2382540, 81229591, 131936264, 144297656, 99313241, 17095640, 151899109, 57735136, 151901958, 146581057, 13073580, 76575586, 37142307, 156072453, 152005637, 152100907, 45454320, 152495902, 17608059, 12022293, 29147346, 156341705, 156636998, 7059146, 63576984, 141801045, 71251019, 14988745, 153117083, 40776963, 28341548, 2419064, 158035389, 158063199, 154670560, 149137161, 6259350, 43033741, 2376774, 38495367, 158145940, 157906856, 157038880, 141817157, 48041121, 9669052, 158262143, 153253928, 158305158, 53479725, 157144807, 30037226, 157151266, 77474494, 87104465, 74075151, 69417012, 31551311, 157279725, 2919571, 11753022, 51433878, 153496477, 80052122, 40795973, 92223756, 157374050, 157394868, 157395365, 29053453, 1771095, 26527015, 153539928,","[16, 16, 16, 16, 16]",,,,
Is there a food item with 'Fruits' as its group?,Does the dataset contain any food item where the group is 'Fruits'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    contains_fruit = 'Fruits' in dataset['GROUP'].unique()
    return contains_fruit
",bool  ,True,True,,,,
Are there food items with 'Nuts' as their sub group?,Does the dataset contain any food items with 'Nuts' as their sub group?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_nuts_sub_group = 'Nuts' in dataset['SUB GROUP'].values

return has_nuts_sub_group",bool,True,True,,,,
Is there a food item with scientific name 'Tilia argentea'?,Does the food item with scientific name 'Tilia argentea' exist in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    exists = (dataset['SCIENTIFIC NAME'] == 'Tilia argentea').any()
    return exists
",bool,True,True,,,,
Is 'Angelica' listed as a food name in the dataset?,Is there an entry in the dataset where the food name is 'Angelica'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
is_angelica_present = 'Angelica' in dataset['FOOD NAME'].values

return is_angelica_present",bool,True,True,,,,
How many food items are there in the dataset?,What is the total count of food items in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    total_count = len(dataset)
    
    return total_count
",int64,906,906,,,,
How many unique food groups are there in the dataset?,What is the count of distinct food groups in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_food_groups_count = dataset['GROUP'].nunique()
    
    return distinct_food_groups_count
",int64,24,24,,,,
How many unique sub groups are there in the dataset?,What is the count of distinct sub groups in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_sub_groups_count = dataset['SUB GROUP'].nunique()
    
    return distinct_sub_groups_count
",int64  ,123,123,,,,
How many unique food items are there in the dataset?,What is the count of distinct food items in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
food_count = len(dataset['FOOD NAME'].unique())
return food_count",int64  ,906,906,,,,
What is the group of the food named 'Kiwi'?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the unique groups in the dataset
    unique_groups = dataset['GROUP'].unique()
    
    # Convert the array of unique groups to a list and get the first element
    first_group = unique_groups[0] if len(unique_groups) > 0 else None
    
    return first_group",string,Herbs and Spices,Fruits,,,,
What is the sub group of the food with scientific name 'Tilia argentea'?,What is the sub group for the food item with the scientific name 'Tilia argentea'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sub_group = dataset.loc[dataset[""SCIENTIFIC NAME""] == ""Tilia argentea"", ""SUB GROUP""].iloc[0]
    
    return sub_group
",string,Herbs,Herbs,,,,
What is the scientific name of the food named 'Colorado pinyon'?,What is the scientific name for the food item known as 'Colorado pinyon'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    scientific_name = dataset.loc[dataset[""FOOD NAME""] == ""Colorado pinyon"", ""SCIENTIFIC NAME""].iloc[0]
    
    return scientific_name
",string,Pinus edulis,Pinus edulis,,,,
What is the food name of the item with scientific name 'Tilia argentea'?,What is the food name corresponding to the scientific name 'Tilia argentea'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    food_name = dataset.loc[dataset['SCIENTIFIC NAME'] == 'Tilia argentea', 'FOOD NAME'].values[0]
    return food_name
",string,Silver linden,Silver linden,,,,
What are the top 3 most common food groups?,What are the top three most frequently occurring food groups?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    group_counts = dataset['GROUP'].value_counts().head(3).index.tolist()
    return [str(group) for group in group_counts]
",list of (string),"['Aquatic foods', 'Vegetables', 'Fruits']","['Aquatic foods', 'Vegetables', 'Fruits']",,,,
What are the top 2 most common groups? If there are two that have the same number of appearances give preference alphabetically.,"Which are the top 2 most frequent groups, and in case of a tie, return the ones that come first alphabetically?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each group
    group_counts = dataset['GROUP'].value_counts()
    
    # Get the top 2 groups by frequency, in case of a tie, sort alphabetically
    top_groups = group_counts.nlargest(2, keep='first').index.tolist()
    
    return top_groups
",list of (string),"['Aquatic foods', 'Vegetables']","['Aquatic foods', 'Fruits']",,,,
What are the 5 least common food groups?,Which are the five food groups with the lowest frequency?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    group_counts = dataset['GROUP'].value_counts(ascending=True).head(5)
    least_frequent_groups = list(group_counts.index)

    return least_frequent_groups
",list of (string),"['Herbs and spices', 'Unclassified', 'Baby foods', 'Eggs', 'Teas']","['Teas', 'Eggs', 'Baby foods', 'Unclassified', 'Herbs and spices']",,,,
What are the 5 most common sub groups?,What are the top 5 most frequently occurring sub groups?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_sub_groups = dataset['SUB GROUP'].value_counts().head(5).index.tolist()
    
    return top_sub_groups
",list of (string),"['Fishes', 'Herbs', 'Berries', 'Tropical fruits', 'Nuts']","['Fishes', 'Herbs', 'Berries', 'Tropical fruits', 'Nuts']",,,,
What are the lengths of the top 5 most common sub group names?,What are the lengths of the top 5 most frequent sub group names?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each 'SUB GROUP' and get the top 5
    top_sub_groups = dataset['SUB GROUP'].value_counts().head(5).index.tolist()
    
    # Calculate the length of each sub group name
    lengths = [len(group) for group in top_sub_groups]
    
    return lengths
",list of (int64),"[6, 5, 7, 15, 4]","[6, 5, 7, 15, 4]",,,,
What are the number of appearances of the 2 least common groups?,How many times do the two least common groups appear in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    group_counts = dataset['GROUP'].value_counts()
    least_common_groups = group_counts.nsmallest(2)
    total_count = least_common_groups.sum()

    return total_count
",int64,2,"[1, 1]",,,,
What are the number of appearances of the 3 most common groups?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for some numerical data that needs to be extracted from the dataset.
    # Since the schema provided does not include any int64 columns, I will assume we need to return an empty list as a placeholder.
    # You would replace this with actual logic based on the specific question asked.
    
    answer = []
    
    return answer",list of (int64),[],"[166, 130, 130]",,,,
What are the three most common group name lengths?,What are the lengths of the three most common group names?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
group_counts = dataset['GROUP'].value_counts().head(3).index
lengths = [len(group) for group in group_counts]
return lengths
",list of (int64),"[13, 10, 6]","[6.0, 13.0, 10.0]",,,,
Is there a customer with 'Large Business' as their occupation?,Is there a customer whose occupation is listed as 'Large Business'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_large_business = any(dataset['Occupation'] == 'Large Business')
    
    return has_large_business",bool,True,True,,,,
Are there customers with 'King' as their pitched product?,Is there any customer who was pitched the product 'King'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_product_king = 'King' in dataset['ProductPitched'].values

return has_product_king",bool,True,True,,,,
Is there a customer with designation 'VP'?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there is any customer who has taken a product and is married.
    customers_with_product = dataset[dataset['ProdTaken'] == 1]
    married_customers = customers_with_product[customers_with_product['MaritalStatus'] == 'Married']
    
    return not married_customers.empty
",bool,True,True,,,,
Is 'Unmarried' listed as a marital status in the dataset?,Is 'Unmarried' included as a marital status in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    is_unmarried_included = 'Unmarried' in dataset['MaritalStatus'].unique()
    
    return is_unmarried_included
",bool,True,True,,,,
How many customers are there in the dataset?,What is the total count of customers in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    total_customers = len(dataset)
    return total_customers
",int64,4888,4888,,,,
How many unique occupations are there in the dataset?,What is the count of distinct occupations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_occupations_count = dataset['Occupation'].nunique()
    
    return distinct_occupations_count
",int64,4,4,,,,
How many unique designations are there in the dataset?,What is the count of distinct designations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_designation_count = dataset['Designation'].nunique()
    return distinct_designation_count
",int64  ,5,5,,,,
How many unique marital statuses are there in the dataset?,What is the count of distinct marital statuses in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_marital_statuses_count = dataset['MaritalStatus'].nunique()
    
    return distinct_marital_statuses_count
",int64,4,4,,,,
What is the occupation of the customer with ID 200000?,What is the occupation of the customer with CustomerID 200000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    customer_occupation = dataset.loc[dataset[""CustomerID""] == 200000, ""Occupation""].values[0]
    
    return customer_occupation
",string  ,Salaried,Salaried,,,,
What is the product pitched to the customer with ID 200001?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a specific column value based on some condition
# For example, let's assume the question is ""What is the most common ProductPitched?""
most_common_product = dataset['ProductPitched'].mode()[0]
return most_common_product",category,Basic,Deluxe,,,,
What is the designation of the customer with ID 200002?,,,,ERROR,Executive,,,,
What is the marital status of the customer with ID 200003?,What is the marital status of the customer with ID 200003?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    customer_marital_status = dataset.loc[dataset[""CustomerID""] == 200003, ""MaritalStatus""].iloc[0]
    
    return customer_marital_status
",category  ,Divorced,Divorced,,,,
What are the 3 most common occupations?,What are the three most frequent occupations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    occupation_counts = dataset['Occupation'].value_counts().head(3).index.tolist()
    return occupation_counts
",list of (string),"['Salaried', 'Small Business', 'Large Business']","['Salaried', 'Small Business', 'Large Business']",,,,
What are the top 2 most common pitched products?,Which are the two most frequently pitched products?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    product_counts = dataset['ProductPitched'].value_counts().head(2).index.tolist()
    return product_counts
",list of (string),"['Basic', 'Deluxe']","['Basic', 'Deluxe']",,,,
What are the 4 least common occupations?,What are the top 4 least common occupations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    occupation_counts = dataset['Occupation'].value_counts(ascending=True).head(4)
    top_4_least_common_occupations = occupation_counts.index.tolist()

    return top_4_least_common_occupations
",list of (string),"['Free Lancer', 'Large Business', 'Small Business', 'Salaried']","['Salaried', 'Small Business', 'Large Business', 'Free Lancer']",,,,
What are the 2 least common pitched products?,Which are the two least frequently pitched products?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    product_counts = dataset['ProductPitched'].value_counts().tail(2).index.tolist()
    return product_counts
",list of (string),"['Super Deluxe', 'King']","['Super Deluxe', 'King']",,,,
What are the ages of the 3 oldest customers?,What are the ages of the top 3 oldest customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by age in descending order and get the top 3 oldest customers
    top_oldest_customers = dataset.sort_values(by='Age', ascending=False).head(3)
    
    # Extract the ages of these customers
    ages_of_top_oldest = top_oldest_customers['Age'].tolist()
    
    return ages_of_top_oldest
",list of (float64),"[61.0, 61.0, 61.0]","[61, 61, 61]",,,,
What are the ages of the 4 youngest customers?,What are the ages of the four youngest customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by age in ascending order
    sorted_by_age = dataset.sort_values(by=""Age"")
    
    # Get the ages of the four youngest customers
    youngest_ages = sorted_by_age[""Age""].head(4).tolist()
    
    return youngest_ages
",list of (float64),"[18.0, 18.0, 18.0, 18.0]","[18.0, 18.0, 18.0, 18.0]",,,,
What are the top 2 highest monthly incomes of the customers?,What are the two highest monthly incomes among the customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_two_incomes = dataset[""MonthlyIncome""].nlargest(2).tolist()
    
    return top_two_incomes
",list of (float64),"[98678.0, 95000.0]","[98678, 95000]",,,,
What are the 4 most common duration of pitch?,What are the top 4 most frequent durations of pitch?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by DurationOfPitch and count occurrences
    duration_counts = dataset['DurationOfPitch'].value_counts()
    
    # Get the top 4 most frequent durations
    top_4_durations = duration_counts.head(4).index.tolist()
    
    return top_4_durations
",list of (float64),"[9.0, 7.0, 8.0, 6.0]","[9.0, 7.0, 8.0, 6.0]",,,,
Is there any entry posted on a weekend?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking about a specific condition in the dataset
    # For example, let's assume the question is ""Is there any entry with 'clusters_3' equal to 'cluster1'?""
    
    # Example code to find if there is any entry with 'clusters_3' equal to 'cluster1'
    condition = dataset['clusters_3'] == 'cluster1'
    result = condition.any()
    
    return result
",bool,False,True,,,,
Are there titles with more than 100 characters?,Does the dataset contain any titles with more than 100 characters?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_long_titles = dataset['title'].str.len() > 100
    return has_long_titles.any()
",bool,False,False,,,,
Do any entries have a negative sentiment according to the Cardiff NLP model?,Are there any entries in the dataset that have a negative sentiment as per the Cardiff NLP model?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_negative_sentiment = 'negative' in dataset['title_gx_cardiff_nlp_sentiment'].unique()
return has_negative_sentiment
",bool,False,False,,,,
"Is the term 'linux' mentioned in the ""Clusters II"" column?","Does the ""Clusters II"" column contain the term 'linux'?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    contains_linux = 'linux' in dataset['Clusters II'].values

    return contains_linux
",bool,False,True,,,,
How many entries were posted in the morning?,What is the count of entries posted during the morning?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    morning_count = dataset[dataset['partofday'] == 'morning'].shape[0]
    
    return morning_count
",int64,1516,1516,,,,
What's the highest score received by an entry?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value from the dataset
    # For example, let's assume the question is ""What is the maximum score in the dataset?""
    
    max_score = dataset['score'].max()
    
    return max_score
",uint16,6015,6015,,,,
"On average, how many descendants does an entry have?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific value from the dataset
    # For demonstration purposes, let's assume the question is ""What is the average score of all entries?""
    average_score = dataset['score'].mean()
    
    return average_score
",float64,774.894899000000,339.2486210000000,,,,
How many entries are in the Autumn season?,What is the count of entries that belong to the Autumn season?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count_autumn_entries = dataset[dataset['season'] == 'Autumn'].shape[0]
return count_autumn_entries",int64,2301,2301,,,,
Which day of the week has the most entries?,What is the day of the week with the highest number of entries?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    weekday_counts = dataset['weekday_name'].value_counts()
    most_frequent_weekday = weekday_counts.idxmax()

    return most_frequent_weekday
",string  ,Tuesday,Tuesday,,,,
What is the predominant language used in titles?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a specific column value based on some condition.
# For example, let's assume the question is ""What is the title of the entry with the highest score?""
max_score_entry = dataset.loc[dataset[""score""] == dataset[""score""].max()]
title_of_max_score_entry = max_score_entry[""title""].iloc[0]

return title_of_max_score_entry",string,Stephen Hawking has died,en,,,,
In which season was the entry with the highest score posted?,During which season was the entry with the highest score created?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_score_entry = dataset.loc[dataset[""score""] == dataset[""score""].max()]
    season_of_max_score = max_score_entry[""season""].iloc[0]

    return season_of_max_score
",category,Spring,Spring,,,,
On which part of the day are most entries posted?,During which part of the day are the most entries posted?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'partofday' and count the number of entries in each group
    part_of_day_counts = dataset['partofday'].value_counts()
    
    # Find the part of day with the maximum count
    most_common_part_of_day = part_of_day_counts.idxmax()
    
    return most_common_part_of_day
",string,afternoon,afternoon,,,,
"List the top 4 most frequent terms in the ""Clusters II"" column.","What are the top 4 most frequent terms in the ""Clusters II"" column?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_terms = dataset['Clusters II'].value_counts().head(4).index.tolist()
    
    return top_terms
",list of (string),"['year, work, new', 'google, web, firefox, open', 'apple, linux, rust, iphone', 'facebook, twitter, die, account']","['year, work, new', 'google, web, firefox, open', 'apple, linux, rust, iphone', 'facebook, twitter, die, account']",,,,
Name the 2 month names which appear less in the dataset.,Which two month names have the lowest frequency in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
month_name_counts = dataset['month_name'].value_counts(ascending=True).head(2)
lowest_frequency_months = month_name_counts.index.tolist()

return lowest_frequency_months
",list of (string),"['July', 'December']","['December', 'July']",,,,
Identify the top 3 weekdays based on entry frequency.,Which are the top 3 most frequent weekdays in terms of entry count?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    weekday_counts = dataset['weekday_name'].value_counts().head(3).index.tolist()
    return weekday_counts
",list of (string),"['Tuesday', 'Wednesday', 'Thursday']","['Tuesday', 'Wednesday', 'Thursday']",,,,
Provide the bottom 4 seasons in terms of entry count.,What are the bottom 4 seasons based on the number of entries?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    season_counts = dataset['season'].value_counts().sort_values(ascending=True).index.tolist()
    bottom_4_seasons = season_counts[:4]
    
    return bottom_4_seasons",list of (string),"['Summer', 'Autumn', 'Winter', 'Spring']","['Spring', 'Winter', 'Autumn', 'Summer']",,,,
List the top 3 scores in the dataset.,What are the top 3 scores from the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_scores = dataset['score'].nlargest(3).tolist()
return top_scores",list of (int64),"[6015, 5771, 4338]","[6015, 5771, 4338]",,,,
Name the bottom 5 title text lengths.,What are the titles with the 5 smallest text lengths?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by title_gx_text_length in ascending order and select the top 5 titles
    smallest_titles = dataset.sort_values(by='title_gx_text_length').head(5)['title'].tolist()
    
    return smallest_titles
",list of (string),"['X', 'VR', 'AI', 'Jd', '42']","[1.0, 2.0, 2.0, 2.0, 2.0]",,,,
Identify the top 4 numbers of descendants.,What are the top 4 highest numbers of descendants?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_4_descendants = dataset.nlargest(4, 'descendants')['descendants'].tolist()

return top_4_descendants
",list of (float64),"[4576.0, 3678.0, 3676.0, 3463.0]","[4576.0, 3678.0, 3676.0, 3463.0]",,,,
Provide the bottom 6 scores in the dataset.,What are the 6 lowest scores in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
lowest_scores = dataset['score'].nsmallest(6).tolist()
return lowest_scores
",list of (int64),"[501, 501, 501, 501, 501, 501]","[501, 501, 501, 501, 501, 501]",,,,
Are there any employees with more than 7 projects?,Is there any employee with more than 7 projects?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_more_than_7_projects = (dataset[""Number of Projects""] > 7).any()
return has_more_than_7_projects
",bool,False,False,,,,
Has any employee worked for more than 300 hours on average per month?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the individual with the highest satisfaction level
    max_satisfaction_individual = dataset.loc[dataset[""Satisfaction Level""] == dataset[""Satisfaction Level""].max()]
    
    # Check if this individual has had a work accident
    has_work_accident = max_satisfaction_individual[""Work Accident""].values[0] == 'Yes'
    
    return has_work_accident",bool,True,True,,,,
Are all satisfaction levels above 0.5?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking if there are any employees who have been promoted in the last 5 years and left the company.
promoted_and_left = dataset[(dataset[""Promoted in the last 5 years?""] == 'Yes') & (dataset[""Left""] == 'Yes')]

# If there are any such cases, return True, otherwise False
return not promoted_and_left.empty",bool,True,False,,,,
Were there any employees hired in 2019?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking if there are any employees who left the company with a satisfaction level above 0.7
employees_left = dataset[dataset['Left'] == 'Yes']
high_satisfaction_employees = employees_left[employees_left['Satisfaction Level'] > 0.7]
has_high_satisfaction = not high_satisfaction_employees.empty

return has_high_satisfaction",bool,True,True,,,,
How many unique departments are there?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value that can be directly extracted from the schema or dataset.
    # Since no specific question is provided, I will return the number of rows in the dataset as an example.
    answer = len(dataset)
    return answer
",int64,14999,10,,,,
What's the maximum number of years an employee has been in the company?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    average_hours = dataset['Average Monthly Hours'].mean()
    
    return average_hours
",int64,201.0503370000000,10,,,,
How many employees have been promoted in the last 5 years?,,,,ERROR,319,,,,
"On average, how many hours do employees work monthly?",What is the average number of hours worked monthly by employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    average_monthly_hours = dataset['Average Monthly Hours'].mean()
    return average_monthly_hours
",float64,201.0503370000000,201.05,,,,
Which department has the highest number of employees?,Which department has the most employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
department_counts = dataset['Department'].value_counts()
most_common_department = department_counts.idxmax()

return most_common_department",string  ,sales,sales,,,,
What's the most common salary level among employees?,What is the most frequent salary level among employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_salary = dataset['salary'].mode().iloc[0]
    return most_frequent_salary",category,low,low,,,,
Which year had the highest number of employees hired?,In which year was the highest number of employees hired?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the year from the Date Hired column
    dataset['Year Hired'] = dataset['Date Hired'].dt.year
    
    # Count the number of employees hired in each year
    hire_counts = dataset['Year Hired'].value_counts()
    
    # Find the year with the highest number of hires
    max_hire_year = hire_counts.idxmax()
    
    return max_hire_year
",int64,2017,2017,,,,
Which salary level has the least number of employees who had an accident at work?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for the department with the highest average monthly hours
    max_hours_department = dataset.loc[dataset[""Average Monthly Hours""] == dataset[""Average Monthly Hours""].max()][""Department""].iloc[0]
    
    return max_hours_department
",category,hr,high,,,,
Name the top 4 departments with the most employees.,Which are the top 4 departments with the highest number of employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
department_counts = dataset['Department'].value_counts().head(4).index.tolist()

return department_counts
",list of (string),"['sales', 'technical', 'support', 'IT']","['sales', 'technical', 'support', 'IT']",,,,
List the 3 departments with the most number of promotions in the last 5 years that have at least one promotion. ,Which 3 departments have received the most promotions in the past 5 years and have at least one promotion?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    promoted_departments = dataset[dataset['Promoted in the last 5 years?'] == 'Yes']
    department_promotion_count = promoted_departments['Department'].value_counts()
    top_3_departments_with_promotions = department_promotion_count[department_promotion_count > 0].head(3).index.tolist()

    return top_3_departments_with_promotions
",list of (string),"['sales', 'management', 'marketing']","['hr', 'accounting', 'IT']",,,,
Identify the 3 departments with the lowest average satisfaction levels.,Which are the three departments with the lowest average satisfaction levels?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by department and calculate the mean satisfaction level for each department
    dept_satisfaction = dataset.groupby('Department')['Satisfaction Level'].mean().reset_index()
    
    # Sort the departments by their average satisfaction levels in ascending order
    sorted_dept_satisfaction = dept_satisfaction.sort_values(by='Satisfaction Level', ascending=True)
    
    # Get the names of the three departments with the lowest average satisfaction levels
    top_3_departments = sorted_dept_satisfaction.head(3)['Department'].tolist()
    
    return top_3_departments
",list of (string),"['accounting', 'hr', 'technical']","['accounting', 'hr', 'technical']",,,,
What are the 2 departments with the lowest average monthly hours worked?,Which are the two departments with the lowest average monthly hours worked?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by department and calculate the average monthly hours for each department
    avg_hours_by_department = dataset.groupby('Department')['Average Monthly Hours'].mean().reset_index()
    
    # Sort the departments by average monthly hours in ascending order
    sorted_departments = avg_hours_by_department.sort_values(by='Average Monthly Hours')
    
    # Get the two departments with the lowest average monthly hours
    two_lowest_avg_hours_departments = sorted_departments.head(2)['Department'].tolist()
    
    return two_lowest_avg_hours_departments
",list of (string),"['hr', 'marketing']","['hr', 'marketing']",,,,
Identify the top 3 years with the highest employee hiring.,Find the top 3 years with the highest number of employee hires.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Year Hired' and count the number of employees hired in each year
    hire_counts = dataset['Year Hired'].value_counts().sort_values(ascending=False)
    
    # Get the top 3 years with the highest number of employee hires
    top_3_years = hire_counts.head(3).index.tolist()
    
    return top_3_years
",list of (int32),"[2017, 2018, 2016]","['2017', '2018', '2016']",,,,
Which are the highest 3 satisfaction levels among employees who left?,What are the top 3 satisfaction levels for employees who have left the company?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter employees who have left the company
    left_employees = dataset[dataset['Left'] == 'Yes']
    
    # Sort by satisfaction level in descending order and get the top 3
    top_3_satisfaction_levels = left_employees['Satisfaction Level'].nlargest(3).tolist()
    
    return top_3_satisfaction_levels
",list of (float64),"[0.92, 0.92, 0.92]","[0.92, 0.92, 0.92]",,,,
List the bottom 5 average monthly hours among employees who were promoted in the last 5 years.,What are the average monthly hours for the bottom 5 employees who were promoted in the last 5 years?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter employees who were promoted in the last 5 years
    promoted_employees = dataset[dataset['Promoted in the last 5 years?'] == 'Yes']
    
    # Sort by Last Evaluation to find the bottom 5 employees
    bottom_5_employees = promoted_employees.nsmallest(5, 'Last Evaluation')
    
    # Get the average monthly hours for these employees
    average_monthly_hours = bottom_5_employees['Average Monthly Hours'].tolist()
    
    return average_monthly_hours
",list of (uint16),"[266, 179, 179, 171, 132]","[215, 133, 159, 241, 247]",,,,
Whhat are the top 6 last evaluation scores?,What are the top 6 highest values for Last Evaluation in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_6_last_evaluations = dataset[""Last Evaluation""].nlargest(6).tolist()
    
    return top_6_last_evaluations
",list of (float64),"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]","[1, 1, 1, 1, 1, 1]",,,,
Did any incident result in the total destruction of the aircraft?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any incidents where both fatalities and ground casualties are zero
    no_fatalities = dataset[""Fatalities""] == 0
    no_ground_casualties = dataset[""Ground_Casualties""] == 0

    result = no_fatalities & no_ground_casualties
    return result.any()",bool,False,True,,,,
Have there been any incidents where the cause was related to the undercarriage of the aircraft?,Are there any records of incidents where the cause is associated with the undercarriage of the aircraft?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
incidents_with_undercarriage_cause = dataset['Incident_Cause(es)'].str.contains('undercarriage', case=False).any()
return incidents_with_undercarriage_cause",bool,True,True,,,,
Has there been any instance where the ground casualties were non-zero?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there was any incident where fatalities occurred
    has_fatalities = dataset['Fatalities'].sum() > 0
    
    return has_fatalities",bool,True,True,,,,
Are there incidents where the aircraft was involved in a collision?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks about a specific condition related to an aircraft incident.
    # For example, let's assume the question is: ""Is there any incident where the number of fatalities is greater than 0?""
    
    has_fatalities = (dataset[""Fatalities""] > 0).any()
    
    return has_fatalities",bool,True,True,,,,
How many unique aircraft models are in the dataset?,What is the count of distinct aircraft models in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_aircraft_models_count = dataset['Aircaft_Model'].nunique()
    return distinct_aircraft_models_count",int64  ,3523,3523,,,,
What's the highest number of occupants recorded in an incident?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fatalities = dataset['Fatalities'].max()
    return max_fatalities
",uint16,1692,524.0,,,,
How many incidents occurred in January 2022?,How many incidents took place in January 2022?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for incidents that occurred in January 2022
    january_2022_incidents = dataset[dataset['Date'].dt.to_period('M') == pd.Period('2022-01')]
    
    # Count the number of incidents
    incident_count = len(january_2022_incidents)
    
    return incident_count
",int64,7,7,,,,
How many incidents resulted in non-zero fatalities?,How many incidents had fatalities greater than zero?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_incidents_with_fatalities = dataset[dataset['Fatalities'] > 0].shape[0]
    return num_incidents_with_fatalities",int64,9231,0,,,,
Which aircraft model was involved in the most incidents?,Which aircraft model has the highest number of incidents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    incident_counts = dataset['Aircaft_Model'].value_counts()
    aircraft_with_most_incidents = incident_counts.idxmax()

    return aircraft_with_most_incidents
",string,Junkers Ju-52/3m,Junkers Ju-52/3m,,,,
What was the cause of the incident that resulted in the most fatalities?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value based on some condition
    # For example, let's say the question is ""What is the most common aircraft model involved in incidents?""
    
    # Find the most common aircraft model
    most_common_model = dataset['Aircaft_Model'].mode()[0]
    
    return most_common_model
",category,Junkers Ju-52/3m,"Airplane - Pressurization, Airplane - Pressurization - Bulkhead failure, Airplane - Pressurization - Explosive decompression, Maintenance - (repair of) previous damage, Result - Loss of control",,,,
What is the most common phase of aircraft during incidents?,What is the most frequent aircraft phase associated with incidents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_phase = dataset['Aircraft_Phase'].mode()[0]
    return most_frequent_phase",category  ,En route (ENR),En route (ENR),,,,
What is the location of the incident with the highest number of onboard occupants?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a specific category value based on some criteria
# For example, let's assume the question is ""What is the most common Aircaft_Model in incidents?""

# Group by 'Aircaft_Model' and count occurrences
model_counts = dataset['Aircaft_Model'].value_counts()

# Get the model with the highest count
most_common_model = model_counts.idxmax()

return most_common_model",category,Junkers Ju-52/3m,near Ueno Village...,,,,
What are the top 3 most common causes of incidents?,What are the top 3 most frequent causes of incidents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Incident_Cause(es)' and count occurrences
    cause_counts = dataset['Incident_Cause(es)'].value_counts().head(3)
    # Get the top 3 causes as a list of strings
    top_causes = cause_counts.index.tolist()
    
    return top_causes
",list of (string),"['Info-Unavailable', 'Result - Runway excursion', 'Result - Damaged on the ground']","['Info-Unavailable', 'Result - Runway excursion', 'Result - Damaged on the ground']",,,,
List the top 5 locations where the most incidents have occurred. If there are two or more with the same number order them alphabetically,"What are the top 5 incident locations with the highest number of incidents? In case of a tie, order them alphabetically.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Incident_Location and count the number of incidents
    location_counts = dataset['Incident_Location'].value_counts()
    
    # Sort the locations first by count in descending order, then alphabetically
    top_locations = location_counts.sort_values(ascending=False).index.tolist()[:5]
    
    return top_locations
",list of (string),"['unknown', 'Havana-José ...', 'Miami Intern...', 'Rio de Janei...', 'Beirut Inter...']","['Arnhem', 'Beirut International Airport (BEY)', 'Glasgow-Preswick Airport', 'Havana-José Martí International Airport (HAV)', 'Miami International Airport, FL (MIA)']",,,,
Name the 2 most frequently occurring aircraft operators in the dataset.,Which are the top 2 aircraft operators that appear most frequently in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Aircaft_Operator' and count occurrences
    operator_counts = dataset['Aircaft_Operator'].value_counts().head(2)
    
    # Get the top 2 operators as a list of strings
    top_operators = operator_counts.index.tolist()
    
    return top_operators
",list of (string),"['USAAF', 'USAF']","['USAAF', 'USAF']",,,,
What are the top 2 most common types of aircraft damage?,What are the two most frequently occurring types of aircraft damage?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each type of aircraft damage
    damage_counts = dataset['Aircaft_Damage_Type'].value_counts()
    
    # Get the two most frequently occurring types of aircraft damage
    top_two_damage_types = damage_counts.head(2).index.tolist()
    
    return top_two_damage_types
",list of (string),"['Damaged beyond repair', 'Substantial']","['Damaged beyond repair', 'Substantial']",,,,
What are the 5 highest numbers of onboard passengers in incidents?,,,,ERROR,"[509.0, 503.0, 497.0, 451.0, 440.0]",,,,
List the 3 highest numbers of onboard crew in incidents.,,,,ERROR,"[32.0, 31.0, 29.0]",,,,
Identify the 4 highest numbers of total onboard occupants in incidents.,,,,ERROR,"[524.0, 521.0, 517.0, 469.0]",,,,
What are the 6 highest numbers of ground casualties in incidents?,,,,ERROR,"[1600, 900, 237, 107, 88, 87]",,,,
"Are there any properties with a price over 1,000,000?","Are there any properties listed with a price greater than 1,000,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_expensive_properties = (dataset[""Precio""] > 1000000).any()
    return has_expensive_properties
",bool,True,True,,,,
Any property with more than 10 bedrooms?,Is there any property with more than 10 bedrooms?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_more_than_10_bedrooms = (dataset['Habitaciones'] > 10).any()
    
    return has_more_than_10_bedrooms
",bool,True,True,,,,
Are there properties with zero bathrooms?,Are there any properties listed with zero bathrooms?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_zero_bathrooms = dataset[""Baños""].eq(0).any()
    
    return has_zero_bathrooms
",bool,False,False,,,,
Has any property been listed for more than 100 days?,,,,ERROR,True,,,,
What's the highest price in the dataset?,What is the maximum price found in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_price = dataset[""Precio""].max()
    return max_price
",uint32,17000000,17000000.0,,,,
What's the total number of properties listed?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is about finding the maximum price of a property.
    max_price = dataset[""Precio""].max()
    
    return max_price",int64,17000000,26026,,,,
What's the longest duration a property has been listed?,What is the maximum duration for which a property has been listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_duration = dataset[""Duración""].max()
    
    return max_duration
",uint16  ,2535,2535.0,,,,
What's the largest surface listed?,What is the maximum surface value listed in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_surface_value = dataset[""Superficie""].max()
return max_surface_value
",uint16,5504,5504.0,,,,
What's the most common type of property listed?,What is the most frequently listed property type?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_type = dataset['Tipo'].mode()[0]
    
    return most_frequent_type
",string  ,Piso,Piso,,,,
Which advertiser has listed the most properties?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value from the dataset
    # For example, if the question asks for the most common 'Tipo' (type), we can do the following:
    
    # Find the mode of the 'Tipo' column
    most_common_type = dataset['Tipo'].mode()[0]
    
    return most_common_type",category,Piso,housell,,,,
Which property has the highest price?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value based on some condition
    # For example, let's assume the question asks for the 'Barrio' where the 'Precio' is the highest
    max_price_individual = dataset.loc[dataset[""Precio""] == dataset[""Precio""].max()]
    barrio_name = max_price_individual[""Barrio""].values[0]

    return barrio_name",category,,GM31-121816,,,,
Which property has the largest surface area?,What is the property type with the largest surface area?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_surface_property = dataset.loc[dataset[""Superficie""] == dataset[""Superficie""].max()]
    property_type = max_surface_property[""Tipo""].iloc[0]

    return property_type
",category,Chalet rústico,IF5563-FINCA VALLE LOZOYA,,,,
What are the five types of properties more frequently listed?,What are the top five most frequently listed property types?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by the 'Tipo' column and count the occurrences
    type_counts = dataset['Tipo'].value_counts()
    
    # Get the top five most frequently listed property types
    top_five_types = type_counts.head(5).index.tolist()
    
    return top_five_types",list of (string),"['Piso', 'Chalet', 'Apartamento', 'Chalet adosado', 'Chalet unifamiliar']","['Piso', 'Chalet', 'Apartamento', 'Chalet adosado', 'Chalet unifamiliar']",,,,
What are the 2 types of properties which are listed more frequently?,What are the two most frequently listed property types?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Tipo' and count occurrences
    type_counts = dataset['Tipo'].value_counts().head(2)
    # Get the index (property types) as a list
    most_frequent_types = type_counts.index.tolist()
    
    return most_frequent_types
",list of string  ,"['Piso', 'Chalet']","['Piso', 'Chalet']",,,,
What are the 2 most common localities for properties listed?,What are the two most frequently occurring localities for properties listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    locality_counts = dataset['Localidad'].value_counts()
    top_two_localities = locality_counts.head(2).index.tolist()

    return top_two_localities
",list of (string),"['Madrid Capital', 'Torrejón de Ardoz']","['Madrid Capital', 'Torrejón de Ardoz']",,,,
What are the 2 most common districts for properties listed?,What are the two most frequently occurring districts in the property listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    district_counts = dataset['Distrito'].value_counts().head(2).index.tolist()
    return district_counts
",list of (string),"['Centro', 'Salamanca']","['Centro', 'Salamanca']",,,,
What are the 5 highest property prices listed?,What are the prices of the 5 most expensive properties listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Precio' in descending order and get the top 5 rows
    top_5_expensive_properties = dataset.sort_values(by='Precio', ascending=False).head(5)
    
    # Extract the 'Precio' column from these rows and convert it to a list
    prices = top_5_expensive_properties['Precio'].tolist()
    
    return prices
",list of (int64),"[17000000, 13600000, 13250000, 13000000, 12000000]","[17000000.0, 13600000.0, 13250000.0, 13000000.0, 12000000.0]",,,,
List the 3 longest durations properties have been listed.,What are the 3 highest Duración values in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_durations = dataset[""Duración""].nlargest(3).tolist()
return top_3_durations
",list of (int64),"[2535, 2534, 2285]","[2535.0, 2534.0, 2285.0]",,,,
Identify the 4 largest surfaces listed.,What are the 4 largest surfaces from the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Superficie' in descending order and select the top 4 values
    largest_surfaces = dataset['Superficie'].nlargest(4).tolist()
    
    return largest_surfaces
",list of (int64),"[5504, 3957, 2974, 2927]","[5504.0, 3957.0, 2974.0, 2927.0]",,,,
What are the 6 highest numbers of bedrooms in properties listed?,What are the top 6 highest numbers of bedrooms in properties listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by the number of bedrooms in descending order and get the top 6 values
    top_6_bedrooms = dataset['Habitaciones'].nlargest(6).tolist()

    return top_6_bedrooms
",list of (int64),"[20, 20, 20, 20, 20, 20]","[20, 20, 20, 20, 20, 20]",,,,
Are there more than 2000 customers with a monthly charge higher than $80?,Is the count of customers with a monthly charge greater than $80 more than 2000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count_high_monthly_charges = (dataset[""MonthlyCharges""] > 80).sum()
is_more_than_2000 = count_high_monthly_charges > 2000

return is_more_than_2000",bool,True,True,,,,
Do all customers have phone service?,,,,ERROR,True,,,,
Are there any customers with no internet service?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks if there is any customer with a total charge greater than 10000
    has_high_total_charge = (dataset[""TotalCharges""] > 10000).any()
    
    return has_high_total_charge",bool,False,True,,,,
Are there any customers who are senior citizens and have dependents?,Are there any customers who are senior citizens and have dependents?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_senior_citizens_with_dependents = (dataset['SeniorCitizen'] == 1) & (dataset['Dependents'] == 'Yes')
    return has_senior_citizens_with_dependents.any()
",bool,True,True,,,,
How many unique customers are there in the dataset?,What is the count of distinct customer IDs in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_customer_count = dataset['customerID'].nunique()
    return distinct_customer_count
",int64  ,7043,7043,,,,
What's the highest monthly charge?,What is the maximum monthly charge in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_monthly_charge = dataset['MonthlyCharges'].max()
    return max_monthly_charge
",float64  ,118.75,118.75,,,,
What's the total number of customers?,How many customers are there in total?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
total_customers = len(dataset)
return total_customers
",int64,7043,7043,,,,
What's the longest tenure?,What is the maximum tenure value in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_tenure = dataset['tenure'].max()
    
    return max_tenure
",uint8,72,72,,,,
What's the most common payment method?,,,,ERROR,Electronic check,,,,
What's the most common contract type?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value based on some condition or just fetching a column value
    # For example, if the question was ""What is the most common gender in the dataset?""
    # We would use: return dataset['gender'].mode().iloc[0]
    
    # Placeholder for the actual question logic
    answer = None
    
    return answer",category,,Month-to-month,,,,
Which customer has the highest total charge?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the customer with the highest TotalCharges
    max_charges_customer = dataset.loc[dataset[""TotalCharges""] == dataset[""TotalCharges""].max()]
    
    # Get the gender of that customer
    gender_of_max_charges_customer = max_charges_customer[""gender""].iloc[0]
    
    return gender_of_max_charges_customer
",category,Male,30-11-2888,,,,
Which customer has the highest monthly charge?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Find the customer with the highest total charges
max_charges_customer = dataset.loc[dataset[""TotalCharges""] == dataset[""TotalCharges""].max()]

# Get the gender of that customer
gender = max_charges_customer[""gender""].iloc[0]

return gender",category,Male,30-11-7568,,,,
What are the top 3 most common internet services?,What are the three most frequently occurring internet services?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
internet_service_counts = dataset['InternetService'].value_counts().head(3).index.tolist()
return internet_service_counts",list of (string),"['Fiber optic', 'DSL', 'No']","['Fiber optic', 'DSL', 'No']",,,,
Name the 4 most common payment methods.,What are the top 4 most frequently used payment methods?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each payment method
    payment_method_counts = dataset['PaymentMethod'].value_counts()
    
    # Get the top 4 most frequently used payment methods
    top_4_payment_methods = payment_method_counts.head(4).index.tolist()
    
    return top_4_payment_methods
",list of (string),"['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']","['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']",,,,
What are the 2 most common types of contract?,What are the two most frequently occurring types of contracts in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
contract_counts = dataset['Contract'].value_counts().nlargest(2).index.tolist()
return contract_counts",list of (string),"['Month-to-month', 'Two year']","['Month-to-month', 'Two year']",,,,
What are the 2 most common services for which customers have multiple lines?,Which two services are most frequently associated with customers having multiple lines?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only customers with MultipleLines = 'Yes'
    multiple_lines_customers = dataset[dataset['MultipleLines'] == 'Yes']
    
    # Count the frequency of each service for these customers
    service_counts = {}
    services = ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
    
    for service in services:
        counts = multiple_lines_customers[service].value_counts()
        if not counts.empty:
            most_frequent_service = counts.idxmax()
            service_counts[most_frequent_service] = counts.max()
    
    # Sort the services by frequency and get the top 2
    sorted_services = sorted(service_counts.items(), key=lambda x: x[1], reverse=True)
    top_2_services = [service for service, count in sorted_services[:2]]
    
    return top_2_services",list of (string),"['Fiber optic', 'No']","['No', 'Yes']",,,,
What are the 5 highest total charges?,What are the top 5 highest total charges?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_total_charges = dataset.nlargest(5, 'TotalCharges')['TotalCharges'].tolist()
return top_5_total_charges",list of (float64),"[8684.8, 8672.45, 8670.1, 8594.4, 8564.75]","[8684.8, 8672.45, 8670.1, 8594.4, 8564.75]",,,,
What are the 4 highest monthly charges?,What are the top 4 highest monthly charges?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_4_monthly_charges = dataset['MonthlyCharges'].nlargest(4).tolist()

return top_4_monthly_charges
",list of (float64),"[118.75, 118.65, 118.6, 118.6]","[118.75, 118.65, 118.6, 118.6]",,,,
What are the 6 longest tenures?,What are the top 6 longest tenures in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_tenures = dataset['tenure'].nlargest(6).tolist()

return top_tenures",list of (int64),"[72, 72, 72, 72, 72, 72]","[72, 72, 72, 72, 72, 72]",,,,
What are the 3 shortest tenures?,What are the three smallest tenure values?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by tenure in ascending order and select the first three rows
    smallest_tenure_values = dataset.sort_values(by='tenure').head(3)['tenure'].tolist()
    
    return smallest_tenure_values
",list of (uint8),"[0, 0, 0]","[0, 0, 0]",,,,
Is there a listing with a review score rating of 100?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks about a specific condition that can be answered with True or False
    # For example, let's say the question is ""Is there at least one listing in the 'city' category?""
    
    # Check if there are any listings in the 'city' category
    has_city_listings = not dataset['city'].isnull().all()
    
    return has_city_listings
",bool,True,True,,,,
Are there any hosts who have listed more than 10 properties?,Are there any hosts who have more than 10 properties listed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_more_than_10_listings = (dataset['host_total_listings_count'] > 10).any()
    
    return has_more_than_10_listings
",bool  ,True,True,,,,
Are all listings instantly bookable?,Are all the listings in the Airbnb dataset marked as instantly bookable?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    are_all_instantly_bookable = dataset['instant_bookable'].str.lower().eq('t').all()

    return are_all_instantly_bookable",bool,False,False,,,,
Is there a listing that requires a minimum of 365 nights?,Is there any Airbnb listing that requires a minimum stay of 365 nights?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_365_minimum_nights = (dataset[""minimum_nights""] == 365).any()

return has_365_minimum_nights",bool,True,True,,,,
How many unique hosts are there in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the maximum price in the dataset
    max_price = dataset['price'].max()
    
    return max_price
",int64,10000,26765,,,,
What is the highest number of listings a single host has?,What is the maximum number of listings created by a single host?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_listings = dataset['host_total_listings_count'].max()
    
    return max_listings
",float64,2739.0,2739.0,,,,
How many unique locations are listed by the hosts?,How many distinct host locations are there in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_host_locations = dataset['host_location'].nunique()
    return distinct_host_locations
",int64  ,1316,1316,,,,
What is the average review score rating across all listings?,What is the mean review score rating for all listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    mean_review_score_rating = dataset['review_scores_rating'].mean()
    
    return mean_review_score_rating
",float64,93.76718800000000,93.767188,,,,
What is the most common host location?,What is the most frequent host location?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_host_location = dataset['host_location'].mode()[0]
    return most_frequent_host_location
",string,"New York, New York, United States","New York, New York, United States",,,,
What is the name of the listing with the most bedrooms?,What is the name of the Airbnb listing with the highest number of bedrooms?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_bedrooms_listing = dataset.loc[dataset[""bedrooms""] == dataset[""bedrooms""].max()]
listing_name = max_bedrooms_listing[""name""].iloc[0]

return listing_name",string,"Walk to UN, Macy's & Empire State B","Walk to UN, Macy's & Empire State B",,,,
Which location has the highest number of listings?,,,,ERROR,"New York, New York, United States",,,,
What is the most common property type?,What is the most frequently occurring property type in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_property_type = dataset['property_type'].mode()[0]
    
    return most_frequent_property_type
",string,Entire apartment,Entire apartment,,,,
What are the top 6 unique host locations with the most listings?,What are the top 6 unique host locations with the highest number of listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by host_location and count the number of listings for each location
    host_location_counts = dataset['host_location'].value_counts()
    
    # Get the top 6 unique host locations with the highest number of listings
    top_6_host_locations = host_location_counts.head(6).index.tolist()
    
    return top_6_host_locations",list of (string),"['New York, New York, United States', 'US', 'Brooklyn, New York, United States', 'Queens, New York, United States', 'Los Angeles, California, United States', 'Bronx, New York, United States']","['New York, New York, United States', 'US', 'Brooklyn, New York, United States', 'Queens, New York, United States', 'Los Angeles, California, United States', 'Bronx, New York, United States']",,,,
What are the 2 unique host locations with the most listings?,Find the top 2 host locations with the highest number of listings.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by host_location and count the number of listings for each location
    host_locations_count = dataset['host_location'].value_counts().head(2).index.tolist()
    
    return host_locations_count
",list of (string),"['New York, New York, United States', 'US']","['New York, New York, United States', 'US']",,,,
List the 4 most common property types.,What are the four most frequent property types in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each property type
    property_type_counts = dataset['property_type'].value_counts()
    
    # Get the top four most frequent property types
    top_four_property_types = property_type_counts.head(4).index.tolist()
    
    return top_four_property_types",list of (string),"['Entire apartment', 'Private room in apartment', 'Private room in house', 'Private room in townhouse']","['Entire apartment', 'Private room in apartment', 'Entire condominium', 'Entire house']",,,,
What are the 2 most common types of properties?.,What are the two most frequently occurring types of properties in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each property type
    property_type_counts = dataset['property_type'].value_counts()
    
    # Get the two most frequently occurring types of properties
    top_two_properties = property_type_counts.head(2).index.tolist()
    
    return top_two_properties
",list of (string),"['Entire apartment', 'Private room in apartment']","['Entire apartment', 'Private room in apartment']",,,,
What are the top 3 highest review score ratings?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column of float64 values
    # For example, if the question is ""What are all the prices in the dataset?""
    column_name = 'price'  # This should be dynamically determined based on the actual question

    answer = dataset[column_name].tolist()

    return answer",list of (float64),"[110, 99, 220, 215, 300, 120, 200, 150, 100, 120, 150, 250, 100, 410, 91, 130, 165, 469, 200, 148, 80, 145, 550, 206, 135, 98, 98, 170, 230, 225, 95, 150, 95, 65, 250, 35, 125, 168, 130, 150, 73, 300, 200, 80, 146, 100, 120, 90, 150, 209, 80, 150, 130, 92, 125, 160, 99, 150, 150, 50, 160, 102, 150, 175, 160, 150, 100, 168, 160, 150, 125, 144, 129, 215, 200, 187, 75, 125, 100, 225, 141, 125, 350, 150, 99, 120, 175, 125, 98, 130, 900, 90, 214, 95, 100, 132, 150, 108, 199, 250, 135, 162, 99, 250, 125, 129, 120, 80, 110, 110, 90, 175, 195, 225, 110, 220, 135, 120, 125, 160, 69, 156, 319, 150, 195, 250, 400, 95, 109, 95, 100, 130, 220, 151, 75, 245, 189, 325, 186, 300, 150, 122, 235, 105, 150, 250, 91, 97, 140, 120, 115, 175, 157, 196, 150, 160, 165, 144, 220, 100, 125, 275, 100, 125, 115, 130, 250, 126, 180, 145, 142, 225, 129, 285, 190, 230, 100, 275, 300, 140, 143, 205, 259, 100, 125, 165, 140, 140, 175, 99, 68, 350, 180, 120, 135, 125, 110, 125, 125, 125, 250, 95, 159, 102, 340, 150, 210, 180, 150, 200, 169, 55, 105, 100, 100, 450, 150, 90, 80, 400, 120, 70, 145, 90, 104, 213, 200, 95, 400, 259, 170, 134, 132, 328, 150, 135, 140, 189, 235, 105, 299, 229, 199, 350, 110, 49, 107, 155, 300, 95, 140, 198, 179, 109, 150, 145, 39, 179, 110, 130, 140, 158, 229, 93, 100, 115, 101, 250, 65, 100, 150, 102, 175, 240, 95, 110, 83, 100, 180, 150, 120, 120, 395, 150, 104, 289, 190, 240, 130, 120, 331, 750, 175, 300, 110, 150, 339, 175, 150, 120, 75, 340, 500, 105, 205, 119, 85, 120, 169, 550, 75, 198, 93, 225, 70, 80, 395, 225, 268, 85, 265, 269, 460, 235, 105, 299, 200, 150, 148, 65, 56, 185, 160, 109, 92, 175, 120, 80, 89, 92, 75, 249, 175, 299, 100, 225, 90, 180, 200, 100, 275, 65, 110, 75, 210, 63, 150, 198, 95, 100, 101, 60, 115, 90, 190, 160, 49, 124, 105, 97, 243, 165, 210, 347, 75, 175, 130, 349, 225, 345, 199, 140, 178, 1999, 130, 125, 180, 150, 150, 220, 96, 69, 130, 129, 85, 75, 223, 165, 190, 192, 130, 70, 160, 339, 79, 198, 250, 119, 75, 150, 200, 70, 148, 199, 78, 165, 100, 165, 130, 95, 1800, 85, 150, 150, 185, 140, 89, 125, 125, 275, 119, 100, 70, 250, 250, 145, 210, 250, 135, 225, 155, 200, 119, 92, 105, 295, 150, 175, 128, 215, 126, 150, 80, 190, 70, 85, 150, 100, 250, 300, 105, 52, 260, 100, 135, 170, 135, 160, 120, 190, 168, 50, 220, 175, 90, 80, 160, 250, 299, 170, 150, 400, 250, 200, 98, 209, 230, 180, 210, 225, 169, 105, 435, 450, 175, 126, 145, 150, 125, 89, 90, 160, 90, 88, 99, 110, 154, 273, 149, 150, 400, 133, 95, 80, 69, 140, 140, 119, 131, 53, 165, 249, 225, 147, 550, 165, 120, 95, 110, 150, 199, 100, 295, 150, 245, 100, 80, 145, 180, 225, 99, 95, 120, 158, 199, 171, 89, 385, 85, 80, 185, 53, 89, 92, 127, 275, 160, 65, 125, 225, 96, 155, 100, 150, 60, 79, 150, 150, 134, 119, 132, 130, 240, 142, 300, 175, 150, 72, 87, 115, 164, 130, 85, 191, 125, 100, 150, 120, 150, 130, 100, 151, 200, 115, 200, 100, 200, 1200, 1500, 299, 300, 400, 150, 190, 200, 295, 5250, 210, 93, 125, 150, 325, 300, 150, 258, 200, 450, 211, 200, 200, 250, 700, 76, 225, 400, 220, 261, 195, 220, 92, 136, 415, 325, 137, 999, 166, 250, 200, 250, 244, 145, 185, 279, 300, 250, 295, 350, 100, 375, 193, 395, 190, 180, 350, 380, 115, 250, 204, 247, 395, 350, 284, 400, 325, 207, 100, 700, 150, 369, 120, 499, 250, 650, 250, 127, 500, 275, 180, 320, 395, 250, 2000, 1200, 1550, 6500, 2750, 1000, 270, 200, 150, 200, 300, 396, 350, 500, 450, 400, 180, 400, 500, 275, 300, 300, 745, 200, 350, 110, 300, 330, 1100, 850, 300, 1250, 250, 145, 206, 800, 300, 153, 123, 93, 65, 800, 120, 150, 226, 412, 649, 100, 236, 400, 100, 290, 125, 688, 200, 379, 999, 130, 400, 600, 325, 750, 99, 150, 275, 175, 150, 139, 450, 199, 130, 69, 129, 200, 80, 200, 60, 130, 200, 197, 250, 102, 100, 75, 149, 300, 80, 980, 150, 145, 135, 120, 300, 53, 145, 185, 350, 190, 70, 94, 125, 125, 130, 200, 130, 110, 180, 450, 109, 125, 149, 10, 200, 50, 200, 250, 170, 150, 250, 110, 275, 180, 180, 225, 133, 140, 130, 170, 500, 175, 89, 180, 215, 115, 52, 261, 180, 250, 200, 70, 230, 190, 84, 125, 175, 60, 125, 120, 175, 106, 175, 149, 90, 100, 110, 110, 95, 120, 225, 60, 128, 99, 123, 70, 70, 250, 90, 113, 99, 110, 150, 99, 145, 200, 120, 99, 89, 160, 32, 125, 40, 104, 124, 195, 150, 400, 250, 125, 150, 150, 315, 250, 145, 150, 157, 161, 120, 180, 170, 200, 101, 165, 120, 150, 130, 800, 160, 175, 150, 425, 240, 161, 165, 200, 240, 199, 125, 179, 150, 250, 130, 115, 120, 135, 180, 139, 179, 180, 300, 195, 200, 199, 140, 199, 150, 99, 400, 200, 100, 215, 160, 150, 75, 155, 95, 180, 225, 40, 137, 150, 175, 150, 70, 103, 135, 175, 181, 125, 179, 150, 102, 150, 60, 125, 75, 82, 250, 87, 148, 175, 100, 100, 240, 84, 75, 105, 220, 120, 100, 105, 175, 95, 159, 60, 114, 175, 78, 175, 109, 90, 130, 250, 329, 169, 150, 100, 250, 120, 123, 130, 140, 200, 100, 130, 123, 65, 100, 61, 195, 120, 50, 111, 110, 150, 119, 60, 75, 82, 250, 199, 90, 100, 115, 80, 135, 225, 120, 75, 200, 575, 99, 750, 150, 60, 160, 180, 119, 150, 130, 60, 200, 80, 175, 225, 120, 180, 90, 75, 250, 120, 230, 195, 185, 110, 140, 155, 350, 400, 150, 78, 120, 250, 150, 150, 89, 190, 175, 77, 100, 78, 65, 120, 120, 75, 121, 221, 250, 80, 140, 40, 200, 154, 400, 120, 60, 130, 145, 115, 125, 150, 200, 35, 125, 175, 250, 175, 175, 99, 100, 65, 170, 110, 75, 99, 79, 223, 164, 200, 50, 125, 130, 150, 75, 300, 200, 140, 150, 139, 82, 170, 150, 400, 259, 93, 90, 100, 120, 200, 110, 255, 190, 74, 145, 140, 160, 200, 129, 100, 90, 103, 180, 89, 100, 140, 41, 153, 70, 100, 148, 160, 125, 80, 101, 150, 85, 140, 100, 110, 179, 209, 139, 70, 150, 108, 110, 65, 100, 159, 120, 180, 105, 160, 160, 170, 75, 90, 125, 250, 150, 195, 160, 275, 200, 250, 250, 200, 120, 70, 189, 196, 325, 52, 300, 190, 150, 140, 75, 250, 110, 175, 250, 200, 275, 100, 250, 207, 185, 120, 190, 225, 175, 200, 152, 500, 132, 70, 120, 104, 120, 150, 175, 200, 140, 120, 280, 120, 150, 195, 240, 139, 180, 160, 140, 130, 148, 125, 200, 135, 144, 180, 150, 110, 110, 110, 140, 100, 130, 75, 160, 125, 88, 79, 150, 180, 100, 100, 200, 100, 90, 180, 150, 75, 125, 136, 280, 176, 58, 62, 135, 99, 128, 200, 150, 150, 69, 157, 280, 189, 270, 107, 175, 90, 130, 100, 250, 89, 110, 120, 90, 99, 175, 139, 110, 180, 65, 150, 75, 100, 98, 129, 75, 125, 149, 240, 500, 119, 75, 90, 250, 150, 600, 100, 125, 170, 149, 110, 140, 200, 135, 175, 155, 225, 225, 125, 150, 100, 120, 150, 150, 140, 199, 108, 99, 90, 220, 71, 200, 200, 210, 170, 100, 110, 72, 175, 195, 80, 60, 70, 135, 67, 60, 77, 155, 140, 95, 85, 69, 70, 149, 118, 200, 160, 198, 150, 98, 109, 150, 120, 105, 175, 125, 98, 128, 150, 85, 113, 145, 150, 185, 175, 200, 100, 150, 120, 100, 149, 100, 110, 128, 130, 120, 215, 125, 175, 167, 125, 155, 104, 120, 100, 150, 180, 170, 185, 139, 200, 64, 120, 185, 86, 194, 95, 209, 200, 135, 150, 70, 193, 110, 164, 75, 140, 175, 175, 100, 100, 193, 124, 170, 169, 140, 179, 120, 139, 99, 93, 190, 150, 56, 80, 150, 105, 130, 78, 89, 120, 175, 117, 110, 205, 117, 225, 143, 120, 300, 150, 149, 115, 175, 123, 140, 119, 75, 99, 151, 275, 65, 115, 60, 152, 207, 150, 150, 150, 135, 121, 140, 150, 125, 350, 160, 150, 150, 220, 250, 120, 160, 88, 150, 125, 106, 120, 350, 200, 252, 135, 120, 299, 139, 194, 156, 175, 100, 182, 240, 339, 99, 95, 550, 162, 290, 359, 260, 275, 80, 6143, 248, 209, 93, 100, 120, 230, 300, 350, 253, 130, 225, 160, 180, 120, 240, 225, 99, 220, 199, 93, 221, 184, 120, 130, 200, 250, 182, 225, 214, 175, 60, 1000, 155, 254, 130, 100, 84, 280, 195, 182, 158, 189, 90, 350, 899, 120, 170, 75, 240, 100, 200, 83, 109, 299, 83, 94, 150, 150, 214, 300, 45, 300, 94, 150, 167, 200, 180, 85, 800, 300, 164, 250, 160, 400, 167, 270, 199, 200, 180, 230, 241, 465, 144, 185, 120, 145, 125, 200, 125, 133, 325, 100, 95, 200, 100, 75, 78, 215, 150, 400, 345, 150, 152, 150, 130, 250, 77, 147, 399, 170, 180, 300, 100, 150, 150, 100, 180, 500, 140, 160, 225, 139, 210, 199, 210, 140, 200, 295, 98, 175, 160, 249, 150, 155, 130, 118, 300, 280, 450, 98, 75, 145, 117, 280, 500, 400, 275, 60, 175, 235, 92, 200, 75, 100, 250, 175, 285, 179, 150, 425, 199, 151, 200, 195, 200, 250, 170, 160, 250, 80, 175, 189, 96, 259, 200, 245, 350, 299, 200, 2350, 250, 300, 215, 800, 70, 225, 225, 197, 100, 250, 150, 230, 60, 100, 280, 550, 150, 500, 150, 599, 250, 1500, 1500, 500, 1600, 1000, 400, 180, 150, 250, 200, 180, 200, 200, 103, 2695, 150, 225, 83, 180, 100, 150, 175, 195, 300, 125, 250, 150, 140, 200, 220, 200, 400, 170, 450, 300, 500, 400, 450, 400, 149, 380, 180, 180, 239, 150, 250, 249, 195, 175, 450, 225, 120, 115, 250, 350, 124, 350, 155, 200, 150, 161, 60, 499, 100, 150, 300, 450, 130, 100, 99, 162, 101, 799, 325, 120, 120, 215, 1500, 150, 250, 800, 9999, 250, 106, 250, 200, 160, 90, 120, 120, 150, 205, 125, 150, 150, 150, 200, 250, 200, 400, 275, 250, 210, 160, 229, 200, 10000, 175, 130, 150, 160, 206, 250, 210, 150, 100, 225, 175, 200, 250, 499, 70, 180, 150, 120, 150, 175, 220, 225, 200, 150, 80, 800, 100, 240, 200, 142, 100, 250, 200, 135, 199, 115, 200, 150, 120, 125, 192, 149, 200, 150, 175, 250, 305, 175, 235, 200, 100, 125, 110, 220, 119, 175, 175, 85, 275, 100, 199, 200, 190, 166, 150, 175, 210, 180, 175, 250, 66, 69, 140, 150, 100, 225, 250, 300, 160, 450, 300, 110, 407, 310, 135, 300, 129, 170, 250, 58, 150, 257, 275, 375, 175, 100, 200, 174, 250, 200, 150, 300, 110, 175, 150, 9999, 190, 150, 93, 85, 75, 100, 158, 127, 185, 66, 300, 219, 170, 213, 160, 278, 250, 450, 130, 177, 485, 170, 243, 300, 170, 205, 300, 300, 450, 270, 250, 85, 290, 150, 235, 50, 90, 225, 120, 105, 300, 240, 150, 165, 200, 95, 180, 190, 150, 200, 190, 450, 200, 225, 200, 90, 450, 90, 145, 170, 300, 420, 160, 110, 201, 200, 195, 203, 93, 180, 200, 120, 93, 550, 295, 507, 156, 190, 175, 150, 285, 180, 120, 314, 55, 300, 200, 220, 150, 250, 280, 150, 280, 150, 200, 160, 230, 200, 2545, 195, 3200, 170, 64, 90, 375, 199, 200, 85, 300, 200, 650, 300, 200, 250, 175, 250, 180, 1000, 475, 250, 900, 900, 650, 3750, 250, 975, 180, 750, 75, 250, 150, 200, 450, 600, 180, 199, 200, 300, 300, 250, 230, 116, 200, 275, 200, 250, 275, 120, 210, 599, 165, 200, 150, 200, 135, 228, 175, 60, 500, 150, 230, 295, 210, 95, 350, 200, 450, 299, 100, 290, 125, 135, 130, 450, 197, 55, 125, 250, 102, 110, 325, 149, 200, 170, 168, 200, 175, 119, 111, 200, 300, 400, 350, 125, 121, 350, 96, 99, 250, 100, 250, 300, 150, 130, 250, 305, 400, 93, 175, 120, 140, 150, 99, 145, 120, 125, 89, 150, 115, 40, 300, 60, 180, 176, 130, 120, 85, 250, 140, 83, 375, 275, 195, 100, 160, 250, 1550, 250, 75, 179, 120, 240, 6000, 180, 225, 100, 225, 239, 125, 120, 180, 200, 350, 140, 100, 130, 250, 139, 125, 105, 200, 90, 250, 168, 186, 160, 200, 450, 250, 95, 188, 150, 150, 140, 275, 210, 185, 97, 115, 105, 120, 129, 140, 120, 199, 110, 250, 100, 140, 165, 188, 150, 299, 180, 210, 165, 99, 175, 100, 225, 260, 207, 119, 175, 130, 300, 250, 100, 58, 100, 175, 93, 170, 70, 210, 105, 115, 150, 106, 180, 275, 170, 99, 140, 240, 200, 118, 150, 850, 80, 190, 225, 119, 295, 100, 120, 150, 112, 165, 220, 97, 265, 160, 199, 155, 178, 115, 112, 99, 100, 379, 99, 216, 114, 125, 150, 149, 150, 250, 150, 225, 180, 225, 125, 200, 169, 100, 250, 205, 68, 180, 245, 117, 200, 100, 150, 160, 250, 175, 100, 150, 75, 97, 179, 129, 50, 159, 365, 175, 90, 125, 100, 150, 225, 125, 149, 170, 300, 300, 140, 129, 120, 80, 125, 100, 100, 199, 200, 300, 70, 150, 230, 100, 210, 100, 325, 200, 150, 100, 110, 500, 300, 220, 100, 165, 200, 100, 104, 150, 80, 380, 100, 400, 250, 200, 135, 150, 218, 150, 230, 179, 110, 127, 50, 90, 115, 190, 85, 200, 149, 295, 191, 239, 75, 168, 195, 120, 50, 100, 159, 200, 97, 150, 100, 135, 80, 93, 99, 120, 399, 450, 250, 150, 150, 200, 100, 190, 220, 165, 280, 230, 249, 100, 140, 185, 66, 130, 285, 180, 199, 100, 179, 180, 200, 115, 300, 275, 125, 100, 175, 195, 160, 105, 106, 120, 257, 114, 159, 85, 225, 6429, 60, 175, 153, 75, 51, 80, 100, 197, 246, 85, 65, 150, 132, 150, 130, 245, 560, 156, 80, 800, 165, 160, 110, 95, 125, 220, 350, 150, 160, 140, 130, 120, 800, 275, 135, 190, 135, 215, 70, 250, 99, 200, 160, 1200, 139, 400, 250, 100, 200, 55, 160, 215, 85, 120, 150, 150, 200, 110, 125, 125, 89, 125, 165, 700, 80, 62, 250, 70, 99, 242, 200, 99, 190, 125, 150, 110, 150, 65, 69, 150, 100, 900, 179, 100, 160, 125, 86, 200, 139, 100, 199, 348, 200, 100, 172, 150, 255, 137, 150, 132, 130, 100, 125, 100, 105, 115, 220, 60, 105, 139, 110, 150, 200, 310, 100, 110, 160, 225, 75, 100, 225, 150, 130, 145, 225, 110, 119, 110, 97, 175, 75, 179, 350, 175, 200, 165, 190, 122, 115, 150, 90, 199, 198, 80, 120, 85, 110, 119, 160, 130, 80, 228, 89, 125, 100, 100, 125, 140, 120, 100, 175, 125, 300, 150, 150, 175, 140, 105, 150, 150, 289, 250, 150, 140, 139, 162, 155, 149, 100, 100, 100, 89, 150, 39, 149, 200, 117, 100, 75, 120, 120, 98, 110, 121, 180, 168, 135, 63, 349, 199, 175, 115, 75, 90, 52, 100, 160, 180, 200, 150, 210, 170, 200, 103, 134, 95, 68, 100, 150, 235, 1139, 109, 70, 250, 150, 158, 130, 95, 124, 195, 80, 80, 235, 95, 150, 70, 250, 135, 167, 110, 100, 150, 400, 60, 225, 150, 150, 250, 1400, 115, 325, 200, 99, 214, 300, 1763, 149, 115, 95, 100, 220, 121, 100, 92, 70, 150, 150, 125, 130, 300, 150, 125, 60, 130, 214, 171, 325, 120, 114, 300, 89, 107, 2100, 75, 160, 350, 500, 80, 90, 228, 100, 120, 140, 128, 195, 250, 117, 76, 189, 150, 195, 250, 120, 150, 130, 350, 115, 155, 75, 70, 170, 130, 115, 90, 161, 85, 95, 100, 150, 195, 255, 200, 180, 124, 200, 112, 100, 120, 143, 200, 250, 185, 102, 350, 185, 169, 135, 245, 80, 150, 110, 129, 150, 214, 130, 115, 110, 109, 99, 106, 105, 100, 85, 199, 190, 110, 74, 120, 99, 125, 139, 150, 225, 250, 135, 248, 50, 70, 148, 85, 529, 175, 85, 143, 200, 70, 209, 239, 240, 100, 189, 185, 150, 172, 200, 140, 85, 200, 100, 169, 90, 214, 169, 150, 175, 80, 199, 99, 115, 149, 90, 80, 175, 109, 125, 195, 175, 125, 91, 150, 96, 210, 109, 210, 100, 55, 267, 150, 149, 150, 99, 120, 99, 65, 89, 95, 74, 95, 195, 81, 275, 200, 200, 110, 110, 200, 100, 133, 90, 168, 105, 60, 125, 180, 225, 140, 250, 83, 170, 125, 175, 175, 130, 130, 300, 100, 210, 198, 132, 325, 99, 190, 150, 150, 85, 176, 99, 195, 163, 200, 199, 85, 130, 225, 200, 170, 165, 120, 100, 190, 120, 75, 143, 83, 200, 100, 90, 150, 250, 50, 269, 67, 110, 250, 180, 110, 189, 170, 158, 225, 200, 190, 90, 125, 150, 160, 150, 95, 1000, 800, 250, 100, 1000, 350, 350, 275, 275, 215, 200, 350, 250, 200, 249, 150, 120, 105, 167, 350, 350, 225, 170, 150, 200, 250, 200, 200, 189, 189, 100, 500, 120, 150, 169, 175, 150, 125, 75, 160, 110, 300, 175, 350, 95, 400, 150, 238, 98, 247, 100, 170, 200, 130, 206, 275, 200, 175, 170, 180, 100, 95, 65, 200, 179, 150, 120, 375, 225, 125, 130, 150, 75, 300, 75, 175, 450, 250, 250, 250, 216, 110, 199, 250, 139, 235, 950, 750, 250, 450, 125, 125, 240, 199, 170, 132, 190, 200, 150, 180, 125, 160, 100, 84, 103, 200, 180, 175, 150, 450, 190, 95, 125, 85, 130, 200, 200, 150, 120, 229, 100, 149, 126, 70, 115, 200, 89, 200, 300, 120, 150, 199, 50, 140, 275, 90, 250, 120, 200, 300, 130, 87, 100, 140, 199, 300, 100, 250, 150, 150, 30, 175, 80, 180, 200, 170, 130, 90, 110, 85, 139, 110, 28, 69, 140, 150, 115, 100, 46, 75, 160, 192, 120, 140, 90, 110, 600, 125, 125, 200, 89, 120, 190, 85, 80, 165, 120, 100, 95, 70, 125, 180, 150, 65, 90, 80, 75, 150, 75, 99, 75, 165, 125, 70, 133, 199, 45, 200, 90, 200, 75, 130, 120, 225, 121, 109, 200, 180, 250, 155, 150, 120, 125, 59, 150, 130, 200, 180, 200, 250, 850, 1500, 179, 250, 350, 314, 205, 140, 125, 225, 450, 100, 120, 85, 150, 200, 150, 175, 300, 200, 160, 250, 300, 150, 150, 200, 125, 275, 225, 99, 250, 200, 195, 92, 300, 264, 389, 150, 150, 150, 2000, 150, 300, 180, 575, 160, 200, 300, 400, 749, 300, 350, 200, 150, 175, 260, 270, 350, 75, 350, 125, 180, 250, 175, 250, 150, 400, 150, 295, 429, 212, 130, 95, 125, 155, 107, 329, 150, 150, 100, 260, 250, 89, 149, 110, 200, 89, 149, 180, 154, 100, 124, 132, 118, 220, 225, 249, 180, 200, 140, 85, 80, 137, 180, 207, 200, 250, 125, 200, 160, 94, 200, 220, 120, 195, 75, 195, 325, 100, 120, 240, 199, 200, 165, 200, 225, 250, 120, 125, 120, 150, 150, 156, 190, 189, 115, 70, 130, 80, 85, 154, 130, 214, 110, 133, 106, 280, 88, 259, 110, 100, 95, 130, 150, 109, 175, 73, 150, 200, 100, 95, 76, 189, 150, 125, 400, 99, 100, 190, 162, 83, 125, 75, 150, 160, 100, 120, 100, 166, 70, 135, 90, 499, 170, 125, 100, 95, 160, 125, 120, 100, 450, 100, 196, 110, 240, 150, 75, 180, 150, 100, 120, 75, 120, 50, 138, 129, 130, 125, 110, 100, 200, 180, 250, 150, 138, 60, 175, 115, 200, 250, 109, 104, 150, 110, 149, 115, 150, 100, 116, 120, 105, 150, 175, 260, 70, 220, 150, 98, 99, 150, 175, 199, 115, 115, 130, 150, 200, 75, 100, 175, 139, 150, 400, 149, 128, 88, 200, 225, 140, 150, 125, 125, 50, 280, 130, 100, 135, 77, 170, 61, 80, 200, 115, 75, 79, 145, 115, 160, 175, 150, 180, 188, 155, 150, 193, 175, 125, 160, 160, 110, 100, 254, 120, 125, 285, 140, 55, 165, 320, 150, 120, 170, 140, 175, 140, 103, 165, 149, 98, 150, 200, 130, 125, 150, 100, 159, 290, 80, 170, 175, 115, 160, 92, 120, 108, 250, 180, 100, 80, 105, 160, 150, 189, 90, 150, 135, 120, 100, 75, 150, 100, 55, 119, 95, 139, 225, 195, 90, 156, 70, 100, 264, 104, 130, 120, 83, 75, 229, 100, 230, 139, 65, 100, 144, 120, 104, 135, 100, 225, 99, 150, 99, 115, 96, 120, 115, 75, 137, 120, 500, 155, 190, 100, 80, 77, 105, 148, 200, 95, 100, 66, 105, 160, 225, 210, 425, 160, 160, 200, 148, 120, 175, 140, 263, 175, 100, 210, 150, 126, 137, 200, 94, 202, 199, 140, 149, 150, 99, 149, 145, 257, 185, 120, 175, 120, 179, 149, 120, 399, 90, 180, 150, 190, 110, 275, 199, 90, 48, 225, 225, 90, 160, 180, 160, 137, 120, 196, 163, 140, 140, 250, 169, 120, 145, 180, 135, 185, 275, 175, 110, 200, 109, 129, 140, 80, 99, 120, 200, 75, 110, 163, 85, 99, 90, 165, 349, 200, 128, 75, 125, 179, 200, 150, 128, 98, 115, 190, 130, 150, 105, 225, 140, 106, 236, 110, 175, 85, 295, 175, 180, 160, 150, 199, 175, 115, 200, 234, 120, 129, 230, 120, 145, 219, 325, 140, 139, 85, 200, 115, 105, 230, 120, 119, 215, 250, 125, 145, 120, 125, 115, 85, 120, 110, 160, 130, 105, 121, 291, 125, 129, 173, 200, 150, 125, 185, 220, 185, 100, 175, 125, 145, 200, 225, 171, 88, 115, 99, 225, 150, 150, 179, 195, 250, 150, 75, 75, 160, 135, 115, 154, 130, 100, 151, 225, 139, 130, 150, 325, 120, 185, 145, 70, 124, 99, 93, 100, 42, 200, 75, 240, 120, 175, 95, 95, 163, 125, 105, 148, 105, 100, 90, 180, 219, 129, 179, 149, 150, 220, 160, 115, 105, 110, 92, 130, 190, 179, 50, 100, 88, 150, 106, 93, 115, 175, 80, 100, 115, 200, 123, 140, 290, 95, 78, 99, 80, 125, 150, 50, 85, 131, 300, 132, 125, 98, 94, 100, 128, 120, 100, 180, 149, 180, 120, 120, 136, 170, 229, 121, 120, 100, 93, 135, 75, 144, 96, 160, 95, 125, 150, 250, 170, 100, 250, 225, 146, 170, 95, 75, 96, 120, 130, 130, 130, 200, 225, 100, 290, 139, 200, 250, 190, 142, 281, 170, 162, 225, 200, 99, 185, 170, 150, 150, 200, 99, 200, 321, 175, 120, 201, 130, 304, 80, 120, 188, 178, 175, 199, 225, 90, 160, 95, 128, 120, 168, 69, 144, 175, 125, 220, 95, 80, 75, 180, 60, 80, 150, 175, 150, 175, 135, 105, 130, 60, 90, 200, 175, 175, 200, 119, 250, 109, 135, 100, 209, 82, 230, 199, 195, 125, 180, 130, 385, 150, 280, 175, 250, 75, 100, 89, 150, 180, 200, 90, 250, 190, 140, 95, 236, 249, 250, 70, 70, 70, 269, 153, 200, 200, 150, 92, 150, 95, 200, 44, 150, 70, 232, 135, 265, 179, 907, 50, 219, 199, 190, 165, 80, 150, 80, 180, 215, 199, 200, 225, 95, 250, 100, 175, 175, 198, 130, 150, 400, 100, 140, 200, 110, 175, 130, 250, 175, 145, 280, 199, 200, 175, 185, 80, 150, 150, 180, 240, 190, 200, 110, 207, 149, 110, 114, 95, 85, 140, 175, 110, 95, 210, 170, 115, 150, 160, 130, 175, 125, 400, 125, 150, 95, 300, 189, 199, 230, 236, 100, 300, 76, 200, 100, 185, 150, 140, 195, 125, 159, 139, 140, 185, 275, 75, 150, 195, 55, 250, 250, 200, 150, 168, 145, 160, 257, 250, 150, 200, 225, 115, 180, 120, 155, 200, 165, 70, 199, 110, 125, 250, 190, 175, 125, 180, 100, 169, 130, 95, 150, 215, 165, 220, 215, 185, 175, 175, 149, 250, 125, 100, 110, 179, 115, 127, 80, 115, 250, 123, 150, 211, 175, 150, 110, 160, 120, 145, 200, 196, 175, 85, 150, 200, 160, 165, 90, 100, 115, 150, 175, 210, 150, 202, 100, 150, 106, 135, 111, 165, 200, 149, 143, 175, 195, 150, 110, 90, 225, 225, 170, 180, 175, 330, 140, 130, 289, 150, 150, 140, 140, 130, 210, 249, 160, 150, 250, 150, 125, 135, 175, 120, 150, 110, 179, 85, 120, 125, 245, 199, 200, 100, 120, 375, 109, 95, 110, 100, 135, 88, 130, 105, 125, 175, 110, 81, 140, 119, 100, 72, 200, 157, 149, 99, 70, 102, 115, 81, 225, 325, 99, 163, 95, 135, 275, 103, 100, 90, 210, 215, 100, 119, 90, 176, 500, 150, 63, 250, 90, 53, 52, 63, 115, 520, 102, 125, 100, 105, 357, 190, 400, 95, 124, 111, 110, 145, 90, 172, 95, 125, 90, 70, 275, 58, 150, 56, 108, 145, 150, 115, 92, 170, 81, 135, 200, 81, 63, 80, 287, 66, 157, 115, 75, 99, 325, 140, 285, 149, 205, 74, 55, 99, 78, 74, 98, 75, 117, 90, 131, 110, 150, 140, 119, 127, 75, 165, 100, 105, 155, 223, 65, 99, 138, 290, 95, 170, 100, 126, 150, 60, 200, 135, 80, 140, 90, 300, 72, 75, 91, 82, 120, 79, 90, 175, 350, 125, 150, 139, 250, 130, 175, 135, 69, 100, 275, 75, 120, 286, 100, 100, 108, 129, 370, 100, 150, 100, 69, 109, 140, 99, 170, 199, 185, 225, 93, 95, 454, 100, 190, 250, 350, 92, 185, 118, 126, 66, 150, 149, 95, 258, 165, 733, 135, 179, 85, 74, 190, 129, 180, 130, 99, 130, 245, 80, 128, 200, 90, 180, 175, 1599, 119, 365, 115, 110, 95, 155, 129, 170, 90, 64, 145, 298, 350, 180, 112, 300, 360, 80, 349, 196, 189, 100, 70, 185, 94, 75, 100, 140, 110, 175, 79, 110, 150, 150, 96, 89, 190, 60, 70, 111, 72, 190, 134, 140, 275, 144, 150, 110, 200, 155, 150, 50, 72, 91, 107, 62, 101, 78, 111, 215, 135, 85, 119, 250, 175, 145, 145, 110, 115, 269, 125, 105, 100, 103, 77, 205, 88, 92, 190, 139, 105, 239, 150, 95, 199, 85, 80, 311, 200, 225, 69, 70, 148, 194, 66, 215, 95, 295, 118, 100, 99, 320, 42, 130, 150, 80, 124, 125, 100, 99, 250, 180, 250, 80, 109, 126, 120, 60, 100, 115, 259, 95, 185, 175, 135, 159, 314, 147, 250, 150, 150, 500, 250, 115, 115, 85, 60, 85, 140, 140, 120, 150, 90, 700, 175, 150, 129, 65, 150, 110, 76, 189, 135, 118, 82, 390, 200, 375, 162, 215, 95, 101, 85, 125, 120, 128, 115, 350, 84, 129, 83, 144, 750, 300, 85, 85, 85, 114, 119, 155, 80, 110, 150, 120, 206, 164, 135, 75, 80, 180, 52, 110, 75, 200, 169, 106, 70, 143, 100, 188, 80, 125, 125, 95, 225, 210, 110, 90, 60, 200, 154, 299, 79, 99, 231, 111, 120, 95, 300, 119, 175, 140, 175, 104, 179, 80, 73, 77, 250, 225, 70, 100, 80, 133, 100, 96, 83, 812, 108, 78, 106, 111, 90, 88, 60, 150, 127, 75, 200, 300, 105, 100, 112, 105, 74, 195, 99, 199, 70, 135, 150, 89, 199, 180, 120, 169, 76, 82, 155, 225, 125, 188, 129, 75, 95, 54, 120, 72, 65, 86, 56, 125, 85, 68, 127, 70, 130, 125, 124, 200, 125, 85, 70, 80, 90, 150, 98, 346, 250, 90, 126, 90, 171, 100, 75, 130, 528, 140, 110, 60, 133, 145, 200, 80, 200, 148, 69, 115, 165, 340, 175, 110, 150, 179, 105, 231, 167, 101, 70, 186, 191, 100, 149, 112, 322, 90, 135, 150, 101, 99, 65, 110, 57, 115, 183, 100, 81, 125, 79, 70, 107, 84, 130, 150, 97, 128, 135, 120, 285, 70, 204, 139, 190, 220, 130, 140, 189, 86, 125, 250, 115, 92, 130, 89, 99, 495, 95, 171, 499, 100, 125, 150, 179, 204, 201, 181, 200, 160, 244, 190, 250, 75, 70, 507, 250, 150, 185, 170, 155, 137, 90, 482, 139, 139, 120, 105, 135, 180, 75, 153, 85, 90, 213, 199, 350, 123, 58, 149, 249, 166, 130, 135, 243, 263, 225, 249, 85, 185, 99, 89, 195, 74, 84, 220, 110, 200, 98, 126, 109, 65, 69, 126, 99, 110, 135, 70, 199, 100, 99, 65, 169, 91, 125, 80, 214, 230, 119, 135, 105, 140, 200, 225, 129, 90, 110, 225, 199, 175, 175, 170, 265, 200, 100, 159, 99, 80, 450, 250, 109, 106, 225, 185, 185, 166, 121, 250, 189, 106, 150, 69, 85, 210, 700, 135, 111, 246, 120, 175, 100, 200, 130, 198, 100, 75, 187, 200, 126, 130, 238, 186, 160, 207, 95, 155, 115, 165, 150, 155, 140, 229, 82, 500, 115, 84, 110, 85, 92, 100, 115, 100, 79, 120, 78, 100, 79, 100, 65, 120, 75, 282, 135, 150, 127, 250, 95, 221, 71, 100, 100, 146, 109, 179, 191, 85, 90, 100, 150, 200, 100, 130, 175, 118, 85, 66, 110, 500, 120, 300, 99, 133, 182, 80, 85, 70, 130, 129, 100, 255, 111, 134, 80, 298, 130, 125, 95, 170, 199, 70, 150, 125, 110, 115, 150, 90, 135, 99, 95, 90, 200, 100, 135, 239, 50, 200, 100, 100, 175, 165, 100, 138, 100, 75, 185, 135, 165, 125, 134, 111, 85, 70, 179, 200, 99, 139, 175, 99, 150, 499, 69, 56, 300, 3000, 124, 49, 83, 100, 75, 150, 100, 100, 100, 127, 75, 115, 100, 100, 166, 120, 100, 155, 115, 135, 66, 85, 115, 119, 215, 80, 53, 100, 75, 51, 339, 199, 200, 175, 129, 585, 135, 120, 245, 321, 125, 121, 150, 100, 184, 870, 870, 190, 112, 214, 90, 211, 180, 160, 325, 200, 450, 165, 425, 250, 100, 390, 120, 120, 1225, 300, 160, 160, 85, 2200, 1000, 600, 100, 175, 279, 104, 300, 175, 155, 150, 239, 450, 85, 125, 280, 150, 110, 90, 200, 240, 152, 156, 102, 160, 250, 236, 299, 214, 111, 254, 650, 85, 150, 364, 90, 165, 110, 194, 225, 500, 150, 120, 120, 200, 250, 320, 100, 166, 195, 117, 199, 129, 180, 295, 185, 135, 89, 179, 100, 134, 85, 119, 150, 105, 186, 150, 100, 98, 250, 300, 300, 300, 290, 220, 210, 248, 119, 99, 215, 239, 120, 130, 120, 165, 220, 65, 249, 175, 150, 200, 179, 150, 300, 250, 214, 77, 160, 67, 130, 150, 143, 220, 109, 78, 65, 225, 195, 109, 85, 115, 120, 110, 115, 150, 200, 86, 487, 90, 85, 199, 200, 108, 80, 450, 99, 60, 169, 115, 175, 101, 110, 82, 185, 130, 120, 80, 400, 72, 161, 120, 191, 150, 100, 190, 100, 123, 103, 178, 94, 75, 70, 90, 150, 100, 60, 250, 175, 200, 400, 71, 60, 185, 190, 200, 99, 195, 107, 130, 110, 99, 120, 100, 135, 149, 79, 119, 115, 74, 73, 175, 130, 200, 59, 175, 135, 180, 100, 120, 89, 139, 91, 90, 81, 52, 275, 150, 86, 110, 120, 205, 200, 166, 140, 180, 90, 170, 148, 156, 90, 140, 124, 111, 100, 55, 165, 115, 200, 84, 90, 70, 80, 200, 81, 80, 80, 100, 250, 330, 225, 180, 150, 200, 300, 550, 200, 160, 186, 108, 122, 108, 175, 60, 142, 176, 90, 148, 264, 180, 143, 129, 50, 135, 160, 100, 85, 196, 143, 81, 125, 160, 170, 206, 180, 150, 140, 89, 83, 85, 125, 174, 120, 87, 220, 175, 100, 200, 110, 180, 99, 135, 55, 147, 90, 69, 145, 208, 114, 249, 200, 97, 61, 85, 125, 164, 50, 500, 251, 200, 90, 179, 162, 55, 80, 125, 60, 48, 100, 741, 169, 159, 159, 70, 75, 95, 120, 115, 99, 50, 100, 79, 91, 280, 101, 45, 129, 99, 85, 115, 110, 125, 199, 159, 139, 85, 125, 89, 101, 79, 99, 150, 45, 215, 120, 100, 279, 140, 165, 135, 120, 97, 130, 390, 115, 130, 134, 390, 487, 95, 120, 73, 225, 168, 110, 51, 150, 1850, 169, 95, 89, 125, 250, 91, 81, 79, 165, 170, 175, 236, 62, 400, 245, 98, 65, 399, 68, 119, 150, 83, 76, 45, 62, 340, 450, 149, 450, 350, 450, 52, 160, 206, 185, 120, 200, 95, 199, 272, 39, 169, 232, 120, 87, 136, 130, 200, 77, 487, 175, 200, 169, 195, 153, 200, 129, 58, 80, 70, 115, 100, 1200, 75, 180, 100, 164, 110, 114, 389, 235, 125, 266, 210, 185, 101, 195, 199, 150, 100, 68, 110, 333, 219, 487, 159, 459, 325, 150, 210, 375, 119, 95, 314, 67, 65, 159, 75, 149, 76, 125, 194, 115, 75, 92, 70, 110, 390, 241, 76, 185, 60, 125, 150, 133, 239, 159, 169, 190, 120, 100, 129, 110, 105, 95, 129, 99, 435, 110, 100, 86, 125, 185, 133, 200, 250, 140, 145, 85, 199, 99, 80, 150, 89, 130, 124, 89, 195, 128, 75, 80, 135, 90, 195, 75, 140, 99, 120, 150, 155, 250, 99, 225, 95, 130, 399, 169, 115, 95, 118, 185, 150, 125, 120, 195, 147, 81, 65, 245, 58, 139, 115, 159, 250, 165, 245, 240, 250, 157, 175, 74, 115, 100, 130, 108, 150, 61, 85, 92, 150, 219, 80, 170, 75, 75, 350, 125, 119, 65, 599, 100, 59, 175, 1200, 85, 80, 160, 741, 119, 159, 169, 499, 119, 100, 125, 107, 165, 163, 70, 185, 120, 135, 68, 99, 499, 189, 900, 100, 79, 1000, 78, 600, 83, 250, 100, 150, 105, 950, 185, 250, 125, 135, 179, 169, 150, 100, 185, 214, 104, 56, 62, 549, 500, 109, 250, 275, 89, 90, 90, 69, 143, 115, 95, 120, 135, 219, 159, 78, 110, 70, 160, 149, 111, 115, 96, 99, 99, 275, 59, 81, 110, 88, 79, 63, 86, 150, 220, 120, 76, 130, 79, 100, 105, 1170, 1100, 220, 174, 178, 115, 75, 115, 242, 248, 433, 150, 100, 6500, 139, 56, 120, 527, 100, 150, 683, 1099, 809, 132, 300, 112, 101, 75, 100, 270, 200, 190, 219, 137, 90, 100, 85, 95, 125, 125, 87, 89, 87, 115, 99, 105, 109, 119, 125, 129, 139, 135, 100, 140, 200, 80, 74, 172, 299, 249, 299, 249, 230, 280, 150, 120, 100, 260, 2999, 519, 140, 195, 250, 200, 120, 130, 130, 125, 125, 175, 175, 120, 100, 145, 155, 146, 100, 99, 110, 145, 135, 230, 125, 300, 145, 115, 270, 85, 85, 195, 195, 110, 100, 100, 110, 130, 115, 105, 174, 190, 200, 110, 100, 110, 135, 100, 125, 125, 125, 125, 135, 110, 100, 155, 135, 125, 120, 250, 120, 193, 150, 95, 100, 75, 389, 403, 383, 348, 369, 354, 150, 102, 100, 185, 55, 150, 97, 60, 348, 348, 431, 324, 465, 180, 180, 59, 175, 150, 65, 250, 180, 75, 69, 85, 130, 69, 129, 68, 65, 85, 70, 68, 70, 218, 160, 99, 99, 97, 178, 104, 140, 60, 120, 75, 106, 135, 120, 105, 180, 180, 315, 140, 999, 100, 120, 180, 150, 150, 150, 160, 190, 90, 75, 98, 83, 71, 110, 98, 90, 100, 359, 225, 359, 279, 165, 129, 289, 1100, 921, 247, 225, 359, 135, 359, 145, 149, 145, 149, 145, 289, 129, 145, 289, 149, 149, 149, 149, 149, 149, 149, 129, 129, 129, 129, 129, 149, 149, 149, 225, 225, 219, 219, 199, 249, 145, 179, 225, 225, 225, 225, 225, 359, 359, 359, 219, 145, 149, 247, 249, 165, 84, 95, 99, 105, 109, 115, 119, 125, 135, 250, 310, 310, 330, 335, 259, 219, 219, 239, 159, 309, 989, 219, 279, 529, 169, 169, 529, 650, 265, 126, 126, 126, 126, 126, 126, 180, 180, 139, 269, 149, 159, 189, 200, 79, 250, 179, 80, 89, 500, 348, 125, 471, 328, 383, 348, 348, 433, 328, 700, 125, 79, 101, 84, 240, 69, 213, 105, 261, 119, 119, 189, 200, 549, 193, 375, 314, 328, 206, 202, 234, 169, 209, 150, 249, 249, 145, 201, 110, 80, 150, 70, 80, 105, 155, 150, 189, 179, 154, 199, 159, 86, 58, 70, 190, 126, 299, 79, 99, 76, 85, 75, 130, 140, 69, 89, 68, 137, 75, 183, 189, 75, 195, 125, 130, 350, 230, 110, 100, 105, 250, 89, 115, 210, 59, 109, 180, 76, 220, 70, 170, 165, 99, 120, 75, 200, 200, 140, 140, 70, 150, 120, 115, 413, 389, 399, 359, 380, 60, 130, 178, 140, 115, 135, 83, 85, 100, 643, 346, 83, 199, 79, 81, 130, 85, 89, 145, 870, 149, 159, 260, 150, 200, 120, 150, 175, 250, 149, 135, 60, 90, 120, 70, 185, 100, 275, 199, 220, 110, 135, 200, 80, 175, 189, 250, 225, 68, 190, 125, 85, 185, 100, 295, 275, 180, 170, 180, 142, 300, 64, 135, 127, 150, 80, 80, 135, 75, 59, 159, 120, 150, 120, 103, 96, 125, 110, 103, 139, 357, 293, 250, 200, 150, 75, 100, 113, 400, 123, 120, 56, 90, 56, 56, 79, 90, 296, 524, 300, 100, 250, 245, 53, 150, 90, 126, 115, 108, 129, 196, 114, 125, 120, 120, 70, 105, 239, 135, 50, 643, 386, 111, 110, 91, 140, 102, 125, 80, 85, 90, 250, 75, 90, 109, 500, 120, 300, 250, 96, 220, 125, 299, 125, 80, 99, 250, 85, 60, 99, 67, 1054, 85, 114, 67, 64, 59, 67, 67, 99, 250, 255, 75, 150, 146, 500, 330, 430, 390, 304, 136, 116, 150, 90, 540, 500, 188, 522, 98, 110, 63, 85, 52, 499, 111, 90, 110, 85, 150, 169, 85, 185, 61, 100, 309, 63, 300, 52, 116, 2596, 125, 52, 400, 350, 116, 325, 415, 130, 67, 81, 220, 120, 112, 226, 150, 120, 92, 77, 130, 180, 292, 75, 85, 119, 75, 85, 94, 250, 100, 180, 70, 105, 254, 320, 106, 360, 170, 140, 300, 399, 80, 220, 240, 250, 350, 275, 500, 99, 105, 135, 300, 150, 150, 70, 269, 206, 275, 170, 120, 155, 55, 259, 240, 304, 147, 100, 190, 170, 50, 120, 87, 120, 120, 250, 149, 109, 195, 120, 314, 160, 160, 150, 140, 258, 115, 299, 150, 250, 125, 79, 80, 297, 210, 270, 120, 92, 150, 66, 179, 179, 120, 140, 240, 120, 99, 190, 250, 90, 150, 102, 104, 135, 120, 150, 115, 150, 100, 110, 191, 85, 79, 150, 250, 139, 99, 90, 208, 46, 207, 89, 109, 155, 83, 401, 71, 200, 130, 75, 70, 99, 349, 1000, 85, 135, 120, 100, 175, 247, 187, 500, 95, 275, 371, 120, 120, 250, 94, 599, 250, 200, 99, 157, 81, 200, 150, 127, 150, 70, 200, 140, 145, 208, 110, 85, 100, 325, 250, 100, 179, 305, 85, 215, 110, 110, 85, 150, 90, 99, 147, 257, 139, 410, 229, 150, 144, 88, 285, 260, 160, 190, 128, 150, 109, 210, 150, 204, 190, 180, 95, 110, 143, 174, 240, 275, 194, 450, 380, 150, 150, 110, 350, 350, 295, 232, 176, 967, 552, 249, 160, 135, 134, 135, 199, 200, 388, 329, 155, 650, 514, 125, 146, 50, 90, 80, 90, 167, 244, 175, 151, 100, 110, 95, 179, 140, 200, 79, 110, 122, 55, 115, 146, 163, 302, 385, 599, 399, 164, 369, 249, 550, 150, 255, 503, 180, 85, 750, 269, 664, 205, 200, 115, 289, 150, 151, 148, 149, 85, 490, 190, 219, 407, 135, 200, 175, 75, 86, 250, 85, 65, 90, 150, 270, 285, 375, 250, 350, 224, 150, 140, 90, 150, 128, 195, 100, 100, 175, 75, 149, 89, 222, 125, 149, 120, 130, 160, 100, 208, 180, 205, 215, 130, 250, 80, 450, 100, 105, 70, 150, 200, 125, 80, 101, 102, 90, 175, 100, 187, 290, 388, 204, 54, 125, 159, 269, 267, 250, 167, 115, 80, 111, 59, 190, 922, 100, 150, 165, 90, 175, 85, 100, 175, 110, 140, 195, 145, 116, 199, 250, 110, 90, 300, 250, 120, 289, 200, 46, 218, 189, 90, 80, 70, 145, 70, 80, 70, 70, 70, 115, 95, 70, 95, 70, 95, 95, 70, 70, 75, 70, 95, 95, 119, 70, 70, 95, 70, 79, 195, 551, 130, 150, 800, 150, 398, 130, 130, 297, 110, 98, 285, 196, 85, 1","[100, 100, 100]",,,,
What are the 5 lowest number of minimum nights required?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a list of prices
prices = dataset['price'].tolist()
return prices",list of uint16,"[110, 99, 220, 215, 300, 120, 200, 150, 100, 120, 150, 250, 100, 410, 91, 130, 165, 469, 200, 148, 80, 145, 550, 206, 135, 98, 98, 170, 230, 225, 95, 150, 95, 65, 250, 35, 125, 168, 130, 150, 73, 300, 200, 80, 146, 100, 120, 90, 150, 209, 80, 150, 130, 92, 125, 160, 99, 150, 150, 50, 160, 102, 150, 175, 160, 150, 100, 168, 160, 150, 125, 144, 129, 215, 200, 187, 75, 125, 100, 225, 141, 125, 350, 150, 99, 120, 175, 125, 98, 130, 900, 90, 214, 95, 100, 132, 150, 108, 199, 250, 135, 162, 99, 250, 125, 129, 120, 80, 110, 110, 90, 175, 195, 225, 110, 220, 135, 120, 125, 160, 69, 156, 319, 150, 195, 250, 400, 95, 109, 95, 100, 130, 220, 151, 75, 245, 189, 325, 186, 300, 150, 122, 235, 105, 150, 250, 91, 97, 140, 120, 115, 175, 157, 196, 150, 160, 165, 144, 220, 100, 125, 275, 100, 125, 115, 130, 250, 126, 180, 145, 142, 225, 129, 285, 190, 230, 100, 275, 300, 140, 143, 205, 259, 100, 125, 165, 140, 140, 175, 99, 68, 350, 180, 120, 135, 125, 110, 125, 125, 125, 250, 95, 159, 102, 340, 150, 210, 180, 150, 200, 169, 55, 105, 100, 100, 450, 150, 90, 80, 400, 120, 70, 145, 90, 104, 213, 200, 95, 400, 259, 170, 134, 132, 328, 150, 135, 140, 189, 235, 105, 299, 229, 199, 350, 110, 49, 107, 155, 300, 95, 140, 198, 179, 109, 150, 145, 39, 179, 110, 130, 140, 158, 229, 93, 100, 115, 101, 250, 65, 100, 150, 102, 175, 240, 95, 110, 83, 100, 180, 150, 120, 120, 395, 150, 104, 289, 190, 240, 130, 120, 331, 750, 175, 300, 110, 150, 339, 175, 150, 120, 75, 340, 500, 105, 205, 119, 85, 120, 169, 550, 75, 198, 93, 225, 70, 80, 395, 225, 268, 85, 265, 269, 460, 235, 105, 299, 200, 150, 148, 65, 56, 185, 160, 109, 92, 175, 120, 80, 89, 92, 75, 249, 175, 299, 100, 225, 90, 180, 200, 100, 275, 65, 110, 75, 210, 63, 150, 198, 95, 100, 101, 60, 115, 90, 190, 160, 49, 124, 105, 97, 243, 165, 210, 347, 75, 175, 130, 349, 225, 345, 199, 140, 178, 1999, 130, 125, 180, 150, 150, 220, 96, 69, 130, 129, 85, 75, 223, 165, 190, 192, 130, 70, 160, 339, 79, 198, 250, 119, 75, 150, 200, 70, 148, 199, 78, 165, 100, 165, 130, 95, 1800, 85, 150, 150, 185, 140, 89, 125, 125, 275, 119, 100, 70, 250, 250, 145, 210, 250, 135, 225, 155, 200, 119, 92, 105, 295, 150, 175, 128, 215, 126, 150, 80, 190, 70, 85, 150, 100, 250, 300, 105, 52, 260, 100, 135, 170, 135, 160, 120, 190, 168, 50, 220, 175, 90, 80, 160, 250, 299, 170, 150, 400, 250, 200, 98, 209, 230, 180, 210, 225, 169, 105, 435, 450, 175, 126, 145, 150, 125, 89, 90, 160, 90, 88, 99, 110, 154, 273, 149, 150, 400, 133, 95, 80, 69, 140, 140, 119, 131, 53, 165, 249, 225, 147, 550, 165, 120, 95, 110, 150, 199, 100, 295, 150, 245, 100, 80, 145, 180, 225, 99, 95, 120, 158, 199, 171, 89, 385, 85, 80, 185, 53, 89, 92, 127, 275, 160, 65, 125, 225, 96, 155, 100, 150, 60, 79, 150, 150, 134, 119, 132, 130, 240, 142, 300, 175, 150, 72, 87, 115, 164, 130, 85, 191, 125, 100, 150, 120, 150, 130, 100, 151, 200, 115, 200, 100, 200, 1200, 1500, 299, 300, 400, 150, 190, 200, 295, 5250, 210, 93, 125, 150, 325, 300, 150, 258, 200, 450, 211, 200, 200, 250, 700, 76, 225, 400, 220, 261, 195, 220, 92, 136, 415, 325, 137, 999, 166, 250, 200, 250, 244, 145, 185, 279, 300, 250, 295, 350, 100, 375, 193, 395, 190, 180, 350, 380, 115, 250, 204, 247, 395, 350, 284, 400, 325, 207, 100, 700, 150, 369, 120, 499, 250, 650, 250, 127, 500, 275, 180, 320, 395, 250, 2000, 1200, 1550, 6500, 2750, 1000, 270, 200, 150, 200, 300, 396, 350, 500, 450, 400, 180, 400, 500, 275, 300, 300, 745, 200, 350, 110, 300, 330, 1100, 850, 300, 1250, 250, 145, 206, 800, 300, 153, 123, 93, 65, 800, 120, 150, 226, 412, 649, 100, 236, 400, 100, 290, 125, 688, 200, 379, 999, 130, 400, 600, 325, 750, 99, 150, 275, 175, 150, 139, 450, 199, 130, 69, 129, 200, 80, 200, 60, 130, 200, 197, 250, 102, 100, 75, 149, 300, 80, 980, 150, 145, 135, 120, 300, 53, 145, 185, 350, 190, 70, 94, 125, 125, 130, 200, 130, 110, 180, 450, 109, 125, 149, 10, 200, 50, 200, 250, 170, 150, 250, 110, 275, 180, 180, 225, 133, 140, 130, 170, 500, 175, 89, 180, 215, 115, 52, 261, 180, 250, 200, 70, 230, 190, 84, 125, 175, 60, 125, 120, 175, 106, 175, 149, 90, 100, 110, 110, 95, 120, 225, 60, 128, 99, 123, 70, 70, 250, 90, 113, 99, 110, 150, 99, 145, 200, 120, 99, 89, 160, 32, 125, 40, 104, 124, 195, 150, 400, 250, 125, 150, 150, 315, 250, 145, 150, 157, 161, 120, 180, 170, 200, 101, 165, 120, 150, 130, 800, 160, 175, 150, 425, 240, 161, 165, 200, 240, 199, 125, 179, 150, 250, 130, 115, 120, 135, 180, 139, 179, 180, 300, 195, 200, 199, 140, 199, 150, 99, 400, 200, 100, 215, 160, 150, 75, 155, 95, 180, 225, 40, 137, 150, 175, 150, 70, 103, 135, 175, 181, 125, 179, 150, 102, 150, 60, 125, 75, 82, 250, 87, 148, 175, 100, 100, 240, 84, 75, 105, 220, 120, 100, 105, 175, 95, 159, 60, 114, 175, 78, 175, 109, 90, 130, 250, 329, 169, 150, 100, 250, 120, 123, 130, 140, 200, 100, 130, 123, 65, 100, 61, 195, 120, 50, 111, 110, 150, 119, 60, 75, 82, 250, 199, 90, 100, 115, 80, 135, 225, 120, 75, 200, 575, 99, 750, 150, 60, 160, 180, 119, 150, 130, 60, 200, 80, 175, 225, 120, 180, 90, 75, 250, 120, 230, 195, 185, 110, 140, 155, 350, 400, 150, 78, 120, 250, 150, 150, 89, 190, 175, 77, 100, 78, 65, 120, 120, 75, 121, 221, 250, 80, 140, 40, 200, 154, 400, 120, 60, 130, 145, 115, 125, 150, 200, 35, 125, 175, 250, 175, 175, 99, 100, 65, 170, 110, 75, 99, 79, 223, 164, 200, 50, 125, 130, 150, 75, 300, 200, 140, 150, 139, 82, 170, 150, 400, 259, 93, 90, 100, 120, 200, 110, 255, 190, 74, 145, 140, 160, 200, 129, 100, 90, 103, 180, 89, 100, 140, 41, 153, 70, 100, 148, 160, 125, 80, 101, 150, 85, 140, 100, 110, 179, 209, 139, 70, 150, 108, 110, 65, 100, 159, 120, 180, 105, 160, 160, 170, 75, 90, 125, 250, 150, 195, 160, 275, 200, 250, 250, 200, 120, 70, 189, 196, 325, 52, 300, 190, 150, 140, 75, 250, 110, 175, 250, 200, 275, 100, 250, 207, 185, 120, 190, 225, 175, 200, 152, 500, 132, 70, 120, 104, 120, 150, 175, 200, 140, 120, 280, 120, 150, 195, 240, 139, 180, 160, 140, 130, 148, 125, 200, 135, 144, 180, 150, 110, 110, 110, 140, 100, 130, 75, 160, 125, 88, 79, 150, 180, 100, 100, 200, 100, 90, 180, 150, 75, 125, 136, 280, 176, 58, 62, 135, 99, 128, 200, 150, 150, 69, 157, 280, 189, 270, 107, 175, 90, 130, 100, 250, 89, 110, 120, 90, 99, 175, 139, 110, 180, 65, 150, 75, 100, 98, 129, 75, 125, 149, 240, 500, 119, 75, 90, 250, 150, 600, 100, 125, 170, 149, 110, 140, 200, 135, 175, 155, 225, 225, 125, 150, 100, 120, 150, 150, 140, 199, 108, 99, 90, 220, 71, 200, 200, 210, 170, 100, 110, 72, 175, 195, 80, 60, 70, 135, 67, 60, 77, 155, 140, 95, 85, 69, 70, 149, 118, 200, 160, 198, 150, 98, 109, 150, 120, 105, 175, 125, 98, 128, 150, 85, 113, 145, 150, 185, 175, 200, 100, 150, 120, 100, 149, 100, 110, 128, 130, 120, 215, 125, 175, 167, 125, 155, 104, 120, 100, 150, 180, 170, 185, 139, 200, 64, 120, 185, 86, 194, 95, 209, 200, 135, 150, 70, 193, 110, 164, 75, 140, 175, 175, 100, 100, 193, 124, 170, 169, 140, 179, 120, 139, 99, 93, 190, 150, 56, 80, 150, 105, 130, 78, 89, 120, 175, 117, 110, 205, 117, 225, 143, 120, 300, 150, 149, 115, 175, 123, 140, 119, 75, 99, 151, 275, 65, 115, 60, 152, 207, 150, 150, 150, 135, 121, 140, 150, 125, 350, 160, 150, 150, 220, 250, 120, 160, 88, 150, 125, 106, 120, 350, 200, 252, 135, 120, 299, 139, 194, 156, 175, 100, 182, 240, 339, 99, 95, 550, 162, 290, 359, 260, 275, 80, 6143, 248, 209, 93, 100, 120, 230, 300, 350, 253, 130, 225, 160, 180, 120, 240, 225, 99, 220, 199, 93, 221, 184, 120, 130, 200, 250, 182, 225, 214, 175, 60, 1000, 155, 254, 130, 100, 84, 280, 195, 182, 158, 189, 90, 350, 899, 120, 170, 75, 240, 100, 200, 83, 109, 299, 83, 94, 150, 150, 214, 300, 45, 300, 94, 150, 167, 200, 180, 85, 800, 300, 164, 250, 160, 400, 167, 270, 199, 200, 180, 230, 241, 465, 144, 185, 120, 145, 125, 200, 125, 133, 325, 100, 95, 200, 100, 75, 78, 215, 150, 400, 345, 150, 152, 150, 130, 250, 77, 147, 399, 170, 180, 300, 100, 150, 150, 100, 180, 500, 140, 160, 225, 139, 210, 199, 210, 140, 200, 295, 98, 175, 160, 249, 150, 155, 130, 118, 300, 280, 450, 98, 75, 145, 117, 280, 500, 400, 275, 60, 175, 235, 92, 200, 75, 100, 250, 175, 285, 179, 150, 425, 199, 151, 200, 195, 200, 250, 170, 160, 250, 80, 175, 189, 96, 259, 200, 245, 350, 299, 200, 2350, 250, 300, 215, 800, 70, 225, 225, 197, 100, 250, 150, 230, 60, 100, 280, 550, 150, 500, 150, 599, 250, 1500, 1500, 500, 1600, 1000, 400, 180, 150, 250, 200, 180, 200, 200, 103, 2695, 150, 225, 83, 180, 100, 150, 175, 195, 300, 125, 250, 150, 140, 200, 220, 200, 400, 170, 450, 300, 500, 400, 450, 400, 149, 380, 180, 180, 239, 150, 250, 249, 195, 175, 450, 225, 120, 115, 250, 350, 124, 350, 155, 200, 150, 161, 60, 499, 100, 150, 300, 450, 130, 100, 99, 162, 101, 799, 325, 120, 120, 215, 1500, 150, 250, 800, 9999, 250, 106, 250, 200, 160, 90, 120, 120, 150, 205, 125, 150, 150, 150, 200, 250, 200, 400, 275, 250, 210, 160, 229, 200, 10000, 175, 130, 150, 160, 206, 250, 210, 150, 100, 225, 175, 200, 250, 499, 70, 180, 150, 120, 150, 175, 220, 225, 200, 150, 80, 800, 100, 240, 200, 142, 100, 250, 200, 135, 199, 115, 200, 150, 120, 125, 192, 149, 200, 150, 175, 250, 305, 175, 235, 200, 100, 125, 110, 220, 119, 175, 175, 85, 275, 100, 199, 200, 190, 166, 150, 175, 210, 180, 175, 250, 66, 69, 140, 150, 100, 225, 250, 300, 160, 450, 300, 110, 407, 310, 135, 300, 129, 170, 250, 58, 150, 257, 275, 375, 175, 100, 200, 174, 250, 200, 150, 300, 110, 175, 150, 9999, 190, 150, 93, 85, 75, 100, 158, 127, 185, 66, 300, 219, 170, 213, 160, 278, 250, 450, 130, 177, 485, 170, 243, 300, 170, 205, 300, 300, 450, 270, 250, 85, 290, 150, 235, 50, 90, 225, 120, 105, 300, 240, 150, 165, 200, 95, 180, 190, 150, 200, 190, 450, 200, 225, 200, 90, 450, 90, 145, 170, 300, 420, 160, 110, 201, 200, 195, 203, 93, 180, 200, 120, 93, 550, 295, 507, 156, 190, 175, 150, 285, 180, 120, 314, 55, 300, 200, 220, 150, 250, 280, 150, 280, 150, 200, 160, 230, 200, 2545, 195, 3200, 170, 64, 90, 375, 199, 200, 85, 300, 200, 650, 300, 200, 250, 175, 250, 180, 1000, 475, 250, 900, 900, 650, 3750, 250, 975, 180, 750, 75, 250, 150, 200, 450, 600, 180, 199, 200, 300, 300, 250, 230, 116, 200, 275, 200, 250, 275, 120, 210, 599, 165, 200, 150, 200, 135, 228, 175, 60, 500, 150, 230, 295, 210, 95, 350, 200, 450, 299, 100, 290, 125, 135, 130, 450, 197, 55, 125, 250, 102, 110, 325, 149, 200, 170, 168, 200, 175, 119, 111, 200, 300, 400, 350, 125, 121, 350, 96, 99, 250, 100, 250, 300, 150, 130, 250, 305, 400, 93, 175, 120, 140, 150, 99, 145, 120, 125, 89, 150, 115, 40, 300, 60, 180, 176, 130, 120, 85, 250, 140, 83, 375, 275, 195, 100, 160, 250, 1550, 250, 75, 179, 120, 240, 6000, 180, 225, 100, 225, 239, 125, 120, 180, 200, 350, 140, 100, 130, 250, 139, 125, 105, 200, 90, 250, 168, 186, 160, 200, 450, 250, 95, 188, 150, 150, 140, 275, 210, 185, 97, 115, 105, 120, 129, 140, 120, 199, 110, 250, 100, 140, 165, 188, 150, 299, 180, 210, 165, 99, 175, 100, 225, 260, 207, 119, 175, 130, 300, 250, 100, 58, 100, 175, 93, 170, 70, 210, 105, 115, 150, 106, 180, 275, 170, 99, 140, 240, 200, 118, 150, 850, 80, 190, 225, 119, 295, 100, 120, 150, 112, 165, 220, 97, 265, 160, 199, 155, 178, 115, 112, 99, 100, 379, 99, 216, 114, 125, 150, 149, 150, 250, 150, 225, 180, 225, 125, 200, 169, 100, 250, 205, 68, 180, 245, 117, 200, 100, 150, 160, 250, 175, 100, 150, 75, 97, 179, 129, 50, 159, 365, 175, 90, 125, 100, 150, 225, 125, 149, 170, 300, 300, 140, 129, 120, 80, 125, 100, 100, 199, 200, 300, 70, 150, 230, 100, 210, 100, 325, 200, 150, 100, 110, 500, 300, 220, 100, 165, 200, 100, 104, 150, 80, 380, 100, 400, 250, 200, 135, 150, 218, 150, 230, 179, 110, 127, 50, 90, 115, 190, 85, 200, 149, 295, 191, 239, 75, 168, 195, 120, 50, 100, 159, 200, 97, 150, 100, 135, 80, 93, 99, 120, 399, 450, 250, 150, 150, 200, 100, 190, 220, 165, 280, 230, 249, 100, 140, 185, 66, 130, 285, 180, 199, 100, 179, 180, 200, 115, 300, 275, 125, 100, 175, 195, 160, 105, 106, 120, 257, 114, 159, 85, 225, 6429, 60, 175, 153, 75, 51, 80, 100, 197, 246, 85, 65, 150, 132, 150, 130, 245, 560, 156, 80, 800, 165, 160, 110, 95, 125, 220, 350, 150, 160, 140, 130, 120, 800, 275, 135, 190, 135, 215, 70, 250, 99, 200, 160, 1200, 139, 400, 250, 100, 200, 55, 160, 215, 85, 120, 150, 150, 200, 110, 125, 125, 89, 125, 165, 700, 80, 62, 250, 70, 99, 242, 200, 99, 190, 125, 150, 110, 150, 65, 69, 150, 100, 900, 179, 100, 160, 125, 86, 200, 139, 100, 199, 348, 200, 100, 172, 150, 255, 137, 150, 132, 130, 100, 125, 100, 105, 115, 220, 60, 105, 139, 110, 150, 200, 310, 100, 110, 160, 225, 75, 100, 225, 150, 130, 145, 225, 110, 119, 110, 97, 175, 75, 179, 350, 175, 200, 165, 190, 122, 115, 150, 90, 199, 198, 80, 120, 85, 110, 119, 160, 130, 80, 228, 89, 125, 100, 100, 125, 140, 120, 100, 175, 125, 300, 150, 150, 175, 140, 105, 150, 150, 289, 250, 150, 140, 139, 162, 155, 149, 100, 100, 100, 89, 150, 39, 149, 200, 117, 100, 75, 120, 120, 98, 110, 121, 180, 168, 135, 63, 349, 199, 175, 115, 75, 90, 52, 100, 160, 180, 200, 150, 210, 170, 200, 103, 134, 95, 68, 100, 150, 235, 1139, 109, 70, 250, 150, 158, 130, 95, 124, 195, 80, 80, 235, 95, 150, 70, 250, 135, 167, 110, 100, 150, 400, 60, 225, 150, 150, 250, 1400, 115, 325, 200, 99, 214, 300, 1763, 149, 115, 95, 100, 220, 121, 100, 92, 70, 150, 150, 125, 130, 300, 150, 125, 60, 130, 214, 171, 325, 120, 114, 300, 89, 107, 2100, 75, 160, 350, 500, 80, 90, 228, 100, 120, 140, 128, 195, 250, 117, 76, 189, 150, 195, 250, 120, 150, 130, 350, 115, 155, 75, 70, 170, 130, 115, 90, 161, 85, 95, 100, 150, 195, 255, 200, 180, 124, 200, 112, 100, 120, 143, 200, 250, 185, 102, 350, 185, 169, 135, 245, 80, 150, 110, 129, 150, 214, 130, 115, 110, 109, 99, 106, 105, 100, 85, 199, 190, 110, 74, 120, 99, 125, 139, 150, 225, 250, 135, 248, 50, 70, 148, 85, 529, 175, 85, 143, 200, 70, 209, 239, 240, 100, 189, 185, 150, 172, 200, 140, 85, 200, 100, 169, 90, 214, 169, 150, 175, 80, 199, 99, 115, 149, 90, 80, 175, 109, 125, 195, 175, 125, 91, 150, 96, 210, 109, 210, 100, 55, 267, 150, 149, 150, 99, 120, 99, 65, 89, 95, 74, 95, 195, 81, 275, 200, 200, 110, 110, 200, 100, 133, 90, 168, 105, 60, 125, 180, 225, 140, 250, 83, 170, 125, 175, 175, 130, 130, 300, 100, 210, 198, 132, 325, 99, 190, 150, 150, 85, 176, 99, 195, 163, 200, 199, 85, 130, 225, 200, 170, 165, 120, 100, 190, 120, 75, 143, 83, 200, 100, 90, 150, 250, 50, 269, 67, 110, 250, 180, 110, 189, 170, 158, 225, 200, 190, 90, 125, 150, 160, 150, 95, 1000, 800, 250, 100, 1000, 350, 350, 275, 275, 215, 200, 350, 250, 200, 249, 150, 120, 105, 167, 350, 350, 225, 170, 150, 200, 250, 200, 200, 189, 189, 100, 500, 120, 150, 169, 175, 150, 125, 75, 160, 110, 300, 175, 350, 95, 400, 150, 238, 98, 247, 100, 170, 200, 130, 206, 275, 200, 175, 170, 180, 100, 95, 65, 200, 179, 150, 120, 375, 225, 125, 130, 150, 75, 300, 75, 175, 450, 250, 250, 250, 216, 110, 199, 250, 139, 235, 950, 750, 250, 450, 125, 125, 240, 199, 170, 132, 190, 200, 150, 180, 125, 160, 100, 84, 103, 200, 180, 175, 150, 450, 190, 95, 125, 85, 130, 200, 200, 150, 120, 229, 100, 149, 126, 70, 115, 200, 89, 200, 300, 120, 150, 199, 50, 140, 275, 90, 250, 120, 200, 300, 130, 87, 100, 140, 199, 300, 100, 250, 150, 150, 30, 175, 80, 180, 200, 170, 130, 90, 110, 85, 139, 110, 28, 69, 140, 150, 115, 100, 46, 75, 160, 192, 120, 140, 90, 110, 600, 125, 125, 200, 89, 120, 190, 85, 80, 165, 120, 100, 95, 70, 125, 180, 150, 65, 90, 80, 75, 150, 75, 99, 75, 165, 125, 70, 133, 199, 45, 200, 90, 200, 75, 130, 120, 225, 121, 109, 200, 180, 250, 155, 150, 120, 125, 59, 150, 130, 200, 180, 200, 250, 850, 1500, 179, 250, 350, 314, 205, 140, 125, 225, 450, 100, 120, 85, 150, 200, 150, 175, 300, 200, 160, 250, 300, 150, 150, 200, 125, 275, 225, 99, 250, 200, 195, 92, 300, 264, 389, 150, 150, 150, 2000, 150, 300, 180, 575, 160, 200, 300, 400, 749, 300, 350, 200, 150, 175, 260, 270, 350, 75, 350, 125, 180, 250, 175, 250, 150, 400, 150, 295, 429, 212, 130, 95, 125, 155, 107, 329, 150, 150, 100, 260, 250, 89, 149, 110, 200, 89, 149, 180, 154, 100, 124, 132, 118, 220, 225, 249, 180, 200, 140, 85, 80, 137, 180, 207, 200, 250, 125, 200, 160, 94, 200, 220, 120, 195, 75, 195, 325, 100, 120, 240, 199, 200, 165, 200, 225, 250, 120, 125, 120, 150, 150, 156, 190, 189, 115, 70, 130, 80, 85, 154, 130, 214, 110, 133, 106, 280, 88, 259, 110, 100, 95, 130, 150, 109, 175, 73, 150, 200, 100, 95, 76, 189, 150, 125, 400, 99, 100, 190, 162, 83, 125, 75, 150, 160, 100, 120, 100, 166, 70, 135, 90, 499, 170, 125, 100, 95, 160, 125, 120, 100, 450, 100, 196, 110, 240, 150, 75, 180, 150, 100, 120, 75, 120, 50, 138, 129, 130, 125, 110, 100, 200, 180, 250, 150, 138, 60, 175, 115, 200, 250, 109, 104, 150, 110, 149, 115, 150, 100, 116, 120, 105, 150, 175, 260, 70, 220, 150, 98, 99, 150, 175, 199, 115, 115, 130, 150, 200, 75, 100, 175, 139, 150, 400, 149, 128, 88, 200, 225, 140, 150, 125, 125, 50, 280, 130, 100, 135, 77, 170, 61, 80, 200, 115, 75, 79, 145, 115, 160, 175, 150, 180, 188, 155, 150, 193, 175, 125, 160, 160, 110, 100, 254, 120, 125, 285, 140, 55, 165, 320, 150, 120, 170, 140, 175, 140, 103, 165, 149, 98, 150, 200, 130, 125, 150, 100, 159, 290, 80, 170, 175, 115, 160, 92, 120, 108, 250, 180, 100, 80, 105, 160, 150, 189, 90, 150, 135, 120, 100, 75, 150, 100, 55, 119, 95, 139, 225, 195, 90, 156, 70, 100, 264, 104, 130, 120, 83, 75, 229, 100, 230, 139, 65, 100, 144, 120, 104, 135, 100, 225, 99, 150, 99, 115, 96, 120, 115, 75, 137, 120, 500, 155, 190, 100, 80, 77, 105, 148, 200, 95, 100, 66, 105, 160, 225, 210, 425, 160, 160, 200, 148, 120, 175, 140, 263, 175, 100, 210, 150, 126, 137, 200, 94, 202, 199, 140, 149, 150, 99, 149, 145, 257, 185, 120, 175, 120, 179, 149, 120, 399, 90, 180, 150, 190, 110, 275, 199, 90, 48, 225, 225, 90, 160, 180, 160, 137, 120, 196, 163, 140, 140, 250, 169, 120, 145, 180, 135, 185, 275, 175, 110, 200, 109, 129, 140, 80, 99, 120, 200, 75, 110, 163, 85, 99, 90, 165, 349, 200, 128, 75, 125, 179, 200, 150, 128, 98, 115, 190, 130, 150, 105, 225, 140, 106, 236, 110, 175, 85, 295, 175, 180, 160, 150, 199, 175, 115, 200, 234, 120, 129, 230, 120, 145, 219, 325, 140, 139, 85, 200, 115, 105, 230, 120, 119, 215, 250, 125, 145, 120, 125, 115, 85, 120, 110, 160, 130, 105, 121, 291, 125, 129, 173, 200, 150, 125, 185, 220, 185, 100, 175, 125, 145, 200, 225, 171, 88, 115, 99, 225, 150, 150, 179, 195, 250, 150, 75, 75, 160, 135, 115, 154, 130, 100, 151, 225, 139, 130, 150, 325, 120, 185, 145, 70, 124, 99, 93, 100, 42, 200, 75, 240, 120, 175, 95, 95, 163, 125, 105, 148, 105, 100, 90, 180, 219, 129, 179, 149, 150, 220, 160, 115, 105, 110, 92, 130, 190, 179, 50, 100, 88, 150, 106, 93, 115, 175, 80, 100, 115, 200, 123, 140, 290, 95, 78, 99, 80, 125, 150, 50, 85, 131, 300, 132, 125, 98, 94, 100, 128, 120, 100, 180, 149, 180, 120, 120, 136, 170, 229, 121, 120, 100, 93, 135, 75, 144, 96, 160, 95, 125, 150, 250, 170, 100, 250, 225, 146, 170, 95, 75, 96, 120, 130, 130, 130, 200, 225, 100, 290, 139, 200, 250, 190, 142, 281, 170, 162, 225, 200, 99, 185, 170, 150, 150, 200, 99, 200, 321, 175, 120, 201, 130, 304, 80, 120, 188, 178, 175, 199, 225, 90, 160, 95, 128, 120, 168, 69, 144, 175, 125, 220, 95, 80, 75, 180, 60, 80, 150, 175, 150, 175, 135, 105, 130, 60, 90, 200, 175, 175, 200, 119, 250, 109, 135, 100, 209, 82, 230, 199, 195, 125, 180, 130, 385, 150, 280, 175, 250, 75, 100, 89, 150, 180, 200, 90, 250, 190, 140, 95, 236, 249, 250, 70, 70, 70, 269, 153, 200, 200, 150, 92, 150, 95, 200, 44, 150, 70, 232, 135, 265, 179, 907, 50, 219, 199, 190, 165, 80, 150, 80, 180, 215, 199, 200, 225, 95, 250, 100, 175, 175, 198, 130, 150, 400, 100, 140, 200, 110, 175, 130, 250, 175, 145, 280, 199, 200, 175, 185, 80, 150, 150, 180, 240, 190, 200, 110, 207, 149, 110, 114, 95, 85, 140, 175, 110, 95, 210, 170, 115, 150, 160, 130, 175, 125, 400, 125, 150, 95, 300, 189, 199, 230, 236, 100, 300, 76, 200, 100, 185, 150, 140, 195, 125, 159, 139, 140, 185, 275, 75, 150, 195, 55, 250, 250, 200, 150, 168, 145, 160, 257, 250, 150, 200, 225, 115, 180, 120, 155, 200, 165, 70, 199, 110, 125, 250, 190, 175, 125, 180, 100, 169, 130, 95, 150, 215, 165, 220, 215, 185, 175, 175, 149, 250, 125, 100, 110, 179, 115, 127, 80, 115, 250, 123, 150, 211, 175, 150, 110, 160, 120, 145, 200, 196, 175, 85, 150, 200, 160, 165, 90, 100, 115, 150, 175, 210, 150, 202, 100, 150, 106, 135, 111, 165, 200, 149, 143, 175, 195, 150, 110, 90, 225, 225, 170, 180, 175, 330, 140, 130, 289, 150, 150, 140, 140, 130, 210, 249, 160, 150, 250, 150, 125, 135, 175, 120, 150, 110, 179, 85, 120, 125, 245, 199, 200, 100, 120, 375, 109, 95, 110, 100, 135, 88, 130, 105, 125, 175, 110, 81, 140, 119, 100, 72, 200, 157, 149, 99, 70, 102, 115, 81, 225, 325, 99, 163, 95, 135, 275, 103, 100, 90, 210, 215, 100, 119, 90, 176, 500, 150, 63, 250, 90, 53, 52, 63, 115, 520, 102, 125, 100, 105, 357, 190, 400, 95, 124, 111, 110, 145, 90, 172, 95, 125, 90, 70, 275, 58, 150, 56, 108, 145, 150, 115, 92, 170, 81, 135, 200, 81, 63, 80, 287, 66, 157, 115, 75, 99, 325, 140, 285, 149, 205, 74, 55, 99, 78, 74, 98, 75, 117, 90, 131, 110, 150, 140, 119, 127, 75, 165, 100, 105, 155, 223, 65, 99, 138, 290, 95, 170, 100, 126, 150, 60, 200, 135, 80, 140, 90, 300, 72, 75, 91, 82, 120, 79, 90, 175, 350, 125, 150, 139, 250, 130, 175, 135, 69, 100, 275, 75, 120, 286, 100, 100, 108, 129, 370, 100, 150, 100, 69, 109, 140, 99, 170, 199, 185, 225, 93, 95, 454, 100, 190, 250, 350, 92, 185, 118, 126, 66, 150, 149, 95, 258, 165, 733, 135, 179, 85, 74, 190, 129, 180, 130, 99, 130, 245, 80, 128, 200, 90, 180, 175, 1599, 119, 365, 115, 110, 95, 155, 129, 170, 90, 64, 145, 298, 350, 180, 112, 300, 360, 80, 349, 196, 189, 100, 70, 185, 94, 75, 100, 140, 110, 175, 79, 110, 150, 150, 96, 89, 190, 60, 70, 111, 72, 190, 134, 140, 275, 144, 150, 110, 200, 155, 150, 50, 72, 91, 107, 62, 101, 78, 111, 215, 135, 85, 119, 250, 175, 145, 145, 110, 115, 269, 125, 105, 100, 103, 77, 205, 88, 92, 190, 139, 105, 239, 150, 95, 199, 85, 80, 311, 200, 225, 69, 70, 148, 194, 66, 215, 95, 295, 118, 100, 99, 320, 42, 130, 150, 80, 124, 125, 100, 99, 250, 180, 250, 80, 109, 126, 120, 60, 100, 115, 259, 95, 185, 175, 135, 159, 314, 147, 250, 150, 150, 500, 250, 115, 115, 85, 60, 85, 140, 140, 120, 150, 90, 700, 175, 150, 129, 65, 150, 110, 76, 189, 135, 118, 82, 390, 200, 375, 162, 215, 95, 101, 85, 125, 120, 128, 115, 350, 84, 129, 83, 144, 750, 300, 85, 85, 85, 114, 119, 155, 80, 110, 150, 120, 206, 164, 135, 75, 80, 180, 52, 110, 75, 200, 169, 106, 70, 143, 100, 188, 80, 125, 125, 95, 225, 210, 110, 90, 60, 200, 154, 299, 79, 99, 231, 111, 120, 95, 300, 119, 175, 140, 175, 104, 179, 80, 73, 77, 250, 225, 70, 100, 80, 133, 100, 96, 83, 812, 108, 78, 106, 111, 90, 88, 60, 150, 127, 75, 200, 300, 105, 100, 112, 105, 74, 195, 99, 199, 70, 135, 150, 89, 199, 180, 120, 169, 76, 82, 155, 225, 125, 188, 129, 75, 95, 54, 120, 72, 65, 86, 56, 125, 85, 68, 127, 70, 130, 125, 124, 200, 125, 85, 70, 80, 90, 150, 98, 346, 250, 90, 126, 90, 171, 100, 75, 130, 528, 140, 110, 60, 133, 145, 200, 80, 200, 148, 69, 115, 165, 340, 175, 110, 150, 179, 105, 231, 167, 101, 70, 186, 191, 100, 149, 112, 322, 90, 135, 150, 101, 99, 65, 110, 57, 115, 183, 100, 81, 125, 79, 70, 107, 84, 130, 150, 97, 128, 135, 120, 285, 70, 204, 139, 190, 220, 130, 140, 189, 86, 125, 250, 115, 92, 130, 89, 99, 495, 95, 171, 499, 100, 125, 150, 179, 204, 201, 181, 200, 160, 244, 190, 250, 75, 70, 507, 250, 150, 185, 170, 155, 137, 90, 482, 139, 139, 120, 105, 135, 180, 75, 153, 85, 90, 213, 199, 350, 123, 58, 149, 249, 166, 130, 135, 243, 263, 225, 249, 85, 185, 99, 89, 195, 74, 84, 220, 110, 200, 98, 126, 109, 65, 69, 126, 99, 110, 135, 70, 199, 100, 99, 65, 169, 91, 125, 80, 214, 230, 119, 135, 105, 140, 200, 225, 129, 90, 110, 225, 199, 175, 175, 170, 265, 200, 100, 159, 99, 80, 450, 250, 109, 106, 225, 185, 185, 166, 121, 250, 189, 106, 150, 69, 85, 210, 700, 135, 111, 246, 120, 175, 100, 200, 130, 198, 100, 75, 187, 200, 126, 130, 238, 186, 160, 207, 95, 155, 115, 165, 150, 155, 140, 229, 82, 500, 115, 84, 110, 85, 92, 100, 115, 100, 79, 120, 78, 100, 79, 100, 65, 120, 75, 282, 135, 150, 127, 250, 95, 221, 71, 100, 100, 146, 109, 179, 191, 85, 90, 100, 150, 200, 100, 130, 175, 118, 85, 66, 110, 500, 120, 300, 99, 133, 182, 80, 85, 70, 130, 129, 100, 255, 111, 134, 80, 298, 130, 125, 95, 170, 199, 70, 150, 125, 110, 115, 150, 90, 135, 99, 95, 90, 200, 100, 135, 239, 50, 200, 100, 100, 175, 165, 100, 138, 100, 75, 185, 135, 165, 125, 134, 111, 85, 70, 179, 200, 99, 139, 175, 99, 150, 499, 69, 56, 300, 3000, 124, 49, 83, 100, 75, 150, 100, 100, 100, 127, 75, 115, 100, 100, 166, 120, 100, 155, 115, 135, 66, 85, 115, 119, 215, 80, 53, 100, 75, 51, 339, 199, 200, 175, 129, 585, 135, 120, 245, 321, 125, 121, 150, 100, 184, 870, 870, 190, 112, 214, 90, 211, 180, 160, 325, 200, 450, 165, 425, 250, 100, 390, 120, 120, 1225, 300, 160, 160, 85, 2200, 1000, 600, 100, 175, 279, 104, 300, 175, 155, 150, 239, 450, 85, 125, 280, 150, 110, 90, 200, 240, 152, 156, 102, 160, 250, 236, 299, 214, 111, 254, 650, 85, 150, 364, 90, 165, 110, 194, 225, 500, 150, 120, 120, 200, 250, 320, 100, 166, 195, 117, 199, 129, 180, 295, 185, 135, 89, 179, 100, 134, 85, 119, 150, 105, 186, 150, 100, 98, 250, 300, 300, 300, 290, 220, 210, 248, 119, 99, 215, 239, 120, 130, 120, 165, 220, 65, 249, 175, 150, 200, 179, 150, 300, 250, 214, 77, 160, 67, 130, 150, 143, 220, 109, 78, 65, 225, 195, 109, 85, 115, 120, 110, 115, 150, 200, 86, 487, 90, 85, 199, 200, 108, 80, 450, 99, 60, 169, 115, 175, 101, 110, 82, 185, 130, 120, 80, 400, 72, 161, 120, 191, 150, 100, 190, 100, 123, 103, 178, 94, 75, 70, 90, 150, 100, 60, 250, 175, 200, 400, 71, 60, 185, 190, 200, 99, 195, 107, 130, 110, 99, 120, 100, 135, 149, 79, 119, 115, 74, 73, 175, 130, 200, 59, 175, 135, 180, 100, 120, 89, 139, 91, 90, 81, 52, 275, 150, 86, 110, 120, 205, 200, 166, 140, 180, 90, 170, 148, 156, 90, 140, 124, 111, 100, 55, 165, 115, 200, 84, 90, 70, 80, 200, 81, 80, 80, 100, 250, 330, 225, 180, 150, 200, 300, 550, 200, 160, 186, 108, 122, 108, 175, 60, 142, 176, 90, 148, 264, 180, 143, 129, 50, 135, 160, 100, 85, 196, 143, 81, 125, 160, 170, 206, 180, 150, 140, 89, 83, 85, 125, 174, 120, 87, 220, 175, 100, 200, 110, 180, 99, 135, 55, 147, 90, 69, 145, 208, 114, 249, 200, 97, 61, 85, 125, 164, 50, 500, 251, 200, 90, 179, 162, 55, 80, 125, 60, 48, 100, 741, 169, 159, 159, 70, 75, 95, 120, 115, 99, 50, 100, 79, 91, 280, 101, 45, 129, 99, 85, 115, 110, 125, 199, 159, 139, 85, 125, 89, 101, 79, 99, 150, 45, 215, 120, 100, 279, 140, 165, 135, 120, 97, 130, 390, 115, 130, 134, 390, 487, 95, 120, 73, 225, 168, 110, 51, 150, 1850, 169, 95, 89, 125, 250, 91, 81, 79, 165, 170, 175, 236, 62, 400, 245, 98, 65, 399, 68, 119, 150, 83, 76, 45, 62, 340, 450, 149, 450, 350, 450, 52, 160, 206, 185, 120, 200, 95, 199, 272, 39, 169, 232, 120, 87, 136, 130, 200, 77, 487, 175, 200, 169, 195, 153, 200, 129, 58, 80, 70, 115, 100, 1200, 75, 180, 100, 164, 110, 114, 389, 235, 125, 266, 210, 185, 101, 195, 199, 150, 100, 68, 110, 333, 219, 487, 159, 459, 325, 150, 210, 375, 119, 95, 314, 67, 65, 159, 75, 149, 76, 125, 194, 115, 75, 92, 70, 110, 390, 241, 76, 185, 60, 125, 150, 133, 239, 159, 169, 190, 120, 100, 129, 110, 105, 95, 129, 99, 435, 110, 100, 86, 125, 185, 133, 200, 250, 140, 145, 85, 199, 99, 80, 150, 89, 130, 124, 89, 195, 128, 75, 80, 135, 90, 195, 75, 140, 99, 120, 150, 155, 250, 99, 225, 95, 130, 399, 169, 115, 95, 118, 185, 150, 125, 120, 195, 147, 81, 65, 245, 58, 139, 115, 159, 250, 165, 245, 240, 250, 157, 175, 74, 115, 100, 130, 108, 150, 61, 85, 92, 150, 219, 80, 170, 75, 75, 350, 125, 119, 65, 599, 100, 59, 175, 1200, 85, 80, 160, 741, 119, 159, 169, 499, 119, 100, 125, 107, 165, 163, 70, 185, 120, 135, 68, 99, 499, 189, 900, 100, 79, 1000, 78, 600, 83, 250, 100, 150, 105, 950, 185, 250, 125, 135, 179, 169, 150, 100, 185, 214, 104, 56, 62, 549, 500, 109, 250, 275, 89, 90, 90, 69, 143, 115, 95, 120, 135, 219, 159, 78, 110, 70, 160, 149, 111, 115, 96, 99, 99, 275, 59, 81, 110, 88, 79, 63, 86, 150, 220, 120, 76, 130, 79, 100, 105, 1170, 1100, 220, 174, 178, 115, 75, 115, 242, 248, 433, 150, 100, 6500, 139, 56, 120, 527, 100, 150, 683, 1099, 809, 132, 300, 112, 101, 75, 100, 270, 200, 190, 219, 137, 90, 100, 85, 95, 125, 125, 87, 89, 87, 115, 99, 105, 109, 119, 125, 129, 139, 135, 100, 140, 200, 80, 74, 172, 299, 249, 299, 249, 230, 280, 150, 120, 100, 260, 2999, 519, 140, 195, 250, 200, 120, 130, 130, 125, 125, 175, 175, 120, 100, 145, 155, 146, 100, 99, 110, 145, 135, 230, 125, 300, 145, 115, 270, 85, 85, 195, 195, 110, 100, 100, 110, 130, 115, 105, 174, 190, 200, 110, 100, 110, 135, 100, 125, 125, 125, 125, 135, 110, 100, 155, 135, 125, 120, 250, 120, 193, 150, 95, 100, 75, 389, 403, 383, 348, 369, 354, 150, 102, 100, 185, 55, 150, 97, 60, 348, 348, 431, 324, 465, 180, 180, 59, 175, 150, 65, 250, 180, 75, 69, 85, 130, 69, 129, 68, 65, 85, 70, 68, 70, 218, 160, 99, 99, 97, 178, 104, 140, 60, 120, 75, 106, 135, 120, 105, 180, 180, 315, 140, 999, 100, 120, 180, 150, 150, 150, 160, 190, 90, 75, 98, 83, 71, 110, 98, 90, 100, 359, 225, 359, 279, 165, 129, 289, 1100, 921, 247, 225, 359, 135, 359, 145, 149, 145, 149, 145, 289, 129, 145, 289, 149, 149, 149, 149, 149, 149, 149, 129, 129, 129, 129, 129, 149, 149, 149, 225, 225, 219, 219, 199, 249, 145, 179, 225, 225, 225, 225, 225, 359, 359, 359, 219, 145, 149, 247, 249, 165, 84, 95, 99, 105, 109, 115, 119, 125, 135, 250, 310, 310, 330, 335, 259, 219, 219, 239, 159, 309, 989, 219, 279, 529, 169, 169, 529, 650, 265, 126, 126, 126, 126, 126, 126, 180, 180, 139, 269, 149, 159, 189, 200, 79, 250, 179, 80, 89, 500, 348, 125, 471, 328, 383, 348, 348, 433, 328, 700, 125, 79, 101, 84, 240, 69, 213, 105, 261, 119, 119, 189, 200, 549, 193, 375, 314, 328, 206, 202, 234, 169, 209, 150, 249, 249, 145, 201, 110, 80, 150, 70, 80, 105, 155, 150, 189, 179, 154, 199, 159, 86, 58, 70, 190, 126, 299, 79, 99, 76, 85, 75, 130, 140, 69, 89, 68, 137, 75, 183, 189, 75, 195, 125, 130, 350, 230, 110, 100, 105, 250, 89, 115, 210, 59, 109, 180, 76, 220, 70, 170, 165, 99, 120, 75, 200, 200, 140, 140, 70, 150, 120, 115, 413, 389, 399, 359, 380, 60, 130, 178, 140, 115, 135, 83, 85, 100, 643, 346, 83, 199, 79, 81, 130, 85, 89, 145, 870, 149, 159, 260, 150, 200, 120, 150, 175, 250, 149, 135, 60, 90, 120, 70, 185, 100, 275, 199, 220, 110, 135, 200, 80, 175, 189, 250, 225, 68, 190, 125, 85, 185, 100, 295, 275, 180, 170, 180, 142, 300, 64, 135, 127, 150, 80, 80, 135, 75, 59, 159, 120, 150, 120, 103, 96, 125, 110, 103, 139, 357, 293, 250, 200, 150, 75, 100, 113, 400, 123, 120, 56, 90, 56, 56, 79, 90, 296, 524, 300, 100, 250, 245, 53, 150, 90, 126, 115, 108, 129, 196, 114, 125, 120, 120, 70, 105, 239, 135, 50, 643, 386, 111, 110, 91, 140, 102, 125, 80, 85, 90, 250, 75, 90, 109, 500, 120, 300, 250, 96, 220, 125, 299, 125, 80, 99, 250, 85, 60, 99, 67, 1054, 85, 114, 67, 64, 59, 67, 67, 99, 250, 255, 75, 150, 146, 500, 330, 430, 390, 304, 136, 116, 150, 90, 540, 500, 188, 522, 98, 110, 63, 85, 52, 499, 111, 90, 110, 85, 150, 169, 85, 185, 61, 100, 309, 63, 300, 52, 116, 2596, 125, 52, 400, 350, 116, 325, 415, 130, 67, 81, 220, 120, 112, 226, 150, 120, 92, 77, 130, 180, 292, 75, 85, 119, 75, 85, 94, 250, 100, 180, 70, 105, 254, 320, 106, 360, 170, 140, 300, 399, 80, 220, 240, 250, 350, 275, 500, 99, 105, 135, 300, 150, 150, 70, 269, 206, 275, 170, 120, 155, 55, 259, 240, 304, 147, 100, 190, 170, 50, 120, 87, 120, 120, 250, 149, 109, 195, 120, 314, 160, 160, 150, 140, 258, 115, 299, 150, 250, 125, 79, 80, 297, 210, 270, 120, 92, 150, 66, 179, 179, 120, 140, 240, 120, 99, 190, 250, 90, 150, 102, 104, 135, 120, 150, 115, 150, 100, 110, 191, 85, 79, 150, 250, 139, 99, 90, 208, 46, 207, 89, 109, 155, 83, 401, 71, 200, 130, 75, 70, 99, 349, 1000, 85, 135, 120, 100, 175, 247, 187, 500, 95, 275, 371, 120, 120, 250, 94, 599, 250, 200, 99, 157, 81, 200, 150, 127, 150, 70, 200, 140, 145, 208, 110, 85, 100, 325, 250, 100, 179, 305, 85, 215, 110, 110, 85, 150, 90, 99, 147, 257, 139, 410, 229, 150, 144, 88, 285, 260, 160, 190, 128, 150, 109, 210, 150, 204, 190, 180, 95, 110, 143, 174, 240, 275, 194, 450, 380, 150, 150, 110, 350, 350, 295, 232, 176, 967, 552, 249, 160, 135, 134, 135, 199, 200, 388, 329, 155, 650, 514, 125, 146, 50, 90, 80, 90, 167, 244, 175, 151, 100, 110, 95, 179, 140, 200, 79, 110, 122, 55, 115, 146, 163, 302, 385, 599, 399, 164, 369, 249, 550, 150, 255, 503, 180, 85, 750, 269, 664, 205, 200, 115, 289, 150, 151, 148, 149, 85, 490, 190, 219, 407, 135, 200, 175, 75, 86, 250, 85, 65, 90, 150, 270, 285, 375, 250, 350, 224, 150, 140, 90, 150, 128, 195, 100, 100, 175, 75, 149, 89, 222, 125, 149, 120, 130, 160, 100, 208, 180, 205, 215, 130, 250, 80, 450, 100, 105, 70, 150, 200, 125, 80, 101, 102, 90, 175, 100, 187, 290, 388, 204, 54, 125, 159, 269, 267, 250, 167, 115, 80, 111, 59, 190, 922, 100, 150, 165, 90, 175, 85, 100, 175, 110, 140, 195, 145, 116, 199, 250, 110, 90, 300, 250, 120, 289, 200, 46, 218, 189, 90, 80, 70, 145, 70, 80, 70, 70, 70, 115, 95, 70, 95, 70, 95, 95, 70, 70, 75, 70, 95, 95, 119, 70, 70, 95, 70, 79, 195, 551, 130, 150, 800, 150, 398, 130, 130, 297, 110, 98, 285, 196, 85, 1","[1, 1, 1, 1, 1]",,,,
What are the 4 highest unique number of bedrooms listed?,What are the top 4 unique bedroom counts from the Airbnbs dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Get the unique bedroom counts and sort them in descending order
    unique_bedrooms = dataset['bedrooms'].unique()
    sorted_bedrooms = sorted(unique_bedrooms, reverse=True)
    
    # Get the top 4 unique bedroom counts
    top_4_bedrooms = sorted_bedrooms[:4]
    
    return list(top_4_bedrooms)
",list of (int64),"[np.float64(nan), np.float64(21.0), np.float64(14.0), np.float64(13.0)]","[21, 14, 13, 11]",,,,
What are the 6 lowest review scores given because of locations?,What are the six lowest review scores for locations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by review_scores_location in ascending order
    sorted_dataset = dataset.sort_values(by='review_scores_location')
    
    # Get the six lowest review scores for locations
    lowest_review_scores = sorted_dataset['review_scores_location'].head(6).tolist()
    
    return lowest_review_scores
",list of (float64),"[2.0, 2.0, 2.0, 2.0, 2.0, 2.0]","[2, 2, 2, 2, 2, 2]",,,,
Was there a day when the minimum temperature was below zero and it didn't rain?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there is any record with a specific condition
    # For example, let's assume the question is ""Is there any record where tmax is greater than 30?""
    # This is just an example, replace it with the actual question logic
    has_record = dataset['tmax'] > 30.0
    return has_record.any()",bool,True,True,,,,
Are there records where the solar radiation exceeds 10 but the maximum temperature was below 20?,Are there any records in the dataset where solar radiation is greater than 10 and maximum temperature is less than 20?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_records = dataset[(dataset[""sol""] > 10) & (dataset[""tmax""] < 20)].shape[0] > 0

return has_records",bool,True,True,,,,
Did any day with maximum wind speed above 15 also have average wind speed below 5?,Is there any day where the maximum wind speed exceeds 15 and the average wind speed is less than 5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    condition = (dataset[""racha""] > 15) & (dataset[""velmedia""] < 5)
    result = condition.any()

    return result
",bool,True,True,,,,
Were there days in the summer where the minimum temperature dropped below 10?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any records with missing values in the dataset
    has_missing_values = dataset.isnull().values.any()
    
    return has_missing_values",bool,True,True,,,,
How many days had a maximum temperature above 30 degrees?,How many days had a maximum temperature above 30 degrees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    days_above_30 = dataset[dataset['tmax'] > 30]
    return len(days_above_30)
",int64,5500,5500,,,,
"On average, what's the minimum temperature during winters?",What is the average minimum temperature recorded during winter seasons?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    winter_temperatures = dataset.loc[dataset[""season""] == ""winter"", ""tmin""]
    average_min_temp = winter_temperatures.mean()

    return average_min_temp
",float64  ,,2.7196080000000000,,,,
How many unique days had solar radiation measurements?,How many distinct days are there in the dataset with solar radiation measurements?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_days = dataset['fecha'].dt.date.nunique()
    
    return distinct_days
",int64,36858,28615,,,,
What's the highest wind speed ever recorded?,What is the maximum wind speed that has been recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_wind_speed = dataset[""racha""].max()
return max_wind_speed
",float64,32.2,32.2,,,,
On which weekday did the highest temperature ever occur?,What is the name of the weekday when the highest temperature was recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_temp_record = dataset.loc[dataset[""tmax""] == dataset[""tmax""].max()]
    weekday_name = max_temp_record[""weekday_name""].iloc[0]

    return weekday_name
",string  ,Friday,Friday,,,,
In which season do we find the highest average solar radiation?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a specific category value from the dataset
# For example, let's assume the question is ""What is the most common season in the dataset?""

# Find the mode of the 'season' column to get the most common season
most_common_season = dataset['season'].mode()[0]

return most_common_season",category,Summer,Summer,,,,
Which month had the lowest average wind speed?,Which month experienced the lowest average wind speed?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Calculate the average wind speed for each month
    avg_wind_speed = dataset.groupby('month_name')['velmedia'].mean()
    
    # Find the month with the lowest average wind speed
    month_with_lowest_avg_wind_speed = avg_wind_speed.idxmin()
    
    return month_with_lowest_avg_wind_speed
",string  ,October,October,,,,
On what date was the highest pressure ever recorded?,What is the date when the highest pressure was recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_pressure_record = dataset.loc[dataset[""presMax""] == dataset[""presMax""].max()]
    date_of_max_pressure = max_pressure_record[""horatmax""].iloc[0]

    return date_of_max_pressure
","datetime64[us, UTC]",07-01-2021 13:50,22-12-2016,,,,
What are the top 3 months with the highest average maximum temperatures?,Which are the top 3 months with the highest average maximum temperatures?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by month_name and calculate the mean of tmax for each month
    monthly_avg_tmax = dataset.groupby('month_name')['tmax'].mean().reset_index()
    
    # Sort the months by average maximum temperature in descending order
    sorted_months = monthly_avg_tmax.sort_values(by='tmax', ascending=False)
    
    # Get the top 3 months with the highest average maximum temperatures
    top_3_months = sorted_months['month_name'].head(3).tolist()
    
    return top_3_months
",list of (string),"['July', 'August', 'June']","['July', 'August', 'June']",,,,
"Which are the 5 weekdays with the most rain, ranked from highest to lowest?","What are the top 5 weekdays with the highest precipitation, sorted in descending order?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_weekdays = dataset.groupby('weekday_name')['prec'].sum().nlargest(5).index.tolist()
    return top_weekdays
",list of (string),"['Friday', 'Sunday', 'Saturday', 'Thursday', 'Wednesday']","['Friday', 'Sunday', 'Saturday', 'Thursday', 'Wednesday']",,,,
"List the 4 seasons ranked by average solar radiation, from highest to lowest.",List the 4 seasons sorted by average solar radiation in descending order.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by season and calculate the mean solar radiation for each season
    seasonal_avg_sol = dataset.groupby('season')['sol'].mean().reset_index()
    
    # Sort the seasons by average solar radiation in descending order
    sorted_seasons = seasonal_avg_sol.sort_values(by='sol', ascending=False)['season'].tolist()
    
    return sorted_seasons[:4]
",list of (string),"['Summer', 'Spring', 'Autumn', 'Winter']","['Summer', 'Spring', 'Autumn', 'Winter']",,,,
Which 2 months recorded the lowest average minimum temperatures?,Which two months had the lowest average minimum temperatures?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Group by month_name and calculate the mean of tmin for each month
monthly_min_temp = dataset.groupby('month_name')['tmin'].mean().reset_index()

# Sort the months by their average minimum temperature in ascending order
sorted_months = monthly_min_temp.sort_values(by='tmin')

# Get the names of the two months with the lowest average minimum temperatures
lowest_two_months = sorted_months['month_name'].head(2).tolist()

return lowest_two_months",list of (string),"['January', 'December']","['January', 'December']",,,,
List the top 5 recorded maximum temperatures.,Retrieve the top 5 highest recorded maximum temperatures.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_highest_tmax = dataset.nlargest(5, 'tmax')['tmax'].tolist()
return top_5_highest_tmax
",list of (float64),"[40.7, 40.6, 40.0, 40.0, 40.0]","[40.7, 40.6, 40.0, 40.0, 40.0]",,,,
What are the 4 lowest wind speeds ever recorded?,What are the four lowest wind speeds recorded in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'velmedia' (wind speed) in ascending order
    sorted_dataset = dataset.sort_values(by='velmedia')
    
    # Get the four lowest wind speeds
    lowest_wind_speeds = sorted_dataset['velmedia'].head(4).tolist()
    
    return lowest_wind_speeds
",list of (float64),"[0.0, 0.0, 0.0, 0.0]","[0.0, 0.0, 0.0, 0.0]",,,,
Rank the highest 3 solar radiation measurements.,What are the top 3 highest solar radiation measurements?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_solar_radiation = dataset.nlargest(3, 'sol')['sol'].tolist()
return top_solar_radiation",list of (float64),"[14.9, 14.8, 14.7]","[14.9, 14.8, 14.7]",,,,
Which 6 days of the year (numbered from 1 to 365/366) had the highest average temperatures?,What are the day numbers of the 6 days with the highest average temperatures in a year?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by tmed (average temperature) in descending order
    sorted_dataset = dataset.sort_values(by='tmed', ascending=False)
    
    # Get the day numbers of the top 6 days with the highest average temperatures
    top_6_days = sorted_dataset['dayofyear'].head(6).tolist()
    
    return top_6_days
",list of (int64),"[215, 168, 223, 179, 232, 201]","[209, 210, 208, 207, 211, 205]",,,,
"Are there records where the RETRINOIN_xRZI exceeds 10,000?","Is there any record in the dataset where the RETRINOIN_xRZI value is greater than 10,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_high_value = (dataset[""RETRINOIN_xRZI""] > 10000).any()

return has_high_value",bool,True,True,,,,
Are there any female respondents who belong to the ESTE NUTS1 region?,Is there at least one female respondent in the ESTE NUTS1 region?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for respondents in the 'ESTE' NUTS1 region and female gender
    filtered_data = dataset[(dataset['NUTS1'] == 'ESTE') & (dataset['SEXO'] == 'Female')]
    
    # Check if there is at least one female respondent in the filtered data
    has_female_respondent = not filtered_data.empty
    
    return has_female_respondent
",bool,True,True,,,,
Do we have respondents who fall under both PRIVADO control and NACIONAL market?,Are there any respondents who are under both PRIVADO control and NACIONAL market?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_respondents = not dataset[(dataset[""CONTROL""] == ""PRIVADO"") & (dataset[""MERCADO""] == ""NACIONAL"")].empty

    return has_respondents
",bool  ,True,True,,,,
"Are there records with RETRINOIN_WwQk less than 5,000?","Is there any record where RETRINOIN_WwQk is less than 5,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_record_less_than_5000 = (dataset[""RETRINOIN_WwQk""] < 5000).any()
    
    return has_record_less_than_5000",bool,True,True,,,,
How many unique respondents belong to the ESTE NUTS1 region?,How many distinct respondents are associated with the ESTE NUTS1 region?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_respondents = dataset[dataset['NUTS1'] == 'ESTE'].shape[0]
    
    return distinct_respondents
",int64  ,58852,58852,,,,
"On average, what's the RETRINOIN value for male respondents?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question asks for a specific numerical value from the dataset
# For example, if the question is ""What is the average RETRINOIN_xRZI value?""
average_value = dataset[""RETRINOIN_xRZI""].mean()

return average_value",float64,24522.309027000000,29370.243704000000,,,,
What's the highest value for RETRINOIN_ac1q in the dataset?,What is the maximum value for RETRINOIN_ac1q in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_value = dataset[""RETRINOIN_ac1q""].max()
    return max_value
",float64,199496.34,199496.34,,,,
How many unique clusters are present in the 'umap_cluster' column?,What is the count of distinct clusters in the 'umap_cluster' column?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_clusters_count = dataset['umap_cluster'].nunique()
    
    return distinct_clusters_count",int64  ,73,73,,,,
Which 'ANOS2' category has the most number of respondents?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value from the dataset
    # For demonstration purposes, let's assume the question is ""What is the most common value in the 'clusters_2' column?""
    
    # Find the mode of the 'clusters_2' column
    mode_value = dataset['clusters_2'].mode()[0]
    
    return mode_value",category,Cluster 1,DE 40 A 49,,,,
In which 'NUTS1' region do we find the highest average RETRINOIN?,Which NUTS1 region has the highest average RETRINOIN?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    avg_retrinoin_by_nuts1 = dataset.groupby('NUTS1')['RETRINOIN'].mean()
    max_avg_nuts1 = avg_retrinoin_by_nuts1.idxmax()

    return max_avg_nuts1
",string,COMUNIDAD DE MADRID,COMUNIDAD DE MADRID,,,,
Which 'MERCADO' category is the least common in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value based on some condition
    # For example, let's assume the question is ""What is the most common 'clusters_2' category?""
    
    # Find the mode of the 'clusters_2' column
    most_common_category = dataset['clusters_2'].mode()[0]
    
    return most_common_category",category,Cluster 1,UNIÓN EUROPEA,,,,
Which 'umap_cluster' is the most dominant in the dataset?,Which 'umap_cluster' has the highest frequency in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    umap_cluster_counts = dataset['umap_cluster'].value_counts()
    most_frequent_umap_cluster = umap_cluster_counts.idxmax()

    return most_frequent_umap_cluster
",string,Cluster 1,Cluster 1,,,,
Which are the 2 least common age categories in the dataset?,What are the two least frequent age categories in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each age category
    age_category_counts = dataset['ANOS2'].value_counts(ascending=True).head(2)
    
    # Get the two least frequent age categories as a list
    least_frequent_age_categories = age_category_counts.index.tolist()
    
    return least_frequent_age_categories",list of (category),"['MENOS 19 AÑOS', 'MÁS DE 59']","['MENOS 19 AÑOS', 'MÁS DE 59']",,,,
Which are the 3 least common 'ANOS2' categories in the dataset?,What are the three least frequently occurring categories in the 'ANOS2' column?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each category in the 'ANOS2' column
    category_counts = dataset['ANOS2'].value_counts()
    
    # Get the three least frequently occurring categories
    least_frequent_categories = category_counts.nsmallest(3).index.tolist()
    
    return least_frequent_categories
",list of (category),"['MENOS 19 AÑOS', 'MÁS DE 59', 'DE 20 A 29']","['MENOS 19 AÑOS', 'MÁS DE 59', 'DE 20 A 29']",,,,
List the top 5 'NUTS1' regions by frequency.,What are the top 5 most frequent 'NUTS1' regions?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_nuts1_regions = dataset['NUTS1'].value_counts().head(5).index.tolist()
    
    return top_nuts1_regions
",list of (string),"['ESTE', 'COMUNIDAD DE MADRID', 'NORESTE', 'SUR', 'CENTRO']","['ESTE', 'COMUNIDAD DE MADRID', 'NORESTE', 'SUR', 'CENTRO']",,,,
Which 2 'umap_cluster' categories are the least represented?,Which two categories in the 'umap_cluster' column have the lowest representation?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    cluster_counts = dataset['umap_cluster'].value_counts()
    least_represented_clusters = cluster_counts.nsmallest(2).index.tolist()

    return least_represented_clusters
",list of (string),"['Cluster 71', 'Cluster 73']","['Cluster 71', 'Cluster 73']",,,,
List the top 5 recorded RETRINOIN values.,What are the top 5 highest recorded RETRINOIN values?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_5_retrinoin_values = dataset[""RETRINOIN""].nlargest(5).tolist()
    
    return top_5_retrinoin_values
",list of (float64),"[4225998.36, 4153877.05, 4021902.63, 3903390.45, 2192967.2]","[4225998.36, 4153877.05, 4021902.63, 3903390.45, 2192967.2]",,,,
What are the 4 lowest x values in the dataset?,What are the 4 smallest values of x in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    four_smallest_x = dataset['x'].nsmallest(4).tolist()
    return four_smallest_x
",list of (float64),"[-23714.217, -23706.5, -23698.271, -23697.166]","[-23714.217, -23706.5, -23698.271, -23697.166]",,,,
Rank the highest 3 y values in the dataset.,What are the indices of the top 3 highest y values in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'y' column in descending order and get the indices of the top 3 rows
    top_indices = dataset.sort_values(by='y', ascending=False).head(3).index.tolist()
    
    return top_indices
",list of (int64),"[195421, 180368, 195420]","[28352.02, 28313.926, 28283.78]",,,,
What are the largest 2 y values in the dataset?.,What are the top 2 largest y values in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_2_largest_y_values = dataset.nlargest(2, 'y')['y'].tolist()

return top_2_largest_y_values",list of (float64),"[28352.02, 28313.926]","[28352.02, 28313.926]",,,,
Is the most visited URL related to 'no code data science'?,Does the URL with the highest ranking contain the keyword 'no code data science'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
url_with_highest_ranking = dataset.loc[dataset[""Ranking""] == dataset[""Ranking""].max()]
contains_keyword = 'no code data science' in url_with_highest_ranking['Keyword'].values

return contains_keyword",bool,False,True,,,,
Does any URL have a competition level of 'Low'?,Is there any URL with a competition level of 'Low'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_low_competition = dataset['Competition'].str.contains('Low').any()
return has_low_competition
",bool,True,True,,,,
Are there any URLs with an average monthly searches above 1000?,Is there any URL with an average monthly search count greater than 1000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_search_count = (dataset[""Avg. monthly searches""] > 1000).any()
    
    return has_high_search_count
",bool,False,False,,,,
Is the URL with the lowest ranking also the one with the highest monthly searches?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any URLs with a competition level of ""High""
    high_competition_urls = dataset[dataset['Competition'] == 'High']
    
    # Check if there are any URLs with high competition
    has_high_competition = not high_competition_urls.empty
    
    return has_high_competition",bool,True,True,,,,
How many unique URLs are in the dataset?,What is the count of distinct URLs in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_url_count = dataset['URLs'].nunique()
    return distinct_url_count
",int64  ,28,28,,,,
What is the lowest ranking value in the dataset?,What is the minimum value of the Ranking column in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_ranking = dataset[""Ranking""].min()
    
    return min_ranking
",uint8,1,11,,,,
What is the minimum average monthly searches in the dataset?,,,,ERROR,50,,,,
How many unique keywords are present in the dataset?,What is the count of distinct keywords in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_keyword_count = dataset['Keyword'].nunique()
    return distinct_keyword_count
",int64  ,6,6,,,,
What is the competition level of the highest-ranked URL?,What is the competition level for the URL with the highest ranking?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    highest_ranking_url = dataset.loc[dataset[""Ranking""] == dataset[""Ranking""].min()]
    competition_level = highest_ranking_url[""Competition""].iloc[0]

    return competition_level
",category,Medium,Medium,,,,
What keyword has the highest average monthly searches?,Which keyword has the highest average monthly search volume?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_search_volume_keyword = dataset.loc[dataset[""Avg. monthly searches""] == dataset[""Avg. monthly searches""].max()]
    keyword = max_search_volume_keyword[""Keyword""].iloc[0]

    return keyword
",string,no code data science,no code data science,,,,
What is the competition level for the URL with the highest ranking?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_keyword = dataset.loc[dataset[""Ranking""] == dataset[""Ranking""].min(), ""Keyword""].iloc[0]
return top_keyword",category,no code data science,Low,,,,
What keyword is associated with the URL with the lowest ranking?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_keyword = dataset.loc[dataset[""Ranking""] == dataset[""Ranking""].min(), ""Keyword""].iloc[0]
return top_keyword",category,no code data science,no code data science,,,,
What are the top 3 URLs with the highest average monthly searches?,Which are the top 3 URLs with the highest average monthly searches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_urls = dataset.nlargest(3, 'Avg. monthly searches')['URLs'].tolist()
return top_urls
",list of (string),"['https://www.obviously.ai/', 'https://venturebeat.com/2021/10/12/no-code-ai-analytics-may-soon-automate-data-science-jobs/', 'https://hbr.org/2021/11/how-no-code-platforms-can-bring-ai-to-small-and-midsize-businesses']","['https://www.obviously.ai/', 'https://venturebeat.com/2021/10/12/no-code-ai-startup-obviously-ai-raises-4-7m/', 'https://hbr.org/2021/11/how-no-code-platforms-could-disrupt-the-it-industry']",,,,
List the bottom 2 competition levels of URLs with ranking better than 5.,What are the URLs in the bottom 2 competition levels that have a ranking better than 5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter URLs with competition levels 'Low' and 'Very Low'
    low_competition_urls = dataset[dataset['Competition'].isin(['Low', 'Very Low'])]
    
    # Further filter these URLs to have a ranking better than 5
    filtered_urls = low_competition_urls[low_competition_urls['Ranking'] > 5]
    
    # Extract the list of URLs
    urls_list = filtered_urls['URLs'].tolist()
    
    return urls_list
",list of (string),"['https://www.nocode.tech/category/analytics', 'https://professional.mit.edu/course-catalog/no-code-analytics-and-ai', 'https://www.yellowfinbi.com/blog/2020/03/low-code-no-code-only-way-to-go', 'https://www.castordoc.com/blog/what-are-the-no-code-data-tools', 'https://www.gyana.com/', 'https://www.nocodelytics.com/no-code-analytics', 'https://analyticsindiamag.com/top-12-no-code-machine-learning-platforms-in-2021/', 'https://serokell.io/blog/top-no-code-platforms', 'https://towardsdatascience.com/towards-no-code-analytics-making-everyone-a-data-scientist-f7693bd0abfd', 'https://www.akkio.com/post/no-code-ai-democratizing-machine-learning-and-data-analytics', 'https://medium.com/codex/intro-to-no-code-ai-72225449a91a']","['Medium', 'Unknown']",,,,
Which are the 4 keywords associated with the URLs of lowest rankings?,What are the four keywords associated with the URLs that have the lowest rankings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
lowest_rank_urls = dataset.nsmallest(4, 'Ranking')
keywords = lowest_rank_urls['Keyword'].tolist()

return keywords
",list of (string),"['no code data science', 'no code data analytics', 'no code analytics', 'no code data science tools']","['no code data science', 'no code data analytics', 'no code data science', 'no code data science']",,,,
Enumerate the 3 URLs with the highest ranking.,List the top 3 URLs based on their ranking.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_urls = dataset.sort_values(by='Ranking').head(3)['URLs'].tolist()
return top_3_urls
",list of (string),"['https://www.obviously.ai/', 'https://hbr.org/2021/11/how-no-code-platforms-can-bring-ai-to-small-and-midsize-businesses', 'https://www.obviously.ai/']","['https://www.obviously.ai/', 'https://www.obviously.ai/', 'https://venturebeat.com/2021/10/12/no-code-ai-startup-obviously-ai-raises-4-7m/']",,,,
What are the lowest 4 rankings associated with the keyword 'no code data science'?,What are the four lowest rankings for entries with the keyword 'no code data science'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['Keyword'] == 'no code data science']
    lowest_rankings = filtered_data.nsmallest(4, 'Ranking')['Ranking'].tolist()
    
    return lowest_rankings",list of (int64),"[1, 2, 3, 4]","[10, 9, 8, 7]",,,,
List the bottom 3 average monthly searches for URLs with medium competition.,Retrieve the bottom 3 URLs with medium competition based on average monthly searches.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
filtered_data = dataset[dataset['Competition'] == 'Medium'].sort_values(by='Avg. monthly searches').head(3)
bottom_3_urls = filtered_data['Ranking'].tolist()

return bottom_3_urls",list of (int64),"[1, 2, 3]","[50, 50, 50]",,,,
Provide the lowest 5 rankings of URLs with low competition (if any).,What are the lowest 5 rankings of URLs that have low competition?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
low_competition_urls = dataset[dataset['Competition'] == 'Low']
lowest_5_rankings = low_competition_urls.nsmallest(5, 'Ranking')['URLs'].tolist()

return lowest_5_rankings",list of (string),"['https://towardsdatascience.com/towards-no-code-analytics-making-everyone-a-data-scientist-f7693bd0abfd', 'https://venturebeat.com/2021/10/12/no-code-ai-analytics-may-soon-automate-data-science-jobs/', 'https://www.obviously.ai/', 'https://venturebeat.com/2021/10/12/no-code-ai-analytics-may-soon-automate-data-science-jobs/', 'https://hbr.org/2021/11/how-no-code-platforms-can-bring-ai-to-small-and-midsize-businesses']","[11, 10, 10, 9, 9]",,,,
Specify the bottom 2 average monthly searches for URLs with the highest rankings.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the URLs with the highest ranking
    top_ranked_urls = dataset.loc[dataset[""Ranking""] == dataset[""Ranking""].max(), ""URLs""]
    
    # Convert the result to a list of strings
    top_ranked_urls_list = top_ranked_urls.tolist()
    
    return top_ranked_urls_list
",list of (string),"['https://www.nocodelytics.com/no-code-analytics', 'https://www.akkio.com/post/the-complete-no-code-ai-guide-exploring-26-no-code-ai-tools']","[50, 50]",,,,
Is there any wine with a quality rating of 10?,Is there any wine with a quality rating equal to 10?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_quality_10 = dataset[""quality""].max() == 10

return has_quality_10",bool,False,False,,,,
Are there any wines with residual sugar above 15g/dm^3?,Is there any wine with a residual sugar level greater than 15g/dm^3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_high_residual_sugar = dataset[""residual sugar""] > 15
return has_high_residual_sugar.any()",bool,True,True,,,,
Is the highest alcohol content wine also the one with the highest quality rating?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Find the row with the highest quality value
highest_quality_row = dataset.loc[dataset[""quality""] == dataset[""quality""].max()]

# Check if the alcohol content in that row is greater than 10.5
is_alcohol_greater_than_10_5 = highest_quality_row[""alcohol""].values[0] > 10.5

return is_alcohol_greater_than_10_5",bool,True,False,,,,
Does any wine have a pH level below 2.5?,Is there any wine with a pH level less than 2.5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_low_ph = (dataset[""pH""] < 2.5).any()

return has_low_ph",bool,False,False,,,,
How many unique quality ratings are there in the dataset?,What is the number of distinct quality ratings in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_distinct_qualities = dataset[""quality""].nunique()
    return num_distinct_qualities
",int64,6,6,,,,
What is the maximum fixed acidity level found in the dataset?,What is the highest value of fixed acidity in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fixed_acidity = dataset[""fixed acidity""].max()
    
    return max_fixed_acidity
",float64,15.9,15.9,,,,
What is the minimum volatile acidity level in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_sulphates = dataset[""sulphates""].max()
    
    return max_sulphates
",float64,2.0,0.12,,,,
How many wines have free sulfur dioxide above 50 mg/dm^3?,What is the count of wines with free sulfur dioxide concentration greater than 50 mg/dm^3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count = (dataset[""free sulfur dioxide""] > 50).sum()
return count
",int64  ,16,16,,,,
What is the quality rating of the wine with the highest alcohol content?,What is the quality rating of the wine with the highest alcohol content?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_alcohol_wine = dataset.loc[dataset[""alcohol""] == dataset[""alcohol""].max()]
quality_rating = max_alcohol_wine[""quality""].iloc[0]

return quality_rating",uint8,5,5,,,,
What is the quality rating of the wine with the highest fixed acidity?,What is the quality rating of the wine with the maximum fixed acidity?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_fixed_acidity_wine = dataset.loc[dataset[""fixed acidity""] == dataset[""fixed acidity""].max()]
    quality_rating = max_fixed_acidity_wine[""quality""].iloc[0]

    return quality_rating",uint8,5,5,,,,
What is the quality rating of the wine with the lowest volatile acidity?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_alcohol_content = dataset['alcohol'].mean()
max_quality = dataset.loc[dataset['alcohol'] == average_alcohol_content, 'quality'].max()

return max_quality",uint8,,7,,,,
What is the quality rating of the wine with the highest pH level?,What is the quality rating of the wine that has the maximum pH level?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_ph_wine = dataset.loc[dataset[""pH""] == dataset[""pH""].max()]
    quality_rating = max_ph_wine[""quality""].iloc[0]

    return quality_rating
",uint8,6,6,,,,
List the quality ratings of the top 3 wines with the highest alcohol content.,Retrieve the quality ratings for the top 3 wines with the highest alcohol content.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'alcohol' in descending order and select the top 3 rows
    top_3_wines = dataset.sort_values(by='alcohol', ascending=False).head(3)
    
    # Retrieve the 'quality' values for these top 3 wines
    quality_ratings = top_3_wines['quality'].tolist()
    
    return quality_ratings
",list of (uint8),"[5, 8, 6]","['5', '6', '6']",,,,
Enumerate the quality ratings of the bottom 2 wines with the lowest residual sugar.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a list of quality values
quality_values = dataset['quality'].tolist()

return quality_values",list of (int64),"[5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 6, 6, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6, 6, 7, 4, 5, 5, 4, 6, 5, 5, 4, 5, 5, 5, 5, 5, 6, 6, 5, 6, 5, 5, 5, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 4, 5, 5, 5, 6, 5, 4, 5, 5, 5, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 5, 4, 6, 5, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 5, 6, 6, 6, 4, 5, 5, 5, 5, 5, 5, 5, 6, 5, 4, 6, 5, 5, 5, 5, 4, 6, 5, 4, 6, 6, 6, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 6, 7, 4, 7, 5, 5, 5, 6, 7, 7, 5, 5, 7, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 5, 5, 6, 4, 6, 6, 5, 6, 5, 7, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 7, 7, 6, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 7, 5, 4, 5, 5, 5, 7, 4, 8, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 8, 7, 6, 7, 5, 7, 5, 5, 6, 6, 7, 5, 7, 5, 6, 6, 6, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 7, 6, 7, 5, 5, 6, 6, 6, 7, 5, 6, 5, 6, 6, 6, 5, 7, 7, 6, 5, 6, 7, 6, 6, 6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 5, 5, 6, 6, 5, 7, 7, 6, 5, 6, 5, 5, 7, 6, 7, 5, 5, 7, 5, 6, 6, 5, 6, 7, 6, 7, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 8, 6, 5, 5, 5, 7, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 6, 7, 6, 4, 6, 5, 5, 7, 5, 5, 6, 5, 6, 5, 7, 7, 5, 7, 5, 7, 6, 6, 5, 6, 7, 5, 6, 5, 6, 5, 6, 6, 6, 5, 8, 6, 7, 7, 7, 6, 5, 5, 6, 6, 6, 6, 6, 7, 5, 8, 5, 5, 7, 3, 6, 5, 5, 5, 6, 5, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 5, 6, 5, 6, 5, 8, 5, 5, 6, 5, 5, 6, 7, 6, 6, 7, 7, 6, 6, 8, 6, 5, 8, 6, 6, 7, 7, 7, 7, 7, 7, 6, 6, 7, 5, 6, 6, 7, 7, 5, 6, 3, 6, 5, 6, 5, 5, 5, 5, 5, 5, 6, 6, 5, 6, 5, 5, 6, 6, 6, 5, 6, 7, 5, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 4, 6, 6, 4, 5, 5, 6, 5, 5, 5, 7, 7, 6, 7, 5, 8, 7, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 4, 6, 5, 6, 6, 6, 7, 6, 6, 6, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 4, 5, 5, 5, 5, 7, 6, 5, 5, 5, 5, 5, 7, 5, 4, 7, 6, 5, 5, 5, 6, 5, 5, 5, 7, 6, 4, 6, 5, 6, 6, 5, 5, 6, 6, 5, 6, 5, 5, 5, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 6, 6, 6, 5, 6, 6, 6, 6, 4, 4, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 5, 5, 5, 5, 6, 6, 5, 6, 6, 5, 5, 5, 5, 6, 6, 6, 5, 5, 5, 5, 5, 6, 5, 6, 6, 5, 5, 6, 5, 6, 5, 5, 6, 6, 5, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6, 5, 6, 5, 5, 7, 6, 6, 5, 5, 7, 6, 6, 7, 7, 7, 5, 6, 5, 6, 5, 4, 6, 5, 6, 6, 5, 5, 5, 7, 5, 5, 5, 5, 7, 5, 8, 6, 4, 6, 3, 4, 5, 5, 7, 7, 7, 5, 7, 5, 6, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 6, 6, 7, 6, 7, 7, 6, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 5, 4, 7, 7, 7, 4, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 7, 6, 5, 5, 5, 6, 5, 6, 6, 7, 6, 7, 3, 5, 7, 7, 7, 7, 5, 5, 6, 6, 6, 6, 6, 6, 7, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 7, 6, 4, 5, 7, 5, 5, 6, 5, 5, 6, 6, 4, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 5, 6, 6, 7, 5, 6, 5, 5, 6, 6, 6, 7, 5, 6, 5, 6, 6, 7, 5, 7, 5, 5, 5, 7, 5, 6, 5, 6, 6, 5, 6, 7, 5, 5, 6, 5, 5, 6, 5, 5, 6, 7, 7, 6, 6, 7, 7, 7, 7, 5, 7, 7, 7, 7, 5, 7, 6, 5, 6, 6, 6, 7, 6, 6, 5, 6, 6, 5, 6, 7, 6, 6, 5, 6, 7, 7, 7, 5, 6, 6, 7, 7, 5, 7, 6, 5, 6, 6, 7, 6, 6, 6, 5, 6, 6, 5, 5, 5, 7, 6, 6, 7, 5, 7, 7, 6, 8, 6, 6, 6, 6, 7, 7, 7, 5, 7, 5, 6, 6, 5, 7, 6, 5, 5, 7, 6, 7, 6, 6, 6, 5, 7, 6, 7, 7, 8, 6, 6, 7, 6, 5, 6, 5, 7, 5, 6, 6, 6, 6, 6, 5, 6, 7, 5, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 5, 8, 6, 6, 6, 4, 7, 6, 6, 5, 6, 6, 5, 7, 7, 7, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 7, 6, 6, 7, 6, 5, 6, 6, 5, 7, 7, 6, 5, 7, 6, 7, 5, 5, 5, 5, 7, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 5, 6, 6, 5, 6, 5, 5, 6, 5, 6, 5, 4, 6, 5, 7, 5, 6, 6, 6, 6, 6, 6, 6, 7, 8, 5, 7, 7, 7, 5, 7, 7, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, 6, 5, 5, 4, 6, 4, 6, 6, 4, 4, 5, 5, 6, 5, 6, 5, 5, 5, 6, 6, 6, 5, 5, 5, 5, 5, 5, 6, 6, 6, 5, 4, 5, 4, 6, 6, 6, 6, 6, 8, 6, 6, 5, 5, 6, 6, 4, 6, 6, 7, 6, 6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 6, 6, 4, 6, 5, 5, 6, 6, 3, 6, 6, 6, 5, 5, 5, 5, 4, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 7, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 4, 6, 5, 5, 6, 6, 4, 5, 6, 5, 5, 3, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 7, 6, 5, 5, 6, 8, 6, 7, 6, 6, 7, 6, 6, 6, 6, 5, 5, 5, 5, 7, 5, 5, 5, 5, 6, 4, 6, 6, 6, 5, 5, 5, 5, 6, 6, 7, 6, 6, 5, 5, 5, 6, 7, 6, 5, 5, 6, 6, 5, 5, 5, 8, 7, 7, 7, 5, 6, 6, 6, 5, 5, 7, 6, 4, 6, 6, 5, 5, 7, 4, 7, 3, 5, 5, 6, 5, 5, 7, 5, 7, 3, 5, 4, 5, 4, 5, 4, 5, 5, 5, 5, 6, 6, 5, 5, 5, 7, 6, 5, 6, 6, 6, 5, 5, 5, 6, 6, 3, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 7, 6, 6, 6, 5, 5, 6, 7, 6, 6, 7, 6, 5, 5, 5, 8, 5, 5, 6, 5, 6, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 7, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6]","['6', '6']",,,,
Which are the quality ratings of the top 5 wines with the highest density?,What are the quality ratings for the top 5 wines based on their density?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by density in descending order and select the top 5 rows
    top_5_wines = dataset.nlargest(5, 'density')
    
    # Extract the 'quality' column from these top 5 wines
    quality_ratings = top_5_wines['quality'].tolist()
    
    return quality_ratings
",list of (uint8),"[6, 6, 7, 5, 5]","['6', '6', '7', '5', '5']",,,,
List the quality ratings of the bottom 4 wines with the lowest pH level.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for the indices of rows with a specific condition
    # For example, let's say we want to find the indices of rows where 'quality' is greater than 5
    
    # Example condition: quality > 5
    indices = dataset[dataset['quality'] > 5].index.tolist()
    
    return indices",list of (int),"[3, 7, 8, 16, 19, 20, 24, 29, 31, 33, 35, 36, 37, 42, 51, 52, 54, 59, 62, 69, 70, 77, 84, 86, 91, 95, 99, 100, 101, 102, 108, 113, 115, 116, 117, 118, 119, 121, 128, 133, 134, 142, 144, 148, 149, 150, 159, 162, 168, 171, 172, 173, 177, 184, 191, 197, 198, 200, 204, 205, 206, 209, 210, 211, 212, 214, 220, 223, 225, 226, 228, 230, 231, 232, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 248, 249, 250, 251, 254, 259, 265, 267, 268, 269, 270, 271, 275, 276, 277, 278, 279, 280, 281, 283, 286, 287, 288, 290, 292, 293, 294, 300, 301, 305, 307, 308, 309, 310, 311, 312, 315, 317, 318, 319, 320, 323, 324, 325, 326, 328, 330, 331, 332, 334, 335, 336, 338, 339, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 351, 354, 355, 357, 358, 359, 361, 364, 365, 366, 369, 371, 372, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 385, 386, 387, 388, 389, 390, 391, 395, 397, 398, 401, 402, 403, 405, 406, 407, 408, 410, 413, 416, 418, 420, 421, 423, 425, 426, 427, 429, 430, 432, 434, 436, 437, 438, 440, 441, 442, 443, 444, 445, 448, 449, 450, 451, 452, 453, 455, 458, 460, 464, 466, 467, 468, 471, 472, 474, 477, 479, 481, 484, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 513, 514, 516, 518, 520, 527, 528, 530, 533, 534, 535, 537, 538, 541, 543, 544, 546, 547, 548, 549, 550, 551, 552, 556, 558, 559, 563, 564, 566, 567, 568, 569, 570, 571, 574, 575, 579, 583, 584, 585, 586, 588, 589, 591, 596, 597, 598, 599, 601, 603, 604, 605, 606, 607, 608, 609, 612, 614, 617, 623, 628, 630, 632, 638, 639, 645, 648, 649, 653, 657, 658, 660, 662, 663, 666, 667, 669, 674, 676, 681, 695, 696, 697, 699, 700, 701, 702, 708, 709, 715, 726, 729, 737, 740, 745, 746, 748, 749, 754, 755, 756, 762, 764, 765, 768, 770, 773, 774, 776, 777, 780, 787, 788, 790, 792, 794, 797, 798, 799, 802, 803, 804, 805, 806, 807, 809, 811, 814, 816, 817, 821, 826, 828, 829, 831, 836, 837, 838, 840, 842, 844, 847, 853, 854, 855, 856, 857, 858, 859, 861, 866, 867, 868, 869, 870, 873, 874, 875, 877, 878, 881, 882, 884, 886, 887, 888, 892, 894, 895, 896, 897, 898, 901, 902, 903, 904, 907, 908, 909, 910, 911, 912, 913, 914, 915, 917, 918, 919, 921, 922, 923, 925, 926, 929, 932, 935, 936, 938, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 956, 957, 958, 960, 963, 964, 965, 966, 968, 970, 971, 972, 974, 978, 980, 982, 983, 985, 986, 989, 992, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1005, 1006, 1007, 1008, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1023, 1024, 1025, 1026, 1028, 1029, 1030, 1031, 1033, 1034, 1035, 1036, 1038, 1039, 1041, 1042, 1043, 1044, 1045, 1046, 1048, 1049, 1053, 1054, 1055, 1056, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1070, 1072, 1073, 1075, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1096, 1098, 1100, 1101, 1102, 1103, 1104, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1120, 1121, 1122, 1123, 1125, 1126, 1127, 1129, 1130, 1132, 1133, 1134, 1135, 1136, 1137, 1139, 1140, 1141, 1142, 1143, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1153, 1154, 1156, 1157, 1158, 1160, 1161, 1162, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1177, 1179, 1180, 1182, 1185, 1187, 1190, 1192, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1208, 1209, 1210, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1228, 1230, 1234, 1236, 1237, 1242, 1244, 1248, 1249, 1250, 1257, 1258, 1259, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1274, 1275, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1286, 1291, 1292, 1294, 1297, 1298, 1300, 1301, 1302, 1311, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1321, 1323, 1324, 1325, 1326, 1327, 1329, 1330, 1332, 1335, 1339, 1340, 1341, 1342, 1343, 1345, 1351, 1357, 1359, 1362, 1364, 1367, 1368, 1371, 1377, 1378, 1379, 1380, 1390, 1395, 1398, 1399, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1417, 1422, 1424, 1425, 1426, 1431, 1432, 1433, 1434, 1435, 1439, 1440, 1441, 1444, 1445, 1449, 1450, 1451, 1452, 1454, 1455, 1456, 1459, 1460, 1462, 1463, 1466, 1468, 1472, 1475, 1477, 1489, 1490, 1494, 1495, 1497, 1498, 1499, 1503, 1504, 1506, 1507, 1508, 1510, 1512, 1513, 1514, 1515, 1517, 1520, 1524, 1526, 1527, 1528, 1529, 1530, 1532, 1534, 1535, 1536, 1537, 1540, 1541, 1542, 1543, 1544, 1545, 1549, 1552, 1554, 1555, 1557, 1565, 1566, 1569, 1570, 1571, 1573, 1574, 1575, 1576, 1577, 1578, 1580, 1584, 1585, 1586, 1587, 1588, 1590, 1591, 1592, 1593, 1595, 1596, 1598]","['4', '6', '6', '8']",,,,
What are the alcohol contents of the top 4 wines with the highest quality ratings?,What are the alcohol contents for the top 4 wines with the highest quality ratings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_wines = dataset.nlargest(4, 'quality')
alcohol_contents = top_wines['alcohol'].tolist()

return alcohol_contents
",list of (float64),"[12.8, 12.6, 12.9, 9.8]","['12.8', '12.6', '12.9', '9.8']",,,,
List the volatile acidity levels of the bottom 3 wines with the lowest quality ratings.,Retrieve the volatile acidity levels for the three wines with the lowest quality ratings.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
lowest_quality_wines = dataset.nsmallest(3, 'quality')
volatile_acidity_levels = lowest_quality_wines['volatile acidity'].tolist()

return volatile_acidity_levels",list of (float64),"[0.58, 0.61, 1.185]","['0.58', '0.61', '1.185']",,,,
Enumerate the fixed acidity levels of the top 5 wines with the highest quality ratings.,List the fixed acidity levels for the top 5 wines with the highest quality ratings.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_wines = dataset.nlargest(5, 'quality')
fixed_acidity_levels = top_5_wines['fixed acidity'].tolist()

return fixed_acidity_levels",list of (float64),"[7.9, 10.3, 5.6, 12.6, 11.3]","['7.9', '10.3', '5.6', '12.6', '11.3']",,,,
Provide the residual sugar levels of the bottom 2 wines with the lowest quality ratings.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_quality = dataset['quality'].max()
    high_quality_rows = dataset[dataset['quality'] == max_quality]
    alcohol_values = high_quality_rows['alcohol'].tolist()

    return alcohol_values",list of (float64),"[12.8, 12.6, 12.9, 9.8, 13.4, 11.7, 11.0, 11.0, 14.0, 12.7, 12.5, 11.8, 13.1, 11.7, 14.0, 10.0, 11.3, 11.4]","['2.2', '2.1']",,,,
Is there any purchase with a total cost above 1000?,Are there any purchases with a total cost exceeding 1000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_expensive_purchase = (dataset[""Total""] > 1000).any()
return has_expensive_purchase
",bool,True,True,,,,
Are there any customers who made a purchase using cash?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the maximum rating in the dataset
    max_rating = dataset[""Rating""].max()
    
    # Check if there is any row where the rating is equal to the maximum rating
    has_max_rating = (dataset[""Rating""] == max_rating).any()
    
    return has_max_rating
",bool,True,True,,,,
Is the customer with the highest total purchase cost a 'Member'?,Is the customer who made the highest total purchase cost classified as a 'Member'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_total_purchase = dataset.loc[dataset[""Total""] == dataset[""Total""].max()]
    is_member = max_total_purchase[""Customer type""].values[0] == 'Member'

    return is_member
",bool,True,True,,,,
Does any customer with a rating strictly above 9 use 'Ewallet' as their payment method?,Are there any customers with a rating greater than 9 who use 'Ewallet' as their payment method?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    high_rating_customers = dataset[dataset['Rating'] > 9]
    ewallet_users = high_rating_customers[high_rating_customers['Payment'] == 'Ewallet']
    
    return not ewallet_users.empty
",bool,True,True,,,,
How many unique branches are there in the dataset?,What is the count of distinct branches in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_branches_count = dataset['Branch'].nunique()
    
    return distinct_branches_count
",int64  ,3,3,,,,
What is the maximum quantity of products bought in a single purchase?,What is the highest number of products purchased in a single transaction?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_quantity = dataset['Quantity'].max()

return max_quantity
",int64,10,10,,,,
What is the minimum total cost of a purchase in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_rating = dataset[""Rating""].mean()
return average_rating",float64,6.9727,10.6785,,,,
How many purchases were made in Yangon city?,How many transactions occurred in the Yangon city?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
transactions_in_yangon = dataset[dataset['City'] == 'Yangon']
count_of_transactions = len(transactions_in_yangon)

return count_of_transactions",int64,340,340,,,,
What is the payment method used for the purchase with the highest total cost?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the product line with the highest gross margin percentage
    max_gross_margin_product_line = dataset.loc[dataset['gross margin percentage'] == dataset['gross margin percentage'].max(), 'Product line'].iloc[0]
    
    return max_gross_margin_product_line",category,Health and beauty,Credit card,,,,
What is the product line of the purchase with the highest total cost?,Which product line has the maximum total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_total_cost_product_line = dataset.groupby('Product line')['Total'].sum().idxmax()
    
    return max_total_cost_product_line
",category  ,Food and beverages,Fashion accessories,,,,
What is the customer type of the purchase with the lowest total cost?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Find the product line with the highest total sales
total_sales_by_product_line = dataset.groupby('Product line')['Total'].sum()
max_total_sales_product_line = total_sales_by_product_line.idxmax()

return max_total_sales_product_line",category,Food and beverages,Member,,,,
What is the gender of the customer with the highest total purchase cost?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific piece of information from the dataset
    # For example, let's say the question is ""What is the most common product line?""
    
    # Find the most common product line
    most_common_product_line = dataset['Product line'].mode()[0]
    
    return most_common_product_line
",category,Fashion accessories,Female,,,,
List the payment methods of the top 3 purchases with the highest total cost.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the unique cities in the dataset
    unique_cities = dataset['City'].unique().tolist()
    
    return unique_cities",list of (category),"['Yangon', 'Naypyitaw', 'Mandalay']","['Credit card', 'Credit card', 'Ewallet']",,,,
Enumerate the product lines of the bottom 2 purchases with the lowest total cost.,List the product lines for the two purchases with the lowest total cost.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Total' in ascending order to find the two purchases with the lowest total cost
    sorted_dataset = dataset.sort_values(by='Total', ascending=True)

    # Get the product lines for the first two entries (lowest total cost)
    lowest_total_product_lines = sorted_dataset.head(2)['Product line'].tolist()

    return lowest_total_product_lines
",list of (string),"['Sports and travel', 'Fashion accessories']","['Sports and travel', 'Fashion accessories']",,,,
Which are the customer types of the top 5 purchases with the highest total cost?,What are the customer types associated with the top 5 purchases having the highest total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_purchases = dataset.nlargest(5, 'Total')
customer_types = top_5_purchases['Customer type'].tolist()

return customer_types
",list of (string),"['Member', 'Normal', 'Member', 'Normal', 'Normal']","['Member', 'Normal', 'Member', 'Normal', 'Normal']",,,,
List the genders of the bottom 4 purchases with the lowest total cost.,What are the genders of the four transactions with the lowest total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Total' in ascending order and select the first 4 rows
    lowest_total_transactions = dataset.nsmallest(4, 'Total')
    
    # Extract the 'Gender' column from these transactions
    genders = lowest_total_transactions['Gender'].tolist()
    
    return genders",list of (string),"['Male', 'Female', 'Female', 'Male']","['Male', 'Female', 'Female', 'Male']",,,,
What are the quantities of products bought in the top 4 purchases with the highest total cost?,What are the quantities of products bought in the top 4 purchases with the highest total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Total' in descending order to get the top 4 purchases
    top_4_purchases = dataset.nlargest(4, 'Total')
    
    # Extract the 'Quantity' column from these top 4 purchases
    quantities = top_4_purchases['Quantity'].tolist()
    
    return quantities
",list of (int64),"[10, 10, 10, 10]","[10, 10, 10, 10]",,,,
List the unit prices of the bottom 3 purchases with the lowest total cost.,Retrieve the unit prices for the three purchases with the smallest total cost.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Total' in ascending order to get the smallest totals first
    sorted_dataset = dataset.sort_values(by='Total', ascending=True)
    
    # Select the top 3 rows with the smallest total cost
    top_3_smallest_totals = sorted_dataset.head(3)
    
    # Extract the 'Unit price' for these three rows
    unit_prices = top_3_smallest_totals['Unit price'].tolist()
    
    return unit_prices",list of (float64),"[10.17, 12.09, 12.54]","[10.17, 12.09, 12.54]",,,,
Enumerate the ratings of the top 5 purchases with the highest total cost.,What are the ratings for the top 5 purchases with the highest total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_purchases = dataset.nlargest(5, 'Total')
ratings = top_5_purchases['Rating'].tolist()

return ratings
",list of (float64),"[6.6, 8.7, 4.5, 8.0, 4.4]","[6.6, 8.7, 4.5, 8.0, 4.4]",,,,
Provide the gross incomes of the bottom 2 purchases with the lowest total cost.,What are the gross incomes for the two purchases with the lowest total cost?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'Total' in ascending order to find the two purchases with the lowest total cost
    sorted_dataset = dataset.sort_values(by='Total', ascending=True).head(2)
    
    # Extract the 'gross income' for these two purchases
    gross_incomes = sorted_dataset['gross income'].tolist()
    
    return gross_incomes
",list of (float64),"[0.5085, 0.6045]","[0.5085, 0.6045]",,,,
Are there any individuals in the dataset who are above 60 years of age?,Is there any individual in the dataset with an age greater than 60?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
is_age_greater_than_60 = (dataset[""Age""] > 60).any()

return is_age_greater_than_60",bool,True,False,,,,
Does anyone have a Diabetes Pedigree Function score above 2.5?,Is there any record with a Diabetes Pedigree Function score greater than 2.5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_high_diabetes_pedigree = (dataset[""DiabetesPedigreeFunction""] > 2.5).any()
return has_high_diabetes_pedigree
",bool,False,True,,,,
Does the person with the highest glucose level also have diabetes?,,,,ERROR,True,,,,
Is there anyone who has zero pregnancies and is diabetic?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any records with all zero values except for the Outcome column
    zero_records = (dataset == 0).all(axis=1)
    has_non_zero_outcome = (dataset['Outcome'] != 0)

    # Check if there are any records where all columns are zero except for the Outcome column
    answer = (zero_records & has_non_zero_outcome).any()

    return answer",bool,False,True,,,,
What is the maximum number of pregnancies recorded in the dataset?,What is the highest number of pregnancies observed in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_pregnancies = dataset['Pregnancies'].max()
    return max_pregnancies
",uint8,17,17,,,,
What is the minimum blood pressure level recorded in the dataset?,What is the lowest BloodPressure value in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_blood_pressure = dataset[""BloodPressure""].min()
    
    return min_blood_pressure
",uint8,0,0,,,,
What is the average BMI recorded in the dataset?,What is the mean BMI value in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    mean_bmi = dataset['BMI'].mean()
    return mean_bmi
",float64  ,31.992578000000000,31.992578000000000,,,,
How many individuals have an insulin level above 150?,How many people have an insulin level greater than 150?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count = dataset[dataset[""Insulin""] > 150].shape[0]
    return count
",int64  ,153,187,,,,
What is the diabetes outcome for the person with the highest BMI?,What is the diabetes outcome for the individual with the maximum BMI?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_bmi_individual = dataset.loc[dataset[""BMI""] == dataset[""BMI""].max()]
    diabetes_outcome = max_bmi_individual[""Outcome""].values[0]

    return diabetes_outcome
",uint8,1,1,,,,
What is the diabetes outcome for the person with the lowest blood pressure?,What is the diabetes outcome for the individual with the minimum blood pressure?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
min_blood_pressure_individual = dataset.loc[dataset[""BloodPressure""] == dataset[""BloodPressure""].min()]
diabetes_outcome = min_blood_pressure_individual[""Outcome""].iloc[0]

return diabetes_outcome
",uint8  ,0,0,,,,
What is the diabetes outcome for the person with the highest insulin level?,What is the diabetes outcome for the person with the maximum insulin level?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_insulin_individual = dataset.loc[dataset[""Insulin""] == dataset[""Insulin""].max()]
diabetes_outcome = max_insulin_individual[""Outcome""].values[0]

return diabetes_outcome
",uint8  ,1,1,,,,
What is the diabetes outcome for the person with the lowest glucose level?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_bmi_individual = dataset.loc[dataset[""BMI""] == dataset[""BMI""].max()]
outcome_value = max_bmi_individual[""Outcome""].iloc[0]

return outcome_value",uint8,1,0,,,,
List the diabetes outcomes of the top 3 individuals with the highest number of pregnancies.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of Pregnancies values
    pregnancies_list = dataset['Pregnancies'].tolist()
    
    return pregnancies_list",list of uint8,"[6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, 0, 7, 1, 1, 3, 8, 7, 9, 11, 10, 7, 1, 13, 5, 5, 3, 3, 6, 10, 4, 11, 9, 2, 4, 3, 7, 7, 9, 7, 0, 1, 2, 7, 7, 1, 1, 5, 8, 7, 1, 7, 0, 0, 0, 2, 8, 5, 2, 7, 5, 0, 2, 1, 4, 2, 5, 13, 4, 1, 1, 7, 5, 0, 2, 3, 2, 7, 0, 5, 2, 13, 2, 15, 1, 1, 4, 7, 4, 2, 6, 2, 1, 6, 1, 1, 1, 0, 1, 2, 1, 1, 4, 3, 0, 3, 8, 1, 4, 7, 4, 5, 5, 4, 4, 0, 6, 2, 5, 0, 1, 3, 1, 1, 0, 4, 9, 3, 8, 2, 2, 0, 0, 0, 5, 3, 5, 2, 10, 4, 0, 9, 2, 5, 2, 1, 4, 9, 1, 8, 7, 2, 1, 2, 17, 4, 7, 0, 2, 0, 6, 3, 4, 4, 3, 6, 6, 2, 1, 2, 8, 6, 0, 5, 5, 6, 0, 1, 5, 4, 7, 8, 1, 8, 5, 3, 9, 7, 11, 8, 5, 1, 3, 4, 4, 0, 1, 0, 2, 6, 5, 8, 5, 1, 7, 2, 0, 7, 0, 9, 12, 5, 6, 5, 5, 0, 2, 7, 7, 1, 1, 0, 3, 4, 0, 4, 6, 1, 4, 3, 4, 7, 0, 9, 0, 1, 4, 3, 6, 2, 9, 10, 0, 9, 1, 9, 2, 2, 0, 12, 1, 3, 2, 1, 11, 3, 3, 4, 3, 4, 5, 0, 2, 0, 2, 10, 2, 3, 1, 13, 2, 7, 0, 5, 2, 0, 10, 7, 7, 2, 7, 5, 1, 4, 5, 0, 0, 2, 1, 0, 6, 2, 0, 14, 8, 0, 2, 5, 5, 3, 2, 10, 0, 0, 2, 6, 0, 2, 3, 7, 2, 3, 3, 3, 6, 4, 3, 0, 13, 2, 1, 1, 10, 2, 6, 8, 2, 1, 12, 1, 0, 0, 5, 9, 7, 1, 1, 1, 5, 8, 8, 1, 3, 3, 5, 4, 4, 3, 1, 3, 9, 1, 13, 12, 1, 5, 5, 5, 4, 4, 5, 6, 0, 3, 1, 3, 0, 0, 2, 2, 12, 0, 1, 4, 0, 1, 0, 1, 1, 1, 1, 5, 8, 5, 3, 1, 5, 1, 4, 4, 2, 3, 0, 3, 3, 4, 6, 5, 9, 5, 2, 4, 0, 8, 1, 6, 1, 1, 1, 0, 3, 1, 4, 1, 3, 1, 2, 0, 2, 8, 4, 0, 1, 0, 1, 2, 3, 1, 2, 1, 0, 12, 5, 1, 6, 0, 2, 4, 8, 4, 0, 1, 0, 0, 0, 1, 2, 0, 2, 2, 14, 1, 5, 10, 9, 9, 1, 8, 5, 10, 0, 0, 0, 8, 6, 1, 0, 0, 7, 4, 0, 2, 7, 8, 4, 3, 0, 4, 0, 0, 0, 1, 0, 4, 8, 2, 2, 4, 4, 3, 6, 5, 2, 7, 6, 2, 3, 6, 7, 3, 10, 0, 1, 2, 8, 12, 0, 9, 2, 3, 3, 9, 7, 13, 6, 2, 3, 6, 9, 3, 3, 1, 3, 0, 0, 2, 0, 1, 6, 1, 4, 0, 0, 0, 3, 8, 3, 10, 4, 1, 8, 5, 4, 1, 4, 1, 3, 6, 1, 1, 7, 1, 8, 11, 11, 6, 0, 1, 6, 0, 2, 1, 6, 4, 0, 3, 2, 3, 2, 1, 1, 6, 2, 10, 2, 0, 6, 12, 8, 8, 1, 8, 6, 3, 0, 11, 2, 3, 2, 6, 0, 0, 1, 1, 1, 1, 6, 1, 7, 4, 1, 1, 1, 0, 1, 3, 3, 7, 6, 11, 3, 6, 2, 9, 0, 2, 2, 6, 0, 2, 4, 0, 0, 5, 4, 7, 0, 2, 1, 10, 13, 5, 2, 7, 1, 0, 4, 6, 4, 3, 2, 1, 0, 11, 0, 1, 1, 5, 2, 1, 2, 2, 1, 11, 3, 10, 1, 8, 9, 6, 1, 4, 10, 6, 9, 6, 1, 10, 3, 8, 6, 9, 0, 3, 2, 2, 0, 0, 4, 5, 2, 3, 1, 1, 1, 8, 13, 2, 7, 2, 7, 3, 0, 4, 4, 2, 6, 1, 2, 4, 6, 10, 2, 9, 2, 3, 5, 10, 0, 3, 7, 3, 10, 1, 5, 4, 1, 1, 5, 1, 4, 1, 0, 2, 2, 3, 8, 2, 2, 2, 4, 0, 8, 2, 1, 11, 3, 1, 9, 13, 12, 1, 1, 3, 6, 4, 1, 3, 0, 8, 1, 7, 0, 1, 6, 2, 9, 9, 10, 2, 5, 1, 1]","[1, 1, 1]",,,,
List the diabetes outcomes of the bottom 2 individuals with the lowest BMI.,What are the diabetes outcomes for the two individuals with the lowest BMI?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the two individuals with the lowest BMI
    min_bmi_individuals = dataset.nsmallest(2, 'BMI')
    
    # Get their diabetes outcomes
    outcomes = min_bmi_individuals['Outcome'].tolist()
    
    return outcomes",list of (uint8),"[1, 0]","[0, 0]",,,,
List the diabetes outcomes of the top 5 individuals with the highest insulin levels.,What are the diabetes outcomes for the top 5 individuals with the highest insulin levels?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_5_insulin_individuals = dataset.nlargest(5, 'Insulin')
    outcomes = top_5_insulin_individuals['Outcome'].tolist()

    return outcomes
",list of (uint8),"[1, 0, 0, 1, 1]","[1, 1, 1, 1, 1]",,,,
List the diabetes outcomes of the bottom 4 individuals with the lowest blood pressure.,Retrieve the diabetes outcomes for the four individuals with the lowest blood pressure.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sorted_dataset = dataset.sort_values(by='BloodPressure')
    lowest_blood_pressure_individuals = sorted_dataset.head(4)
    outcomes = lowest_blood_pressure_individuals['Outcome'].tolist()

    return outcomes
",list of (uint8),"[0, 0, 0, 0]","[0, 0, 0, 0]",,,,
What are the ages of the top 4 individuals with the highest number of pregnancies?,What are the ages of the top 4 individuals with the highest number of pregnancies?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_4_pregnancies = dataset.nlargest(4, 'Pregnancies')
ages_of_top_4 = top_4_pregnancies['Age'].tolist()

return ages_of_top_4
",list of (int64),"[47, 43, 46, 38]","[51, 67, 67, 67]",,,,
List the BMI of the bottom 3 individuals with the lowest glucose levels.,Retrieve the BMI values for the three individuals with the lowest glucose levels.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by Glucose in ascending order
    sorted_dataset = dataset.sort_values(by='Glucose', ascending=True)
    
    # Retrieve the BMI values for the three individuals with the lowest glucose levels
    bmi_values = sorted_dataset.head(3)['BMI'].tolist()
    
    return bmi_values
",list of (float64),"[24.7, 39.0, 41.0]","[32.0, 32.0, 32.0]",,,,
Enumerate the blood pressure levels of the top 5 individuals with the highest Diabetes Pedigree Function scores.,List the blood pressure levels for the top 5 individuals with the highest Diabetes Pedigree Function scores.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_5_individuals = dataset.nlargest(5, 'DiabetesPedigreeFunction')
    blood_pressure_levels = top_5_individuals['BloodPressure'].tolist()

    return blood_pressure_levels
",list of (uint8),"[78, 70, 40, 82, 66]","[0, 0, 0, 0, 0]",,,,
Provide the glucose levels of the 2 individuals with the highest insulin levels.,What are the glucose levels for the two individuals with the highest insulin levels?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_two_insulin_individuals = dataset.nlargest(2, 'Insulin')
    glucose_levels = top_two_insulin_individuals['Glucose'].tolist()

    return glucose_levels",list of (int64),"[189, 197]","[189, 197]",,,,
Are there any articles that have the material type 'Op-Ed'?,Is there at least one article with the material type 'Op-Ed'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_op_ed = 'Op-Ed' in dataset['material_type'].values

return has_op_ed
",bool,True,True,,,,
Does the article with the longest headline contain the keyword 'United States Politics and Government'?,,,,ERROR,False,,,,
Is there any article published on '2021-01-05'?,,,,ERROR,True,,,,
Does any article contain more than 10 keywords?,,,,ERROR,True,,,,
How many unique material types are there in the dataset?,What is the count of distinct material types in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_material_types_count = dataset['material_type'].nunique()
    return distinct_material_types_count
",int64,16,16,,,,
What is the longest length of a headline in the dataset?,What is the maximum length of headlines in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_headline_length = dataset['headline'].str.len().max()
return max_headline_length
",int64,145.0,147,,,,
How many articles were published on '2021-01-02'?,"What is the count of articles published on January 2, 2021?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    date_filter = pd.to_datetime('2021-01-02')
    count_of_articles = dataset[dataset['date'].dt.date == date_filter.date()].shape[0]
    
    return count_of_articles
",int64,56,52,,,,
What is the highest number of keywords associated with a single article?,,,,ERROR,45,,,,
What is the material type of the article with the longest headline?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific headline or material type based on some criteria
    # For example, let's assume the question is ""What is the material type of the latest news article?""
    latest_article = dataset.loc[dataset['date'] == dataset['date'].max()]
    material_type = latest_article['material_type'].iloc[0]

    return material_type",category,Op-Ed,News,,,,
What is the material type of the article with the shortest headline that is not news or video?,What is the material type of the article with the shortest headline that is neither news nor a video?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter out articles that are either 'News' or 'Video'
    filtered_articles = dataset[~dataset['material_type'].isin(['News', 'Video'])]
    
    # Find the article with the shortest headline
    shortest_headline_article = filtered_articles.loc[filtered_articles['headline'].str.len().idxmin()]
    
    # Get the material type of that article
    material_type = shortest_headline_article['material_type']
    
    return material_type
",category,,Slideshow,,,,
What is the material type of the non-editorial article with the most number of keywords?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a headline based on some criteria
    # For example, let's say we want the most recent headline
    most_recent_headline = dataset.loc[dataset['date'] == dataset['date'].max(), 'headline'].iloc[0]
    
    return most_recent_headline",string,Biden Should Not Run Again — and He Should Say He Won’t,News,,,,
What is the most common material amongst articles with the least number of keywords?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    latest_article = dataset.loc[dataset['date'] == dataset['date'].max()]
    headline = latest_article['headline'].iloc[0]

    return headline",category,Biden Should Not Run Again — and He Should Say He Won’t,News,,,,
List the material types of the top 3 articles with the longest headlines.,What are the material types of the top 3 articles with the longest headlines?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by headline length in descending order
    sorted_dataset = dataset.sort_values(by='headline', key=lambda x: x.str.len(), ascending=False)
    
    # Get the top 3 articles with the longest headlines
    top_3_articles = sorted_dataset.head(3)
    
    # Extract the material types of these articles
    material_types = top_3_articles['material_type'].tolist()
    
    return material_types
",list of (string),"['Interactive Feature', 'News', 'News']","['News', 'News', 'News']",,,,
List the material types of the bottom 2 articles with the shortest headlines that are not videos or slides.,Retrieve the material types for the two articles with the shortest headlines that are neither videos nor slides.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter out articles that are either videos or slides
    filtered_articles = dataset[~dataset['material_type'].isin(['video', 'slides'])]
    
    # Sort the articles by headline length in ascending order
    sorted_articles = filtered_articles.sort_values(by='headline', key=lambda x: x.str.len())
    
    # Retrieve the material types for the two articles with the shortest headlines
    top_material_types = sorted_articles.head(2)['material_type'].tolist()
    
    return top_material_types
",list of (string),"['News', 'News']","['News', 'News']",,,,
List the material types of the top 5 articles with the most number of keywords.,,,,ERROR,"['News', 'News', 'News', 'News', 'News']",,,,
List the material types of the bottom 4 articles with the least number of keywords.,,,,ERROR,"['News', 'News', 'News', 'News']",,,,
What are the lengths of the headlines of the top 4 articles with the most number of keywords?,,,,ERROR,"[86, 85, 84, 84]",,,,
List the number of keywords in the bottom 3 articles with the shortest headlines.,,,,ERROR,"[1, 1, 1]",,,,
Enumerate the lengths of the headlines of the top 5 articles with the longest headlines.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for something that requires a list of integers as an answer,
    # we need to extract relevant data and convert it to the expected format.
    
    # For demonstration purposes, let's assume the question is:
    # ""What are the indices of all articles published in 2020?""
    
    # Filter the dataset for articles published in 2020
    filtered_articles = dataset[dataset['date'].dt.year == 2020]
    
    # Get the indices of these articles
    article_indices = filtered_articles.index.tolist()
    
    return article_indices",list of (int64),[],"[96, 96, 95, 95, 95]",,,,
Provide the number of keywords in the bottom 2 articles with the least number of keywords.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a numerical value based on some condition or aggregation.
    # For example, let's say we want to count the number of articles published on a specific date.
    
    # Example question: ""How many articles were published on '2023-01-01'?""
    
    # Convert the date string to datetime if needed
    target_date = pd.to_datetime('2023-01-01')
    
    # Filter the dataset for the target date
    filtered_articles = dataset[dataset['date'].dt.date == target_date.date()]
    
    # Count the number of articles
    article_count = len(filtered_articles)
    
    return article_count",int64,0,"[1, 1]",,,,
Is the 'USA' the most common entry in the 'Geographies' column?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass
",bool,,False,,,,
Are there any participants who are unemployed with a bachelor's degree from Africa?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass
",bool,,False,,,,
Do all participants recommend Python as the first programming language?,Does every participant suggest Python as the initial programming language to learn?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Check if every participant suggests Python as the initial programming language to learn
    all_suggest_python = dataset['What programming language would you recommend an aspiring data scientist to learn first?'].str.lower() == 'python'
    
    return all_suggest_python.all()
",bool,False,False,,,,
Are there more than 1000 participants who hope to become familiar with AWS in the next 2 years?,,,,ERROR,False,,,,
How many unique job titles are represented in the dataset?,,,,ERROR,14,,,,
What's the median of the average number of years participants have used machine learning methods?,,,,ERROR,1.5,,,,
How many participants are from the United Kingdom?,,,,ERROR,450,,,,
What is the most common number of programming languages used by participants on a regular basis?,What is the highest frequency of programming languages used by participants on a regular basis?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each programming language in the 'What programming languages do you use on a regular basis?' column
    language_counts = dataset['What programming languages do you use on a regular basis?'].str.split(';').explode().value_counts()
    
    # Get the highest frequency
    max_frequency = language_counts.max()

    return max_frequency
",int64  ,,2,,,,
What's the most common computing platform used for data science projects?,,,,ERROR,A laptop,,,,
What's the most common programming language used on a regular basis?,,,,ERROR,Python,,,,
Which country has the second highest number of participants?,,,,ERROR,United States of America,,,,
Which title is the most common among participants?,,,,ERROR,Data Scientist,,,,
What are the top 4 geographies represented in the dataset?,,,,ERROR,"['India', 'USA', 'Western Europe', 'China - Japan - Korea']",,,,
Name the top 3 general segments of participants.,What are the top 3 general segments of participants in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_3_segments = dataset['General Segments'].value_counts().head(3).index.tolist()
    return top_3_segments
",list of (string),"[array(['Analysts'], dtype=object), array(['Data Scientists'], dtype=object), array(['Academics'], dtype=object)]","['Analysts', 'Data Scientists', 'Academics']",,,,
list the top 4 most common job titles.,,,,ERROR,"['Data Scientist', 'Software Engineer', 'Other', 'Data Analyst']",,,,
Identify the top 6 programming languages used regularly.,What are the top 6 programming languages used regularly by professionals?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the occurrences of each programming language in the 'What programming languages do you use on a regular basis?' column
    language_counts = dataset['What programming languages do you use on a regular basis?'].str.split(';').explode().value_counts()
    
    # Get the top 6 most common programming languages
    top_languages = language_counts.head(6).index.tolist()
    
    return top_languages
",list of (string),[],"['Python', 'SQL', 'R', 'Javascript', 'C++', 'Java']",,,,
Report the top 4 age ranges of participants by frequency,,,,ERROR,"['25-29', '30-34', '22-24', '35-39']",,,,
list the highest average 3 years of machine learning experience.,Provide the highest average 3 years of machine learning experience from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_experience = dataset['(Average) For how many years have you used machine learning methods?'].max()
    return [max_experience]
",list of (float64),[np.float64(20.0)],"[19.83, 19.74, 19.68]",,,,
Identify the 5 highest yearly compensations.,Find the top 5 highest yearly compensations.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_compensations = dataset.nlargest(5, '(Average) What is your current yearly compensation (approximate $USD)?')
compensation_values = top_5_compensations['(Average) What is your current yearly compensation (approximate $USD)?'].tolist()

return compensation_values
",list of (float64),"[1000000.0, 1000000.0, 1000000.0, 1000000.0, 1000000.0]","[1000000, 1000000, 1000000, 1000000, 1000000]",,,,
Report the 5 most common sizes of the company where participants work.,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass
",list of (int64),,"['0-49 employees', '10,000 or more employees', '1000-9,999 employees', '50-249 employees', '250-999 employees']",,,,
Are there more reviews with rating 5 from 'GB' than 'US'?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the maximum rating in the dataset
    max_rating = dataset['rating'].max()
    
    # Check if there is at least one review with the maximum rating
    has_max_rating_review = (dataset['rating'] == max_rating).any()

    return has_max_rating_review",bool,True,True,,,,
Is the average rating for 'Wise' in 'GB' above 4?,Is the average rating for entries with title 'Wise' and country code 'GB' greater than 4?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_rating = dataset.loc[(dataset[""title""] == ""Wise"") & (dataset[""country_code""] == ""GB""), ""rating""].mean()
is_greater_than_four = average_rating > 4

return is_greater_than_four",bool,True,True,,,,
Do any reviews originate from 'AO'?,Are there any reviews from the country code 'AO'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_reviews_from_AO = not dataset[dataset['country_code'] == 'AO'].empty

    return has_reviews_from_AO
",bool,True,True,,,,
Did any reviews receive a rating of 1?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any reviews with a rating of 5
    has_five_star_review = (dataset['rating'] == 5).any()
    
    return has_five_star_review
",bool,True,True,,,,
What's the total number of reviews for 'Wise'?,What is the sum of reviews for the title 'Wise'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count = dataset[dataset['title'] == 'Wise'].shape[0]
    return count
",int64,4,3840,,,,
How many unique countries gave 'Wise' a rating of 5?,How many distinct countries have given the title 'Wise' a rating of 5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[(dataset['title'] == 'Wise') & (dataset['rating'] == 5)]
    distinct_countries_count = filtered_data['country_code'].nunique()
    
    return distinct_countries_count
",int64  ,3,120,,,,
What is the highest rating received?,What is the maximum rating given in the reviews?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_rating = dataset[""rating""].max()
return max_rating",uint8,5,5,,,,
What's the average rating across all reviews?,What is the average rating for all reviews?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_rating = dataset['rating'].mean()
return average_rating
",float64,4.097756000000000,4.097756000000000,,,,
Which company received the most 5-star reviews?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific piece of information from the dataset
    # For example, if the question is ""What is the title of the review with the highest rating?"",
    # we can find the answer as follows:
    
    # Find the row with the highest rating
    max_rating_review = dataset.loc[dataset[""rating""] == dataset[""rating""].max()]
    
    # Get the title of that review
    title_of_max_rating_review = max_rating_review[""title""].iloc[0]
    
    return title_of_max_rating_review",string,Great service,Wise,,,,
From which country did 'Wise' receive the most reviews?,In which country did the company 'Wise' receive the highest number of reviews?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    wise_reviews = dataset[dataset['Company'] == 'Wise']
    country_counts = wise_reviews['country_code'].value_counts()
    highest_review_country = country_counts.idxmax()

    return highest_review_country
",string,GB,GB,,,,
Which country had the lowest representation in the reviews?,"In the reviews, which country had the fewest entries?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    country_counts = dataset['country_code'].value_counts()
    country_with_fewest_entries = country_counts.idxmin()

    return country_with_fewest_entries",string,CW,CW,,,,
Which company received the lowest rating?,Which company has the minimum rating?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_rating_company = dataset.loc[dataset[""rating""] == dataset[""rating""].min()]
    company_name = min_rating_company[""Company""].iloc[0]

    return company_name
",category,Wise,N26,,,,
Which are the top 3 countries with the most 5-star reviews for 'Wise'?,What are the top 3 countries with the highest number of 5-star reviews for the company 'Wise'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for the company 'Wise' and 5-star reviews
    wise_5_star_reviews = dataset[(dataset['Company'] == 'Wise') & (dataset['rating'] == 5)]
    
    # Group by country_code and count the number of 5-star reviews
    country_counts = wise_5_star_reviews['country_code'].value_counts()
    
    # Get the top 3 countries with the highest number of 5-star reviews
    top_countries = country_counts.head(3).index.tolist()
    
    return top_countries
",list of (string),"['GB', 'US', 'ES']","['GB', 'US', 'ES']",,,,
Which are the 2 companies represented in the dataset?,What are the names of the two companies included in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    company_names = dataset['Company'].unique().tolist()
    
    return company_names[:2]
",list of (string),"['Wise', 'N26']","['Wise', 'N26']",,,,
Which are the bottom 4 countries in terms of review count? If two or more have the same number order them alphabetically.,"What are the countries with the lowest 4 review counts? If there is a tie, order them alphabetically.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by country_code and count the number of reviews for each country
    review_counts = dataset['country_code'].value_counts().reset_index()
    review_counts.columns = ['country_code', 'count']
    
    # Sort by count in ascending order, then alphabetically by country_code
    sorted_countries = review_counts.sort_values(by=['count', 'country_code'], ascending=[True, True])
    
    # Get the lowest 4 countries
    lowest_4_countries = sorted_countries.head(4)['country_code'].tolist()
    
    return lowest_4_countries
",list of (string),"['AI', 'KR', 'FO', 'PY']","['CW', 'FO', 'KZ', 'NE']",,,,
What are the 3 most common countries? If two or more have the same number order them alphabetically.,"Which are the top 3 countries with the highest frequency? If there is a tie, order them alphabetically.","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    country_counts = dataset['country_code'].value_counts().sort_values(ascending=False)
    top_countries = country_counts.index[:3].tolist()
    
    return top_countries
",list of (string),"['GB', 'DE', 'FR']","['GB', 'DE', 'FR']",,,,
What are the 3 most common ratings?,What are the top 3 most frequent ratings in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    rating_counts = dataset['rating'].value_counts().nlargest(3).index.tolist()
    
    return rating_counts
",list of (int64),"[5, 1, 4]","[5, 1, 4]",,,,
What are the 2 least common ratings?,What are the two least frequent ratings in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
rating_counts = dataset['rating'].value_counts().sort_values(ascending=True).head(2)
least_frequent_ratings = rating_counts.index.tolist()

return least_frequent_ratings",list of (int64),"[3, 2]","[3, 2]",,,,
What are the best 4 unique ratings given to 'Wise'?,What are the top 4 distinct ratings given to the product titled 'Wise'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['title'] == 'Wise']
    top_ratings = filtered_data['rating'].unique().tolist()
    top_ratings.sort(reverse=True)
    return top_ratings[:4]",list of (int64),[5],"[5, 4, 2, 1]",,,,
What are the bottom 5 unique ratings given to 'N26'?,What are the five lowest unique ratings given to the company 'N26'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    n26_reviews = dataset[dataset['Company'] == 'N26']
    unique_ratings = n26_reviews['rating'].unique()
    lowest_unique_ratings = sorted(unique_ratings)[:5]

    return lowest_unique_ratings
",list of (int64),"[np.uint8(1), np.uint8(2), np.uint8(3), np.uint8(4), np.uint8(5)]","[1, 2, 3, 4, 5]",,,,
Is there any customer with a PhD education level?,Is there any customer in the dataset with an education level of PhD?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_phd = ""PhD"" in dataset[""Education""].values

return has_phd
",bool  ,True,True,,,,
Do we have any customers who are married?,Are there any customers with a marital status indicating they are married?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_married_customers = ""Married"" in dataset[""Marital_Status""].values

return has_married_customers",bool,True,True,,,,
Is there any customer with income higher than 100000?,Is there any customer with an income greater than 100000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_income_customer = (dataset[""Income""] > 100000).any()
    
    return has_high_income_customer
",bool,True,True,,,,
Has any customer made more than 10 web purchases?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is ""Is the average income of customers who have made more than 5 web purchases higher than $5000?""
    avg_income_high_web_purchases = dataset[dataset['NumWebPurchases'] > 5]['Income'].mean()
    is_avg_income_higher_than_5000 = avg_income_high_web_purchases > 5000

    return is_avg_income_higher_than_5000
",bool,True,True,,,,
How many customers do we have in the dataset?,What is the total number of customers in the Delicatessen dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    total_customers = len(dataset)
    return total_customers
",int64  ,2240,2240,,,,
What's the average income of our customers?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_income = dataset[""Income""].mean()

return average_income",float64,52247.25135400000,52247.25135400000,,,,
What's the maximum number of web purchases made by a customer?,What is the highest number of web purchases made by any customer?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_web_purchases = dataset[""NumWebPurchases""].max()
return max_web_purchases
",uint8  ,27,27,,,,
What's the minimum recency of purchase among the customers?,What is the smallest recency value among all customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_recency = dataset[""Recency""].min()
    return min_recency
",uint8  ,0,0,,,,
What's the most common education level among our customers?,What is the most frequent education level among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_education = dataset['Education'].mode()[0]
    return most_frequent_education
",string,Graduation,Graduation,,,,
What's the most common marital status among our customers?,What is the most frequent marital status among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
most_frequent_marital_status = dataset['Marital_Status'].mode()[0]
return most_frequent_marital_status
",string,Married,Married,,,,
Who is the customer with the highest income?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value from the dataset
    # For example, if the question is ""What is the maximum income in the dataset?""
    max_income = dataset['Income'].max()
    
    return max_income",uint16,666666.0,9432,,,,
Who is the customer with the most recent purchase?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value or some derived information from the dataset.
    # For demonstration purposes, let's assume the question is ""What is the most common education level among customers?""
    
    # Find the mode of the 'Education' column
    most_common_education = dataset['Education'].mode()[0]
    
    return most_common_education
",string,Graduation,4047,,,,
Who are the 3 customers with the highest income?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of unique marital statuses
    unique_marital_statuses = dataset['Marital_Status'].unique().tolist()
    
    return unique_marital_statuses",list of (string),"['Single', 'Together', 'Married', 'Divorced', 'Widow', 'Alone', 'Absurd', 'YOLO']","[9432, 1503, 1501]",,,,
What are the 2 most common education levels among our customers?,What are the top 2 most frequent education levels among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Education and count occurrences
    education_counts = dataset['Education'].value_counts()
    
    # Get the top 2 most frequent education levels
    top_2_education_levels = education_counts.head(2).index.tolist()
    
    return top_2_education_levels
",list of (string),"['Graduation', 'PhD']","['Graduation', 'PhD']",,,,
What are the 3 most common marital statuses among our customers?,What are the three most frequent marital statuses among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each marital status
    marital_status_counts = dataset['Marital_Status'].value_counts()
    
    # Get the three most frequent marital statuses
    top_three_marital_statuses = marital_status_counts.head(3).index.tolist()
    
    return top_three_marital_statuses
",list of (string),"['Married', 'Together', 'Single']","['Married', 'Together', 'Single']",,,,
Who are the 3 customers with the most web purchases?,Which are the top 3 customers with the highest number of web purchases?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_customers = dataset.nlargest(3, 'NumWebPurchases')
customer_ids = top_customers['ID'].astype(str).tolist()

return customer_ids",list of (string),"['5255', '4619', '10311']","[5255, 4619, 10311]",,,,
What are the top 3 income values among our customers?,What are the three highest income values among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_three_incomes = dataset['Income'].nlargest(3).tolist()
    
    return top_three_incomes
",list of (float64),"[666666.0, 162397.0, 160803.0]","[666666.0, 162397.0, 160803.0]",,,,
What are the top 2 recency values among our customers?,What are the two highest Recency values in our customer dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_two_recency_values = dataset['Recency'].nlargest(2).tolist()
    return top_two_recency_values
",list of (int64),"[99, 99]","[99, 99]",,,,
What are the bottom 3 income values among our customers?,What are the three lowest income values among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by Income in ascending order and get the first three rows
    lowest_income_customers = dataset.nsmallest(3, 'Income')
    
    # Extract the Income values from these rows
    income_values = lowest_income_customers['Income'].tolist()
    
    return income_values",list of (float64),"[1730.0, 2447.0, 3502.0]","[1730.0, 2447.0, 3502.0]",,,,
What are the bottom 2 recency values among our customers?,What are the two smallest recency values among our customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sorted_recency = dataset.sort_values(by='Recency')
    smallest_two_recency = sorted_recency['Recency'].head(2).tolist()
    
    return smallest_two_recency
",list of (uint8),"[0, 0]","[0, 0]",,,,
Is there any customer with a high salary?,Is there any employee with a high salary level?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_salary = any(dataset[""salary""] == ""high"")
    
    return has_high_salary
",bool,True,True,,,,
Do we have any employees who suffered a work accident?,Are there any employees who had a work accident?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_work_accident = ""Yes"" in dataset[""Work Accident""].unique()
    
    return has_work_accident
",bool,True,True,,,,
Is there any employee with more than 100 hours per month on average?,Are there any employees with an average of more than 100 hours worked per month?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
employees_with_high_hours = dataset[dataset['Average Monthly Hours'] > 100]
has_employees_with_high_hours = not employees_with_high_hours.empty

return has_employees_with_high_hours",bool,True,True,,,,
Does any employee have a satisfaction level above 0.9?,Is there any employee with a satisfaction level greater than 0.9?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_satisfaction = not dataset[dataset[""Satisfaction Level""] > 0.9].empty

    return has_high_satisfaction
",bool,True,True,,,,
How many employees do we have in the dataset?,What is the total count of employees in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    total_count = len(dataset)
    return total_count
",int64,14999,14999,,,,
What's the median satisfaction level of our employees?,What is the median satisfaction level among our employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
median_satisfaction_level = dataset[""Satisfaction Level""].median()
return median_satisfaction_level
",float64  ,0.64,0.64,,,,
What's the highest number of projects for a given employee?,What is the maximum number of projects completed by any employee?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_projects_employee = dataset['Number of Projects'].max()
return max_projects_employee",uint8  ,7,7,,,,
What's the most common marital status among the employees?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a specific category value based on some condition
# For example, let's say we want to find the most common department where employees have not had a work accident.

# Filter employees who have not had a work accident
no_accident_employees = dataset[dataset[""Work Accident""] == 'No']

# Find the most common department among these employees
most_common_department = no_accident_employees['Department'].mode()[0]

return most_common_department",category,sales,Together,,,,
What's the most common education level among our employees?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Filter the dataset for employees who have left the company
left_employees = dataset[dataset['Left'] == 'Yes']

# Find the employee with the highest satisfaction level among those who have left
highest_satisfaction_employee = left_employees.loc[left_employees['Satisfaction Level'].idxmax()]

# Get the marital status of this employee
marital_status = highest_satisfaction_employee['Marital_Status']

return marital_status",category,Married,Graduation,,,,
What's the most common marital status in the database?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific category value from the dataset
    # For example, if the question asks for the most common department, you can use the following code:
    
    # Find the mode of the 'Department' column
    most_common_department = dataset['Department'].mode()[0]
    
    return most_common_department
",category,sales,Married,,,,
"Among the employees who have left the company in sales, what's the most common salary level?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a specific column value based on some condition
# For example, finding the most common department where employees left

left_employees = dataset[dataset['Left'] == 'Yes']
most_common_department = left_employees['Department'].mode()[0]

return most_common_department",category,sales,low,,,,
"Among the employees who have had a work accident in sales, what's the most common salary level?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
department_with_most_employees = dataset[""Department""].mode()[0]
return department_with_most_employees",category,sales,low,,,,
What are the top 3 satisfaction levels?,What are the top three satisfaction levels among employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_three_satisfaction_levels = dataset['Satisfaction Level'].nlargest(3).tolist()
    
    return top_three_satisfaction_levels
",list of (float64),"[1.0, 1.0, 1.0]","[1, 1, 1]",,,,
What are the top 2 most common Work Accident statuses among our employees?,What are the top 2 most frequent statuses for work accidents among our employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    work_accident_counts = dataset['Work Accident'].value_counts().head(2).index.tolist()
    return work_accident_counts
",list of (string),"['No', 'Yes']","['No', 'Yes']",,,,
What are the top 3 most common marital statuses among our employees?,What are the three most frequently occurring marital statuses among our employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the frequency of each marital status
    marital_status_counts = dataset['Marital_Status'].value_counts()
    
    # Get the top 3 most frequent marital statuses
    top_3_marital_statuses = marital_status_counts.head(3).index.tolist()
    
    return top_3_marital_statuses
",list of (string),"['Together', 'Single', 'Married']","['Together', 'Single', 'Married']",,,,
What are the highest 3 years spent in the company? ,What are the top three highest values for years spent in the company?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_three_years = dataset['Years in the Company'].nlargest(3).tolist()
return top_three_years
",list of (int64),"[10, 10, 10]","[10, 10, 10]",,,,
What are the 3 departments with more 'medium' salary levels?,Which three departments have the highest count of employees with a 'medium' salary level?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    medium_salary_employees = dataset[dataset['salary'] == 'medium']
    department_counts = medium_salary_employees['Department'].value_counts().head(3).index.tolist()
    
    return list(department_counts)
",list of (string),"['sales', 'technical', 'support']","['sales', 'technical', 'support']",,,,
"For the 2 employees with the top satisfaction levels who belong to the sales department, what are their salary levels?",What are the salary levels of the two employees with the highest satisfaction levels who work in the sales department?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only employees in the Sales department
    sales_employees = dataset[dataset['Department'] == 'Sales']
    
    # Sort the filtered dataset by Satisfaction Level in descending order
    sorted_sales_employees = sales_employees.sort_values(by='Satisfaction Level', ascending=False)
    
    # Get the top 2 employees with the highest satisfaction levels
    top_2_employees = sorted_sales_employees.head(2)
    
    # Extract the salary levels of these two employees
    salaries = top_2_employees['salary'].tolist()
    
    return salaries
",list of (string),[],"['low', 'low']",,,,
What are the top 3 average monthly hours worked among the employees in the top 3 departments with the most employees?,What are the top 3 average monthly hours worked by employees in the departments with the highest number of employees?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by department and count the number of employees in each department
    department_counts = dataset['Department'].value_counts()
    
    # Get the top 3 departments with the highest number of employees
    top_departments = department_counts.index[:3]
    
    # Filter the dataset to include only the top departments
    filtered_dataset = dataset[dataset['Department'].isin(top_departments)]
    
    # Sort the filtered dataset by 'Average Monthly Hours' in descending order
    sorted_dataset = filtered_dataset.sort_values(by='Average Monthly Hours', ascending=False)
    
    # Get the top 3 average monthly hours from the sorted dataset
    top_3_average_hours = sorted_dataset['Average Monthly Hours'].head(3).tolist()
    
    return top_3_average_hours
",list of (int64),"[310, 310, 310]","[200.91135265700484, 202.49742647058824, 200.75818752803949]",,,,
What are the lowest 2 satisfaction levels among the employees who have not had a work accident?,What are the two lowest satisfaction levels for employees who have not experienced a work accident?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter employees who have not experienced a work accident
    no_accident_employees = dataset[dataset['Work Accident'] == 'No']
    
    # Get the two lowest satisfaction levels from these employees
    two_lowest_satisfactions = no_accident_employees['Satisfaction Level'].nsmallest(2).tolist()
    
    return two_lowest_satisfactions
",list of (float64),"[0.09, 0.09]","[0.09, 0.09]",,,,
"Is there any country with a Ladder score above 7.5, a Generosity score above 0.2, and a Social support score above 0.7?","Is there any country with a Ladder score greater than 7.5, a Generosity score greater than 0.2, and a Social support score greater than 0.7?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_countries = dataset[(dataset[""Ladder score""] > 7.5) & 
                               (dataset[""Generosity""] > 0.2) & 
                               (dataset[""Social support""] > 0.7)]
    
    return not filtered_countries.empty
",bool,True,True,,,,
"Are there any countries in Western Europe with a Perceptions of corruption score above 0.5, a Ladder score above 7, and a Social support score above 0.7?","Is there any country in Western Europe with a Perceptions of corruption score greater than 0.5, a Ladder score greater than 7, and a Social support score greater than 0.7?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    western_europe_countries = dataset[dataset['Regional indicator'] == 'Western Europe']
    filtered_countries = western_europe_countries[(western_europe_countries['Perceptions of corruption'] > 0.5) & 
                                                 (western_europe_countries['Ladder score'] > 7) & 
                                                 (western_europe_countries['Social support'] > 0.7)]
    result = not filtered_countries.empty
    return result
",bool,True,True,,,,
Are there any countries in Western Europe with a Perceptions of corruption score above 0.5?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there exists any country with a ladder score greater than 7.5
    high_ladder_score_countries = dataset[dataset['Ladder score'] > 7.5]
    
    # Check if there are any countries meeting this criteria
    has_high_ladder_score_country = not high_ladder_score_countries.empty
    
    return has_high_ladder_score_country",bool,True,True,,,,
Is there any country with a Social support score below 0.5?,Is there any country in the dataset with a Social support score less than 0.5?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_low_social_support = dataset[""Social support""].min() < 0.5

return has_low_social_support",bool,True,True,,,,
What's the average Ladder score among the countries in Western Europe with a Generosity score above 0.2 and a Social support score above 0.7?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_ladder_score = dataset[""Ladder score""].mean()
return average_ladder_score",float64,5.473240000000000,7.222675000000000,,,,
What's the average Perceptions of corruption score among the countries in Sub-Saharan Africa with a Ladder score below 5 and a Social support score below 0.5?,,,,ERROR,0.7493710000,,,,
What's the maximum Generosity score among the countries?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Find the average ladder score for countries in the 'Sub-Saharan Africa' region
sub_saharan_africa_avg_ladder_score = dataset.loc[dataset['Regional indicator'] == 'Sub-Saharan Africa', 'Ladder score'].mean()

return sub_saharan_africa_avg_ladder_score",float64,4.383495000000000,0.560664000,,,,
What's the minimum Social support score among the countries?,What is the lowest Social support score across all countries?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_social_support = dataset[""Social support""].min()
    
    return min_social_support
",float64,0.319460000,0.319460000,,,,
Which region has the highest number of countries with a Ladder score above 7 and a Generosity score above 0.2?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific country name or regional indicator
    # For example, ""What is the Regional indicator of France?""
    # The code will need to be adjusted based on the actual question

    # Example: Extracting the 'Regional indicator' for 'France'
    country_name = ""France""  # This should be replaced with the actual country name from the question
    regional_indicator = dataset.loc[dataset[""Country name""] == country_name, ""Regional indicator""].iloc[0]

    return regional_indicator",string,Western Europe,Western Europe,,,,
Which region accounts for the most countries with a Generosity score above 0.2?,Which regional indicator has the highest number of countries with a Generosity score greater than 0.2?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['Generosity'] > 0.2]
    regional_counts = filtered_data['Regional indicator'].value_counts()
    highest_count_region = regional_counts.idxmax()

    return highest_count_region
",category,Western Europe,Western Europe,,,,
In which region are the majority of countries with a Perceptions of corruption score below 0.5 located?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    country_with_highest_ladder_score = dataset.loc[dataset[""Ladder score""] == dataset[""Ladder score""].max()]
    highest_ladder_score_country_name = country_with_highest_ladder_score['Country name'].iloc[0]

    return highest_ladder_score_country_name",category,Finland,Western Europe,,,,
In which region can you find the majority of countries with a Social support score above 0.7?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column value from the first row of the dataset
    country_name = dataset.iloc[0]['Country name']
    
    return country_name
",string,Finland,Western Europe,,,,
Can you name the three regions that have the most countries with a Ladder score above 7 and a Generosity score above 0.2?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a list of country names that meet certain criteria
    # For example, let's say we want to find countries with a Ladder score greater than 7.0
    filtered_countries = dataset[dataset['Ladder score'] > 7.0]['Country name'].tolist()
    
    return filtered_countries",list of (string),"['Finland', 'Denmark', 'Switzerland', 'Iceland', 'Norway', 'Netherlands', 'Sweden', 'New Zealand', 'Austria', 'Luxembourg', 'Canada', 'Australia', 'United Kingdom', 'Israel', 'Costa Rica', 'Ireland', 'Germany']",['Western Europe'],,,,
What are the top 3 regions with the most countries with a Generosity score above 0.2?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the country names from the dataset
    country_names = dataset['Country name'].tolist()
    
    return country_names",list of (string),"['Finland', 'Denmark', 'Switzerland', 'Iceland', 'Norway', 'Netherlands', 'Sweden', 'New Zealand', 'Austria', 'Luxembourg', 'Canada', 'Australia', 'United Kingdom', 'Israel', 'Costa Rica', 'Ireland', 'Germany', 'United States', 'Czech Republic', 'Belgium', 'United Arab Emirates', 'Malta', 'France', 'Mexico', 'Taiwan Province of China', 'Uruguay', 'Saudi Arabia', 'Spain', 'Guatemala', 'Italy', 'Singapore', 'Brazil', 'Slovenia', 'El Salvador', 'Kosovo', 'Panama', 'Slovakia', 'Uzbekistan', 'Chile', 'Bahrain', 'Lithuania', 'Trinidad and Tobago', 'Poland', 'Colombia', 'Cyprus', 'Nicaragua', 'Romania', 'Kuwait', 'Mauritius', 'Kazakhstan', 'Estonia', 'Philippines', 'Hungary', 'Thailand', 'Argentina', 'Honduras', 'Latvia', 'Ecuador', 'Portugal', 'Jamaica', 'South Korea', 'Japan', 'Peru', 'Serbia', 'Bolivia', 'Pakistan', 'Paraguay', 'Dominican Republic', 'Bosnia and Herzegovina', 'Moldova', 'Tajikistan', 'Montenegro', 'Russia', 'Kyrgyzstan', 'Belarus', 'North Cyprus', 'Greece', 'Hong Kong S.A.R. of China', 'Croatia', 'Libya', 'Mongolia', 'Malaysia', 'Vietnam', 'Indonesia', 'Ivory Coast', 'Benin', 'Maldives', 'Congo (Brazzaville)', 'Azerbaijan', 'Macedonia', 'Ghana', 'Nepal', 'Turkey', 'China', 'Turkmenistan', 'Bulgaria', 'Morocco', 'Cameroon', 'Venezuela', 'Algeria', 'Senegal', 'Guinea', 'Niger', 'Laos', 'Albania', 'Cambodia', 'Bangladesh', 'Gabon', 'South Africa', 'Iraq', 'Lebanon', 'Burkina Faso', 'Gambia', 'Mali', 'Nigeria', 'Armenia', 'Georgia', 'Iran', 'Jordan', 'Mozambique', 'Kenya', 'Namibia', 'Ukraine', 'Liberia', 'Palestinian Territories', 'Uganda', 'Chad', 'Tunisia', 'Mauritania', 'Sri Lanka', 'Congo (Kinshasa)', 'Swaziland', 'Myanmar', 'Comoros', 'Togo', 'Ethiopia', 'Madagascar', 'Egypt', 'Sierra Leone', 'Burundi', 'Zambia', 'Haiti', 'Lesotho', 'India', 'Malawi', 'Yemen', 'Botswana', 'Tanzania', 'Central African Republic', 'Rwanda', 'Zimbabwe', 'South Sudan', 'Afghanistan']","['Western Europe', 'Southeast Asia', 'Sub-Saharan Africa']",,,,
Identify the three highest Ladder scores from countries in Western Europe that have a Generosity score above 0.2 and a Social support score above 0.7.,Find the three highest Ladder scores from countries in Western Europe that have a Generosity score above 0.2 and a Social support score above 0.7.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter countries in Western Europe with Generosity > 0.2 and Social support > 0.7
    filtered_countries = dataset[
        (dataset['Regional indicator'] == 'Western Europe') &
        (dataset['Generosity'] > 0.2) &
        (dataset['Social support'] > 0.7)
    ]
    
    # Sort the filtered countries by Ladder score in descending order
    sorted_countries = filtered_countries.sort_values(by='Ladder score', ascending=False)
    
    # Get the top three Ladder scores
    top_three_ladder_scores = sorted_countries.head(3)['Ladder score'].tolist()
    
    return top_three_ladder_scores
",list of (float64),"[7.504499912, 7.448900223, 7.164500237]","[7.504499912, 7.448900223, 7.164500237]",,,,
What are the top 3 Perceptions of corruption scores among the countries in Sub-Saharan Africa?,What are the top 3 perceptions of corruption scores for countries in Sub-Saharan Africa?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sub_saharan_africa_countries = dataset[dataset['Regional indicator'] == 'Sub-Saharan Africa']
    top_3_perceptions_of_corruption = sub_saharan_africa_countries.nlargest(3, 'Perceptions of corruption')['Perceptions of corruption'].tolist()
    
    return top_3_perceptions_of_corruption",list of (float64),"[0.891806662, 0.861874342, 0.861330688]","[0.891806662, 0.861874342, 0.861330688]",,,,
What are the top 3 Generosity scores among the countries in Western Europe?,What are the top 3 generosity scores for countries located in Western Europe?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    western_europe_countries = dataset[dataset['Regional indicator'] == 'Western Europe']
    top_3_generosity_scores = western_europe_countries.sort_values(by='Generosity', ascending=False)['Generosity'].head(3).tolist()
    
    return top_3_generosity_scores
",list of (float64),"[0.263732493, 0.246944219, 0.214965805]","[0.263732493, 0.246944219, 0.214965805]",,,,
What are the top 3 Social support scores among the countries in Sub-Saharan Africa?,What are the top 3 Social support scores for countries in Sub-Saharan Africa?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sub_saharan_africa_countries = dataset[dataset['Regional indicator'] == 'Sub-Saharan Africa']
    top_3_social_support_scores = sub_saharan_africa_countries.nlargest(3, 'Social support')['Social support'].tolist()

    return top_3_social_support_scores
",list of (float64),"[0.910357833, 0.852532268, 0.846880972]","[0.910357833, 0.852532268, 0.846880972]",,,,
Which are the three lowest Ladder scores in Western Europe?,What are the names of the three countries with the lowest Ladder scores in Western Europe?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for countries in Western Europe
    western_europe_countries = dataset[dataset['Regional indicator'] == 'Western Europe']
    
    # Sort the filtered dataset by Ladder score in ascending order
    sorted_countries = western_europe_countries.sort_values(by='Ladder score')
    
    # Get the names of the three countries with the lowest Ladder scores
    lowest_ladder_countries = sorted_countries.head(3)['Country name'].tolist()
    
    return lowest_ladder_countries
",list of (string),"['Greece', 'North Cyprus', 'Portugal']","[5.514999866, 5.53550005, 5.910900116]",,,,
Which are the three lowest Perceptions of corruption scores in Sub-Saharan Africa?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a list of unique country names
unique_countries = dataset['Country name'].unique().tolist()

return unique_countries",list of (string),"['Finland', 'Denmark', 'Switzerland', 'Iceland', 'Norway', 'Netherlands', 'Sweden', 'New Zealand', 'Austria', 'Luxembourg', 'Canada', 'Australia', 'United Kingdom', 'Israel', 'Costa Rica', 'Ireland', 'Germany', 'United States', 'Czech Republic', 'Belgium', 'United Arab Emirates', 'Malta', 'France', 'Mexico', 'Taiwan Province of China', 'Uruguay', 'Saudi Arabia', 'Spain', 'Guatemala', 'Italy', 'Singapore', 'Brazil', 'Slovenia', 'El Salvador', 'Kosovo', 'Panama', 'Slovakia', 'Uzbekistan', 'Chile', 'Bahrain', 'Lithuania', 'Trinidad and Tobago', 'Poland', 'Colombia', 'Cyprus', 'Nicaragua', 'Romania', 'Kuwait', 'Mauritius', 'Kazakhstan', 'Estonia', 'Philippines', 'Hungary', 'Thailand', 'Argentina', 'Honduras', 'Latvia', 'Ecuador', 'Portugal', 'Jamaica', 'South Korea', 'Japan', 'Peru', 'Serbia', 'Bolivia', 'Pakistan', 'Paraguay', 'Dominican Republic', 'Bosnia and Herzegovina', 'Moldova', 'Tajikistan', 'Montenegro', 'Russia', 'Kyrgyzstan', 'Belarus', 'North Cyprus', 'Greece', 'Hong Kong S.A.R. of China', 'Croatia', 'Libya', 'Mongolia', 'Malaysia', 'Vietnam', 'Indonesia', 'Ivory Coast', 'Benin', 'Maldives', 'Congo (Brazzaville)', 'Azerbaijan', 'Macedonia', 'Ghana', 'Nepal', 'Turkey', 'China', 'Turkmenistan', 'Bulgaria', 'Morocco', 'Cameroon', 'Venezuela', 'Algeria', 'Senegal', 'Guinea', 'Niger', 'Laos', 'Albania', 'Cambodia', 'Bangladesh', 'Gabon', 'South Africa', 'Iraq', 'Lebanon', 'Burkina Faso', 'Gambia', 'Mali', 'Nigeria', 'Armenia', 'Georgia', 'Iran', 'Jordan', 'Mozambique', 'Kenya', 'Namibia', 'Ukraine', 'Liberia', 'Palestinian Territories', 'Uganda', 'Chad', 'Tunisia', 'Mauritania', 'Sri Lanka', 'Congo (Kinshasa)', 'Swaziland', 'Myanmar', 'Comoros', 'Togo', 'Ethiopia', 'Madagascar', 'Egypt', 'Sierra Leone', 'Burundi', 'Zambia', 'Haiti', 'Lesotho', 'India', 'Malawi', 'Yemen', 'Botswana', 'Tanzania', 'Central African Republic', 'Rwanda', 'Zimbabwe', 'South Sudan', 'Afghanistan']","[0.183541179, 0.606934547, 0.619799435]",,,,
Is the song with the highest rank from 1965?,Does the song with the highest rank in 1965 exist?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter songs from the year 1965
    songs_1965 = dataset[dataset['Year'] == 1965]
    
    # Check if there are any songs in 1965
    exists_song_in_1965 = not songs_1965.empty
    
    return exists_song_in_1965
",bool,True,True,,,,
Does the song with the lowest rank contain the word 'love' in its lyrics?,Is the song with the minimum rank in the Billboard dataset and contains the word 'love' in its lyrics?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_rank_song = dataset.loc[dataset[""Rank""] == dataset[""Rank""].min()]
    contains_love = 'love' in min_rank_song[""Lyrics""].str.lower().values[0]

    return contains_love
",bool,False,True,,,,
Is the artist of the song with the highest rank the same as the artist of the song with the lowest rank?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the song with the highest rank (lowest numerical value)
    top_song = dataset.loc[dataset[""Rank""] == dataset[""Rank""].min()]
    
    # Check if the lyrics contain the word ""love""
    contains_love = ""love"" in top_song[""Lyrics""].values[0].lower()
    
    return contains_love",bool,False,False,,,,
Are there songs without lyrics?,Is there any song in the dataset that does not have lyrics?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_no_lyrics = dataset['Lyrics'].isnull().any()

    return has_no_lyrics",bool,True,True,,,,
How many songs were produced in 1965?,What is the count of songs released in the year 1965?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count_songs_1965 = dataset[dataset['Year'] == 1965].shape[0]
return count_songs_1965
",int64  ,100,100,,,,
In which year was the song with the highest rank produced?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the song with the highest source value
    max_source_song = dataset.loc[dataset[""Source""] == dataset[""Source""].max()]
    
    # Get the year of the song with the highest source value
    year_of_max_source_song = max_source_song[""Year""].iloc[0]
    
    return year_of_max_source_song",uint16,1965,1965,,,,
What's the rank of the song with the longest lyrics?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_ranked_song = dataset.loc[dataset[""Rank""] == dataset[""Rank""].min()]
rank_value = top_ranked_song[""Rank""].iloc[0]

return rank_value",uint8,1,19,,,,
How many unique artists are there in the dataset?,What is the count of distinct artists in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_artist_count = dataset['Artist'].nunique()
    
    return distinct_artist_count
",int64,2473,2473,,,,
Who is the artist of the song with the highest rank?,What is the name of the artist for the song that has the highest rank?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    highest_rank_song = dataset.loc[dataset[""Rank""] == dataset[""Rank""].min()]
    artist_name = highest_rank_song[""Artist""].iloc[0]

    return artist_name
",category  ,sam the sham and the pharaohs,sam the sham and the pharaohs,,,,
What is the title of the song with the lowest rank?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_song = dataset.loc[dataset[""Rank""] == 1]
    song_title = top_song[""Song""].iloc[0]

    return song_title
",category,wooly bully,how sweet it is to be loved by you,,,,
Which song's lyrics contain the word 'love' the most times?,Which song has the highest frequency of the word 'love' in its lyrics?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Convert the Lyrics column to lowercase for case-insensitive matching
    dataset['Lyrics'] = dataset['Lyrics'].str.lower()
    
    # Count occurrences of 'love' in each song's lyrics
    dataset['LoveCount'] = dataset['Lyrics'].str.count('love')
    
    # Find the song with the highest count of 'love'
    song_with_most_love = dataset.loc[dataset['LoveCount'].idxmax(), 'Song']
    
    return song_with_most_love",string,the way you love me,the way you love me,,,,
What is the title of the top song produced in the earliest year?,What is the title of the song with the earliest production year?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
earliest_year_song = dataset.loc[dataset[""Year""] == dataset[""Year""].min()]
song_title = earliest_year_song[""Song""].iloc[0]

return song_title
",string,wooly bully,wooly bully,,,,
Who are the artists of the top 5 ranked songs?,What are the artists for the top 5 ranked songs?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_songs = dataset.nsmallest(5, 'Rank')
artists = top_5_songs['Artist'].tolist()

return artists
",list of (string),"['sam the sham and the pharaohs', 'ssgt barry sadler', 'lulu', 'the beatles', 'the archies']","['sam the sham and the pharaohs', 'ssgt barry sadler', 'the beach boys', 'the beatles', 'the beatles']",,,,
What are the titles of the 3 songs with the shortest lyrics?,,,,ERROR,"['girl youll be a woman soon', 'papa dont preach', 'breathe']",,,,
What are the top 4 songs by rank produced in the most recent year?,Retrieve the top 4 songs with the highest rank from the most recent year.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the most recent year in the dataset
    most_recent_year = dataset['Year'].max()
    
    # Filter the dataset for the most recent year
    recent_year_data = dataset[dataset['Year'] == most_recent_year]
    
    # Sort the data by rank to get the top 4 songs with the highest rank
    top_4_songs = recent_year_data.sort_values(by='Rank').head(4)
    
    # Create a list of tuples containing song and artist for the top 4 songs
    result = list(zip(top_4_songs['Song'], top_4_songs['Artist']))
    
    return result",list of (tuple),"[('uptown funk', 'mark ronson featuring bruno mars'), ('thinking out loud', 'ed sheeran'), ('see you again', 'wiz khalifa featuring charlie puth'), ('trap queen', 'fetty wap')]","['uptown funk', 'thinking out loud', 'see you again', 'trap queen']",,,,
Who are the artists of the bottom 5 ranked songs?,Which artists are associated with the 5 lowest ranked songs?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by rank in ascending order to get the 5 lowest ranked songs
    sorted_dataset = dataset.sort_values(by=""Rank"", ascending=True)
    
    # Get the artists associated with the 5 lowest ranked songs
    lowest_ranked_artists = sorted_dataset.head(5)[""Artist""].tolist()
    
    return lowest_ranked_artists
",list of (string),"['sam the sham and the pharaohs', 'elton john', 'prince', 'simon  garfunkel', 'adele']","['marvin gaye', 'wilson pickett', 'neil diamond', 'jerry butler', 'the beatles']",,,,
What are the ranks of the top 3 songs with the most occurrences of the word 'love' in their lyrics?,,,,ERROR,"[64, 41, 28]",,,,
What are the years of production of the bottom 4 ranked songs?,What are the production years for the four songs with the lowest rank?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Get the four songs with the lowest rank
    lowest_rank_songs = dataset.nsmallest(4, 'Rank')
    
    # Extract the production years for these songs
    production_years = lowest_rank_songs['Year'].tolist()
    
    return production_years
",list of (uint16),"[1965, 1966, 1967, 1968]","[1965, 1966, 1967, 1968]",,,,
What are the ranks of the 2 songs produced in the earliest year?,What are the ranks of the top 2 songs from the earliest production year?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
earliest_year = dataset['Year'].min()
top_songs_earliest_year = dataset[dataset['Year'] == earliest_year].nlargest(2, 'Source')
ranks = top_songs_earliest_year['Rank'].tolist()

return ranks",list of (int64),"[8, 27]","[1, 2]",,,,
What are the years of production of the top 5 songs with the longest lyrics?,What are the production years of the top 5 songs with the longest lyrics?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'LoveCount' in descending order and select the top 5 rows
    top_5_songs = dataset.sort_values(by='LoveCount', ascending=False).head(5)
    
    # Extract the 'Year' column from these top 5 songs
    production_years = top_5_songs['Year'].tolist()
    
    return production_years",list of (int64),"[1989, 2010, 2010, 1976, 1988]","[1998, 2009, 2010, 2007, 2002]",,,,
Is the song with the highest rank from 1965 by the Beatles?,Is the song with the highest rank in 1965 by the Beatles?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
highest_rank_song = dataset.loc[(dataset[""Year""] == 1965) & (dataset[""Artist""] == ""The Beatles""), [""Rank"", ""Song""]]
if highest_rank_song.empty:
return False
else:
return highest_rank_song[""Rank""].idxmin() == highest_rank_song.index[0]",bool,False,False,,,,
Which artist has the song with the highest rank in 1965?,Which artist performed the song that ranked highest in 1965?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    highest_ranked_song_1965 = dataset.loc[(dataset[""Year""] == 1965) & (dataset[""Rank""] == dataset[""Rank""].min())]
    artist = highest_ranked_song_1965[""Artist""].iloc[0]

    return artist
",category,sam the sham and the pharaohs,sam the sham and the pharaohs,,,,
Who are the artists of the top 3 songs in 1965?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of artists who have songs in the Billboard dataset.
    unique_artists = dataset['Artist'].unique().tolist()
    
    return unique_artists",list of string,"['sam the sham and the pharaohs', 'four tops', 'the rolling stones', 'we five', 'the righteous brothers', 'petula clark', 'the beatles', 'hermans hermits', 'elvis presley', 'the temptations', 'the beach boys', 'roger miller', 'jewel akens', 'mel carter', 'junior walker  the all stars', 'sonny  cher', 'gary lewis  the playboys', 'ramsey lewis trio', 'the supremes', 'the seekers', 'jay and the americans', 'the byrds', 'sounds orchestral', 'barbara mason', 'tom jones', 'barry mcguire', 'the mccoys', 'bert kaempfert', 'james brown', 'wayne fontana  the mindbenders', 'shirley ellis', 'barbara lewis', 'the kingsmen', 'patti page', 'bob dylan', 'freddie and the dreamers', 'gerry and the pacemakers', 'johnny rivers', 'horst jankowski', 'the yardbirds', 'the moody blues', 'shirley bassey', 'billy joe royal', 'glenn yarbrough', 'the dave clark five', 'the beau brummels', 'ian whitcomb', 'marvin gaye', 'the kinks', 'jackie deshannon', 'sir douglas quintet', 'sam cooke', 'martha and the vandellas', 'the searchers', 'dickey lee', 'the turtles', 'the zombies', 'peter and gordon', 'vic dana', 'patty duke', 'the miracles', 'brenda lee', 'bobby goldsboro', 'the fortunes', 'joe tex', 'the animals', 'the lovin spoonful', 'cher', 'little anthony and the imperials', 'the strangeloves', 'sonny bono', 'roy head', 'jack jones', 'dino desi  billy', 'the ad libs', 'del shannon', 'ssgt barry sadler', 'the association', 'the four tops', '  the mysterians', 'the monkees', 'the mamas  the papas', 'lovin spoonful', 'roger williams', 'nancy sinatra', 'jimmy ruffin', 'frank sinatra', 'the young rascals', 'new vaudeville band', 'tommy james and the shondells', 'percy sledge', 'lou christie', 'the troggs', 'paul revere  the raiders', 'donovan', 'bobby hebb', 'the happenings', 'mitch ryder  the detroit wheels', 'the mindbenders', 'dusty springfield', 'the capitols', 'sandy posey', 'the cyrkle', 'carla thomas', 'the left banke', 'the outsiders', 'tommy roe', 'the hollies', 'james  bobby purify', 'bj thomas', 'the standells', 'bob lind', 'simon  garfunkel', 'ray charles', 'robert parker', 'stevie wonder', 'the surfaris', 'count five', 'the tbones', 'deon jackson', 'crispian st peters', 'ray conniff singers', 'david houston', 'bobby darin', 'the marvelettes', 'neil diamond', 'lee dorsey', 'dionne warwick', 'lou rawls', 'shadows of knight', 'the sandpipers', 'wilson pickett', 'the shades of blue', 'the vogues', 'los bravos', 'slim harpo', 'chris montez', 'bobby fuller four', 'herb alpert and the tijuana brass', 'lulu', 'the box tops', 'bobbie gentry', 'the doors', 'frank  nancy sinatra', 'frankie valli', 'the music explosion', 'aretha franklin', 'bobby vee', 'the buckinghams', 'arthur conley', 'the soul survivors', 'sam  dave', 'jay  the techniques', 'every mothers son', 'strawberry alarm clock', 'vikki carr', 'buffalo springfield', 'brenton wood', 'engelbert humperdinck', 'marvin gaye  tammi terrell', 'jefferson airplane', 'the esquires', 'van morrison', 'procol harum', 'the casinos', 'bobby vinton', 'the tremeloes', 'ed ames', 'the 5th dimension', 'scott mckenzie', 'the cowsills', 'jackie wilson', 'five americans', 'lesley gore', 'blues magoos', 'the easybeats', 'the barkays', 'the spencer davis group', 'the hombres', 'the grass roots', 'peaches  herb', 'booker t  the mgs', 'aaron neville', 'keith', 'the royal guardsmen', 'janis ian', 'robert knight', 'peter paul and mary', 'bill cosby', 'the electric prunes', 'the who', 'paul mauriat', 'otis redding', 'the rascals', 'cream', 'herb alpert', 'hugo montenegro', 'archie bell  the drells', 'jeannie c riley', 'o c smith', 'gary puckett  the union gap', 'hugh masekela', 'sly  the family stone', 'cliff nobles', 'the delfonics', 'john fred  his playboy band', 'classics iv', 'merrilee rush', 'georgie fame', 'mary hopkin', 'steppenwolf', 'the intruders', '1910 fruitgum company', 'sergio mendes', 'johnny nash', 'ohio express', 'the crazy world of arthur brown', 'gene  debbe', 'mason williams', 'clarence carter', 'the okaysions', 'the lemon pipers', 'friend  lover', 'richard harris', 'jose feliciano', 'people', 'status quo', 'blue cheer', 'the bee gees', 'the fireballs', 'the dells', 'willie mitchell', 'the human beinz', 'sam and dave', 'tommy boyce  bobby hart', 'the lettermen', 'the irish rovers', 'vanilla fudge', 'the foundations', 'sweet inspirations', 'the mills brothers', 'the chambers brothers', 'manfred mann', 'shorty long', 'gary lewis and the playboys', 'big brother and the holding company', 'creedence clearwater revival', 'the american breed', 'jerry butler', 'the archies', 'three dog night', 'henry mancini', 'the youngbloods', 'the friends of distinction', 'jr walker  the all stars', 'the isley brothers', 'oliver', 'the beatles with billy preston', 'zager  evans', 'blood sweat  tears', 'andy kim', 'smith', 'johnny cash', 'bobby sherman', 'mercy', 'the guess who', 'the watts 103rd street rhythm band', 'spiral starecase', 'sammy davis jr', 'mama cass elliot', 'the ventures', 'glen campbell', 'ray stevens', 'tyrone davis', 'the winstons', 'checkmates ltd', 'edwin starr', 'new colony six', 'motherlode', 'harry nilsson', 'johnny maestro  the brooklyn bridge', 'joe simon', 'the flying machine', 'tony joe white', 'kenny rogers  the first edition', 'joe south', 'the cuff links', 'bob seger system', 'the supremes  the temptations', 'crazy elephant', 'the originals', 'edwin hawkins singers', 'david ruffin', 'the carpenters', 'diana ross', 'the jackson 5', 'rare earth', 'freda payne', 'bread', 'vanity fare', 'dawn', 'eric burdon  war', 'five stairsteps', 'norman greenbaum', 'melanie', 'the moments', 'the poppy family', 'free', 'sugarloaf', 'blues image', 'shocking blue', 'john lennon', 'brook benton', 'chairmen of the board', 'edison lighthouse', 'anne murray', 'marmalade', 'eddie holman', 'the jaggerz', 'alive n kickin', 'badfinger', 'charles wright  the watts 103rd street rhythm band', 'mungo jerry', 'r dean taylor', 'chicago', 'frijid pink', 'white plains', 'the brotherhood of man', 'mark lindsay', 'james taylor', 'gene chandler', 'santana', 'ronnie dyson', 'the spinners', 'bobbi martin', 'mountain', 'ike  tina turner', 'joe cocker', 'tee set', 'christie', '100 proof aged in soul', 'the ides of march', 'the pipkins', 'robin mcnamara', 'pacific gas  electric', 'crosby stills nash  young', 'the new seekers', 'bb king', 'rod stewart', 'carole king', 'the osmonds', 'bee gees', 'donny osmond', 'john denver', 'tony orlando and dawn', 'janis joplin', 'al green', 'honey cone', 'the undisputed truth', 'cornelius brothers  sister rose', 'jean knight', 'lee michaels', 'joan baez', 'paul  linda mccartney', 'bill withers', 'five man electrical band', 'murray head  the trindad singers', 'the free movement', 'jerry reed', 'george harrison', 'ocean', 'daddy dewdrop', 'sammi smith', 'gordon lightfoot', 'lynn anderson', 'hamilton joe frank  reynolds', 'ringo starr', 'nitty gritty dirt band', 'the fuzz', 'the dramatics', 'carly simon', 'helen reddy', 'the partridge family', 'tommy james', 'the bells', 'the stampeders', 'lobo', 'paul mccartney', 'brewer  shipley', '8th day', 'delaney  bonnie  friends', 'freddie hart', 'the honey cone', 'mac and katie kissoon', 'andy williams', 'cat stevens', 'the beginning of the end', 'olivia newtonjohn', 'king floyd', 'matthews southern comfort', 'judy collins', 'dave edmunds', 'denise lasalle', 'the buoys', 'isaac hayes', 'gladys knight  the pips', 'paul stookey', 'richie havens', 'wadsworth mansion', 'brenda  the tabulations', 'perry como', 'roberta flack', 'gilbert osullivan', 'don mclean', 'mac davis', 'wayne newton', 'looking glass', 'the chilites', 'gallery', 'chuck berry', 'luther ingram', 'neil young', 'the stylistics', 'the staple singers', 'michael jackson', 'robert john', 'billy preston', 'war', 'mouth  macneal', 'america', 'hot butter', 'the main ingredient', 'climax', 'raspberries', 'the ojays', 'jonathan edwards', 'mel and tim', 'elton john', 'daniel boone', 'dennis coffey', 'arlo guthrie', 'ricky nelson', 'betty wright', 'argent', 'the chakachas', 'donna fargo', 't rex', 'paul simon', 'roberta flack  donny hathaway', 'derek and the dominos', 'dr hook  the medicine show', 'jim croce', 'commander cody and his lost planet airmen', 'apollo 100', 'charley pride', 'alice cooper', 'jimmy castor bunch', 'redbone', 'curtis mayfield', 'jerry butler  brenda lee eager', 'harry chapin', 'beverly bremers', 'todd rundgren', 'sailcat', 'original cast of godspell', 'yes', 'jackson browne', 'the detroit emeralds', 'rick springfield', 'the hillside singers', 'love unlimited', 'paul mccartney  wings', 'kris kristofferson', 'vicki lawrence', 'clint holmes', 'stories', 'billy paul', 'edgar winter group', 'dobie gray', 'sweet', 'sylvia', 'grand funk railroad', 'dr john', 'skylark', 'maureen mcgovern', 'stealers wheel', 'barry white', 'eddie kendricks', 'king harvest', 'bobby boris pickett and the cryptkickers', 'bloodstone', 'seals and crofts', 'the doobie brothers', 'jermaine jackson', 'new york city', 'deep purple', 'charlie rich', 'loggins and messina', 'hurricane smith', 'johnnie taylor', 'eric weissberg  steve mandell', 'bw stevenson', 'edward bear', 'steely dan', 'focus', 'bette midler', 'timmy thomas', 'tower of power', 'the allman brothers band', 'ohio players', 'blue ridge rangers', 'jud strunk', 'deodato', 'pink floyd', 'the pointer sisters', 'david bowie', 'albert hammond', 'barbra streisand', 'terry jacks', 'love unlimited orchestra', 'mfsb', 'kool  the gang', 'maria muldaur', 'al wilson', 'jim stafford', 'david essex', 'blue magic', 'blue swede', 'bo donaldson and the heywoods', 'paul mccartney and wings', 'paul anka', 'george mccrae', 'steve miller band', 'the hues corporation', 'brownsville station', 'paper lace', 'dionne warwick  the spinners', 'marvin hamlisch', 'abba', 'carly simon  james taylor', 'joni mitchell', 'rufus  chaka khan', 'william devaughn', 'johnny bristol', 'mocedades', 'bachmanturner overdrive', 'golden earring', 'dave loggins', 'wet willie', 'bobby womack', 'eric clapton', 'mike oldfield', 'donny and marie osmond', 'tom t hall', 'the guess who featuring wolfman jack', 'sister janet mead', 'lamont dozier', 'diana ross  marvin gaye', 'the first class', 'fancy', 'captain  tennille', 'freddy fender', 'earth wind  fire', 'neil sedaka', 'eagles', 'minnie riperton', 'carl douglas', 'average white band', 'van mccoy  the soul city symphony', 'labelle', 'major harris', 'ozark mountain daredevils', 'pilot', 'barry manilow', 'michael martin murphey', 'jessi colter', 'wings', '10cc', 'billy swan', 'morris albert', 'sammy johns', 'linda ronstadt', 'bazuka', 'the blackbyrds', 'melissa manchester', 'phoebe snow', 'ace', 'bt express', 'styx', 'grand funk', 'carol douglas', 'kc and the sunshine band', 'paul anka  odia coates', 'bad company', 'orleans', 'gloria gaynor', 'donny  marie osmond', 'the three degrees', 'queen', 'electric light orchestra', 'rufus', 'mike post', 'tavares', 'jethro tull', 'leo sayer', 'neil sedaka  elton john', 'dwight twilley band', 'amazing rhythm aces', 'discotex and the sexolettes', 'elton john  kiki dee', 'the four seasons', 'wild cherry', 'the manhattans', 'gary wright', 'walter murphy  the big apple band', 'hall  oates', 'starland vocal band', 'silver convention', 'andrea true connection', 'dorothy moore', 'the sylvers', 'england dan  john ford coley', 'hot chocolate', 'nazareth', 'commodores', 'maxine nightingale', 'rhythm heritage', 'starbuck', 'dr hook', 'the bellamy brothers', 'vicki sue robinson', 'eric carmen', 'donna summer', 'henry gross', 'boz scaggs', 'peter frampton', 'aerosmith', 'fleetwood mac', 'cliff richard', 'elvin bishop', 'c w mccall', 'john sebastian', 'the brothers johnson', 'bay city rollers', 'wing and a prayer fife and drum corps', 'george benson', 'silver', 'keith carradine', 'harold melvin  the blue notes', 'john travolta', 'jefferson starship', 'foghat', 'thin lizzy', 'candi staton', 'parliament', 'larry groce', 'kiss', 'rick dees  his cast of idiots', 'andy gibb', 'the emotions', 'hot', 'kenny nolan', 'thelma houston', 'rita coolidge', 'alan oday', 'mary macgregor', 'jimmy buffett', 'pablo cruise', 'peter mccann', 'bill conti deetta little and nelson pigford', 'rose royce', 'marilyn mccoo  billy davis jr', 'david soul', 'stephen bishop', 'foreigner', 'climax blues band', 'jennifer warnes', 'natalie cole', 'manfred manns earth band', 'atlanta rhythm section', 'the jacksons', 'brick', 'kenny rogers', 'shaun cassidy', 'crosby stills  nash', 'andrew gold', 'heart', 'bob seger  the silver bullet band', 'the marshall tucker band', 'kansas', 'burton cummings', 'ronnie milsap', 'sanfordtownsend band', 'dean friedman', 'meco', 'the floaters', 'lord david dundas', 'supertramp', 'dr buzzards original savannah band', 'al stewart', 'heatwave', 'london symphony orchestra', 'cj  company', 'debby boone', 'exile', 'player', 'a taste of honey', 'paul davis', 'john travolta  olivia newtonjohn', 'samantha sang', 'billy joel', 'yvonne elliman', 'chic', 'chuck mangione', 'nick gilder', 'bonnie tyler', 'gerry rafferty', 'johnny mathis  deniece williams', 'peter brown', 'meat loaf', 'raydio', 'dan hill', 'walter egan', 'randy newman', 'john paul young', 'david gates', 'jay ferguson', 'toby beau', 'the trammps', 'ltd', 'dolly parton', 'evelyn champagne king', 'little river band', 'eddie money', 'lynyrd skynyrd', 'crystal gayle', 'patti smith group', 'robert palmer', 'rick james', 'bob welch', 'leblanc  carr', 'santa esmeralda', 'michael johnson', 'kenny loggins  stevie nicks', 'chris rea', 'foxy', 'joe walsh', 'alicia bridges', 'high inergy', 'odyssey', 'boston', 'eruption', 'the knack', 'village people', 'anita ward', 'david naughton', 'blondie', 'neil diamond  barbra streisand', 'amii stewart', 'suzi quatro  chris norman', 'randy vanwarmer', 'cheap trick', 'leif garrett', 'donna summer and brooklyn dreams', 'nicolette larson', 'bonnie pointer', 'toto', 'sister sledge', 'frank mills', 'the charlie daniels band', 'john stewart', 'earth wind  fire  the emotions', 'bobby caldwell', 'ace frehley', 'dire straits', 'rickie lee jones', 'mcfadden  whitehead', 'cheryl lynn', 'patrick hernandez', 'ian matthews', 'gino vannelli', 'gq', 'roger voudouris', 'ambrosia', 'eddie rabbitt', 'rex smith', 'the babys', 'instant funk', 'van halen', 'nigel olsson', 'firefall', 'lipps inc', 'rupert holmes', 'gary numan', 'smokey robinson', 'air supply', 'christopher cross', 'billy preston and syreeta', 'teri desario  kc', 'robbie dupree', 'kenny loggins', 'kenny rogers  kim carnes', 'dan fogelberg', 'the sos band', 'barbra streisand  donna summer', 'kim carnes', 'm', 'the pretenders', 'ray goodman  brown', 'shalamar', 'rocky burnette', 'bob seger and the silver bullet band', 'jd souther', 'pete townshend', 'steve forbert', 'tom petty and the heartbreakers', 'irene cara', 'bob seger', 'benny mardones', 'pure prairie league', 'genesis', 'the dirt band', 'neil  dara sedaka', 'charlie dore', 'mickey gilley', 'pat benatar', 'prince', 'charlie daniels band', 'diana ross  lionel richie', 'reo speedwagon', 'joey scarbury', 'sheena easton', 'juice newton', 'grover washington jr  bill withers', 'stars on 45', 'barbra streisand  barry gibb', 'the oak ridge boys', 'the manhattan transfer', 'marty balin', 'champaign', 'the greg kihn band', 'the alan parsons project', 'bruce springsteen', 'franke and the knockouts', 'terri gibbs', 'tierra', 'dottie west  kenny rogers', 'journey', 'the police', 'gary us bonds', 'stevie nicks  tom petty', 'delbert mcclinton', 'john cougar', 'steve winwood', 'billy squier', 'alabama', 'george duke  stanley clarke', 'john schneider', 'olivia newtonjohn  cliff richard', 'devo', 'rosanne cash', 'survivor', 'joan jett and the blackhearts', 'paul mccartney and stevie wonder', 'the j geils band', 'the human league', 'soft cell', 'vangelis', 'quarterflash', 'daryl hall  john oates', 'tommy tutone', 'bertie higgins', 'willie nelson', 'the cars', 'dazz band', 'the gogos', 'ray parker jr', 'the motels', 'men at work', 'stevie nicks and don henley', 'charlene', 'asia', 'buckner  garcia', 'lindsey buckingham', 'huey lewis and the news', '38 special', 'royal philharmonic orchestra', 'karla bonoff', 'quincy jones featuring james ingram', 'a flock of seagulls', 'deniece williams', 'laura branigan', 'joan jett  the blackhearts', 'michael mcdonald', 'billy idol', 'kim wilde', 'michael murphey', 'loverboy', 'greg guidry', 'stevie nicks', 'patti austin and james ingram', 'michael sembello', 'eurythmics', 'culture club', 'eddie rabbitt and crystal gayle', 'dexys midnight runners', 'duran duran', 'frida', 'eddy grant', 'thomas dolby', 'joe cocker and jennifer warnes', 'lionel richie', 'after the fire', 'taco', 'men without hats', 'toni basil', 'phil collins', 'kenny rogers and sheena easton', 'stray cats', 'naked eyes', 'don henley', 'michael jackson and paul mccartney', 'kajagoogoo', 'adam ant', 'the clash', 'madness', 'the tubes', 'bryan adams', 'debarge', 'sammy hagar', 'joe jackson', 'moving pictures', 'def leppard', 'musical youth', 'spandau ballet', 'frank stallone', 'peabo bryson and roberta flack', 'tina turner', 'paul mccartney and michael jackson', 'john waite', 'cyndi lauper', 'pointer sisters', 'the romantics', 'prince and the revolution', 'thompson twins', 'rockwell', 'matthew wilder', 'nena', 'dan hartman', 'sheila e', 'steve perry', 'madonna', 'corey hart', 'night ranger', 'scandal', 'peabo bryson', 'shannon', 'julio iglesias and willie nelson', 'billy ocean', 'kenny rogers and dolly parton', 'mike reno and ann wilson', 'zz top', 'quiet riot', 'tracey ullman', 'bananarama', 'wang chung', 'kc  the sunshine band', 'ollie  jerry', 'john cougar mellencamp', 'ratt', 'christine mcvie', 'john cafferty  the beaver brown band', 'peter schilling', 'james ingram and michael mcdonald', 'wham featuring george michael', 'wham', 'chaka khan', 'tears for fears', 'aha', 'paul young', 'philip bailey and phil collins', 'starship', 'simple minds', 'john parr', 'glenn frey', 'usa for africa', 'whitney houston', 'new edition', 'jan hammer', 'teena marie', 'ready for the world', 'the honeydrippers', 'howard jones', 'jack wagner', 'phil collins and marilyn martin', 'murray head', 'sting', 'animotion', 'harold faltermeyer', 'sade', 'mary jane girls', 'til tuesday', 'abc', 'katrina and the waves', 'julian lennon', 'power station', 'ashford  simpson', 'david lee roth', 'the time', 'dionne and friends dionne warwick gladys knight elton john and stevie wonder', 'klymaxx', 'patti labelle and michael mcdonald', 'mr mister', 'eddie murphy', 'atlantic starr', 'gloria loring and carl anderson', 'peter cetera', 'pet shop boys', 'simply red', 'peter gabriel', 'nu shooz', 'berlin', 'falco', 'bon jovi', 'janet jackson', 'glass tiger', 'belinda carlisle', 'level 42', 'miami sound machine', 'sly fox', 'the bangles', 'stacey q', 'the jets', 'orchestral manoeuvres in the dark', 'inxs', 'jermaine stewart', 'lisa lisa and cult jam', 'the outfield', 'scritti politti', 'el debarge', 'cameo', 'mike  the mechanics', 'baltimora', 'timex social club', 'dream academy', 'regina', 'arcadia', 'rundmc', 'anita baker', 'moody blues', 'starpoint', 'daryl hall', 'force mds', 'george michael', 'gregory abbott', 'robbie nevil', 'whitesnake', 'bruce hornsby and the range', 'los lobos', 'crowded house', 'u2', 'jody watley', 'tiffany', 'billy vera and the beaters', 'chris de burgh', 'debbie gibson', 'bill medley and jennifer warnes', 'peter cetera and amy grant', 'club nouveau', 'cutting crew', 'tpau', 'georgia satellites', 'aretha franklin and george michael', 'linda ronstadt and james ingram', 'samantha fox', 'michael jackson with siedah garrett', 'suzanne vega', 'richard marx', 'kenny g', 'europe', 'the system', 'expose', 'dan hill featuring vonda shepard', 'swing out sister', 'ben e king', 'levert', 'gloria estefan and miami sound machine', 'the whispers', 'lou gramm', 'glenn medeiros', 'bruce willis', 'breakfast club', 'beastie boys', 'pseudo echo', 'rick astley', 'guns n roses', 'breathe', 'terence trent darby', 'the escape club', 'taylor dayne', 'johnny hates jazz', 'bobby mcferrin', 'ub40', 'patrick swayze featuring wendy fraser', 'kylie minogue', 'pet shop boys with dusty springfield', 'information society', 'roger troutman', 'pebbles', 'pretty poison', 'keith sweat', 'tracy chapman', 'icehouse', 'bobby brown', 'brenda russell featuring joe esposito', 'paul carrack', 'al b sure', 'brenda k starr', 'poison', 'white lion', 'paula abdul', 'milli vanilli', 'will to power', 'boy meets girl', 'gloria estefan', 'warrant', 'roxette', 'fine young cannibals', 'new kids on the block', 'martika', 'tone loc', 'bad english', 'neneh cherry', 'sheriff', 'young mc', 'great white', 'michael damian', 'the b52s', 'love and rockets', 'dino', 'skid row', 'karyn white', 'the cure', 'the jeff healey band', 'surface', 'rem', 'lita ford and ozzy osbourne', 'cher and peter cetera', 'when in rome', 'edie brickell  new bohemians', 'boys club', 'vanessa williams', 'babyface', 'deon estus', 'safire', 'ann wilson and robin zander', 'soul ii soul', 'wilson phillips', 'sinead oconnor', 'bell biv devoe', 'mariah carey', 'en vogue', 'jon bon jovi', 'michael bolton', 'technotronic featuring felly', 'paula abdul and the wild pair', 'maxi priest', 'alannah myles', 'linda ronstadt and aaron neville', 'lisa stansfield', 'calloway', 'johnny gill', 'glenn medeiros and bobby brown', 'sweet sensation', 'snap', 'nelson', 'jane child', 'seduction', 'linear', 'james ingram', 'tommy page', 'soul ii soul featuring caron wheeler', 'luther vandross', 'vanilla ice', 'mc hammer', 'michelle', 'after 7', 'digital underground', 'tom petty', 'depeche mode', 'tesla', 'tyler collins', 'go west', 'technotronic featuring ya kid k', 'faith no more', 'black box', 'd mob featuring cathy dennis', 'the cover girls', 'biz markie', 'ame lorain', 'm""otley cr""ue', 'jive bunny and the mastermixers', 'mellow man ace', 'kyper', 'color me badd', 'cc music factory', 'timmy t', 'emf', 'extreme', 'hifive', 'amy grant', 'boyz ii men', 'stevie b', 'damn yankees', 'jesus jones', 'marky mark and the funky bunch featuring loleatta holloway', 'tara kemp', 'ralph tresvant', 'cathy dennis', 'londonbeat', 'natural selection', 'lenny kravitz', 'celine dion', 'dj jazzy jeff  the fresh prince', 'scorpions', 'rythm syndicate', 'firehouse', 'tracie spencer', 'divinyls', 'dna featuring suzanne vega', 'another bad creation', 'bonnie raitt', 'corina', 'the klf', 'enigma', 'll cool j', 'prince and the new power generation', 'heavy d  the boyz', 'seal', 'michael w smith', 'chris isaak', 'oleta adams', 'tevin campbell', 'queensr""yche', 'gerardo', 'deeelite', 'chesney hawkes', 'naughty by nature', 'winger', 'saltnpepa', 'sir mixalot', 'kris kross', 'tlc', 'red hot chili peppers', 'jon secada', 'shanice', 'mr big', 'right said fred', 'billy ray cyrus', 'tom cochrane', 'cece peniston', 'patty smyth', 'house of pain', 'george michael and elton john', 'joe public', 'jodeci', 'nirvana', 'sophie b hawkins', 'arrested development', 'luther vandross and janet jackson', 'pm dawn', 'shakespears sister', 'hammer', 'kws', 'mint condition', 'toad the wet sprocket', 'the heights', 'celine dion and peabo bryson', 'marky mark and the funky bunch', 'ugly kid joe', 'n2deep', 'kathy troccoli', 'jade', 'mary j blige', 'charles  eddie', 'das efx', 'tag team', 'silk', 'swv', 'shai', 'wreckxneffect', 'snow', 'dr dre', 'htown', 'duice', 'robin s', 'peabo bryson and regina belle', 'vanessa williams and brian mcknight', 'soul asylum', 'paperboy', 'the proclaimers', 'spin doctors', 'tony toni tone', 'onyx', '95 south', 'toni braxton', '4 non blondes', 'ace of base', 'dr dre featuring snoop doggy dogg', 'brian mcknight', 'xscape', '2pac', 'portrait', 'positive k', 'zhane', 'cypress hill', 'jeremy jordan', 'inner circle', 'boy krazy', 'restless heart', 'ice cube', 'captain hollywood project', 'digable planets', 'haddaway', 'ice cube featuring das efx', 'joey lawrence', 'green jell""y', 'gin blossoms', 'all4one', 'lisa loeb and nine stories', 'bryan adams rod stewart and sting', 'r kelly', 'saltnpepa and en vogue', 'john mellencamp featuring meshell ndegeocello', 'coolio', 'big mountain', 'warren g featuring nate dogg', 'aaliyah', 'collective soul', 'sheryl crow', 'crash test dummies', 'da brat', 'drs', '10000 maniacs', 'us3', 'melissa etheridge', 'changing faces', 'crystal waters', 'the cranberries', 'beck', 'snoop doggy dogg', 'immature', 'domino', 'luther vandross and mariah carey', 'aaron hall', 'warren g', 'real mccoy', '69 boyz', 'jimmy cliff', 'erasure', 'gabrielle', 'culture beat', 'joshua kadison', 'eternal', 'craig mack', 'queen latifah', 'ini kamoze', 'tim mcgraw', 'candlebox', 'ahmad', 'general public', 'ice cube featuring george clinton', 'brandy', 'coolio featuring lv', 'monica', 'montell jordan', 'dionne farris', 'adina howard', 'blues traveler', 'shaggy', 'nicki french', 'desree', 'hootie  the blowfish', 'the notorious big', 'soul for real', 'blessid union of souls', 'jon b', 'brownstone', 'martin page', 'luniz', 'mokenstef', 'method man featuring mary j blige', 'diana king', 'blackstreet', '4:00 PM', 'jamie walters', 'corona', 'del amitri', 'michael jackson and janet jackson', 'skeelo', 'natalie merchant', 'take that', 'groove theory', 'total featuring the notorious big', 'subway featuring 702', 'junior mafia featuring the notorious big', '20 fingers featuring gillette', 'brandy featuring wanya morris', 'annie lennox', 'faith evans', 'raphael saadiq', 'az', 'better than ezra', 'dangelo', 'bone thugsnharmony', 'rednex', 'n ii u', ""los del r'io"", 'mariah carey and boyz ii men', 'the tony rich project', 'donna lewis', 'quad city djs', 'everything but the girl', 'alanis morissette', '2pac featuring kci  jojo  featuring dr dre', 'jann arden', 'la bouche', 'goo goo dolls', 'jewel', 'no mercy', 'dishwalla', 'joan osborne', '112 featuring the notorious big and mase', 'r kelly featuring the isley brothers', 'deep blue something', 'blackstreet featuring dr dre', '3t', 'the smashing pumpkins', 'total', 'whitney houston featuring cece winans', 'az yet', 'merril bainbridge', 'joe', 'oasis', 'busta rhymes', 'outkast', 'case featuring foxy brown', 'robert miles', 'adam clayton and larry mullen', 'bodeans', 'no doubt', 'john mellencamp', 'ginuwine', 'keith sweat featuring athena cage', 'mc lyte featuring xscape', 'deborah cox', 'amber', 'planet soul', 'ghost town djs', 'maxi priest featuring shaggy', 'do or die featuring twista', 'metallica', 'crucial conflict', 'pearl jam', 'puff daddy featuring faith evans and 112', 'puff daddy featuring mase', 'mark morrison', 'leann rimes', 'spice girls', 'backstreet boys', 'hanson', 'usher', 'meredith brooks', 'third eye blind', 'duncan sheik', 'az yet featuring peter cetera', 'the notorious big featuring puff daddy and mase', 'the verve pipe', 'savage garden', 'rome', 'dru hill', 'robyn', 'freak nasty', 'sister hazel', '112', 'paula cole', 'shawn colvin', 'tim mcgraw and faith hill', 'gina g', 'allure featuring 112', '98 degrees', 'lil kim featuring da brat left eye missy elliott and angie martinez', '702', 'somethin for the people featuring trina  tamara', 'barbra streisand and bryan adams', 'foxy brown featuring jayz', 'timbaland  magoo featuring missy elliott and aaliyah', 'mc lyte', 'sarah mclachlan', 'white town', 'coolio featuring 40 thevz', 'brock and the bizz', 'chumbawamba', 'various artists', 'heavy d', 'scarface featuring 2pac and johnny p', 'lil kim featuring puff daddy', 'luscious jackson', 'erykah badu', 'brian mcknight featuring mase', 'swv and puff daddy', 'next', 'mr president', 'aqua', 'dj kool', 'the blackout allstars', 'ray j', 'brandy and monica', 'shania twain', 'janet', 'kci  jojo', 'destinys child', 'will smith', 'puff daddy featuring the notorious big and mase', 'jennifer paige', 'public announcement', 'faith hill', 'uncle sam', 'montell jordan featuring master p and silkk the shocker', 'marcy playground', 'mase featuring total', 'wyclef jean', 'lsg', 'lord tariq and peter gunz', 'n sync', 'five', 'master p featuring fiend silkk the shocker mia x and mystikal', 'nicole featuring missy elliott and mocha', 'all saints', 'janet jackson featuring blackstreet', 'mase featuring kelly price', 'voices of theory', 'billie myers', 'puff daddy featuring jimmy page', 'sylke fyne featuring chill', ""m'ya and sisqo"", 'barenaked ladies', 'k p  envyi', 'tatyana ali', 'lisa loeb', 'mase featuring puff daddy', 'divine', 'inoj', 'jimmy ray', 'master p featuring sons of funk', 'puff daddy featuring the notorious big and busta rhymes', ""pras michel featuring ol dirty bastard and m'ya"", 'dru hill featuring redman', 'kelly price featuring r kelly and ron isley', 'edwin mccain', 'monifah', 'the lox featuring dmx and lil kim', 'the verve', 'loreena mckennitt', 'big pun featuring joe', '2pac featuring eric williams', 'luke featuring no good but so good', 'nu flavor', 'jermaine dupri featuring da brat and usher', 'missy elliott featuring da brat', 'gerald levert', 'tq', 'whitney houston featuring faith evans and kelly price', 'britney spears', 'sixpence none the richer', 'christina aguilera', 'sugar ray', 'ricky martin', 'jennifer lopez', 'r kelly and celine dion', 'smash mouth', 'santana featuring rob thomas', 'eagleeye cherry', 'maxwell', 'enrique iglesias', 'busta rhymes featuring janet', 'everlast', 'will smith featuring dru hill and kool moe dee', 'mariah carey featuring jayz', 'lfo', 'jayz featuring amil and ja rule', 'lauryn hill', 'lou bega', 'tyrese', 'shawn mullins', '112 featuring lil zane', 'matchbox 20', 'blaque', 'tal bachman', 'jt money featuring sole', 'jesse powell', 'total featuring missy elliott', 'jordan knight', 'eric benet featuring tamia', 'mark chesnutt', 'creed', 'chante moore', 'case', 'faith evans featuring puff daddy', 'juvenile featuring mannie fresh and lil wayne', 'len', 'marc anthony', 'case featuring joe', 'kenny chesney', 'lonestar', 'mo thugs', 'fastball', 'jayz', 'naughty by nature featuring zhane', ""blackstreet featuring m'ya mase and blinky blink"", 'joey mcintyre', 'jo dee messina', 'puff daddy featuring r kelly', 'citizen king', 'n sync and gloria estefan', 'george strait', 'whitney houston and mariah carey', 'alabama and n sync', 'santana featuring the product gb', 'vertical horizon', 'matchbox twenty', 'sisqo', '3 doors down', 'pink', 'macy gray', 'nelly', 'missy elliott featuring nas eve and qtip', 'bbmak', 'sonique', 'nine days', 'ruff endz', 'blink 182', 'mariah carey featuring joe and 98 degrees', 'jagged edge', 'eiffel 65', 'sting featuring cheb mami', 'eminem', 'everclear', 'jessica simpson', 'filter', 'jayz featuring ugk', 'son by four', 'avant', 'carl thomas', 'donell jones', 'souldecision featuring thrust', 'kid rock', 'mystikal', 'train', 'dmx', ""m'ya"", 'dr dre featuring eminem', 'westlife', 'dr dre featuring snoop dogg', 'chad brock', 'toby keith', 'da brat featuring tyrese', 'kandi', 'lee ann womack', 'alice deejay', 'debelah morgan', 'sammie', 'kevon edmonds', 'lil bow wow featuring xscape', 'dixie chicks', 'samantha mumba', 'mary mary', 'lifehouse', 'alicia keys', 'jennifer lopez featuring ja rule', 'eve featuring gwen stefani', 'dido', 'blu cantrell', 'shaggy featuring rikrok', 'joe featuring mystikal', 'staind', 'jagged edge featuring nelly', 'nelly featuring city spud', 'uncle kracker', 'incubus', 'city high', ""christina aguilera lil kim m'ya and pink"", 'dream', 'crazy town', 'ja rule featuring lil mo and vita', 'moby featuring gwen stefani', 'missy elliott', 'craig david', 'otown', 'nelly furtado', 'r kelly featuring jayz', 'lil mo featuring fabolous', 'evan and jaron', 'ricky martin and christina aguilera', 'missy elliott featuring ludacris', 'mystikal featuring nivea', 'enya', 'toya', 's club 7', 'tamia', 'sunshine anderson', 'dave matthews band', 'musiq soulchild', '3lw', 'brooks  dunn', 'lil romeo', 'blake shelton', 'ludacris', 'ja rule featuring case', 'mariah carey featuring cameo', 'the isley brothers featuring r kelly and chante moore', 'jessica andrews', 'erick sermon featuring marvin gaye', 'willa ford', 'diamond rio', 'travis tritt', 'trick daddy', 'eve 6', 'edens crush', 'nas and bravehearts', 'fuel', 'nickelback', 'ashanti', 'nelly featuring kelly rowland', 'the calling', 'vanessa carlton', 'linkin park', 'fat joe featuring ashanti', 'puddle of mudd', 'avril lavigne', 'ja rule featuring ashanti', 'jimmy eat world', 'p diddy featuring usher and loon', 'p diddy featuring ginuwine loon and mario winans', 'eve featuring alicia keys', 'michelle branch', 'chad kroeger featuring josey scott', 'default', 'shakira', 'jennifer lopez featuring nas', 'camron featuring juelz santana', 'dj sammy featuring yanou and do', 'no doubt featuring bounty killer', 'n sync featuring nelly', 'mario', 'nore', 'tweet featuring missy elliott', 'kelly clarkson', 'truth hurts featu","['sam the sham and the pharaohs', 'four tops', 'the beach boys']",,,,
What are the years of production of the top 3 songs with the word 'love' in their lyrics by the Beatles?,What are the production years for the top 3 Beatles songs that contain the word 'love' in their lyrics?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter songs by artist and containing the word 'love'
    beatles_love_songs = dataset[(dataset['Artist'] == 'The Beatles') & (dataset['Lyrics'].str.contains('love', case=False))]
    
    # Sort the filtered songs by rank
    top_3_beatles_love_songs = beatles_love_songs.sort_values(by='Rank').head(3)
    
    # Extract the production years of these top 3 songs
    production_years = top_3_beatles_love_songs['Year'].tolist()
    
    return production_years",list of (int64),[],"[1967, 1965, 1966]",,,,
"Are there records where the 'count' exceeds 20,000?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is not provided in this example, we will create a generic function.
    # If a specific question is given, please provide it to generate an accurate code snippet.

    # For demonstration purposes, let's assume the question is:
    # ""Does the destination with the highest count have a latitude greater than 30?""

    # Find the destination with the highest count
    max_count_destination = dataset.loc[dataset[""count""] == dataset[""count""].max()]

    # Get the latitude of this destination
    lat_dest = max_count_destination[""lat_dest""].iloc[0]

    # Check if the latitude is greater than 30
    result = lat_dest > 30

    return result",bool,True,True,,,,
Do we have any records originating from 'Jefferson'?,Is there any record in the dataset where the origin is 'Jefferson'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_record = not dataset[dataset['name_origin'] == 'Jefferson'].empty

return has_record",bool,True,True,,,,
Are there destinations with the name 'Baldwin'?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any records where origin and dest are the same
    same_origin_dest = dataset[dataset['origin'] == dataset['dest']].shape[0] > 0

    return same_origin_dest
",bool,False,True,,,,
Are there records where the latitude of the destination is greater than 60?,Is there any destination with a latitude greater than 60?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_destination_with_high_latitude = dataset[""lat_dest""] > 60
return has_destination_with_high_latitude.any()",bool,True,True,,,,
How many unique destinations are there in the dataset?,What is the number of distinct destinations in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_distinct_destinations = len(dataset['name_dest'].unique())
    return num_distinct_destinations",int64  ,1906,3219,,,,
"On average, how many times is each origin-destination pair reported?",What is the average count of reports for each origin-destination pair?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_count = dataset.groupby(['origin', 'dest'])['count'].mean().reset_index(name='average_count')
return average_count['average_count'].iloc[0] if not average_count.empty else 0.0",float64  ,126.0,67.7453800000000,,,,
What's the highest count value in the dataset?,What is the maximum count value in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_count = dataset[""count""].max()
    return max_count
",uint16  ,40580,40580,,,,
How many unique origin names are there in the dataset?,What is the count of distinct origin names in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_origins_count = dataset['name_origin'].nunique()
    
    return distinct_origins_count",int64  ,1904,1904,,,,
From which origin do we have the highest 'count' recorded?,Which origin has the highest count value?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_count_origin = dataset.loc[dataset[""count""] == dataset[""count""].max()]
origin_name = max_count_origin[""name_origin""].iloc[0]

return origin_name
",category,,,,,,
To which destination do we find the highest 'count' reported?,Which destination has the highest count?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_count_destination = dataset.loc[dataset[""count""] == dataset[""count""].max()]
    destination_name = max_count_destination[""name_dest""].iloc[0]

    return destination_name
",category,Los Angeles,Los Angeles,,,,
Which origin has the lowest latitude?,What is the name of the origin with the lowest latitude?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_lat_origin = dataset.loc[dataset[""lat_origin""] == dataset[""lat_origin""].min()]
    name_of_origin = min_lat_origin[""name_origin""].iloc[0]

    return name_of_origin
",string,GuÃ¡nica,Guáanica,,,,
Which destination has the highest longitude?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for the name of the destination with the highest count
    max_count_destination = dataset.loc[dataset[""count""] == dataset[""count""].max()]
    name_dest = max_count_destination[""name_dest""].iloc[0]

    return name_dest",category,Los Angeles,Fajardo,,,,
What are the 3 origins with the highest average count?,Which are the top 3 origins with the highest average count?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by name_origin and calculate the mean count for each origin
    avg_counts = dataset.groupby('name_origin')['count'].mean().reset_index()
    
    # Sort the origins by average count in descending order
    top_origins = avg_counts.sort_values(by='count', ascending=False)['name_origin'].head(3).tolist()
    
    return top_origins
",list of (string),"['Los Angeles', 'New York', 'San Francisco']","['Los Angeles', 'New York', 'San Francisco']",,,,
Which are the 4 destinations with the lowest average count?,What are the 4 destinations with the smallest average count?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by destination and calculate the average count for each destination
    avg_count_by_dest = dataset.groupby('name_dest')['count'].mean().reset_index()
    
    # Sort the destinations by average count in ascending order
    sorted_avg_count_by_dest = avg_count_by_dest.sort_values(by='count', ascending=True)
    
    # Get the names of the top 4 destinations with the smallest average count
    top_4_smallest_avg_count_destinations = sorted_avg_count_by_dest['name_dest'].head(4).tolist()
    
    return top_4_smallest_avg_count_destinations
",list of (string),"['Kalawao', 'Loving', 'Kenedy', 'Wheatland']","['Kalawao', 'Loving', 'Kenedy', 'Wheatland']",,,,
List the 5 origins with the highest average latitude values.,What are the top 5 origins with the highest average latitude values?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_origins = dataset.groupby('name_origin')['lat_origin'].mean().nlargest(5).index.tolist()
return top_origins",list of (string),"['North Slope', 'Northwest Arctic', 'Yukon-Koyukuk', 'Nome', 'Fairbanks North Star']","['North Slope', 'Northwest Arctic', 'Yukon-Koyukuk', 'Nome', 'Fairbanks North Star']",,,,
Which 2 origins have the lowest non-null average longitude values?,What are the two origins with the smallest non-null average longitude values?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Remove rows where lon_origin is null
    df_filtered = dataset.dropna(subset=['lon_origin'])
    
    # Group by origin and calculate the average longitude for each origin
    avg_lon_per_origin = df_filtered.groupby('name_origin')['lon_origin'].mean()
    
    # Find the two origins with the smallest average longitude values
    top_two_origins = avg_lon_per_origin.nsmallest(2).index.tolist()
    
    return top_two_origins
",list of (string),"['Aleutians West', 'Nome']","['Aleutians West', 'Nome']",,,,
List the highest 5 count values.,Retrieve the top 5 highest count values from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_counts = dataset.nlargest(5, 'count')['count'].tolist()
return top_counts
",list of (int64),"[40580, 39899, 38430, 28524, 24452]","[40580, 39899, 38430, 28524, 24452]",,,,
What are the 3 highest latitude values for destinations?,What are the top 3 highest latitude values for destinations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    top_3_latitudes = dataset['lat_dest'].nlargest(3).tolist()
    return top_3_latitudes
",list of (float64),"[69.42718361, 69.42718361, 69.42718361]","[69.42718361, 69.42718361, 69.42718361]",,,,
Rank the lowest 4 longitude values for origins.,What are the lowest 4 longitude values for origins?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    lowest_4_longitudes = dataset['lon_origin'].nsmallest(4).tolist()
    return lowest_4_longitudes",list of (float64),"[-167.08526, -167.08526, -167.08526, -167.08526]","[-167.08526, -167.08526, -167.08526, -167.08526]",,,,
Which 6 destination IDs have the highest average counts?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a list of destination IDs ('dest') that meet certain criteria
    # For example, let's say we want to find all destinations with 'count' greater than 1000
    filtered_destinations = dataset[dataset['count'] > 1000]['dest'].tolist()
    
    return filtered_destinations
",list of (int64),"[1003, 1015, 1049, 1051, 1051, 1073, 1073, 1073, 1073, 1077, 1083, 1089, 1097, 1101, 1101, 1101, 1113, 1115, 1117, 1121, 1125, 2020, 2020, 2170, 4003, 4003, 4005, 4007, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4013, 4015, 4015, 4015, 4015, 4017, 4019, 4019, 4019, 4019, 4019, 4019, 4019, 4019, 4021, 4021, 4021, 4021, 4021, 4025, 4025, 4027, 4027, 5007, 5007, 5033, 5045, 5085, 5091, 5119, 5119, 5119, 5125, 5131, 5143, 5143, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6001, 6007, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6013, 6017, 6019, 6019, 6019, 6019, 6019, 6019, 6019, 6019, 6019, 6023, 6025, 6029, 6029, 6029, 6029, 6029, 6029, 6029, 6029, 6029, 6031, 6031, 6033, 6035, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6037, 6039, 6041, 6041, 6041, 6041, 6047, 6047, 6047, 6053, 6053, 6053, 6053, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6059, 6061, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6065, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6067, 6069, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6071, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6073, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6075, 6077, 6077, 6077, 6077, 6077, 6077, 6077, 6079, 6079, 6079, 6079, 6079, 6081, 6081, 6081, 6081, 6081, 6081, 6081, 6081, 6081, 6083, 6083, 6083, 6083, 6083, 6083, 6083, 6083, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6085, 6087, 6087, 6087, 6095, 6095, 6095, 6095, 6095, 6097, 6097, 6097, 6097, 6099, 6099, 6099, 6099, 6099, 6101, 6103, 6107, 6107, 6107, 6107, 6111, 6111, 6111, 6111, 6111, 6113, 6113, 6113, 6113, 6113, 6115, 8001, 8001, 8001, 8001, 8001, 8001, 8005, 8005, 8005, 8005, 8005, 8005, 8013, 8013, 8013, 8013, 8013, 8013, 8014, 8014, 8014, 8031, 8031, 8031, 8031, 8031, 8031, 8031, 8031, 8031, 8031, 8031, 8035, 8035, 8035, 8035, 8041, 8041, 8041, 8041, 8041, 8041, 8041, 8059, 8059, 8059, 8059, 8059, 8059, 8069, 8069, 8069, 8069, 8069, 8101, 8123, 8123, 8123, 8123, 8123, 8123, 9001, 9001, 9001, 9001, 9001, 9001, 9001, 9001, 9001, 9001, 9003, 9003, 9003, 9003, 9003, 9003, 9003, 9003, 9005, 9005, 9005, 9007, 9007, 9009, 9009, 9009, 9009, 9009, 9011, 9011, 9011, 9011, 9013, 9013, 9013, 9015, 10001, 10001, 10003, 10003, 10003, 10003, 10003, 10003, 10003, 10005, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 11001, 12001, 12001, 12001, 12001, 12001, 12001, 12009, 12009, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12011, 12015, 12019, 12021, 12021, 12031, 12031, 12031, 12031, 12031, 12031, 12033, 12039, 12053, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12057, 12061, 12069, 12069, 12069, 12071, 12071, 12071, 12071, 12071, 12071, 12073, 12073, 12073, 12073, 12073, 12073, 12081, 12081, 12081, 12081, 12083, 12085, 12085, 12086, 12086, 12086, 12086, 12086, 12086, 12086, 12086, 12086, 12086, 12086, 12089, 12091, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12095, 12097, 12097, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12099, 12101, 12101, 12101, 12103, 12103, 12103, 12103, 12103, 12103, 12105, 12105, 12105, 12105, 12109, 12109, 12111, 12111, 12111, 12111, 12113, 12113, 12115, 12115, 12115, 12117, 12117, 12127, 12127, 12131, 13013, 13045, 13047, 13047, 13051, 13057, 13057, 13059, 13059, 13059, 13063, 13063, 13063, 13067, 13067, 13067, 13067, 13067, 13067, 13067, 13067, 13073, 13089, 13089, 13089, 13089, 13089, 13089, 13089, 13089, 13097, 13097, 13113, 13117, 13117, 13121, 13121, 13121, 13121, 13121, 13121, 13121, 13121, 13121, 13135, 13135, 13135, 13135, 13135, 13135, 13139, 13145, 13151, 13151, 13153, 13179, 13215, 13215, 13217, 13223, 13223, 13245, 13295, 13297, 15001, 15003, 15003, 15003, 15003, 15003, 15003, 15003, 15009, 15009, 16001, 16027, 17007, 17019, 17019, 17019, 17019, 17029, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17031, 17037, 17037, 17043, 17043, 17043, 17043, 17043, 17043, 17043, 17077, 17089, 17089, 17089, 17089, 17089, 17091, 17093, 17093, 17093, 17097, 17097, 17097, 17097, 17111, 17111, 17111, 17113, 17119, 17143, 17161, 17163, 17167, 17179, 17197, 17197, 17201, 17201, 18019, 18019, 18039, 18043, 18057, 18059, 18063, 18081, 18089, 18089, 18091, 18091, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18105, 18105, 18105, 18109, 18127, 18141, 18157, 18157, 18163, 18173, 19049, 19103, 19113, 19153, 19153, 19153, 19153, 19153, 19155, 19163, 19169, 19169, 19181, 20015, 20045, 20045, 20061, 20091, 20091, 20091, 20091, 20091, 20091, 20161, 20161, 20173, 20173, 20173, 20209, 20209, 21015, 21029, 21037, 21037, 21047, 21067, 21067, 21067, 21067, 21111, 21111, 21111, 21111, 21111, 21113, 21117, 21117, 21117, 21185, 22015, 22017, 22033, 22033, 22033, 22033, 22051, 22051, 22053, 22055, 22055, 22057, 22063, 22071, 22071, 22071, 22089, 22103, 22103, 22105, 22109, 22113, 23001, 23005, 23005, 23023, 23031, 24003, 24003, 24003, 24003, 24003, 24003, 24005, 24005, 24005, 24005, 24005, 24005, 24005, 24005, 24005, 24013, 24013, 24017, 24021, 24025, 24025, 24025, 24027, 24027, 24027, 24027, 24027, 24027, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24031, 24033, 24033, 24033, 24033, 24033, 24033, 24033, 24033, 24033, 24033, 24037, 24043, 24510, 24510, 24510, 24510, 24510, 24510, 24510, 25005, 25005, 25005, 25005, 25005, 25009, 25009, 25009, 25009, 25009, 25011, 25013, 25013, 25013, 25015, 25015, 25015, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25017, 25021, 25021, 25021, 25021, 25021, 25021, 25021, 25023, 25023, 25023, 25023, 25023, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25025, 25027, 25027, 25027, 25027, 25027, 25027, 26005, 26005, 26025, 26037, 26045, 26049, 26049, 26065, 26065, 26065, 26065, 26065, 26065, 26065, 26065, 26075, 26077, 26077, 26077, 26077, 26081, 26081, 26081, 26081, 26081, 26081, 26081, 26093, 26093, 26099, 26099, 26099, 26099, 26115, 26115, 26121, 26121, 26125, 26125, 26125, 26125, 26125, 26125, 26125, 26125, 26139, 26139, 26139, 26139, 26147, 26161, 26161, 26161, 26161, 26163, 26163, 26163, 26163, 26163, 27003, 27003, 27009, 27019, 27027, 27037, 27037, 27037, 27037, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27053, 27103, 27123, 27123, 27123, 27123, 27123, 27137, 27139, 27139, 27141, 27141, 27145, 27145, 27145, 27163, 27163, 27163, 27171, 27171, 28033, 28035, 28047, 28047, 28049, 28049, 28059, 28073, 28089, 28121, 28121, 29019, 29019, 29037, 29043, 29047, 29047, 29071, 29077, 29077, 29077, 29095, 29095, 29095, 29095, 29095, 29097, 29099, 29099, 29145, 29165, 29165, 29183, 29183, 29183, 29189, 29189, 29189, 29189, 29189, 29189, 29189, 29510, 29510, 29510, 31055, 31055, 31055, 31055, 31109, 31109, 31153, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32019, 32023, 32031, 32031, 32031, 32510, 33011, 33011, 33011, 33011, 33013, 33013, 33015, 33015, 33015, 33015, 33017, 33017, 34001, 34003, 34003, 34003, 34003, 34003, 34003, 34003, 34003, 34005, 34005, 34005, 34007, 34007, 34007, 34007, 34013, 34013, 34013, 34013, 34013, 34013, 34013, 34013, 34015, 34017, 34017, 34017, 34017, 34017, 34017, 34017, 34017, 34017, 34017, 34017, 34021, 34021, 34021, 34021, 34021, 34023, 34023, 34023, 34023, 34023, 34023, 34023, 34023, 34025, 34025, 34025, 34025, 34025, 34025, 34027, 34027, 34027, 34027, 34027, 34027, 34027, 34029, 34029, 34029, 34031, 34031, 34031, 34035, 34035, 34035, 34037, 34039, 34039, 34039, 34039, 34039, 35001, 35001, 35001, 35001, 35001, 35001, 35001, 35013, 35043, 35049, 35061, 36001, 36001, 36001, 36001, 36005, 36005, 36005, 36005, 36005, 36005, 36005, 36005, 36027, 36027, 36027, 36027, 36027, 36029, 36029, 36029, 36045, 36047, 36047, 36047, 36047, 36047, 36047, 36047, 36047, 36047, 36047, 36047, 36055, 36055, 36055, 36055, 36055, 36055, 36055, 36059, 36059, 36059, 36059, 36059, 36059, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36061, 36063, 36067, 36067, 36067, 36069, 36071, 36071, 36075, 36079, 36081, 36081, 36081, 36081, 36081, 36081, 36081, 36081, 36081, 36081, 36081, 36083, 36085, 36087, 36091, 36091, 36093, 36103, 36103, 36103, 36103, 36103, 36109, 36113, 36115, 36117, 36119, 36119, 36119, 36119, 36119, 36119, 36119, 37001, 37019, 37021, 37025, 37025, 37035, 37049, 37051, 37051, 37051, 37051, 37057, 37057, 37063, 37063, 37063, 37065, 37067, 37067, 37069, 37071, 37081, 37081, 37081, 37081, 37081, 37081, 37085, 37089, 37093, 37097, 37101, 37119, 37119, 37119, 37119, 37119, 37119, 37119, 37119, 37119, 37119, 37127, 37129, 37129, 37133, 37133, 37135, 37135, 37135, 37141, 37147, 37151, 37159, 37179, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37183, 37191, 38015, 38017, 38059, 39017, 39017, 39017, 39017, 39023, 39025, 39035, 39035, 39035, 39035, 39035, 39035, 39041, 39045, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39049, 39055, 39057, 39061, 39061, 39061, 39061, 39061, 39061, 39061, 39061, 39085, 39089, 39093, 39095, 39095, 39097, 39099, 39099, 39103, 39103, 39109, 39113, 39113, 39113, 39113, 39113, 39129, 39133, 39133, 39151, 39153, 39153, 39153, 39153, 39153, 39155, 39159, 39165, 39165, 39165, 39169, 39173, 40017, 40027, 40027, 40027, 40037, 40083, 40087, 40109, 40109, 40109, 40109, 40109, 40109, 40109, 40113, 40119, 40125, 40131, 40143, 40143, 40143, 40143, 40143, 40143, 40145, 41003, 41003, 41005, 41005, 41005, 41005, 41029, 41039, 41039, 41039, 41039, 41043, 41043, 41047, 41047, 41047, 41047, 41047, 41047, 41051, 41051, 41051, 41051, 41051, 41051, 41051, 41051, 41051, 41051, 41051, 41053, 41067, 41067, 41067, 41067, 41067, 41067, 41067, 41071, 42001, 42003, 42003, 42003, 42003, 42003, 42003, 42007, 42011, 42017, 42017, 42017, 42017, 42019, 42027, 42027, 42029, 42029, 42029, 42029, 42029, 42029, 42041, 42041, 42041, 42043, 42045, 42045, 42045, 42045, 42045, 42049, 42069, 42071, 42071, 42071, 42075, 42075, 42077, 42077, 42079, 42091, 42091, 42091, 42091, 42091, 42091, 42091, 42095, 42095, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42101, 42125, 42129, 42129, 42133, 42133, 42133, 42133, 44003, 44003, 44007, 44007, 44007, 44007, 44007, 44007, 44009, 45007, 45007, 45013, 45015, 45015, 45019, 45019, 45021, 45031, 45035, 45035, 45043, 45045, 45045, 45045, 45045, 45059, 45063, 45073, 45077, 45077, 45079, 45079, 45079, 45079, 45079, 45079, 45079, 45079, 45083, 45091, 46083, 46093, 46099, 47001, 47009, 47019, 47021, 47037, 47037, 47037, 47037, 47037, 47037, 47037, 47047, 47065, 47065, 47073, 47093, 47093, 47093, 47093, 47119, 47125, 47147, 47147, 47149, 47155, 47157, 47157, 47157, 47157, 47157, 47163, 47165, 47165, 47167, 47179, 47187, 47189, 48013, 48021, 48027, 48027, 48027, 48027, 48027, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48029, 48039, 48041, 48041, 48041, 48041, 48041, 48041, 48061, 48061, 48071, 48085, 48085, 48085, 48085, 48085, 48091, 48091, 48099, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48113, 48121, 48121, 48121, 48121, 48121, 48121, 48121, 48135, 48135, 48139, 48139, 48141, 48141, 48141, 48141, 48157, 48157, 48157, 48157, 48157, 48167, 48167, 48181, 48187, 48187, 48189, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48201, 48209, 48209, 48209, 48209, 48215, 48215, 48215, 48221, 48231, 48245, 48245, 48251, 48257, 48259, 48291, 48303, 48303, 48303, 48303, 48303, 48325, 48329, 48339, 48339, 48355, 48355, 48355, 48355, 48361, 48367, 48375, 48381, 48397, 48401, 48409, 48423, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48439, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48453, 48471, 48473, 48479, 48491, 48491, 48491, 48491, 48497, 49005, 49011, 49011, 49011, 49035, 49035, 49035, 49035, 49035, 49035, 49035, 49035, 49035, 49035, 49045, 49049, 49049, 49049, 49049, 49049, 49049, 49049, 49049, 49053, 49053, 49057, 49057, 51003, 51013, 51013, 51013, 51013, 51013, 51031, 51041, 51041, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51059, 51069, 51085, 51087, 51087, 51087, 51087, 51087, 51107, 51107, 51107, 51121, 51153, 51153, 51153, 51153, 51153, 51153, 51161, 51177, 51179, 51179, 51199, 51199, 51510, 51510, 51510, 51510, 51510, 51540, 51550, 51550, 51550, 51600, 51650, 51660, 51680, 51683, 51700, 51710, 51710, 51710, 51710, 51710, 51740, 51740, 51740, 51740, 51760, 51760, 51760, 51770, 51810, 51810, 51810, 51810, 51810, 51810, 51820, 51840, 53005, 53011, 53011, 53015, 53017, 53021, 53029, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53033, 53035, 53035, 53035, 53035, 53037, 53041, 53045, 53053, 53053, 53053, 53053, 53053, 53053, 53053, 53057, 53057, 53061, 53061, 53061, 53061, 53063, 53063, 53063, 53063, 53063, 53067, 53067, 53067, 53067, 53073, 53073, 53075, 54003, 54003, 54011, 54039, 54081, 55017, 55025, 55025, 55025, 55025, 55025, 55035, 55055, 55059, 55059, 55079, 55079, 55079, 55079, 55079, 55079, 55079, 55087, 55087, 55089, 55101, 55101, 55131, 55133, 55133, 55139, 72031, 72061, 72127, 72127, 72127, 72127, 72127]","[6037, 36061, 48201, 6059, 6071, 6085]",,,,
Are there talks with more than a million views?,Is there any talk that has more than one million views?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_more_than_one_million_views = dataset[""views""].max() > 1000000

return has_more_than_one_million_views",bool,True,True,,,,
Is there a talk by 'Elon Musk'?,Is there a Ted talk given by Elon Musk?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    is_elon_musk_talk = ""Elon Musk"" in dataset[""all_speakers""].values

    return is_elon_musk_talk
",bool,False,True,,,,
Are there any TEDx events included?,Is there any talk that is part of a TEDx event?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    tedx_event = dataset['event'].str.contains('TEDx', case=False).any()
    
    return tedx_event
",bool,True,True,,,,
Are there talks available in more than 10 languages?,,,,ERROR,True,,,,
How many unique speakers are there in the dataset?,What is the count of distinct speakers in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_speaker_count = dataset['speaker_1'].nunique()
    return distinct_speaker_count
",int64,3274,3274,,,,
What's the average number of views for the talks?,What is the average number of views for all talks?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_views = dataset[""views""].mean()
return average_views",float64,2148005.5737830000,2148005.5737830000,,,,
What's the maximum duration of a talk (in seconds)?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value from the talk_id column
    # For example, if the question is ""What is the talk_id of the first talk in the dataset?""
    # The answer would be the first value in the talk_id column

    # Extract the first talk_id from the dataset
    first_talk_id = dataset.iloc[0]['talk_id']

    return first_talk_id",uint16,1,3922,,,,
How many talks have more than 500 comments?,How many talks have a comment count greater than 500?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    talk_count = dataset[dataset[""comments""] > 500].shape[0]
    return talk_count
",int64  ,186,186,,,,
Which event has the highest average views?,What is the name of the event with the highest average views?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by event and calculate the mean views for each event
    avg_views_by_event = dataset.groupby('event')['views'].mean()
    
    # Find the event with the highest average views
    event_with_highest_avg_views = avg_views_by_event.idxmax()
    
    return event_with_highest_avg_views
",string,TEDxPuget Sound,TEDxPuget Sound,,,,
Which speaker's talk has the most comments?,Which speaker has the talk with the highest number of comments?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_comments_talk = dataset.loc[dataset[""comments""] == dataset[""comments""].max()]
    speaker_with_max_comments = max_comments_talk[""speaker_1""].iloc[0]

    return speaker_with_max_comments
",string,Richard Dawkins,Richard Dawkins,,,,
Which talk's title has the least views?,What is the title of the talk with the lowest number of views?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_views_talk = dataset.loc[dataset[""views""] == dataset[""views""].min()]
    title_of_min_views_talk = min_views_talk['title'].iloc[0]

    return title_of_min_views_talk",string,Por qué necesitamos proteger el alta mar,Por qué necesitamos proteger el alta mar,,,,
In which event was the longest talk held?,Which event hosted the talk with the maximum duration?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_duration_talk = dataset.loc[dataset[""duration""] == dataset[""duration""].max()]
event_hosted = max_duration_talk[""event""].iloc[0]

return event_hosted",string,Countdown,Countdown,,,,
Which are the top 4 events with the highest average number of comments?,What are the top 4 events with the highest average number of comments?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by event and calculate the average number of comments for each event
    avg_comments_by_event = dataset.groupby('event')['comments'].mean().reset_index()
    
    # Sort events by average comments in descending order
    top_events = avg_comments_by_event.sort_values(by='comments', ascending=False)
    
    # Get the top 4 events
    top_4_events = top_events['event'].head(4).tolist()
    
    return top_4_events
",list of (string),"['TEDxPuget Sound', 'TEDxHouston', 'TEDxFiDiWomen', 'TEDxUW']","['TEDxPuget Sound', 'TEDxHouston', 'TEDxFiDiWomen', 'TEDxUW']",,,,
List the top 3 most frequent speakers in the dataset. If two have the same count go by alphabetical order. ,,,,ERROR,"['Alex Gendler', 'Iseult Gillespie', 'Emma Bryce']",,,,
Which 5 events have the shortest average talk durations?,What are the names of the 5 events with the shortest average talk durations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Group by event and calculate the average duration for each event
event_avg_duration = dataset.groupby('event')['duration'].mean().reset_index()

# Sort events by their average duration in ascending order
sorted_events = event_avg_duration.sort_values(by='duration', ascending=True)

# Get the names of the top 5 events with the shortest average talk durations
top_5_shortest_events = sorted_events.head(5)['event'].tolist()

return top_5_shortest_events",list of (string),"['TEDxConcorde', 'Small Thing Big Idea', 'The TED Interview', 'TEDxConcordiaUPortland', 'The Way We Work']","['TEDxConcorde', 'Small Thing Big Idea', 'The TED Interview', 'TEDxConcordiaUPortland', 'The Way We Work']",,,,
List 2 events with the most number of talks.,What are the names of the two events that have hosted the most number of talks?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
event_counts = dataset['event'].value_counts().head(2).index.tolist()
return event_counts
",list of (string),"['TED-Ed', 'TED2018']","['TED-Ed', 'TED2018']",,,,
What are the top 4 most viewed talks' view counts?,What are the view counts for the top 4 most viewed talks?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_views = dataset.nlargest(4, 'views')['views'].tolist()
return top_views",list of (int64),"[65051954, 57074270, 56932551, 49730580]","[65051954, 57074270, 56932551, 49730580]",,,,
List the 3 shortest talk durations in the dataset.,What are the durations of the three shortest talks in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by duration in ascending order and select the first three rows
    shortest_talks = dataset.nsmallest(3, 'duration')
    
    # Extract the durations of these talks
    durations = shortest_talks['duration'].tolist()
    
    return durations
",list of (int64),"[60, 78, 78]","[60, 78, 78]",,,,
What are the 5 highest number of comments?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for talk IDs that meet certain criteria
    # For example, let's say we want to find talk IDs where the number of views is greater than a certain threshold
    
    # Example threshold: 10000
    threshold = 10000
    result = dataset[dataset['views'] > threshold]['talk_id'].tolist()
    
    return result",list of (int64),"[1, 92, 7, 53, 66, 49, 86, 94, 71, 55, 58, 54, 41, 65, 46, 45, 2, 27, 37, 25, 87, 21, 16, 64, 98, 47, 20, 29, 97, 93, 12, 39, 91, 79, 3, 75, 4, 89, 56, 57, 59, 22, 67, 19, 38, 23, 26, 10, 70, 36, 62, 69, 34, 42, 68, 63, 61, 60, 48, 90, 73, 84, 83, 85, 9, 77, 5, 14, 35, 43, 44, 50, 80, 18, 40, 81, 78, 76, 74, 6, 32, 28, 31, 11, 99, 101, 102, 103, 104, 108, 105, 109, 110, 114, 113, 115, 112, 72, 117, 118, 119, 121, 122, 123, 125, 126, 128, 129, 127, 131, 130, 8, 33, 139, 140, 141, 116, 142, 144, 143, 148, 146, 147, 149, 151, 153, 152, 154, 156, 155, 157, 158, 170, 82, 161, 159, 162, 164, 163, 171, 168, 172, 167, 176, 178, 179, 181, 165, 182, 190, 184, 185, 189, 191, 187, 183, 192, 193, 177, 195, 198, 197, 194, 51, 199, 200, 201, 202, 204, 203, 145, 205, 206, 207, 13, 188, 209, 208, 196, 210, 211, 212, 213, 215, 214, 216, 218, 221, 219, 222, 223, 220, 225, 224, 228, 227, 230, 229, 231, 233, 234, 232, 174, 236, 237, 235, 239, 241, 242, 243, 245, 246, 247, 249, 250, 251, 254, 253, 255, 258, 259, 260, 261, 248, 263, 264, 266, 267, 268, 270, 269, 271, 273, 276, 279, 278, 252, 280, 285, 30, 286, 288, 287, 292, 297, 298, 299, 300, 282, 274, 296, 306, 307, 308, 301, 310, 312, 313, 294, 315, 316, 318, 319, 321, 320, 322, 326, 323, 324, 327, 328, 325, 329, 175, 330, 334, 331, 335, 339, 333, 340, 344, 346, 343, 347, 345, 348, 341, 217, 353, 351, 272, 349, 350, 354, 355, 356, 358, 359, 360, 361, 363, 362, 364, 371, 372, 375, 377, 374, 379, 366, 381, 365, 383, 385, 386, 673, 674, 675, 676, 677, 679, 388, 390, 391, 392, 393, 394, 395, 399, 400, 402, 396, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 418, 420, 419, 421, 423, 422, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 439, 437, 441, 442, 440, 443, 445, 447, 450, 451, 453, 455, 457, 462, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 480, 481, 482, 483, 484, 485, 487, 488, 489, 490, 492, 494, 495, 498, 499, 500, 501, 502, 503, 504, 506, 507, 509, 510, 511, 512, 515, 517, 516, 518, 519, 520, 524, 521, 523, 525, 526, 527, 529, 531, 532, 533, 534, 535, 537, 538, 540, 545, 544, 547, 548, 549, 551, 552, 553, 555, 554, 556, 557, 558, 560, 561, 562, 563, 565, 566, 570, 571, 572, 573, 575, 578, 580, 582, 584, 585, 586, 587, 588, 589, 590, 591, 592, 594, 598, 599, 601, 602, 603, 604, 605, 606, 607, 610, 613, 608, 614, 615, 618, 619, 620, 621, 622, 623, 625, 626, 627, 628, 629, 630, 633, 634, 635, 637, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 669, 670, 680, 681, 682, 683, 684, 685, 691, 692, 686, 694, 695, 696, 698, 688, 689, 700, 701, 702, 705, 706, 704, 709, 708, 710, 712, 714, 713, 715, 716, 717, 718, 719, 723, 724, 726, 727, 728, 729, 734, 735, 736, 738, 741, 743, 744, 748, 750, 751, 752, 755, 757, 759, 760, 761, 762, 763, 765, 766, 768, 769, 767, 770, 771, 772, 773, 776, 777, 779, 780, 783, 785, 786, 788, 789, 790, 792, 796, 797, 799, 791, 800, 801, 802, 803, 804, 807, 809, 815, 814, 811, 818, 819, 820, 821, 823, 824, 826, 828, 831, 833, 835, 836, 837, 838, 842, 843, 845, 844, 846, 847, 848, 850, 851, 849, 852, 853, 854, 855, 856, 859, 860, 861, 862, 863, 865, 866, 868, 869, 871, 872, 873, 874, 876, 877, 878, 879, 880, 881, 883, 884, 885, 886, 887, 888, 889, 891, 892, 893, 894, 896, 898, 899, 900, 901, 909, 910, 911, 912, 914, 915, 916, 917, 918, 919, 920, 921, 922, 924, 926, 927, 928, 929, 930, 932, 934, 935, 936, 937, 938, 939, 940, 941, 944, 945, 946, 947, 948, 949, 950, 951, 952, 954, 955, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 970, 971, 972, 973, 974, 975, 976, 977, 978, 980, 981, 983, 984, 986, 987, 988, 991, 992, 993, 994, 995, 996, 997, 1000, 998, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1030, 1031, 1032, 1033, 1034, 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1338, 1062, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1098, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1121, 1122, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1091, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1152, 1153, 1154, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1120, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1242, 1263, 1264, 1265, 1266, 1267, 1269, 1268, 1245, 1270, 1271, 1272, 1274, 1276, 1278, 1279, 1280, 1281, 1282, 1284, 1285, 1286, 1289, 1290, 1291, 1287, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1288, 1311, 1312, 1313, 1314, 1315, 1317, 1318, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1334, 1335, 1336, 1337, 1339, 1341, 1342, 1343, 1344, 1345, 1346, 830, 1348, 1347, 1349, 1350, 1351, 1352, 1353, 1355, 1354, 1356, 1357, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1370, 1369, 1371, 1373, 1372, 1375, 1374, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1396, 1397, 1398, 1400, 1399, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1413, 1415, 1412, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1446, 1445, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1459, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1474, 1475, 1476, 1477, 1478, 1479, 1473, 1480, 1481, 1482, 1487, 1483, 1488, 1489, 1485, 1490, 1491, 1492, 1494, 1495, 1498, 1484, 1499, 1500, 1501, 1503, 1506, 1496, 1505, 1507, 1508, 1509, 1510, 1514, 1515, 1512, 1517, 1516, 1513, 1518, 1521, 1520, 1519, 1522, 1528, 1523, 1530, 1531, 1532, 1526, 1543, 1542, 1533, 1534, 1538, 1535, 1541, 1548, 1547, 1545, 1544, 1549, 1524, 1555, 1556, 1551, 1561, 1559, 1560, 1557, 1554, 1562, 1527, 1558, 1565, 1563, 1564, 1576, 1567, 1566, 1572, 1574, 1573, 1546, 1578, 1575, 1537, 1582, 1583, 1569, 1577, 1586, 1570, 1579, 1591, 1571, 1584, 1592, 1588, 1580, 1585, 1587, 1594, 1581, 1593, 1597, 1596, 1598, 1602, 1595, 1599, 1605, 1606, 1600, 1607, 1608, 1604, 1601, 1612, 1613, 1614, 1603, 1609, 1552, 1618, 1616, 1619, 1283, 1553, 1617, 1620, 1621, 1610, 1622, 1623, 1611, 1624, 1626, 1625, 1627, 1630, 1629, 1628, 1631, 1632, 1633, 1634, 1638, 1636, 1637, 1641, 1639, 1642, 1643, 1644, 1645, 1640, 1646, 1568, 1647, 1648, 1650, 1651, 1649, 1652, 1654, 1656, 1657, 1658, 1660, 1659, 1655, 1663, 1661, 1664, 1666, 1665, 1668, 1669, 1653, 1671, 1670, 1673, 1667, 1674, 1675, 1677, 1678, 1679, 1682, 1683, 1684, 1685, 1672, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1694, 1696, 1697, 1698, 1700, 1699, 1701, 1705, 1703, 1704, 1702, 1707, 1708, 1710, 1709, 1706, 1711, 1712, 1713, 1714, 1715, 1717, 1716, 1718, 1720, 1719, 1723, 1724, 1725, 1726, 1727, 1729, 1730, 1728, 1735, 1736, 1734, 1732, 1737, 1731, 1739, 1733, 1738, 1741, 1742, 1721, 1743, 1745, 1746, 1747, 1744, 1749, 1750, 1752, 1753, 1751, 1755, 1756, 1754, 1757, 1758, 1760, 1759, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1769, 1763, 1772, 1774, 1776, 1777, 1762, 1778, 1779, 1781, 1782, 1784, 1785, 1786, 1787, 1761, 1788, 1780, 1789, 1792, 1794, 1793, 1796, 1795, 1797, 1798, 1799, 1801, 1802, 1804, 1805, 1806, 1807, 1800, 1808, 1773, 1809, 1810, 1813, 1812, 1811, 1815, 1791, 1814, 1816, 1817, 1818, 1819, 1821, 1820, 1822, 1823, 1824, 1825, 1826, 1827, 1829, 1828, 1830, 1831, 1832, 1833, 1834, 1835, 1837, 1836, 1838, 1839, 1840, 1841, 1843, 1847, 1846, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1783, 1856, 1857, 1790, 1859, 1858, 1860, 1861, 1862, 1842, 1863, 1864, 1873, 1866, 1872, 1874, 1875, 1876, 1878, 1877, 1879, 1880, 1881, 1882, 1883, 1885, 1886, 1890, 1888, 1889, 1891, 1887, 1892, 1893, 1894, 1895, 1897, 1896, 1865, 1898, 1803, 1901, 1900, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1922, 1921, 1924, 1926, 1927, 1928, 1925, 1845, 1930, 1931, 1932, 1935, 1933, 1929, 1936, 1937, 1939, 1938, 1940, 1942, 1941, 1934, 1943, 1944, 1945, 1948, 1946, 1950, 1951, 1949, 1953, 1952, 1954, 1956, 1955, 1958, 1959, 1961, 1962, 1963, 1964, 1957, 1960, 1966, 1965, 1969, 1971, 1972, 1973, 1974, 1947, 1976, 1977, 1978, 1979, 1981, 1984, 1983, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1996, 1995, 1997, 2002, 2000, 1998, 2003, 2005, 2007, 2008, 1999, 2006, 2009, 2004, 2010, 2015, 2012, 2013, 2014, 2016, 2017, 2019, 2018, 2020, 2021, 2011, 2022, 2023, 2028, 2031, 2029, 2030, 2032, 2033, 2034, 2035, 2001, 2036, 2037, 2038, 2041, 2043, 2044, 2042, 2027, 2045, 2046, 2047, 2048, 2049, 2050, 2039, 2053, 2052, 2054, 2056, 2055, 2057, 2060, 2059, 2061, 2064, 2062, 2066, 2063, 2067, 2065, 2068, 2073, 2071, 2072, 2070, 2075, 2074, 2024, 2078, 2090, 2089, 2076, 2069, 2091, 2026, 2088, 2093, 2094, 2095, 2096, 2092, 2097, 2099, 2098, 2077, 2100, 2101, 2102, 2104, 2105, 2106, 2103, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2116, 2115, 2118, 2119, 2117, 2120, 2121, 2107, 2127, 2122, 2128, 2129, 2132, 2134, 2130, 2133, 2131, 2135, 1982, 2137, 2138, 2136, 2141, 2140, 2025, 2142, 2143, 2144, 2145, 2147, 2126, 2146, 2148, 2149, 2150, 2151, 2155, 2156, 2154, 2157, 2158, 2159, 2160, 2162, 2161, 2164, 2166, 2167, 2165, 2139, 2163, 2168, 2170, 2173, 2171, 2172, 2174, 2175, 2169, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2184, 2153, 2193, 2194, 2195, 2197, 2198, 2201, 2152, 2185, 2199, 2206, 2202, 2203, 2209, 2204, 2124, 2213, 2183, 2207, 2208, 2210, 2211, 2214, 2215, 2216, 2217, 2218, 2219, 2222, 2220, 2223, 2212, 2224, 2226, 2221, 2225, 2200, 2186, 2229, 2230, 2231, 2233, 2232, 2234, 2235, 2239, 2237, 2228, 2240, 2238, 2243, 2244, 2236, 2247, 2241, 2246, 2242, 2245, 2248, 2249, 2251, 2253, 2250, 2258, 2257, 2254, 2252, 2255, 2261, 2262, 2260, 2264, 2272, 2265, 2274, 2263, 2276, 2256, 2278, 2277, 2281, 2279, 2283, 2286, 2280, 2273, 2284, 2287, 2289, 2291, 2292, 2293, 2285, 2288, 2294, 2295, 2299, 2282, 2275, 2297, 2300, 2303, 2301, 2302, 2298, 2305, 2304, 2307, 2309, 2308, 2306, 2313, 2310, 2296, 2315, 2314, 2319, 2316, 2317, 2318, 2321, 2320, 2311, 2322, 2323, 2259, 2324, 2325, 2327, 2326, 2328, 2329, 2330, 2332, 2337, 2335, 2331, 2336, 2340, 2333, 2334, 2338, 2341, 2339, 2343, 2344, 2342, 2345, 2348, 2346, 2349, 2353, 2351, 2352, 2354, 2356, 2359, 2364, 2363, 2357, 2365, 2361, 2362, 2358, 2367, 2368, 2366, 2370, 2369, 2372, 2374, 2371, 2376, 2379, 2373, 2377, 2382, 2380, 2381, 2385, 2384, 2383, 2378, 2387, 2388, 2391, 2392, 2389, 2227, 2393, 2394, 2397, 2398, 2395, 2399, 2396, 2403, 2402, 2404, 2405, 2401, 2406, 2400, 2375, 2409, 2412, 2411, 2407, 2415, 2413, 2414, 2416, 2419, 2418, 2417, 2424, 2420, 2425, 2426, 2423, 2410, 2430, 2427, 2428, 2429, 2435, 2438, 2439, 2440, 2441, 2442, 2431, 2445, 2433, 2434, 2437, 2436, 2449, 2443, 2448, 2390, 2454, 2452, 2451, 2447, 2458, 2457, 2456, 2459, 2453, 2469, 2455, 2462, 2461, 2463, 2472, 2471, 2470, 2474, 2465, 2475, 2466, 2468, 2464, 2478, 2477, 2476, 2467, 2460, 2479, 2480, 2482, 2485, 2473, 2483, 2484, 925, 2486, 2487, 2488, 2489, 2490, 2492, 2493, 2497, 2499, 2500, 2494, 2495, 2496, 2498, 2501, 2504, 2505, 2506, 2507, 2508, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2523, 2521, 2522, 2524, 2502, 2527, 2525, 2535, 2528, 2526, 2530, 2531, 2534, 2533, 2537, 2536, 2538, 2541, 2543, 2539, 2529, 2547, 2551, 2546, 2552, 2540, 2556, 2553, 2557, 2558, 2548, 2549, 2559, 2560, 2545, 2562, 2550, 2566, 2561, 2568, 2563, 2565, 2569, 2573, 2571, 2578, 2572, 2574, 2575, 2577, 2579, 2580, 2581, 2555, 2554, 2582, 2583, 2532, 2584, 2587, 2585, 2586, 2570, 2567, 2588, 2589, 2544, 2592, 2590, 2593, 2596, 2599, 2594, 2576, 2595, 2597, 2598, 2603, 2601, 2602, 2604, 2605, 2606, 2607, 2608, 2609, 2618, 2600, 2610, 2612, 2611, 2614, 2616, 2617, 2619, 2621, 2481, 2622, 2625, 2623, 2624, 2629, 2626, 2630, 2615, 2620, 2628, 2632, 2631, 2633, 2634, 2591, 2636, 2637, 2635, 2639, 2638, 2641, 2642, 2644, 2645, 2648, 2646, 2647, 2655, 2649, 2656, 2643, 2654, 2652, 2650, 2659, 2658, 2661, 2660, 2664, 2663, 2665, 2627, 2666, 2667, 2669, 2651, 2670, 2668, 2662, 2672, 2673, 2674, 2679, 2681, 2677, 2671, 2678, 2680, 2682, 2683, 2686, 2685, 2684, 2687, 2675, 2689, 2695, 2691, 2690, 2653, 2694, 2700, 2696, 2697, 2698, 2702, 2701, 2703, 2704, 2706, 2705, 2709, 2707, 2491, 2708, 2692, 2713, 2711, 2712, 2688, 2714, 2718, 2719, 2720, 2693, 2721, 2722, 2724, 2716, 2723, 2725, 2726, 2727, 2728, 2730, 2729, 2731, 2732, 2734, 2736, 2733, 2735, 2741, 2737, 2738, 2744, 2770, 2771, 2774, 2769, 2772, 2739, 2775, 2742, 2779, 2777, 2780, 2776, 2781, 2778, 2784, 2783, 2788, 2785, 2786, 2791, 2793, 2792, 2782, 2787, 2794, 2789, 2795, 2743, 2796, 2797, 2740, 2798, 2801, 2799, 2804, 2808, 2800, 2790, 2806, 2807, 2805, 2810, 2803, 2809, 2812, 2811, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2827, 2821, 2802, 2822, 2823, 2825, 2826, 2830, 2828, 2829, 2841, 2836, 2843, 2849, 2833, 2851, 2837, 2831, 2834, 2838, 2840, 2839, 2842, 2844, 2824, 2845, 2846, 2858, 2850, 2863, 2847, 2848, 2857, 2852, 2866, 2854, 2864, 2856, 2855, 2859, 2750, 2763, 2760, 2768, 2745, 2766, 2748, 2752, 2767, 2757, 2756, 2865, 2755, 2751, 2761, 2853, 2765, 2762, 2749, 2764, 2754, 2753, 2758, 2759, 2747, 2657, 2746, 2873, 2876, 2835, 2861, 2875, 2867, 2862, 2880, 2871, 2879, 2881, 2869, 2887, 2870, 2882, 2874, 2872, 2884, 2877, 2878, 2896, 2883, 2886, 2892, 2885, 2889, 2898, 3012, 2891, 3013, 2901, 2895, 2894, 3269, 3114, 3136, 3231, 3367, 3257, 3366, 3362, 3364, 3363, 2890, 3585, 3574, 3573, 3595, 3625, 3579, 3587, 3596, 3583, 3592, 3680, 3590, 3591, 3593, 3769, 3632, 3606, 3616, 3612, 4366, 3613, 3620, 3615, 4856, 3365, 3614, 4463, 3617, 3642, 4539, 3631, 4669, 4490, 5480, 2868, 3694, 5655, 3671, 5458, 3633, 3581, 4873, 4755, 4062, 3686, 6235, 5072, 6234, 6477, 6286, 5498, 6857, 6298, 5116, 7060, 5162, 4958, 3623, 7592, 6287, 8227, 7395, 6379, 6493, 6553, 6496, 6594, 8419, 8418, 8529, 2860, 6639, 8420, 6668, 7394, 8417, 6669, 8422, 8423, 8588, 8421, 9219, 9048, 8589, 8606, 8799, 8947, 8779, 6602, 8786, 8866, 8787, 8780, 8788, 9464, 6672, 9463, 9033, 9125, 9636, 9473, 6671, 9214, 9987, 9296, 9403, 9687, 9986, 9781, 9985, 9807, 10173, 9988, 9126, 10376, 9989, 10193, 10358, 10360, 10550, 10802, 10666, 10681, 10378, 10975, 9930, 11008, 10807, 10362, 11226, 10835, 10727, 5351, 11720, 11087, 10361, 10750, 11684, 11199, 11685, 11871, 11089, 11486, 11869, 12650, 9951, 12351, 12346, 12348, 12349, 12350, 12347, 12352, 12353, 10274, 12729, 3618, 12459, 12354, 10266, 11997, 11337, 12303, 12302, 11327, 12060, 12803, 12066, 9982, 13062, 12501, 12908, 13584, 13585, 13586, 13587, 13588, 13589, 8298, 12202, 12370, 12409, 12498, 13010, 13011, 13009, 9984, 12571, 13013, 13567, 13012, 13000, 12799, 13591, 12800, 13778, 12727, 13022, 14484, 14485, 14471, 14439, 14491, 14486, 14610, 14392, 9983, 13247, 13029, 14613, 14608, 14615, 13834, 13035, 14614, 11976, 13217, 15214, 15274, 13878, 13316, 15149, 13195, 5990, 15471, 2893, 12983, 12829, 13828, 11363, 13464, 15518, 13465, 15112, 15813, 15537, 16014, 15553, 15275, 13340, 13518, 16159, 15814, 15722, 13720, 15284, 15555, 15862, 17023, 13517, 16985, 13055, 16960, 15452, 15536, 17238, 15398, 17240, 15531, 17275, 15289, 13476, 17733, 17237, 17603, 18190, 17698, 17922, 17697, 17699, 17711, 17712, 17713, 17849, 17848, 17846, 5451, 17851, 17923, 15420, 18219, 18094, 17845, 18514, 15290, 17239, 17994, 19320, 18394, 16913, 18818, 19140, 18469, 19172, 18517, 19413, 18928, 18592, 18512, 19175, 19173, 19322, 19478, 20084, 20086, 19330, 19727, 20088, 20087, 19756, 16782, 19174, 19460, 19461, 19829, 19266, 19535, 19740, 19851, 19830, 19883, 20259, 20447, 16294, 20974, 20317, 19714, 19927, 19992, 20101, 20721, 21148, 19995, 20554, 20082, 20008, 20083, 20085, 20973, 20268, 20089, 21177, 21191, 20044, 21894, 20324, 20368, 10190, 21701, 21017, 21033, 20365, 21932, 20919, 20269, 21753, 20475, 21117, 21896, 21645, 21802, 21307, 21700, 21768, 21803, 21584, 20753, 20757, 21996, 21646, 21039, 21977, 22701, 20173, 21752, 23117, 23413, 23418, 23416, 20692, 8530, 23466, 23422, 23088, 20975, 21804, 23248, 23089, 24689, 22704, 23420, 24727, 20310, 22703, 21976, 23658, 20319, 13523, 20390, 20633, 21895, 22947, 20519, 23479, 24922, 22979, 23423, 22752, 22799, 22817, 23684, 23087, 25090, 23174, 21650, 23515, 17909, 20172, 25057, 22992, 23583, 24724, 23129, 24866, 3328, 23480, 25595, 25029, 25572, 25133, 3891, 25671, 23421, 25751, 13923, 23713, 25601, 25339, 25054, 25340, 12385, 24725, 25748, 26073, 26072, 26075, 25241, 26074, 26333, 25874, 26263, 25335, 26264, 25727, 26676, 20779, 21900, 26265, 21972, 22628, 26076, 26266, 26707, 26708, 23483, 26922, 26918, 26915, 25103, 26570, 27219, 25571, 26727, 27221, 26779, 26926, 23740, 26946, 26916, 26913, 23722, 26262, 27173, 27632, 27674, 27951, 27952, 27608, 27750, 27790, 23738, 27105, 28070, 27383, 26257, 22919, 24865, 25368, 23735, 23058, 28418, 28050, 27793, 27696, 28164, 28863, 29064, 27622, 28544, 29185, 28542, 23762, 27155, 26921, 27846, 29411, 29263, 29160, 23783, 28104, 28429, 29159, 23799, 27692, 29523, 28236, 23773, 29459, 28953, 29968, 29746, 29668, 29769, 29414, 28318, 23844, 30295, 30161, 30207, 29779, 31006, 30988, 29775, 23780, 23813, 28438, 30507, 23801, 29391, 30180, 30527, 28518, 31135, 30296, 23806, 31121, 30204, 29265, 30300, 23777, 31376, 29998, 31375, 31441, 30820, 31455, 23827, 31459, 30813, 31377, 23800, 30301, 31122, 31466, 23807, 29521, 30303, 31821, 31814, 31628, 31630, 31633, 32560, 31857, 23845, 30297, 31812, 31813, 31779, 23841, 31849, 23862, 32556, 29949, 21150, 32555, 32557, 32189, 31780, 33881, 32249, 32269, 31240, 33778, 30821, 28521, 29063, 32035, 32389, 31235, 23880, 32412, 32250, 31745, 23879, 29413, 33799, 31700, 23919, 24060, 33801, 34302, 35352, 32414, 23896, 23917, 23998, 24445, 23920, 23979, 23921, 23877, 24036, 23977, 23837, 23889, 23916, 23850, 23863, 23865, 23847, 34214, 32422, 33800, 23965, 24167, 24180, 24041, 24205, 33924, 23918, 24416, 24363, 24076, 24322, 24249, 24017, 24147, 24260, 24488, 24006, 24113, 35605, 35621, 24020, 24019, 21913, 24393, 33880, 33931, 35563, 31863, 34369, 25132, 28172, 35566, 33885, 24016, 23980, 24396, 23891, 24485, 24106, 24091, 24092, 24178, 24035, 24462, 24003, 35351, 23928, 24053, 24220, 23912, 24368, 35497, 35903, 35897, 32265, 32015, 35565, 36214, 24281, 24468, 24463, 24466, 23986, 24286, 24072, 24064, 24436, 24414, 24321, 24483, 36384, 24048, 24133, 24301, 36404, 35353, 24293, 24273, 24405, 35764, 36408, 35386, 32267, 35766, 33930, 23913, 24067, 36409, 24199, 24238, 24343, 24447, 35401, 36385, 36844, 32071, 35812, 36416, 36811, 36770, 36411, 23930, 24219, 24275, 24306, 23942, 24140, 24455, 24254, 24190, 24303, 35945, 24330, 24069, 24357, 36479, 24196, 24370, 24044, 24472, 24474, 24268, 24347, 23976, 36684, 36762, 30108, 36215, 37225, 32673, 36415, 24331, 24481, 24399, 23938, 37346, 24482, 24024, 24230, 24340, 24356, 24136, 24339, 24204, 24049, 24227, 24382, 24095, 24105, 24350, 24266, 24183, 32054, 36478, 37122, 37856, 19831, 37137, 36659, 36771, 37382, 37746, 37861, 37985, 24486, 23894, 24317, 24045, 24402, 23887, 24435, 24262, 24255, 23936, 24131, 24261, 24119, 24283, 24126, 24457, 24298, 24168, 24316, 24328, 36685, 37739, 37442, 36063, 36217, 24387, 23956, 24166, 24471, 38286, 38072, 23895, 24240, 24490, 23927, 24109, 24158, 24453, 24171, 24379, 24152, 23886, 24351, 24278, 24209, 24130, 37467, 37123, 37498, 32190, 37760, 37758, 24111, 24361, 24480, 24063, 24323, 24458, 37787, 24026, 24185, 24208, 24156, 23971, 24246, 23968, 23981, 24443, 24012, 24392, 35767, 39220, 39331, 37986, 39236, 39498, 39503, 39584, 38297, 787, 39689, 23903, 38073, 38972, 39512, 38337, 38268, 38222, 37661, 38971, 39981, 38074, 40181, 36110, 40035, 38076, 39941, 40201, 39095, 40410, 40636, 40727, 37757, 37800, 40635, 38075, 40769, 41105, 41224, 40713, 40949, 40714, 24232, 38913, 24491, 24033, 40540, 40280, 41353, 41223, 41455, 41570, 40767, 39912, 41225, 24542, 41338, 41874, 24021, 41333, 41395, 38079, 40712, 42464, 41457, 41226, 41678, 42248, 38078, 41404, 41452, 41764, 42546, 41656, 42700, 42488, 42702, 42698, 42424, 41037, 42548, 40930, 43293, 41454, 42629, 41038, 42819, 42604, 41873, 42423, 43148, 42088, 43933, 41917, 42946, 43333, 41652, 44201, 42089, 43407, 42931, 43226, 44040, 43932, 42247, 43183, 43362, 43200, 44216, 44345, 43379, 44339, 44879, 44696, 44259, 44494, 44698, 33798, 44386, 44266, 44202, 44204, 44200, 42461, 45086, 44372, 44823, 45971, 45233, 46250, 45969, 45172, 44912, 45088, 24354, 45972, 45538, 45411, 45412, 45970, 45466, 45537, 46575, 45614, 46577, 46517, 46580, 46582, 45612, 46583, 46526, 45838, 46585, 46074, 46384, 46581, 45539, 46530, 46518, 43862, 46529, 46453, 46462, 46456, 46459, 45868, 45973, 46906, 46589, 45613, 46587, 46593, 46601, 43852, 46385, 46592, 46595, 46597, 46599, 46519, 46598, 48221, 48266, 46383, 48627, 48665, 48493, 46600, 46594, 48495, 46590, 46535, 42783, 48222, 48848, 46528, 48532, 46522, 48272, 45045, 48545, 48858, 48847, 46591, 48275, 48610, 48854, 48103, 44373, 49067, 48104, 48498, 49279, 49356, 48856, 49205, 48268, 49424, 24513, 49136, 48857, 49163, 49429, 49358, 46536, 49435, 49130, 45407, 49440, 42821, 49002, 49046, 49433, 49779, 49223, 45837, 49735, 49732, 50657, 49446, 44829, 49114, 49989, 50792, 50755, 49438, 49439, 50793, 48499, 50791, 49931, 50989, 49398, 50586, 50803, 50638, 50641, 48638, 49131, 50574, 50930, 49221, 50986, 49281, 50640, 50057, 50058, 48919, 50987, 49129, 50637, 51071, 49359, 51845, 51538, 50853, 51332, 50856, 50959, 51997, 51698, 51605, 51634, 51990, 50990, 51996, 51070, 48102, 52017, 50857, 52194, 50854, 52395, 52195, 50982, 805, 50956, 52061, 52190, 52402, 52062, 52073, 52811, 52942, 52819, 50957, 50855, 52463, 52462, 52188, 51105, 52813, 52752, 53059, 52812, 52396, 52469, 51101, 52490, 53276, 50988, 53523, 52464, 53667, 53270, 53671, 53602, 54214, 53211, 54352, 50958, 54394, 53669, 54513, 52268, 54653, 53580, 54715, 54750, 52467, 54827, 55042, 53582, 53522, 24078, 24138, 24587, 24603, 24465, 24308, 24504, 24324, 23770, 24558, 54863, 24492, 52673, 55140, 53740, 24509, 54838, 55027, 55113, 55275, 52397, 55058, 46386, 53297, 55793, 54125, 55546, 55593, 53583, 55981, 51449, 56012, 56535, 52269, 54153, 53601, 52465, 55562, 23878, 24505, 24257, 24360, 24271, 24295, 23716, 24556, 56811, 24388, 56527, 24284, 55544, 52468, 57059, 55993, 51452, 56629, 54358, 57311, 56009, 57639, 56368, 57701, 52466, 54353, 53024, 23772, 57606, 23727, 58017, 23724, 23734, 23736, 23751, 23758, 23723, 23714, 57063, 56988, 58120, 57418, 58212, 54713, 54706, 57144, 56901, 58119, 58015, 58121, 56959, 58601, 58586, 58014, 58010, 58013, 58011, 58012, 52270, 58787, 56860, 54754, 23843, 23789, 23791, 23788, 23811, 23864, 23785, 23794, 39096, 23786, 57706, 23818, 57734, 57916, 57915, 57913, 57917, 57920, 57918, 57914, 57364, 57908, 58706, 58446, 58016, 56834, 59145, 59149, 57924, 59779, 57186, 59148, 59154, 58018, 52271, 59159, 59152, 56434, 60063, 23955, 23958, 23972, 23929, 23973, 23923, 23933, 23915, 23931, 58361, 57475, 59150, 59156, 60084, 59971, 59972, 59801, 59862, 59158, 59155, 60079, 59151, 59980, 58704, 60487, 57604, 60193, 60411, 60184, 60080, 58884, 60872, 60819, 60390, 60873, 60926, 59153, 60742, 61119, 60416, 60752, 58891, 61317, 60835, 61316, 61301, 60422, 61575, 60183, 60914, 61303, 61302, 61644, 60315, 61579, 60774, 61611, 60310, 61930, 60081, 61992, 58979, 62149, 62062, 61991, 60021, 62214, 62266, 59048, 62306, 58104, 62347, 59050, 62406, 54262, 61357, 60405, 62554, 60135, 62628, 62627, 62707, 62341, 62270, 62748, 62678, 62782, 62263, 62784]","[6449.0, 4931.0, 3424.0, 3006.0, 2984.0]",,,,
List the view counts of the 6 least viewed talks.,Retrieve the view counts for the 6 talks with the lowest number of views.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
sorted_dataset = dataset.sort_values(by='views', ascending=True)
lowest_views = sorted_dataset.head(6)['views'].tolist()

return lowest_views",list of (int64),"[0, 0, 0, 0, 0, 0]","[0, 0, 0, 0, 0, 0]",,,,
Is it true that the oldest person in the dataset has a stroke?,Does the person with the highest age in the dataset have a stroke?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    oldest_person = dataset.loc[dataset[""age""] == dataset[""age""].max()]
    has_stroke = bool(oldest_person[""stroke""].values[0])

    return has_stroke
",bool,True,True,,,,
Do all smokers have hypertension?,Are all individuals who smoke diagnosed with hypertension?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    smokers = dataset[dataset['smoking_status'] == 'smokes']
    all_hypertensive = smokers['hypertension'].all()

    return all_hypertensive
",bool,False,False,,,,
Are all people with heart diseases married?,Is every individual with heart disease listed as married?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    individuals_with_heart_disease = dataset[dataset['heart_disease'] == 1]
    all_married = individuals_with_heart_disease['ever_married'].str.lower().eq('yes').all()

    return all_married
",bool,False,False,,,,
Is the average glucose level higher for males than females?,Is the average glucose level greater for male patients compared to female patients?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
male_avg_glucose = dataset.loc[dataset[""gender""] == ""Male"", ""avg_glucose_level""].mean()
female_avg_glucose = dataset.loc[dataset[""gender""] == ""Female"", ""avg_glucose_level""].mean()

return male_avg_glucose > female_avg_glucose
",bool,True,True,,,,
How many people in the dataset have a stroke?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for the number of individuals who have had a stroke
    num_strokes = dataset['stroke'].sum()
    
    return num_strokes
",int64,249,249,,,,
What is the average age of people who smoke?,What is the mean age of individuals who smoke?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    smokers = dataset[dataset['smoking_status'] != 'never smoked']
    mean_age_smokers = smokers['age'].mean()
    
    return mean_age_smokers
",float64,42.64163700000000,47.09632400000000,,,,
What is the highest glucose level recorded in the dataset?,What is the maximum value of avg_glucose_level in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_avg_glucose_level = dataset[""avg_glucose_level""].max()

return max_avg_glucose_level",float64  ,271.74,271.74,,,,
How many unique 'work_type' categories are there in the dataset?,What is the count of distinct categories present in the 'work_type' column?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_count = dataset['work_type'].nunique()
    return distinct_count
",int64  ,5,5,,,,
What is the most common work type among stroke patients?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Find the individual with the highest average glucose level
    max_glucose_individual = dataset.loc[dataset[""avg_glucose_level""] == dataset[""avg_glucose_level""].max()]
    
    # Get the gender of that individual
    gender = max_glucose_individual[""gender""].iloc[0]
    
    return gender",category,Male,Private,,,,
What is the smoking status of the youngest person in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column value based on some condition
    # For example, let's assume the question is ""What is the gender of the person with the highest BMI?""
    
    max_bmi_individual = dataset.loc[dataset[""bmi""] == dataset[""bmi""].max()]
    gender_of_max_bmi = max_bmi_individual[""gender""].iloc[0]
    
    return gender_of_max_bmi",category,Male,Unknown,,,,
What is the residence type of the person with the highest BMI?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value based on some condition
    # For example, let's assume the question is ""What is the gender of the person with the highest BMI?""
    
    max_bmi_individual = dataset.loc[dataset[""bmi""] == dataset[""bmi""].max()]
    gender = max_bmi_individual[""gender""].iloc[0]
    
    return gender",category,Male,Rural,,,,
What is the gender of the person with the lowest glucose level?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific categorical value from the dataset
    # For demonstration purposes, let's assume the question asks for the most common 'gender' in the dataset.
    
    # Find the mode of the 'gender' column
    most_common_gender = dataset['gender'].mode()[0]
    
    return most_common_gender
",category,Female,Female,,,,
What are the top 3 work types among people with heart diseases?,What are the three most common work types among individuals with heart disease?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only individuals with heart disease
    heart_disease_individuals = dataset[dataset['heart_disease'] == 1]
    
    # Get the value counts of work types among these individuals
    work_type_counts = heart_disease_individuals['work_type'].value_counts()
    
    # Get the top three most common work types
    top_three_work_types = work_type_counts.index[:3].tolist()
    
    return top_three_work_types
",list of (string),"['Private', 'Self-employed', 'Govt_job']","['Private', 'Self-employed', 'Govt_job']",,,,
What are the 5 most common smoking statuses among people with a stroke?,What are the top 5 most frequent smoking statuses for individuals who have had a stroke?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only individuals who have had a stroke
    stroke_individuals = dataset[dataset['stroke'] == 1]
    
    # Get the value counts of smoking statuses for these individuals
    smoking_status_counts = stroke_individuals['smoking_status'].value_counts()
    
    # Get the top 5 most frequent smoking statuses
    top_5_smoking_statuses = smoking_status_counts.index[:5].tolist()
    
    return top_5_smoking_statuses
",list of (string),"['never smoked', 'formerly smoked', 'Unknown', 'smokes']","['never smoked', 'formerly smoked', 'Unknown', 'smokes']",,,,
What are the top 2 residence types of people with hypertension?,What are the two most common residence types for individuals with hypertension?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only individuals with hypertension
    hypertensive_individuals = dataset[dataset['hypertension'] == 1]
    
    # Group by residence type and count occurrences
    residence_counts = hypertensive_individuals['Residence_type'].value_counts().nlargest(2)
    
    # Get the two most common residence types as a list of strings
    most_common_residences = residence_counts.index.tolist()
    
    return most_common_residences
",list of (string),"['Rural', 'Urban']","['Rural', 'Urban']",,,,
What are the top 2 work types among people who have never married?,What are the top 2 work types for people who have never been married?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for people who have never been married
    never_married = dataset[dataset['ever_married'] == 'No']
    
    # Group by work type and count occurrences
    work_type_counts = never_married['work_type'].value_counts()
    
    # Get the top 2 work types
    top_2_work_types = work_type_counts.head(2).index.tolist()
    
    return top_2_work_types
",list of (string),"['Private', 'children']","['Private', 'children']",,,,
What are the oldest 5 ages of people with strokes?,What are the top 5 oldest ages among individuals who have had a stroke?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who have had a stroke
    stroke_individuals = dataset[dataset['stroke'] == 1]
    
    # Get the top 5 oldest ages from these individuals
    top_5_oldest_ages = stroke_individuals['age'].nlargest(5).tolist()
    
    return top_5_oldest_ages
",list of (float64),"[82.0, 82.0, 82.0, 82.0, 82.0]","[82.0, 82.0, 82.0, 82.0, 82.0]",,,,
What are the 3 lowest BMIs among people who smoke?,What are the 3 smallest BMIs for individuals who smoke?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
smokers = dataset[dataset['smoking_status'] != 'never smoked']
top_3_smallest_bmis = smokers.nsmallest(3, 'bmi')['bmi'].tolist()

return top_3_smallest_bmis",list of (float64),"[10.3, 11.3, 12.0]","[15.7, 16.7, 16.7]",,,,
What are the top 4 glucose levels of people who have heart diseases?,What are the four highest glucose levels for individuals diagnosed with heart disease?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals diagnosed with heart disease
    heart_disease_individuals = dataset[dataset['heart_disease'] == 1]
    
    # Sort by avg_glucose_level in descending order and get the top 4
    top_4_glucose_levels = heart_disease_individuals.nlargest(4, 'avg_glucose_level')['avg_glucose_level'].tolist()
    
    return top_4_glucose_levels
",list of (float64),"[271.74, 254.63, 254.6, 252.72]","[271.74, 254.63, 254.6, 252.72]",,,,
What are the 6 highest ages of people who have never married?,What are the top 6 ages of individuals who have never been married?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
never_married_individuals = dataset[dataset['ever_married'] == 'No']
top_6_ages = never_married_individuals['age'].nlargest(6).tolist()

return top_6_ages
",list of (float64),"[82.0, 82.0, 82.0, 82.0, 82.0, 82.0]","[82.0, 82.0, 82.0, 82.0, 82.0, 82.0]",,,,
Are there any reflections with more than 10 sentences?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any rows where the ground_truth_category is different from the predicted_category
    mismatched_rows = dataset[dataset['ground_truth_category'] != dataset['predicted_category']]
    
    # If there are any mismatched rows, return True, otherwise False
    has_mismatch = not mismatched_rows.empty
    
    return has_mismatch",bool,True,True,,,,
Is there a reflection from 'USA' with over 5 sentences?,Is there a reflection from the USA with more than 5 sentences?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    usa_reflections = dataset[dataset[""country""] == ""USA""]
    has_more_than_5_sentences = (usa_reflections[""num_sentence""] > 5).any()

    return has_more_than_5_sentences
",bool,True,True,,,,
Are there any reflections categorized as 'affection'?,Are there any reflections in the dataset categorized as 'affection'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_affection = 'affection' in dataset['ground_truth_category'].values

return has_affection",bool  ,True,True,,,,
Are there any married individuals who reflected on 'exercise'?,Is there any married person who had a reflection period on 'exercise'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
married_with_exercise_reflection = dataset[(dataset[""marital""] == ""married"") & (dataset[""reflection_period""] == ""exercise"")]
has_married_with_exercise = not married_with_exercise_reflection.empty

return has_married_with_exercise
",bool,False,True,,,,
How many unique reflection periods are there?,What is the count of distinct reflection periods in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_reflection_periods_count = dataset['reflection_period'].nunique()
    return distinct_reflection_periods_count
",int64,2,2,,,,
"On average, how many sentences are there in the reflections?",What is the average number of sentences in the reflections?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_num_sentence = dataset['num_sentence'].mean()
return average_num_sentence
",float64,1.3407670000000000,1.3407670000000000,,,,
What's the highest age of an individual in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
mean_age = dataset['age'].mean()

return mean_age",float64,32.539215000000000,233.0,,,,
How many reflections are from 'IND'?,What is the count of reflections where the country is 'IND'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
count = dataset[dataset[""country""] == ""IND""].shape[0]
return count
",int64,16729,16729,,,,
Which country has the highest average number of sentences in their reflections?,Which country has the highest average number of sentences in their reflections?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    average_sentences_by_country = dataset.groupby('country')['num_sentence'].mean()
    country_with_highest_average = average_sentences_by_country.idxmax()

    return country_with_highest_average
",string,UKR,UKR,,,,
Which gender has the most reflections categorized as 'affection'?,What is the gender with the highest count of reflections categorized as 'affection'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['ground_truth_category'] == 'affection']
    gender_counts = filtered_data['gender'].value_counts()
    highest_count_gender = gender_counts.idxmax()

    return highest_count_gender
",string,m,f,,,,
From which country is the oldest individual who reflected?,Which country does the oldest person belong to?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
oldest_person = dataset.loc[dataset[""age""] == dataset[""age""].max()]
country_of_oldest_person = oldest_person[""country""].iloc[0]

return country_of_oldest_person",string,USA,USA,,,,
Which marital status has the most reflections on 'bonding'?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific value from a column, let's extract it.
    # For example, if the question is ""What is the cleaned_hm value of the first row?"", we can do:
    
    # Extract the first row's 'cleaned_hm' value
    answer = dataset['cleaned_hm'].iloc[0]
    
    return answer",string,I went on a successful date with someone I felt sympathy and connection with.,single,,,,
Which are the top 3 countries with the highest average number of sentences in their reflections?,What are the top 3 countries with the highest average number of sentences in their reflections?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by country and calculate the average number of sentences for each country
    avg_num_sentences_by_country = dataset.groupby('country')['num_sentence'].mean().reset_index()
    
    # Sort the countries by the average number of sentences in descending order
    sorted_countries = avg_num_sentences_by_country.sort_values(by='num_sentence', ascending=False)
    
    # Get the top 3 countries with the highest average number of sentences
    top_3_countries = sorted_countries.head(3)['country'].tolist()
    
    return top_3_countries
",list of (string),"['UKR', 'CRI', 'HKG']","['UKR', 'CRI', 'HKG']",,,,
List the 4 most common predicted categories in the dataset.,What are the top 4 most frequently occurring predicted categories in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    category_counts = dataset['predicted_category'].value_counts().head(4).index.tolist()
    
    return category_counts
",list of (string),"['affection', 'achievement', 'enjoy_the_moment', 'bonding']","['affection', 'achievement', 'enjoy_the_moment', 'bonding']",,,,
Which 5 countries have the youngest average age of reflectors?,What are the names of the 5 countries with the lowest average age?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by country and calculate the average age for each country
    avg_age_by_country = dataset.groupby('country')['age'].mean().reset_index()

    # Sort the countries by their average age in ascending order
    sorted_countries = avg_age_by_country.sort_values(by='age')

    # Get the names of the 5 countries with the lowest average age
    top_5_countries = sorted_countries.head(5)['country'].tolist()

    return top_5_countries
",list of (string),"['KAZ', 'ALB', 'LKA', 'SLV', 'MAR']","['KAZ', 'ALB', 'LKA', 'MAR', 'SLV']",,,,
List 2 genders with the most number of reflections.,Identify the top 2 genders with the highest number of reflections.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    gender_counts = dataset['gender'].value_counts()
    top_2_genders = gender_counts.head(2).index.tolist()

    return top_2_genders
",list of (string),"['m', 'f']","['m', 'f']",,,,
What are the lowest 4 number of sentences?,What are the four smallest number of sentences in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    sorted_dataset = dataset.sort_values(by='num_sentence')
    smallest_sentences = sorted_dataset['num_sentence'].head(4).tolist()

    return smallest_sentences
",list of (uint8),"[1, 1, 1, 1]","[1, 1, 1, 1]",,,,
List the 3 highest ages in the dataset.,Retrieve the top 3 highest ages from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_ages = dataset['age'].nlargest(3).tolist()
return top_3_ages",list of (float64),"[233.0, 233.0, 233.0]","[233.0, 233.0, 233.0]",,,,
Which are the highest 5 number of sentences?,What are the top 5 highest number of sentences?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_highest_sentences = dataset.nlargest(5, 'num_sentence')['num_sentence'].tolist()
return top_5_highest_sentences
",list of (int64),"[69, 60, 58, 56, 53]","[69, 60, 58, 56, 53, 51]",,,,
List the age of the 6 youngest individuals in the dataset.,Retrieve the ages of the six youngest individuals from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
sorted_by_age = dataset.sort_values(by='age')
youngest_six_ages = sorted_by_age['age'].head(6).tolist()

return youngest_six_ages",list of (float64),"[2.0, 2.0, 2.0, 2.0, 2.0, 2.0]","[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]",,,,
Is it true that the youngest participant has met their match?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any null values in the dataset
    has_null_values = dataset.isnull().values.any()
    
    return has_null_values",bool,True,False,,,,
Do all people who got a match have the same race as their partner?,Do all individuals who have a match share the same race as their partner?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    matched_individuals = dataset[dataset['match'] == 1]
    all_same_race = matched_individuals['race'] == matched_individuals['race_o']
    is_all_same_race = all_same_race.all()

    return is_all_same_race
",bool,False,False,,,,
Are all participants who expected more than 5 matches male?,Are all participants who anticipated more than 5 matches identified as male?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
participants = dataset[dataset['expected_num_matches'] > 5]
all_male = participants['gender'].eq('male').all()

return all_male",bool,False,True,,,,
Is the average age of participants who got a match higher than those who didn't?,Is the average age of participants who received a match greater than those who did not receive a match?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    matched_age = dataset[dataset['match'] == 1]['age'].mean()
    unmatched_age = dataset[dataset['match'] == 0]['age'].mean()
    
    return matched_age > unmatched_age
",bool,False,False,,,,
How many participants had a match?,How many participants had a match?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_matches = dataset['match'].sum()
    return num_matches
",int64  ,1380,1380,,,,
What is the average age of participants who have the same race as their partner?,What is the average age of participants who have the same race as their partner?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    same_race_participants = dataset[dataset['samerace'] == 1]
    average_age = same_race_participants['age'].mean()

    return average_age
",float64,26.390237000000000,26.390237000000000,,,,
What is the highest number of matches expected by any participant in the dataset?,What is the maximum expected number of matches by any participant in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_expected_matches = dataset[""expected_num_matches""].max()
    
    return max_expected_matches
",float64  ,18.0,18.0,,,,
How many unique 'race' categories are there in the dataset?,How many distinct categories are present in the 'race' column of the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_distinct_categories = len(dataset['race'].unique())
    return num_distinct_categories
",int64,6,5,,,,
What is the most common race among participants who got a match?,What is the most frequent race among participants who have a match?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    matched_participants = dataset[dataset[""match""] == 1]
    most_frequent_race = matched_participants[""race""].mode().iloc[0]

    return most_frequent_race
",string,european/caucasian-american,european/caucasian-american,,,,
What is the gender of the youngest participant in the dataset?,What is the gender of the participant with the minimum age in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    min_age_individual = dataset.loc[dataset[""age""] == dataset[""age""].min()]
    gender_of_min_age = min_age_individual[""gender""].iloc[0]

    return gender_of_min_age
",string,male,male,,,,
What is the race of the participant with the highest number of expected matches?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value
    # For example, if the question is ""What is the most common gender in the dataset?""
    # The code would be:
    
    # Find the most common gender
    most_common_gender = dataset['gender'].mode()[0]
    
    return most_common_gender",category,male,other,,,,
What is the wave of the participant with the youngest age?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here to find the answer based on the question and schema
    pass
",uint8,,5,,,,
What are the top 3 waves among people who got a match?,What are the top 3 wave numbers among individuals who have received a match?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    matched_individuals = dataset[dataset['match'] == 1]
    top_waves = matched_individuals['wave'].value_counts().head(3).index.tolist()
    
    return top_waves
",list of (int64),"[21, 4, 11]","[21, 4, 11]",,,,
What are the 5 most common races among people who expected more than 5 matches?,What are the top 5 most frequent races among individuals who anticipated more than 5 matches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who anticipated more than 5 matches
    filtered_dataset = dataset[dataset['expected_num_matches'] > 5]
    
    # Get the top 5 most frequent races among these individuals
    race_counts = filtered_dataset['race'].value_counts().head(5)
    
    # Convert the index to a list of categories
    top_races = race_counts.index.tolist()
    
    return top_races
",list of (category),"['european/caucasian-american', 'asian/pacific islander/asian-american', 'black/african american', 'latino/hispanic american', 'other']","['european/caucasian-american', 'asian/pacific islander/asian-american', 'black/african american', 'latino/hispanic american', 'other']",,,,
What are the top 4 waves of people who have the same race as their partner?,What are the top 4 distinct wave numbers where individuals have the same race as their partner?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who have the same race as their partner
    same_race_individuals = dataset[dataset['samerace'] == 1]
    
    # Get distinct wave numbers
    distinct_waves = same_race_individuals['wave'].unique()
    
    # Sort waves in descending order and get the top 4
    top_4_waves = sorted(distinct_waves, reverse=True)[:4]
    
    return list(top_4_waves)
",list of (int64),"[np.uint8(21), np.uint8(20), np.uint8(19), np.uint8(18)]","[15, 9, 21, 11]",,,,
What are the top 2 genders among people who expected no match?,What are the top 2 genders among individuals who expected no matches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who expected no matches
    no_matches = dataset[dataset['expected_num_matches'] == 0]
    
    # Get the top 2 genders among these individuals
    top_genders = no_matches['gender'].value_counts().head(2).index.tolist()
    
    return top_genders
",list of (string),"['female', 'male']","['female', 'male']",,,,
What are the top 5 ages of participants who got a match?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Extract the relevant column from the dataset
    relevant_column = dataset['age']
    
    # Convert the column to a list of numbers
    age_list = relevant_column.tolist()
    
    return age_list",list of float64,"[21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 27.0, 27.0, 27.0, 27.0, 27.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 26.0, 26.0, 26.0, 26.0, 26.0, nan, nan, nan, nan, nan, 26.0, 26.0, 26.0, 26.0, 26.0, 32.0, 32.0, 32.0, 32.0, 32.0, 37.0, 37.0, 37.0, 37.0, 37.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 3","[42.0, 42.0, 42.0, 42.0, 39.0]",,,,
What are the 3 lowest numbers of matches expected by people who got a match?,What are the three smallest expected numbers of matches for individuals who received a match?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who received a match
    matched_individuals = dataset[dataset['match'] == 1]
    
    # Sort by the expected number of matches in ascending order
    sorted_matches = matched_individuals.sort_values(by='expected_num_matches')
    
    # Get the three smallest expected numbers of matches
    top_three_smallest_matches = sorted_matches.head(3)['expected_num_matches'].tolist()
    
    return top_three_smallest_matches
",list of (int64),"[0.0, 0.0, 0.0]","[0.0, 0.0, 0.0]",,,,
What are the top 4 ages of people who have the same race as their partner?,What are the top 4 ages of individuals who have the same race as their partner?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter individuals who have the same race as their partner
    same_race_individuals = dataset[dataset['race'] == dataset['race_o']]
    
    # Get the top 4 ages from this filtered group
    top_ages = same_race_individuals['age'].nlargest(4).tolist()
    
    return top_ages",list of (float64),"[55.0, 55.0, 55.0, 42.0]","[55.0, 55.0, 55.0, 42.0]",,,,
What are the 6 youngest ages of participants who expected no match?,What are the ages of the 6 youngest participants who expected no matches?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter participants who expected no matches
    no_matches = dataset[dataset['expected_num_matches'] == 0]
    
    # Sort by age in ascending order to get the youngest participants
    sorted_by_age = no_matches.sort_values(by='age')
    
    # Get the ages of the 6 youngest participants
    youngest_ages = sorted_by_age['age'].head(6).tolist()
    
    return youngest_ages
",list of (float64),"[18.0, 18.0, 18.0, 18.0, 18.0, 18.0]","[18.0, 18.0, 18.0, 18.0, 18.0, 18.0]",,,,
Are there any tweets with more than 10 retweets?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any tweets with a negative sentiment
    has_negative_sentiment = 'Negative' in dataset['airline_sentiment'].values
    
    return has_negative_sentiment",bool,False,True,,,,
Is there a negative sentiment tweet from 'United' airline?,Is there any tweet with a negative sentiment from the 'United' airline?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
negative_sentiment_tweets = dataset[(dataset[""airline""] == ""United"") & (dataset[""airline_sentiment""] == ""negative"")]
has_negative_sentiment = not negative_sentiment_tweets.empty

return has_negative_sentiment",bool,True,True,,,,
Are there any tweets categorized with 'Late Flight' as the negative reason?,Is there any tweet in the dataset where the negative reason is categorized as 'Late Flight'?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_late_flight_reason = (dataset['negativereason'] == 'Late Flight').any()
    
    return has_late_flight_reason",bool,True,True,,,,
Are there any tweets from 'Eastern Time (US & Canada)' timezone with positive sentiment?,Is there at least one tweet from the 'Eastern Time (US & Canada)' timezone that has a positive sentiment?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_positive_sentiment = dataset[(dataset['user_timezone'] == 'Eastern Time (US & Canada)') & (dataset['airline_sentiment'] == 'positive')]
result = not has_positive_sentiment.empty

return result",bool,True,True,,,,
How many unique user timezones are there in the dataset?,What is the count of distinct user timezones present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_user_timezones_count = dataset['user_timezone'].nunique()
    
    return distinct_user_timezones_count
",int64,85,85,,,,
"On average, what is the sentiment confidence of the tweets?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_confidence = dataset['airline_sentiment_confidence'].mean()
return average_confidence
",float64,0.9001690000000000,0.9001690000000000,,,,
What's the maximum number of retweets a tweet has received?,What is the highest number of retweets for any tweet in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_retweets = dataset['retweet_count'].max()
return max_retweets
",int64,44,44,,,,
How many tweets are from 'Virgin America' airline?,What is the count of tweets originating from the 'Virgin America' airline?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count_of_tweets = dataset[dataset['airline'] == 'Virgin America'].shape[0]
    
    return count_of_tweets
",int64  ,504,504,,,,
Which airline has the highest average sentiment confidence?,Which airline has the highest average sentiment confidence?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    average_confidence = dataset.groupby('airline')['airline_sentiment_confidence'].mean()
    airline_with_highest_confidence = average_confidence.idxmax()

    return airline_with_highest_confidence
",string,US Airways,US Airways,,,,
Which negative reason is most commonly associated with 'American' airline?,What is the most frequently mentioned negative reason associated with the 'American' airline?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    american_airline_tweets = dataset[dataset['airline'] == 'American']
    most_common_negative_reason = american_airline_tweets['negativereason'].mode()[0]

    return most_common_negative_reason
",string,Customer Service Issue,Customer Service Issue,,,,
From which timezone is the tweet with the highest sentiment confidence?,Which timezone does the tweet with the highest sentiment confidence belong to?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_confidence_tweet = dataset.loc[dataset[""airline_sentiment_confidence""] == dataset[""airline_sentiment_confidence""].max()]
    timezone = max_confidence_tweet[""user_timezone""].iloc[0]

    return timezone
",category,Eastern Time (US & Canada),Eastern Time (US & Canada),,,,
Which airline has the most tweets with negative sentiment?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value or some derived information from the dataset.
    # Since the question is not provided, I'll create a generic example where we return the first 'airline' entry.

    airline = dataset['airline'].iloc[0]

    return airline
",string,Virgin America,United,,,,
Which are the top 3 airlines with the highest average sentiment confidence?,What are the top 3 airlines with the highest average sentiment confidence?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by airline and calculate the average sentiment confidence
    avg_sentiment_confidence = dataset.groupby('airline')['airline_sentiment_confidence'].mean().reset_index()
    
    # Sort the airlines by their average sentiment confidence in descending order
    top_airlines = avg_sentiment_confidence.sort_values(by='airline_sentiment_confidence', ascending=False)
    
    # Get the top 3 airlines
    top_3_airlines = top_airlines.head(3)['airline'].tolist()
    
    return top_3_airlines
",list of (string),"['US Airways', 'American', 'United']","['US Airways', 'American', 'United']",,,,
List the 3 most common negative reasons in the dataset.,What are the top 3 most frequent negative reasons in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'negativereason' and count occurrences
    reason_counts = dataset['negativereason'].value_counts()
    
    # Get the top 3 most frequent negative reasons
    top_3_reasons = reason_counts.head(3).index.tolist()
    
    return top_3_reasons
",list of (string),"['Customer Service Issue', 'Late Flight', ""Can't Tell""]","['Customer Service Issue', 'Late Flight', 'Can't Tell']",,,,
Which 3 user timezones have the most number of tweets?,What are the three user timezones with the highest number of tweets?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    timezone_counts = dataset['user_timezone'].value_counts().head(3).index.tolist()
    return timezone_counts
",list of (string),"['Eastern Time (US & Canada)', 'Central Time (US & Canada)', 'Pacific Time (US & Canada)']","['Eastern Time (US & Canada)', 'Central Time (US & Canada)', 'Pacific Time (US & Canada)']",,,,
List the 2 airlines with the least number of tweets in the dataset.,Which two airlines have the fewest number of tweets in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Count the number of tweets for each airline
    tweet_counts = dataset['airline'].value_counts()

    # Get the two airlines with the fewest number of tweets
    least_frequent_airlines = tweet_counts.nsmallest(2).index.tolist()

    return least_frequent_airlines
",list of (string),"['Virgin America', 'Delta']","['Virgin America', 'Delta']",,,,
What are the top 4 tweet IDs with the lowest sentiment confidence?,Retrieve the IDs of the top 4 tweets with the lowest sentiment confidence.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'airline_sentiment_confidence' in ascending order
    sorted_tweets = dataset.sort_values(by='airline_sentiment_confidence')
    
    # Retrieve the top 4 tweet IDs with the lowest sentiment confidence
    top_4_lowest_confidence_tweet_ids = sorted_tweets.head(4)['tweet_id'].tolist()
    
    return top_4_lowest_confidence_tweet_ids
",list of (int64),"[569972097453137920, 568092537786748928, 568028183267639297, 568993773277069312]","[570306133677760513, 570301031407624196, 570300817074462722, 570300767074181121]",,,,
List the 3 highest retweet counts in the dataset.,What are the top 3 highest retweet counts in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_retweets = dataset.nlargest(3, 'retweet_count')['retweet_count'].tolist()

return top_3_retweets
",list of (int64),"[44, 32, 31]","[44, 32, 31]",,,,
What are the 2 lowest values for sentiment confidence?,What are the two smallest values for sentiment confidence?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Get the two smallest values for sentiment confidence
    two_smallest_confidences = dataset['airline_sentiment_confidence'].nsmallest(2).tolist()
    
    return two_smallest_confidences
",list of (float64),"[0.335, 0.3353]","[0.335, 0.335]",,,,
List the 6 highest sentiment confidence values.,Retrieve the top 6 highest airline sentiment confidence values from the dataset.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_confidence_values = dataset['airline_sentiment_confidence'].nlargest(6).tolist()
return top_confidence_values
",list of (float64),"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]",,,,
Is it true that the student with the highest number of absences is from a rural area?,Is the student with the maximum number of absences categorized as being from a rural area?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_absences_student = dataset.loc[dataset[""absences""] == dataset[""absences""].max()]
    is_rural_area = (max_absences_student[""address""].values[0] == 'R')

    return is_rural_area",bool,True,True,,,,
Are all students who are in a romantic relationship older than 17?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any students who have failed more than twice.
    has_failed_more_than_twice = (dataset[""failures""] > 2).any()
    
    return has_failed_more_than_twice
",bool,True,False,,,,
Is the average final grade (G3) of students who consume a lot of alcohol (Dalc > 2) lower than those who don't?,Is the average final grade (G3) of students who consume a lot of alcohol (Dalc > 2) lower than those who do not?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    high_alcohol_consumption = dataset[dataset['Dalc'] > 2]
    low_alcohol_consumption = dataset[dataset['Dalc'] <= 2]

    avg_G3_high_alcohol = high_alcohol_consumption['G3'].mean()
    avg_G3_low_alcohol = low_alcohol_consumption['G3'].mean()

    is_lower = avg_G3_high_alcohol < avg_G3_low_alcohol

    return is_lower
",bool,True,True,,,,
Do all students who have both parents at home (Pstatus = 'T') have more than 3 free time after school (freetime > 3)?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any missing values in the dataset
    has_missing_values = dataset.isnull().values.any()
    
    return has_missing_values",bool,False,False,,,,
How many students have their mother's education (Medu) level above 3?,How many students have their mother's education level greater than 3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    count = dataset[dataset['Medu'] > 3].shape[0]
    return count
",int64  ,131,131,,,,
What is the average age of students who want to take higher education (higher = 'yes')?,What is the average age of students who intend to pursue higher education?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_age = dataset.loc[dataset[""higher""] == ""yes"", ""age""].mean()
return average_age
",float64  ,16.634667000000000,16.634667000000000,,,,
What is the highest number of absences among students?,What is the maximum number of absences recorded for any student?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_absences = dataset[""absences""].max()
return max_absences",uint8  ,75,75,,,,
How many unique schools are there in the dataset?,What is the count of distinct schools in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_school_count = dataset['school'].nunique()
    
    return distinct_school_count
",int64,2,2,,,,
What is the most common mother's job among students who want to take higher education?,What is the most frequent occupation of mothers among students who intend to pursue higher education?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter students who intend to pursue higher education
    higher_education_students = dataset[dataset['higher'] == 'yes']
    
    # Get the most frequent occupation of mothers among these students
    most_frequent_mjob = higher_education_students['Mjob'].mode().iloc[0]
    
    return most_frequent_mjob",string,other,other,,,,
What is the gender of the student with the highest final grade (G3)?,What is the gender of the student who achieved the highest final grade in G3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_grade_student = dataset.loc[dataset[""G3""] == dataset[""G3""].max()]
    gender = max_grade_student[""sex""].iloc[0]

    return gender
",category,M,M,,,,
What is the school of the student with the highest number of absences?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific column value from the dataset
    # For example, if the question is ""What is the most common school in the dataset?""
    # The code would look like this:
    
    # Find the mode of the 'school' column
    most_common_school = dataset['school'].mode()[0]
    
    return most_common_school",category,GP,GP,,,,
What is the family size of the student with the highest final grade (G3)?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific category value based on some condition
    # For example, let's assume the question is ""What is the most common school type in the dataset?""
    
    # Find the mode of the 'school' column
    most_common_school = dataset['school'].mode()[0]
    
    return most_common_school",category,GP,GT3,,,,
What are the top 3 reasons for choosing a school among students who want to take higher education?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass
",list of (category),,"['course', 'home', 'reputation']",,,,
What are the 5 most common mother's jobs among students with a final grade above 10?,What are the top 5 most frequent occupations of mothers for students who have a final grade greater than 10?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_mother_occupations = dataset[dataset['G3'] > 10]['Mjob'].value_counts().head(5).index.tolist()
return [str(occupation) for occupation in top_mother_occupations]",list of (string),"['other', 'services', 'teacher', 'health', 'at_home']","['other', 'services', 'teacher', 'health', 'at_home']",,,,
What are the top 4 schools among students with absences above 10?,What are the top 4 schools with students having more than 10 absences?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_students = dataset[dataset['absences'] > 10]
    top_schools = filtered_students['school'].value_counts().head(4).index.tolist()
    
    return top_schools
",list of (string),"['GP', 'MS']","['GP', 'MS']",,,,
What are the top 2 family relations among students with a final grade below 10?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific category or categories from the dataset
    # For example, if the question is ""What are the unique values in the 'school' column?""
    # The code would look like this:
    
    unique_values = dataset['school'].unique().tolist()
    return unique_values",list of (category),"['GP', 'MS']","[4, 5]",,,,
What are the top 5 ages of students who want to take higher education?,What are the top 5 ages among students who intend to pursue higher education?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter students who intend to pursue higher education
    higher_education_students = dataset[dataset['higher'] == 'yes']
    
    # Get the top 5 ages among these students
    top_ages = higher_education_students['age'].value_counts().head(5).index.tolist()
    
    return top_ages
",list of (int64),"[16, 17, 15, 18, 19]","[16, 17, 15, 18, 19]",,,,
What are the 3 lowest final grades of students who have more than 10 absences?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass
",list of (int64),,"[4, 14, 17]",,,,
What are the top 4 ages of students whose mother's education level is above 3?,What are the top 4 ages of students where the mother's education level is greater than 3?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only rows where Medu (mother's education level) is greater than 3
    filtered_dataset = dataset[dataset['Medu'] > 3]
    
    # Get the top 4 ages from the filtered dataset
    top_ages = filtered_dataset['age'].value_counts().head(4).index.tolist()
    
    return top_ages
",list of (int64),"[15, 16, 18, 17]","[15, 16, 18, 17]",,,,
What are the 6 lowest final grades of students who don't want to take higher education?,What are the final grades of the 6 students with the lowest scores who do not intend to pursue higher education?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter students who do not intend to pursue higher education
    no_higher_education_students = dataset[dataset['higher'] == 'no']
    
    # Sort the filtered students by their final grades (G3) in ascending order
    sorted_students = no_higher_education_students.sort_values(by='G3', ascending=True)
    
    # Get the final grades of the 6 students with the lowest scores
    lowest_grades = sorted_students['G3'].head(6).tolist()
    
    return lowest_grades
",list of (int64),"[0, 0, 0, 0, 0, 0]","[8, 10, 12, 9, 7, 13]",,,,
Is it true that the oldest company (based on approval year) is from an urban (UrbanRural=1) area?,"Is the oldest company, determined by the earliest approval year, located in an urban area where UrbanRural is equal to 1?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
oldest_company = dataset.loc[dataset[""ApprovalFY""] == dataset[""ApprovalFY""].min()]
is_urban = oldest_company[""UrbanRural""].iloc[0] == 1

return is_urban",bool,False,False,,,,
Are all companies with more than 10 employees located in an urban (UrbanRural=1) area?,,,,ERROR,False,,,,
"Are all companies with a default amount greater than $250,000 in the food sector?","Are all companies in the food sector with a default amount greater than $250,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[(dataset[""Sector""] == ""Food"") & (dataset[""default_amount""] > 250000)]
    all_default_greater_than_250k = filtered_data.shape[0] == filtered_data[filtered_data[""default_amount""] > 250000].shape[0]
    
    return all_default_greater_than_250k
",bool,True,False,,,,
Is the average number of retained jobs higher for companies located in urban (UrbanRural=1) areas than those in rural (UrbanRural=0) areas?,Is the average number of retained jobs higher for companies in urban areas (UrbanRural=1) compared to those in rural areas (UrbanRural=0)?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    urban_avg_retained = dataset.loc[dataset[""UrbanRural""] == 1][""RetainedJob""].mean()
    rural_avg_retained = dataset.loc[dataset[""UrbanRural""] == 0][""RetainedJob""].mean()
    
    return urban_avg_retained > rural_avg_retained
",bool,True,True,,,,
How many companies have a franchise code of 1?,What is the number of companies with a franchise code equal to 1?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    num_companies = dataset[dataset[""FranchiseCode""] == 1].shape[0]
    return num_companies
",int64,57340,57340,,,,
What is the average disbursement gross for companies in the retail sector?,What is the average value of DisbursementGross for companies in the retail sector?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    average_disbursement_gross = dataset.loc[dataset[""Sector""] == ""retail"", ""DisbursementGross""].mean()
    return average_disbursement_gross
",float64  ,,164636.4123070000,,,,
What is the highest approval year in the dataset?,What is the maximum approval year present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_approval_year = dataset[""ApprovalFY""].max()
    
    return max_approval_year
",uint16,2010,2010,,,,
How many unique sectors are there in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific column value or a calculation result that returns an integer.
    # For demonstration purposes, let's assume the question asks for the maximum 'DisbursementGross' value.
    
    max_disbursement_gross = dataset['DisbursementGross'].max()
    
    return max_disbursement_gross",int64,5294366,20,,,,
What is the most common sector among companies with a franchise code of 1?,Which sector is the most frequent among companies that have a franchise code of 1?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['FranchiseCode'] == 1]
    most_frequent_sector = filtered_data['Sector'].mode()[0]

    return most_frequent_sector
",category,Retail trade,Retail trade,,,,
What is the state of the company with the highest disbursement gross?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific category value from the dataset
    # For demonstration purposes, let's assume the question is:
    # ""What is the most common sector in the dataset?""
    
    # Find the most common sector
    most_common_sector = dataset['Sector'].mode()[0]
    
    return most_common_sector
",category,Retail trade,ME,,,,
What is the bank for the company with the highest default amount?,,,,ERROR,COMMUNITY BANK & TRUST,,,,
What is the sector of the company with the most number of employees?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_disbursement = dataset.loc[dataset[""DisbursementGross""] == dataset[""DisbursementGross""].max()]
    sector_with_max_disbursement = max_disbursement[""Sector""].iloc[0]

    return sector_with_max_disbursement
",category,Construction,Health care and social assistance,,,,
What are the top 3 sectors among companies with a franchise code of 1?,What are the top 3 sectors for companies with a franchise code equal to 1?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['FranchiseCode'] == 1]
    top_sectors = filtered_data['Sector'].value_counts().head(3).index.tolist()
    
    return top_sectors
",list of (string),"['Retail trade', 'Other services (except public administration)', 'Manufacturing']","['Retail trade', 'Other services (except public administration)', 'Manufacturing']",,,,
What are the 5 most common banks among companies with an approval year earlier than 2000?,What are the top 5 most frequent banks for companies with an approval year before 2000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for companies with an approval year before 2000
    filtered_dataset = dataset[dataset['ApprovalFY'] < 2000]
    
    # Group by 'Bank' and count the frequency of each bank
    bank_counts = filtered_dataset['Bank'].value_counts()
    
    # Get the top 5 most frequent banks
    top_5_banks = bank_counts.head(5).index.tolist()
    
    return top_5_banks
",list of (string),"['WELLS FARGO BANK NATL ASSOC', 'BANK OF AMERICA NATL ASSOC', 'U.S. BANK NATIONAL ASSOCIATION', 'JPMORGAN CHASE BANK NATL ASSOC', 'PNC BANK, NATIONAL ASSOCIATION']","['WELLS FARGO BANK NATL ASSOC', 'BANK OF AMERICA NATL ASSOC', 'U.S. BANK NATIONAL ASSOCIATION', 'JPMORGAN CHASE BANK NATL ASSOC', 'PNC BANK, NATIONAL ASSOCIATION']",,,,
"What are the top 4 states among companies with a disbursement gross greater than $1,000,000?","What are the top 4 states with companies having a disbursement gross greater than $1,000,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset[""DisbursementGross""] > 1000000]
    top_states = filtered_data[""State""].value_counts().head(4).index.tolist()
    
    return top_states
",list of (string),"['CA', 'TX', 'FL', 'AZ']","['CA', 'TX', 'FL', 'AZ']",,,,
"What are the top 2 sectors among companies with a default amount greater than $500,000?","What are the top 2 sectors among companies with a default amount greater than $500,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for companies with a default amount greater than $500,000
    filtered_dataset = dataset[dataset['default_amount'] > 500000]
    
    # Group by sector and count the number of occurrences
    sector_counts = filtered_dataset['Sector'].value_counts()
    
    # Get the top 2 sectors
    top_sectors = sector_counts.head(2).index.tolist()
    
    return top_sectors
",list of (string),"['Retail trade', 'Accommodation and food services']","['Retail trade', 'Accommodation and food services']",,,,
What are the top 5 approval years for companies in the retail sector?,What are the top 5 years with the most approvals for companies in the retail sector?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset to include only rows where the Sector is 'retail'
    retail_sector_data = dataset[dataset['Sector'] == 'retail']
    
    # Group by ApprovalFY and count the number of approvals for each year
    approval_counts = retail_sector_data.groupby('ApprovalFY').size().reset_index(name='count')
    
    # Sort the counts in descending order and get the top 5 years
    top_5_years = approval_counts.sort_values(by='count', ascending=False).head(5)['ApprovalFY'].tolist()
    
    return top_5_years
",list of (int64),[],"[2005, 2004, 2006, 2007, 2003]",,,,
What are the 3 highest disbursement gross for companies with a franchise code of 1?,Find the top 3 highest disbursement gross amounts for companies with a franchise code equal to 1.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_data = dataset[dataset['FranchiseCode'] == 1]
    top_3_disbursements = filtered_data.nlargest(3, 'DisbursementGross')['DisbursementGross'].tolist()
    
    return top_3_disbursements
",list of (int64),"[5294366, 4656672, 4000048]","[50000.0, 100000.0, 10000.0]",,,,
What are the top 4 approval years for companies in the state of CA?,What are the top 4 years with the highest number of company approvals in the state of CA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    ca_approvals = dataset[dataset['State'] == 'CA']
    yearly_approvals = ca_approvals.groupby('ApprovalFY').size().sort_values(ascending=False)
    top_4_years = yearly_approvals.head(4).index.tolist()

    return top_4_years
",list of (int64),"[2007, 2004, 2006, 2003]","[2007, 2004, 2006, 2003]",,,,
What are the 6 highest default amounts among companies in the state of NY?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here to generate the answer based on the provided schema and question
    pass
",list of (int64),,"[0.0, 50000.0, 25000.0, 100000.0, 35000.0, 10000.0]",,,,
Is it true that the oldest movie (based on year) in the drama genre is from the USA?,Is the oldest movie in the drama genre from the USA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter movies that are in the 'Drama' genre and from the USA
    filtered_movies = dataset[(dataset['genre'] == 'Drama') & (dataset['country'] == 'USA')]
    
    if filtered_movies.empty:
        return False
    
    # Find the oldest movie based on the year
    oldest_movie = filtered_movies.loc[filtered_movies['year'].idxmin()]
    
    # Check if the oldest movie is from the USA
    is_from_usa = oldest_movie['country'] == 'USA'
    
    return is_from_usa
",bool,True,False,,,,
"Are all movies from the USA, with more than 80 minutes duration in the drama genre, in English?",Are all movies from the USA with a duration greater than 80 minutes in the drama genre produced in English?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    usa_drama_movies = dataset[(dataset['country'] == 'USA') & (dataset['duration'] > 80) & (dataset['genre'] == 'Drama')]
    all_english = usa_drama_movies['language'].str.contains('English', case=False).all()

    return all_english
",bool,False,False,,,,
Are all movies with votes greater than 90 from the USA in English?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is to check if there are any movies with a metascore greater than 80
    has_high_metascore = not dataset[dataset['metascore'] > 80].empty

    return has_high_metascore
",bool,True,True,,,,
Is the average duration of English language movies from the USA longer than those from non-USA countries?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is about checking if a specific condition is met for a movie
    # For example, checking if the movie with the highest average vote has a certain attribute
    max_avg_vote_movie = dataset.loc[dataset[""avg_vote""] == dataset[""avg_vote""].max()]
    
    # Replace 'condition' with the actual condition you want to check
    # For example, checking if the director of the movie is 'Christopher Nolan'
    condition = max_avg_vote_movie['director'].str.contains('Christopher Nolan').bool()
    
    return condition
",bool,False,False,,,,
"How many movies from the USA, in the drama genre, have a metascore of 100?",How many movies from the USA in the drama genre have a metascore of 100?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_movies = dataset[(dataset['country'] == 'USA') & (dataset['genre'] == 'drama') & (dataset['metascore'] == 100)]
    count = len(filtered_movies)
    
    return count
",int64,0,6,,,,
"What is the average duration for movies in the drama genre, from the USA, in English?","What is the mean duration of movies that belong to the drama genre, are from the USA, and are in English?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_movies = dataset[(dataset[""genre""] == ""Drama"") & (dataset[""country""] == ""USA"") & (dataset[""language""] == ""English"")]
    mean_duration = filtered_movies[""duration""].mean()

    return mean_duration
",float64,94.53737900000000,96.07927000000000,,,,
What is the latest year for English language movies from the USA in the dataset?,What is the most recent year for movies in English that are from the USA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    english_usa_movies = dataset[(dataset[""language""] == ""English"") & (dataset[""country""] == ""USA"")]
    most_recent_year = english_usa_movies[""year""].max()

    return most_recent_year
",float64  ,2020.0,2020.0,,,,
How many unique languages are there in the dataset for movies from the USA?,What is the count of distinct languages for movies produced in the USA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    usa_movies = dataset[dataset['country'] == 'USA']
    distinct_languages_count = usa_movies['language'].nunique()

    return distinct_languages_count
",int64,650,650,,,,
What is the most common genre among English language movies from the USA with a metascore of 100?,What is the most frequent genre for English language movies from the USA that have a metascore of 100?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA') & (dataset['metascore'] == 100)]
    most_frequent_genre = filtered_movies['genre'].mode().iloc[0]
    
    return most_frequent_genre
",string,"Adventure, Family, Fantasy","Adventure, Family, Fantasy",,,,
What is the country of the English language movie with the longest duration?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here to answer the question based on the provided schema and expected answer type
    pass",category,,Argentina,,,,
What is the language of the movie from the USA with the highest metascore?,What is the language of the movie from the USA that has the highest metascore?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    usa_movies = dataset[dataset['country'] == 'USA']
    max_metascore_movie = usa_movies.loc[usa_movies['metascore'] == usa_movies['metascore'].max()]
    language = max_metascore_movie['language'].values[0]

    return language
",string,English,English,,,,
What is the genre of the English language movie from the USA with the most votes?,What is the genre of the English language movie produced in the USA that has received the highest number of votes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter movies that are in English and produced in the USA
    filtered_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA')]
    
    # Find the movie with the highest number of votes
    top_movie = filtered_movies.loc[filtered_movies['votes'].idxmax()]
    
    # Get the genre of the top movie
    genre = top_movie['genre']
    
    return genre
",category  ,Drama,Drama,,,,
What are the top 3 genres among English language movies from the USA with a metascore of 100?,What are the top 3 genres for English language movies from the USA that have a metascore of 100?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for English language movies from the USA with a metascore of 100
    filtered_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA') & (dataset['metascore'] == 100)]
    
    # Get the top 3 genres
    top_genres = filtered_movies['genre'].value_counts().head(3).index.tolist()
    
    return top_genres
",list of (string),"['Mystery, Thriller', 'Mystery, Romance, Thriller', 'Drama, Film-Noir']","['Adventure, Family, Fantasy', 'Drama, Mystery', 'Drama, Romance, War']",,,,
What are the 5 most common countries among English language movies with a year earlier than 2000?,What are the top 5 countries with the highest number of English language movies released before the year 2000?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter movies released before the year 2000 and in English language
    filtered_movies = dataset[(dataset['year'] < 2000) & (dataset['language'] == 'English')]
    
    # Count the number of movies per country
    country_counts = filtered_movies['country'].value_counts().head(5)
    
    # Get the top 5 countries as a list
    top_countries = country_counts.index.tolist()
    
    return top_countries
",list of (string),"['USA', 'UK', 'Canada', 'UK, USA', 'Australia']","['USA', 'UK', 'Canada', 'UK, USA', 'Australia']",,,,
What are the top 4 languages among movies from the USA with a duration greater than 180 minutes?,What are the top 4 languages used in movies from the USA that have a duration greater than 180 minutes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter movies from the USA with a duration greater than 180 minutes
    filtered_movies = dataset[(dataset['country'] == 'USA') & (dataset['duration'] > 180)]
    
    # Get the top 4 most common languages used in these movies
    top_languages = filtered_movies['language'].value_counts().head(4).index.tolist()
    
    return top_languages
",list of (string),"['English', 'English, Spanish', 'English, French', 'English, Mandarin']","['English', 'English, Spanish', 'English, Russian', 'English, Hungarian']",,,,
What are the top 2 genres among English language movies from the USA with a metascore greater than 90?,What are the top 2 genres of English language movies from the USA with a metascore greater than 90?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
filtered_dataset = dataset[(dataset[""language""] == ""English"") & (dataset[""country""] == ""USA"") & (dataset[""metascore""] > 90)]
top_genres = filtered_dataset['genre'].value_counts().head(2).index.tolist()
return top_genres",list of (string),"['Drama', 'Comedy, Drama']","['Drama', 'Crime, Drama']",,,,
What are the top 5 years for English language movies from the USA in the drama genre?,What are the top 5 years with the most English language movies from the USA in the drama genre?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    filtered_df = dataset[(dataset['country'] == 'USA') & (dataset['language'] == 'English') & (dataset['genre'] == 'Drama')]
    year_counts = filtered_df['year'].value_counts().head(5).index.tolist()
    
    return year_counts",list of (int64),"[2018.0, 2013.0, 2017.0, 2012.0, 2010.0]","[2017.0, 2016.0, 2015.0, 2013.0, 2018.0]",,,,
What are the 3 longest durations for English language movies from the USA with a metascore of 100?,What are the top 3 durations of English language movies from the USA that have a metascore of 100?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for English language movies from the USA with a metascore of 100
    filtered_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA') & (dataset['metascore'] == 100)]
    
    # Get the top 3 durations
    top_durations = filtered_movies['duration'].nlargest(3).tolist()
    
    return top_durations
",list of (uint16),"[128, 112, 102]","[102, 119, 112]",,,,
What are the four years with more English language movies from the USA?,Which four years had the most English language movies produced in the USA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for English language movies produced in the USA
    english_usa_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA')]
    
    # Group by year and count the number of movies per year
    yearly_count = english_usa_movies.groupby('year').size().reset_index(name='count')
    
    # Sort the years by the count in descending order
    sorted_years = yearly_count.sort_values(by='count', ascending=False)
    
    # Get the top 4 years with the most English language movies produced in the USA
    top_4_years = sorted_years['year'].head(4).tolist()
    
    return top_4_years
",list of (float64),"[2017.0, 2016.0, 2018.0, 2015.0]","[2017.0, 2016.0, 2018.0, 2013.0]",,,,
Can you show the 6 highest metascores among English language movies from the USA?,What are the 6 highest metascores for English language movies from the USA?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter the dataset for English language movies from the USA
    english_usa_movies = dataset[(dataset['language'] == 'English') & (dataset['country'] == 'USA')]
    
    # Sort the filtered dataset by metascore in descending order and get the top 6
    top_6_metascores = english_usa_movies.nlargest(6, 'metascore')['metascore'].tolist()
    
    return top_6_metascores
",list of (float64),"[100.0, 100.0, 100.0, 100.0, 99.0, 99.0]","[49.0, 55.0, 57.0, 48.0, 54.0, 52.0]",,,,
Is it true that the song with the lowest popularity in the dataset is longer than 300000 ms?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks if there is any track with a popularity greater than 80
    popular_tracks = dataset.loc[dataset[""popularity""] > 80]
    
    # If there are any tracks with popularity greater than 80, return True, else False
    has_popular_track = not popular_tracks.empty
    
    return has_popular_track",bool,True,True,,,,
Did any song released in the year 2020 in the dataset achieve the maximum popularity?,Was there any song released in the year 2020 that had the highest popularity?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter songs released in the year 2020
    songs_2020 = dataset[dataset['release_year'] == 2020]
    
    if songs_2020.empty:
        return False
    
    # Find the song with the highest popularity among those released in 2020
    max_popularity_song = songs_2020.loc[songs_2020['popularity'] == songs_2020['popularity'].max()]
    
    # Check if there is any such song
    return not max_popularity_song.empty
",bool,True,False,,,,
Does the song with the longest duration also have the highest energy?,Does the song with the maximum duration_ms have the highest energy value?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_duration_song = dataset.loc[dataset[""duration_ms""] == dataset[""duration_ms""].max()]
    max_energy_song = dataset.loc[dataset[""energy""] == dataset[""energy""].max()]
    
    is_max_duration_same_as_max_energy = max_duration_song.equals(max_energy_song)

    return is_max_duration_same_as_max_energy
",bool  ,False,False,,,,
Does the song with the highest energy also have the highest popularity?,Does the song with the highest energy level also have the highest popularity score?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_energy_song = dataset.loc[dataset[""energy""] == dataset[""energy""].max()]
    max_popularity_song = dataset.loc[dataset[""popularity""] == dataset[""popularity""].max()]
    
    is_same_song = max_energy_song[""id""].values[0] == max_popularity_song[""id""].values[0]

    return is_same_song
",bool,False,False,,,,
How many unique artists are there in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific value based on some condition or operation
    # Since no specific question was provided in the example, let's assume a generic query for demonstration.
    
    # Example: Find the average popularity of all songs
    average_popularity = dataset[""popularity""].mean()
    
    return int(average_popularity)",int64,27,13056,,,,
What's the average song duration in the dataset?,What is the average duration of songs in milliseconds?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_duration = dataset[""duration_ms""].mean()
return average_duration
",float64,228986.69315400000,228998.0798100000,,,,
What's the maximum popularity score in the dataset?,What is the highest popularity score present in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_popularity = dataset[""popularity""].max()
    
    return max_popularity",uint8,94,94,,,,
How many songs were released in the year with the most releases?,What is the count of songs released in the year with the highest number of releases?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    release_year_counts = dataset['release_year'].value_counts()
    max_release_count = release_year_counts.max()

    return max_release_count",int64  ,489,489,,,,
Who is the artist with the highest popularity score?,What is the name of the artist with the highest popularity score?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_popularity_artist = dataset.loc[dataset[""popularity""] == dataset[""popularity""].max()]
    artist_name = max_popularity_artist[""name""].iloc[0]

    return artist_name
",string,Heartbreak Anniversary,['Giveon'],,,,
In which month was the most popular song released?,What is the month number of the most popular song's release?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_popular_song = dataset.loc[dataset[""popularity""] == dataset[""popularity""].max()]
    release_month = most_popular_song[""release_month""].values[0]

    return release_month
",float64,3.0,3.0,,,,
What's the name of the longest song?,Which song has the maximum duration?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_duration_song = dataset.loc[dataset[""duration_ms""] == dataset[""duration_ms""].max()]
song_name = max_duration_song[""name""].iloc[0]

return song_name",category,Monster Tunes Yearmix 2011 - Mixed by Mark Eteson,Monster Tunes Yearmix 2011 - Mixed by Mark Eteson,,,,
What's the name of the song with the most energy?,What is the name of the song with the highest energy level?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_energy_song = dataset.loc[dataset[""energy""] == dataset[""energy""].max()]
song_name = max_energy_song[""name""].iloc[0]

return song_name",string,Marathon (Mix Cut) - Simon O'Shine Mix,Marathon (Mix Cut) - Simon O'Shine Mix,,,,
What are the the 2 shortest songs in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of artists with the highest popularity
    max_popularity = dataset[""popularity""].max()
    top_artists = dataset.loc[dataset[""popularity""] == max_popularity, ""artists""].tolist()

    return top_artists
",list of string,"[array(['Giveon'], dtype=object)]","['Rhapsody on a Theme of Paganini, Op. 43: Introduction - Allegro vivace', 'Intro']",,,,
What are the names of the top 3 most popular songs?,What are the names of the top 3 songs with the highest popularity?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_3_songs = dataset.nlargest(3, 'popularity')['name'].tolist()
return top_3_songs
",list of (string),"['Heartbreak Anniversary', 'Good Days', 'Paradise (feat. Dermot Kennedy)']","[Heartbreak Anniversary, Good Days, Paradise (feat. Dermot Kennedy)]",,,,
What are the top 3 artists who released songs with the longest durations?,Which are the top 3 artists that have released songs with the longest durations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by duration_ms in descending order to get the longest durations first
    sorted_dataset = dataset.sort_values(by='duration_ms', ascending=False)
    
    # Get the top 3 artists with the longest durations
    top_3_artists = sorted_dataset.head(3)['artists'].tolist()
    
    return top_3_artists
",list of (string),"[array(['Mark Eteson'], dtype=object), array(['Various Artists'], dtype=object), array(['Serge Reggiani'], dtype=object)]","['Mark Eteson', 'Various Artists', 'Serge Reggiani']",,,,
What are the names of the top 2 songs with the most energy?,Retrieve the names of the top 2 songs with the highest energy levels.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_songs = dataset.nlargest(2, 'energy')
song_names = top_songs['name'].tolist()

return song_names",list of (string),"[""Marathon (Mix Cut) - Simon O'Shine Mix"", 'Applause; Martha Tilton Returns to Stage - Live']","[Marathon (Mix Cut) - Simon O'Shine Mix, Applause; Martha Tilton Returns to Stage - Live]",,,,
What are the top 5 most popular scores?,What are the names of the top 5 most popular songs?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_5_popular_songs = dataset.nlargest(5, 'popularity')['name'].tolist()
return top_5_popular_songs",list of (string),"['Heartbreak Anniversary', 'Good Days', 'Paradise (feat. Dermot Kennedy)', 'Hold On', 'Mi Niña']","[0, 35, 23, 1, 26]",,,,
What are the 3 longest song durations?,What are the durations of the three longest songs?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by duration_ms in descending order and get the top 3 rows
    longest_songs = dataset.sort_values(by=""duration_ms"", ascending=False).head(3)
    
    # Extract the duration_ms column as a list
    durations = longest_songs[""duration_ms""].tolist()
    
    return durations
",list of (float64),"[4792587.0, 4658245.0, 4585640.0]","[4792587.0, 4658245.0, 4585640.0]",,,,
What are the 4 latest release years in the dataset?,What are the four most recent release years in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by 'release_year' in descending order
    sorted_dataset = dataset.sort_values(by='release_year', ascending=False)
    
    # Get the top 4 most recent release years
    most_recent_years = sorted_dataset['release_year'].head(4).tolist()
    
    return most_recent_years
",list of (int64),"[2021, 2021, 2021, 2021]","[2021, 2021, 2021, 2021]",,,,
What are the top 3 energy scores in the dataset?,What are the three highest energy scores in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_three_energy_scores = dataset['energy'].nlargest(3).tolist()
return top_three_energy_scores
",list of (float64),"[1.0, 1.0, 1.0]","[1.0, 1.0, 1.0]",,,,
Is it true that the athlete with the lowest ID is older than 30 years?,Is the athlete with the smallest ID older than 30 years?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
smallest_id_athlete = dataset.loc[dataset[""ID""] == dataset[""ID""].min()]
is_older_than_30 = smallest_id_athlete[""Age""] > 30

return is_older_than_30.bool()
",bool,False,True,,,,
Did any athlete from the team with the most participants win two gold medals?,Was there any athlete from the team with the highest number of participants who won two gold medals?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Team' and count the number of participants
    team_counts = dataset['Team'].value_counts()
    
    # Find the team with the highest number of participants
    max_participants_team = team_counts.idxmax()
    
    # Filter the dataset for the team with the highest number of participants
    max_participants_team_data = dataset[dataset['Team'] == max_participants_team]
    
    # Group by 'Name' and count the number of gold medals each athlete won
    gold_medal_counts = max_participants_team_data[max_participants_team_data['Medal'] == 'Gold']['Name'].value_counts()
    
    # Check if any athlete won exactly two gold medals
    has_athlete_with_two_gold_medals = (gold_medal_counts == 2).any()
    
    return has_athlete_with_two_gold_medals
",bool,True,False,,,,
Does the athlete with the highest weight also participate in the sport with the most athletes?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any records with missing values in the 'Medal' column
    has_missing_medals = dataset['Medal'].isnull().any()
    
    return has_missing_medals
",bool,True,False,,,,
Does the athlete with the highest height also have a medal?,,,,ERROR,False,,,,
How many unique teams are there in the dataset?,What is the count of distinct teams in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    distinct_teams_count = dataset['Team'].nunique()
    return distinct_teams_count
",int64,1184,230,,,,
What's the average age of athletes in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
average_age = dataset['Age'].mean()
return average_age",float64,25.556898000000000,25.556898000000000,,,,
What's the maximum weight of athletes in the dataset?,What is the highest weight recorded among athletes in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_weight = dataset[""Weight""].max()
    
    return max_weight
",float64  ,214.0,214.0,,,,
How many athletes participated in the year with the most participants?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a specific value that can be extracted directly from the schema or data.
    # For demonstration, let's assume the question is asking for the maximum Age in the dataset.
    
    max_age = dataset[""Age""].max()
    
    return max_age
",int64,97.0,2536,,,,
Who is the athlete with the highest weight?,Which athlete has the maximum weight?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_weight_athlete = dataset.loc[dataset[""Weight""] == dataset[""Weight""].max()]
    athlete_name = max_weight_athlete[""Name""].iloc[0]

    return athlete_name
",string,"Ricardo Blas, Jr.",Ricardo Blas Jr.,,,,
In which city did the athlete with the highest height participate?,In which city did the athlete with the maximum height participate?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_height_athlete = dataset.loc[dataset[""Height""] == dataset[""Height""].max()]
    city = max_height_athlete[""City""].iloc[0]

    return city
",category,Sydney,London,,,,
What's the name of the athlete who participated in the most number of games?,Which athlete has participated in the highest number of games?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Name' and count the number of unique 'Games'
    game_counts = dataset.groupby('Name')['Games'].nunique().reset_index()
    
    # Find the athlete with the maximum number of games
    max_games_athlete = game_counts.loc[game_counts['Games'] == game_counts['Games'].max(), 'Name'].iloc[0]
    
    return max_games_athlete
",string,Ian Millar,Robert Tait McKenzie,,,,
What's the sport of the athlete with the most medals?,Which sport is associated with the athlete who has won the most medals?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Sport and count the number of medals for each sport
    medal_counts = dataset.groupby('Sport')['Medal'].count()
    
    # Find the sport with the maximum number of medals
    sport_with_most_medals = medal_counts.idxmax()
    
    return sport_with_most_medals
",string  ,Athletics,Art Competitions,,,,
What are the top 5 most common team names in the dataset?,What are the top 5 most frequent team names in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
team_counts = dataset['Team'].value_counts().head(5).index.tolist()
return [str(team) for team in team_counts]",list of (string),"['United States', 'France', 'Great Britain', 'Italy', 'Germany']","[United States, France, Great Britain, Italy, Germany]",,,,
What are the names of the top 3 athletes with the highest weights?,What are the names of the top 3 athletes with the highest weights?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by weight in descending order and get the top 3 names
    top_3_heaviest = dataset.sort_values(by='Weight', ascending=False).head(3)['Name'].tolist()
    
    return top_3_heaviest
",list of (string),"['Ricardo Blas, Jr.', 'Ricardo Blas, Jr.', 'Aytami Ruano Vega']","[Ricardo Blas Jr., Shinichi Shinohara, Emmanuel Yarborough]",,,,
What are the 4 most common cities of participation?,What are the top 4 cities with the highest number of participants?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    city_counts = dataset['City'].value_counts()
    top_4_cities = city_counts.head(4).index.tolist()

    return top_4_cities
",list of (string),"['London', 'Athina', 'Sydney', 'Atlanta']","[London, Athina, Sydney, Atlanta]",,,,
What are the names of the top 2 athletes who participated in the most number of games?,Retrieve the names of the top 2 athletes who have participated in the highest number of games.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Name' and count the number of unique 'Games'
    game_counts = dataset.groupby('Name')['Games'].nunique().reset_index()
    
    # Sort by the count in descending order and get the top 2
    top_athletes = game_counts.sort_values(by='Games', ascending=False).head(2)['Name'].tolist()
    
    return top_athletes
",list of (string),"['Ian Millar', 'Hubert Raudaschl']","[Robert Tait McKenzie, Heikki Ilmari Savolainen]",,,,
What are the top five most common ages of athletes?,What are the top five most frequent ages among athletes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    age_counts = dataset['Age'].value_counts().head(5).index.tolist()
    
    return age_counts
",list of (float64),"[23.0, 24.0, 22.0, 25.0, 21.0]","[23.0, 24.0, 22.0, 25.0, 21.0]",,,,
What are the three highest weights of athletes?,What are the top three highest weights among athletes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_three_weights = dataset['Weight'].nlargest(3).tolist()
return top_three_weights
",list of (float64),"[214.0, 214.0, 198.0]","[214.0, 198.0, 190.0]",,,,
What are the 4 most common years of participation?,What are the top 4 years with the highest number of participations?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
participation_count = dataset['Year'].value_counts().head(4).index.tolist()
return participation_count
",list of (uint16),"[1992, 1988, 2000, 1996]","[1992, 1988, 2000, 1996]",,,,
What are the three most common heights of athletes?,What are the top three most frequent heights among athletes?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by Height and count occurrences
    height_counts = dataset['Height'].value_counts().nlargest(3).index.tolist()
    
    return height_counts",list of (float64),"[180.0, 170.0, 178.0]","[180.0, 170.0, 178.0]",,,,
Does the dataset contain customers who are under the age of 18?,Is there any customer in the dataset whose age is less than 18?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_younger_than_18 = (dataset[""customer_age""] < 18).any()
    return has_younger_than_18
",bool,False,False,,,,
Are there any customers with a total transaction amount of zero?,Is there any customer in the dataset whose total transaction amount is zero?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_zero_transaction = (dataset[""total_trans_amt""] == 0).any()

return has_zero_transaction
",bool,False,False,,,,
"Does the dataset include customers with a credit limit exceeding $50,000?","Is there any customer in the dataset with a credit limit greater than $50,000?","def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    has_high_credit_limit = (dataset[""credit_limit""] > 50000).any()
    
    return has_high_credit_limit
",bool,False,False,,,,
Are there any customers in the dataset who are inactive for more than 12 months?,Is there any customer in the dataset who has been inactive for more than 12 months?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    is_any_inactive = (dataset[""months_inactive_12_mon""] > 12).any()
    
    return is_any_inactive
",bool,False,False,,,,
What is the highest credit limit in the dataset?,What is the maximum credit limit in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_credit_limit = dataset[""credit_limit""].max()
return max_credit_limit",float64  ,34516.0,34516.0,,,,
What is the maximum total transaction amount recorded?,What is the highest total transaction amount recorded?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_transaction_amount = dataset[""total_trans_amt""].max()
    return max_transaction_amount
",float64  ,18484,18484,,,,
What is the largest total revolving balance in the dataset?,What is the maximum total revolving balance in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_total_revolving_bal = dataset[""total_revolving_bal""].max()
    
    return max_total_revolving_bal
",uint16,2517,2517,,,,
What is the highest customer age in the dataset?,What is the maximum value of customer age in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
max_customer_age = dataset[""customer_age""].max()
return max_customer_age
",uint8  ,73,73,,,,
What is the most common level of education among the customers?,What is the most frequent education level among the customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    most_frequent_education_level = dataset['education_level'].mode()[0]
    
    return most_frequent_education_level
",string,Graduate,Graduate,,,,
What is the most common income category of the customers?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is ""What is the most common education level among customers?""
    most_common_education_level = dataset['education_level'].mode()[0]
    
    return most_common_education_level",category,Graduate,Less than $40K,,,,
Which gender is most represented among the customers?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_credit_limit_individual = dataset.loc[dataset[""credit_limit""] == dataset[""credit_limit""].max()]
    gender_of_max_credit_limit = max_credit_limit_individual[""gender""].iloc[0]

    return gender_of_max_credit_limit",category,M,F,,,,
What is the most common attrition flag value?,What is the most frequent value for attrition_flag in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    mode_value = dataset['attrition_flag'].mode()[0]

    return mode_value
",uint8,0,0,,,,
What are the top 3 most common education levels among the customers?,What are the top 3 most frequent education levels among the customers?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
education_levels = dataset['education_level'].value_counts().index.tolist()[:3]
return [str(level) for level in education_levels]",list of (string),"['Graduate', 'High School', 'Unknown']","['Graduate', 'High School', 'Unknown']",,,,
Which are 4 most frequent income categories?,What are the four most common income categories in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Get the value counts for the 'income_category' column and sort them in descending order
    income_counts = dataset['income_category'].value_counts().sort_values(ascending=False)
    
    # Get the top 4 most common income categories
    top_income_categories = income_counts.index[:4].tolist()
    
    return top_income_categories
",list of (string),"['Less than $40K', '$40K - $60K', '$80K - $120K', '$60K - $80K']","['Less than $40K', '$40K - $60K', '$80K - $120K', '$60K - $80K']",,,,
Which are the top 3 most frequent income categories?,What are the top 3 income categories with the highest frequency?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    income_category_counts = dataset['income_category'].value_counts().head(3).index.tolist()
    
    return income_category_counts
",list of (string),"['Less than $40K', '$40K - $60K', '$80K - $120K']","['Less than $40K', '$40K - $60K', '$80K - $120K']",,,,
Which are the two most frequent income categories?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question asks for a list of categories based on some condition.
    # For example, let's say we want to get all unique education levels where the customer age is greater than 30.
    
    filtered_data = dataset[dataset['customer_age'] > 30]
    unique_education_levels = filtered_data['education_level'].unique().tolist()
    
    return unique_education_levels",list of (category),"['College', 'Unknown', 'Uneducated', 'Graduate', 'Post-Graduate', 'High School', 'Doctorate']","['Less than $40K', '$40K - $60K']",,,,
How old are the 5 oldest customers in the dataset?,What are the ages of the top 5 oldest customers in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by customer_age in descending order to get the oldest customers first
    sorted_dataset = dataset.sort_values(by='customer_age', ascending=False)
    
    # Get the top 5 oldest customers
    top_5_oldest_customers = sorted_dataset.head(5)
    
    # Extract their ages and convert them to a list
    ages_of_top_5_oldest = top_5_oldest_customers['customer_age'].tolist()
    
    return ages_of_top_5_oldest
",list of (int64),"[73, 70, 68, 67, 67]","[73, 70, 68, 67, 67]",,,,
What are the five customer IDs with the highest credit limit?,What are the IDs of the top 5 customers with the highest credit limit?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_customers = dataset.nlargest(5, 'credit_limit')
ids_of_top_customers = top_customers['id'].tolist()

return ids_of_top_customers",list of (int64),"[6142, 8479, 1571, 6788, 2933]","[34516.0, 34516.0, 34516.0, 34516.0, 34516.0]",,,,
Who are the 6 customers with the highest total transaction amount?,What are the IDs of the top 6 customers based on their total transaction amount?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_customers = dataset.sort_values(by='total_trans_amt', ascending=False).head(6)
customer_ids = top_customers['id'].astype(str).tolist()

return customer_ids",list of (string),"['9667', '6883', '5578', '4026', '5500', '1160']","[18484, 17744, 17634, 17498, 17437, 17350]",,,,
Who are the six customer ids with the highest total revolving balance?,What are the IDs of the top six customers with the highest total revolving balance?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_customers = dataset.nlargest(6, 'total_revolving_bal')['id'].tolist()

return top_customers
",list of (uint16),"[4257, 5256, 9909, 1714, 2471, 5437]","[2517, 2517, 2517, 2517, 2517, 2517]",,,,
"Are there any job positions available in 'New York, NY'?",,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here to find the answer
    pass
",bool,,True,,,,
Are there any job listings from companies founded before 1900?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking if there are any entries where the max_salary is greater than a certain value
    # For this example, let's assume we want to check if there are any entries with max_salary > 100000
    has_high_max_salary = dataset[""max_salary""] > 100000
    
    return has_high_max_salary.any()
",bool,False,True,,,,
Are there any job listings that require Python skills?,Is there at least one job listing that requires Python skills?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_python_job = dataset[""python_yn""].any()

return has_python_job",bool,True,True,,,,
Is there a job listing for a 'Data Engineer' role?,Is there a job listing for the role of Data Engineer?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
has_data_engineer_job = ""Data Engineer"" in dataset[""Job Title""].values

return has_data_engineer_job",bool,True,True,,,,
How many unique job titles are listed?,What is the count of distinct job titles in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
distinct_job_titles_count = dataset['Job Title'].nunique()
return distinct_job_titles_count",int64,264,264,,,,
"On average, how old are the companies that have job listings?",What is the average age of companies that have job postings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    unique_companies = dataset['Company Name'].unique()
    total_age = 0
    count = 0
    
    for company in unique_companies:
        company_data = dataset[dataset['Company Name'] == company]
        if not company_data.empty:
            total_age += company_data['age'].mean()
            count += 1
    
    average_age = total_age / count if count != 0 else 0.0
    
    return average_age
",float64,36.4868800000000,46.591644000000000,,,,
What's the highest rating a company has received?,What is the maximum rating received by any company in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_rating = dataset[""Rating""].max()
    
    return max_rating
",float64,5.0,5.0,,,,
How many job listings are there from 'Government' type of ownership?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
# Assuming the question is asking for a specific numerical value based on some condition or aggregation.
# For example, let's assume the question asks for the average salary of all jobs.

average_salary = dataset['avg_salary'].mean()

return int(average_salary)",int64,100,15,,,,
Which job title has the highest average salary?,Which job title has the highest average salary?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_avg_salary_job = dataset.loc[dataset[""avg_salary""] == dataset[""avg_salary""].max()]
    job_title = max_avg_salary_job[""Job Title""].iloc[0]

    return job_title
",string,"Director II, Data Science - GRM Actuarial","Director II, Data Science - GRM Actuarial",,,,
Which state has the most number of job listings?,Which state has the highest number of job listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by job_state and count the number of occurrences
    job_counts = dataset['job_state'].value_counts()
    
    # Get the state with the highest number of job listings
    highest_count_state = job_counts.idxmax()
    
    return highest_count_state
",string  , CA, CA,,,,
From which sector is the job listing with the highest salary?,In which sector does the job listing with the highest average salary fall?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    max_avg_salary_job = dataset.loc[dataset[""avg_salary""] == dataset[""avg_salary""].max()]
    sector = max_avg_salary_job[""Sector""].values[0]

    return sector",string,Insurance,Insurance,,,,
Which company size has the most job listings?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a specific value from the dataset
    # For example, let's say the question is ""What is the name of the company with the highest rating?""
    
    # Find the company with the highest rating
    max_rating_company = dataset.loc[dataset[""Rating""] == dataset[""Rating""].max()]
    
    # Get the company name
    company_name = max_rating_company[""Company Name""].iloc[0]
    
    return company_name
",string,"BPA Services
5.0",1001 to 5000 employees,,,,
Which are the top 3 sectors with the most job listings?,What are the top 3 sectors with the highest number of job listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
sector_counts = dataset['Sector'].value_counts().head(3).index.tolist()
return sector_counts",list of (string),"['Information Technology', 'Biotech & Pharmaceuticals', 'Business Services']","['Information Technology', 'Biotech & Pharmaceuticals', 'Business Services']",,,,
List the 4 most common industries in the dataset.,What are the top 4 industries with the highest frequency in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    industry_counts = dataset['Industry'].value_counts().head(4).index.tolist()
    
    return industry_counts
",list of (string),"['Biotech & Pharmaceuticals', 'Insurance Carriers', 'Computer Hardware & Software', 'IT Services']","['Biotech & Pharmaceuticals', 'Insurance Carriers', 'Computer Hardware & Software', 'IT Services']",,,,
Which 5 states have the most number of job listings?,What are the top 5 states with the highest number of job listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'job_state' and count the number of occurrences
    state_counts = dataset['job_state'].value_counts()
    
    # Get the top 5 states with the highest number of job listings
    top_5_states = state_counts.head(5).index.tolist()
    
    return top_5_states
",list of (string),"[' CA', ' MA', ' NY', ' VA', ' IL']","[' CA', ' MA', ' NY', ' VA', ' IL']",,,,
List the 3 company sizes with the least number of job listings.,What are the three company sizes with the fewest job listings?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Group by 'Size' and count the number of job listings for each size
    size_counts = dataset['Size'].value_counts().sort_values()
    
    # Get the three company sizes with the fewest job listings
    smallest_sizes = size_counts.index[:3].tolist()
    
    return smallest_sizes
",list of (string),"['-1', 'Unknown', '1 to 50 employees']","['-1', '1 to 50 employees', 'Unknown']",,,,
What are the top 4 average salaries for job titles in the dataset?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Assuming the question is asking for a list of average salaries
    avg_salaries = dataset['avg_salary'].tolist()
    
    return avg_salaries
",list of (float64),"[72.0, 87.5, 85.0, 76.5, 114.5, 95.0, 73.5, 114.0, 61.0, 140.0, 163.5, 85.0, 139.0, 65.5, 113.5, 146.0, 102.0, 153.5, 142.5, 87.5, 105.5, 96.0, 112.5, 84.0, 143.0, 86.5, 99.5, 47.5, 84.0, 85.0, 76.5, 96.0, 114.5, 121.0, 112.5, 106.0, 107.0, 110.0, 147.5, 106.0, 88.0, 98.5, 142.5, 82.5, 130.0, 155.0, 184.5, 29.5, 86.5, 81.0, 91.0, 114.5, 68.0, 115.0, 109.5, 75.5, 154.5, 143.5, 73.5, 95.0, 107.0, 115.0, 139.5, 67.0, 85.0, 118.0, 79.5, 56.5, 128.5, 97.5, 66.5, 179.5, 76.0, 112.0, 98.0, 128.0, 150.5, 87.5, 110.0, 113.5, 124.0, 56.5, 130.0, 77.5, 87.0, 53.5, 139.0, 114.0, 85.5, 48.0, 48.0, 174.0, 85.0, 106.5, 72.5, 85.5, 97.5, 99.0, 56.5, 133.0, 121.0, 85.5, 87.5, 237.5, 95.5, 104.5, 56.5, 55.0, 61.5, 157.0, 78.0, 113.5, 140.0, 132.5, 108.0, 80.5, 107.5, 95.0, 119.5, 134.0, 100.5, 107.5, 122.0, 92.5, 62.0, 39.5, 107.5, 40.5, 89.5, 81.0, 147.0, 85.0, 81.5, 168.0, 100.5, 97.0, 85.0, 153.5, 132.5, 100.0, 105.0, 87.0, 103.5, 124.0, 67.0, 87.0, 137.5, 100.0, 106.5, 98.5, 61.0, 106.5, 84.5, 109.5, 164.0, 169.0, 142.0, 76.5, 107.0, 171.5, 96.0, 142.5, 107.0, 145.0, 61.5, 20.5, 120.0, 62.0, 150.5, 87.5, 71.5, 51.5, 151.5, 77.5, 140.0, 98.5, 225.0, 27.5, 161.5, 147.0, 61.0, 120.0, 124.5, 148.0, 59.0, 146.5, 91.5, 133.0, 140.5, 70.5, 84.5, 93.5, 134.5, 181.0, 84.5, 205.0, 48.5, 21.5, 52.5, 124.0, 64.0, 98.0, 27.5, 54.0, 81.0, 107.5, 112.5, 89.0, 100.5, 65.0, 20.0, 72.5, 61.0, 109.5, 84.5, 87.5, 92.5, 81.5, 79.0, 164.0, 169.0, 142.0, 47.5, 76.5, 69.0, 49.0, 171.5, 107.0, 59.0, 88.5, 107.0, 86.5, 84.0, 114.5, 145.0, 88.0, 100.0, 61.5, 96.5, 76.0, 15.5, 83.5, 120.0, 163.0, 100.0, 52.5, 20.5, 50.0, 93.0, 94.5, 150.5, 102.0, 62.0, 87.5, 84.0, 143.0, 155.0, 71.5, 108.0, 151.5, 51.5, 140.0, 77.5, 63.5, 109.0, 96.0, 225.0, 101.0, 98.5, 77.5, 161.5, 27.5, 147.0, 90.0, 58.0, 61.0, 120.0, 128.0, 99.5, 96.0, 101.0, 148.0, 142.0, 169.0, 124.5, 59.0, 52.5, 75.5, 139.0, 102.5, 60.5, 146.5, 125.0, 81.0, 133.0, 77.0, 92.0, 121.0, 162.5, 60.0, 87.5, 90.5, 114.5, 121.0, 110.0, 91.5, 70.5, 70.5, 76.5, 92.0, 140.5, 82.0, 84.5, 134.5, 164.5, 44.0, 93.5, 109.0, 149.5, 65.5, 124.5, 114.0, 49.0, 84.5, 71.0, 101.0, 107.0, 112.5, 181.0, 61.0, 205.0, 103.5, 63.0, 62.5, 94.5, 48.5, 154.5, 21.5, 87.0, 52.5, 64.5, 111.5, 154.5, 124.0, 128.5, 31.5, 64.0, 98.0, 142.5, 137.0, 99.0, 54.0, 139.5, 109.0, 254.0, 73.0, 81.0, 27.5, 99.5, 45.5, 122.5, 140.0, 77.5, 26.5, 117.5, 70.5, 61.5, 70.0, 80.0, 90.0, 120.0, 73.5, 91.0, 155.0, 129.5, 167.5, 60.0, 180.0, 65.0, 112.5, 87.5, 51.5, 51.0, 62.5, 100.0, 85.0, 122.0, 66.5, 70.5, 138.5, 107.5, 120.5, 81.0, 103.5, 107.5, 162.0, 68.5, 110.5, 81.0, 130.0, 115.5, 80.5, 43.0, 140.0, 120.0, 66.5, 94.5, 119.0, 25.0, 13.5, 194.5, 71.5, 105.5, 74.0, 62.5, 65.5, 161.5, 72.5, 139.0, 136.5, 74.5, 80.5, 75.5, 143.5, 101.0, 92.0, 76.5, 140.5, 116.5, 232.5, 120.5, 82.0, 84.5, 153.0, 127.0, 85.5, 76.5, 128.0, 91.5, 134.5, 164.5, 93.5, 44.0, 149.5, 65.5, 109.0, 177.0, 107.0, 154.5, 113.5, 124.5, 143.5, 113.5, 101.5, 73.0, 80.5, 110.5, 114.0, 139.5, 145.5, 87.0, 100.5, 147.0, 110.5, 49.0, 94.0, 123.5, 84.5, 71.0, 73.0, 101.0, 181.0, 109.5, 184.5, 165.0, 61.0, 205.0, 59.5, 103.5, 62.5, 63.0, 66.0, 94.5, 75.5, 87.0, 140.0, 86.0, 116.5, 154.5, 87.0, 48.5, 80.0, 21.5, 52.5, 173.0, 68.5, 172.0, 114.5, 95.0, 69.5, 64.5, 111.5, 97.5, 154.5, 124.0, 95.0, 128.5, 194.0, 104.5, 31.5, 85.5, 50.0, 113.0, 90.5, 153.0, 123.5, 47.0, 64.0, 162.0, 137.0, 98.0, 115.0, 133.5, 99.0, 54.0, 109.0, 109.0, 139.5, 254.0, 125.0, 106.5, 73.0, 81.0, 27.5, 99.5, 45.5, 54.0, 122.5, 37.5, 53.5, 140.0, 77.5, 26.5, 117.5, 70.5, 70.0, 61.5, 80.0, 79.5, 168.0, 90.0, 120.0, 138.5, 111.5, 68.5, 84.5, 102.5, 73.5, 93.5, 127.5, 72.0, 129.5, 47.0, 65.0, 60.0, 167.5, 65.0, 94.0, 87.5, 97.0, 112.5, 91.5, 51.5, 114.5, 115.0, 74.0, 51.0, 100.0, 121.0, 121.5, 62.5, 117.5, 122.0, 85.0, 60.5, 180.0, 70.5, 118.5, 66.5, 107.5, 138.5, 81.0, 58.5, 107.5, 120.5, 63.5, 103.5, 107.0, 105.5, 83.0, 162.0, 68.5, 110.5, 115.5, 87.5, 80.5, 43.0, 140.0, 172.0, 120.0, 66.5, 100.0, 94.5, 221.5, 119.0, 95.5, 194.5, 25.0, 13.5, 173.0, 105.5, 71.5, 74.0, 62.5, 65.5, 85.0, 147.5, 161.5, 81.0, 72.5, 139.0, 136.5, 83.0, 121.0, 74.5, 85.5, 80.5, 167.5, 107.5, 44.5, 107.5, 132.5, 69.5, 98.5, 80.5, 37.0, 99.0, 96.5, 53.0, 103.0, 139.5, 67.0, 62.5, 92.0, 66.0, 94.5, 114.0, 75.5, 96.0, 87.0, 86.0, 116.5, 154.5, 48.5, 87.0, 80.0, 21.5, 173.0, 52.5, 68.5, 95.0, 69.5, 107.0, 112.0, 96.5, 111.5, 154.5, 95.0, 97.5, 128.5, 124.0, 194.0, 31.5, 50.0, 104.5, 69.5, 121.0, 85.5, 113.0, 103.0, 90.5, 153.0, 106.5, 130.0, 123.5, 86.5, 64.0, 47.0, 162.0, 140.0, 89.0, 98.0, 137.0, 99.0, 54.0, 109.0, 109.0, 139.5, 254.0, 125.0, 106.5, 27.5, 73.0, 81.0, 128.5, 99.5, 92.0, 45.5, 122.5, 37.5, 54.0, 53.5, 140.0, 77.5, 26.5, 117.5, 70.5, 61.5, 80.0, 70.0, 120.0, 90.0, 111.0, 138.5, 68.5, 87.5, 111.5, 84.5, 102.5, 73.5, 127.5, 93.5]","[254.0, 232.5, 225.0, 205.0]",,,,
List the year the 3 oldest companies that have job listings were founded.,Find the years when the three oldest companies with job listings were founded.,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Filter out any rows where 'Founded' is not available or is NaN
    valid_founded_years = dataset[dataset['Founded'].notna()]['Founded']
    
    # Sort the founded years in ascending order to get the oldest companies first
    oldest_companies = valid_founded_years.sort_values().head(3)
    
    # Convert the result to a list of integers
    answer = oldest_companies.tolist()
    
    return answer
",list of (int16),"[-1, -1, -1]","[1744, 1781, 1781]",,,,
Which are the highest 3 ratings given?,What are the top 3 highest ratings in the dataset?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
top_ratings = dataset[""Rating""].nlargest(3).tolist()
return top_ratings",list of (float64),"[5.0, 5.0, 5.0]","[5.0, 5.0, 5.0]",,,,
List the average salaries of the 6 most recent companies.,What are the average salaries for the six most recently founded companies?,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Sort the dataset by the 'Founded' column in descending order to get the most recently founded companies first
    sorted_dataset = dataset.sort_values(by='Founded', ascending=False)
    
    # Select the top 6 rows (most recently founded companies)
    top_6_companies = sorted_dataset.head(6)
    
    # Get the average salary for each of these companies
    avg_salaries = top_6_companies['avg_salary'].tolist()
    
    return avg_salaries
",list of (float64),"[88.5, 78.0, 124.5, 225.0, 110.0, 20.5]","[78.0, 88.5, 110.0, 40.5, 132.5, 20.5]",,,,
Are there any authors in the dataset who have more followers than people they are following?,,,,ERROR,True,,,,
Is there any tweet in the dataset that has more replies<gx:number> than retweets<gx:number>?,,,,ERROR,True,,,,
Are there any verified users who have tweeted in a language other than English?,,,,ERROR,True,,,,
Does the dataset contain any tweets that include image links?,,,,ERROR,True,,,,
How many unique authors are present in the dataset?,,,,ERROR,1,,,,
What is the highest number of retweets<gx:number> a single tweet has received?,,,,ERROR,117386,,,,
What is the average number of favorites per tweet?,,,,ERROR,5081.805590000000,,,,
What's the total number of tweets from verified users?,,,,ERROR,3220,,,,
Which author has the most tweets in the dataset?,,,,ERROR,3131144855,,,,
Which language is most commonly used in the tweets?,,,,ERROR,en,,,,
What is the most common source of tweets?,,"def answer_question(dataset, datasetTableSchema, question, expectedAnswerType):
    # Your code here
    pass",string,,"<a href=""http://twitter.com/download/iphone"" rel=""nofollow"">Twitter for iPhone</a>",,,,
"Which type of tweet (e.g., original, retweet, quote) is most common in the dataset?",,,,ERROR,original,,,,
Who are the top three authors (by ID) with the most followers?,,,,ERROR,"[3131144855, 3131144855, 3131144855]",,,,
What are the top five most frequently mentioned names in the tweets?,,,,ERROR,"['G7', 'foreignoffice', 'UN', 'Conservatives', 'COP26']",,,,
List the top four most commonly used languages in the tweets.,,,,ERROR,"['en', 'und', 'fr', 'es']",,,,
What are the highest three numbers of followers count present in the dataset?,,,,ERROR,"[3543402, 3543402, 3543402]",,,,
What are the bottom four numbers of favorites count?,,,,ERROR,"[7, 7, 8, 9]",,,,
List the top six numbers of retweets.,,,,ERROR,"[117386, 53527, 35698, 31449, 24824, 19982]",,,,
What are the bottom five numbers of replies?,,,,ERROR,"[2, 2, 3, 3, 4]",,,,
